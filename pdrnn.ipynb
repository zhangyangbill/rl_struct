{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "#from tensorflow.python.client import device_lib\n",
    "#print device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pdrnn import general_logpmf, pmf_entropy\n",
    "from StochasticDilateNet import StochasticDilateNet\n",
    "from scipy.stats import bernoulli\n",
    "import hdf5storage as hdst\n",
    "from time import clock\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=False)\n",
    "from subset_data import subset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequence(T, batch_size = 64):\n",
    "    head = np.random.randint(1, 8, size=(10,batch_size,1))\n",
    "    body = np.full([T-1,batch_size,1], 8)\n",
    "    tail = np.full([11,batch_size,1], 9)\n",
    "    return np.concatenate((head, body, tail), axis=0)\n",
    "\n",
    "seq =  make_sequence(T=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, target_train = mnist.train.next_batch(500)\n",
    "tiny_mnist = subset_data(inputs_train, target_train)\n",
    "\n",
    "#X, Y = mnist.train.next_batch(batch_size)\n",
    "def make_noisy_mnist(X, Y, T):\n",
    "    X = np.expand_dims(np.transpose(X), axis=2)\n",
    "    noisy = np.random.uniform(size=(T-784,X.shape[1],1))\n",
    "    return (np.concatenate((X, noisy), axis=0), Y[np.newaxis,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs_train, target_train = make_noisy_mnist(1000, batch_size=64)\n",
    "inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hdst.savemat('/mnt/hdd1/kqian3/rl_struct/seq',{'seq':seq})\n",
    "data = hdst.loadmat('/mnt/hdd1/kqian3/rl_struct/seq')\n",
    "seq = data['seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "support = [[1,197],[1,296],[1,444],[1,666],[1,1000]]\n",
    "n_layers = len(support)\n",
    "hidden_structs = [20]*n_layers\n",
    "lambda_b = 0.9\n",
    "model = StochasticDilateNet(hidden_structs,\n",
    "                            support,\n",
    "                            n_layers=n_layers,\n",
    "                            n_classes=10,\n",
    "                            n_evaluate=1,\n",
    "                            input_dims=1,\n",
    "                            cell_type=\"RNN\")\n",
    "# define session\n",
    "sess_config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                             log_device_placement=False,\n",
    "                             intra_op_parallelism_threads=20,\n",
    "                             inter_op_parallelism_threads=4)\n",
    "sess_config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.struct_train_ops[3] = tf.no_op('stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'NoOp_1' type=NoOp>,\n",
       " <tf.Operation 'Adam_2' type=NoOp>,\n",
       " <tf.Operation 'Adam_3' type=NoOp>,\n",
       " <tf.Operation 'stop' type=NoOp>,\n",
       " <tf.Operation 'Adam_5' type=NoOp>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.struct_train_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf   0. -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      "  -inf -inf -inf -inf -inf -inf]]\n",
      "[5.283203, 5.6903586, 6.0958247, 6.50129, nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.941647\n"
     ]
    }
   ],
   "source": [
    "X, Y = mnist.train.next_batch(64)\n",
    "inputs_test, target_test = make_noisy_mnist(X, Y, 1000)\n",
    "feed_dict = {d: r for d, r in zip(model.selections, [5, 238, 43, 72, 72])}  \n",
    "feed_dict[model.inputs] = inputs_test\n",
    "feed_dict[model.labels] = target_test\n",
    "masks = [np.full((1,support[i][1]),-np.inf) for i in xrange(n_layers)]\n",
    "masks[4][0,100] = 0.0\n",
    "log_prob = general_logpmf(100,masks[4])\n",
    "entropy = pmf_entropy(masks[4])\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print sess.run(log_prob)\n",
    "    print sess.run(tf.nn.softmax(masks[4]))\n",
    "    \n",
    "    print sess.run(model.struct_vars[4], \n",
    "                   feed_dict={model.struct_vars[4]:masks[4]})\n",
    "    \n",
    "    print sess.run(model.entropy,\n",
    "                   feed_dict={model.struct_vars[4]:masks[4]})\n",
    "  \n",
    "    a = clock()\n",
    "    for _ in range(100):\n",
    "        sess.run(model.struct_train_ops, feed_dict=feed_dict)\n",
    "    print clock()-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.98\n",
      "0.96040004\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "x = tf.get_variable('input', dtype=tf.float32, initializer=tf.constant(1.0))\n",
    "y = x * x\n",
    "y_ = tf.placeholder(shape=(), dtype=tf.float32)\n",
    "fixed = tf.placeholder_with_default(False, shape=())\n",
    "z = tf.where(tf.fill(y.get_shape(), fixed), y_, y)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "minimize = optimizer.minimize(z)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print sess.run(x)\n",
    "    \n",
    "    sess.run(minimize)\n",
    "    \n",
    "    print sess.run(x)\n",
    "    \n",
    "    sess.run(minimize, feed_dict={fixed:False, y_:1.0})\n",
    "\n",
    "    \n",
    "    print sess.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "X, Y = mnist.validation.next_batch(batch_size)\n",
    "inputs_valid, target_valid = make_noisy_mnist(X, Y, 2000, batch_size)\n",
    "feed_dict = {d: r for d, r in zip(model.dilations, [231,130])}  \n",
    "feed_dict[model.inputs] = inputs_valid\n",
    "feed_dict[model.labels] = target_valid\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    start = clock()\n",
    "    print sess.run(model.logits, feed_dict=feed_dict).shape\n",
    "    print sess.run(model.labels, feed_dict=feed_dict).shape\n",
    "    print clock()-start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_enqueue(x, lst, L=10):\n",
    "    if len(lst) == L:\n",
    "        lst.pop(0)\n",
    "        lst.append(x)\n",
    "    else:\n",
    "        lst.append(x)\n",
    "        \n",
    "def find_closest_element(myNumber, lst):\n",
    "    a = min(lst[::-1], key=lambda x:abs(x-myNumber))\n",
    "    k = len(lst)-1-lst[::-1].index(a)\n",
    "    return k\n",
    "\n",
    "def list_enqueue_batch(xs, lsts):\n",
    "    for i, x in enumerate(xs):\n",
    "        list_enqueue(x, lsts[i])\n",
    "        \n",
    "def find_closest_element_batch(xs, lsts):\n",
    "    ks = []\n",
    "    for i, x in enumerate(xs):\n",
    "        k = find_closest_element(x, lsts[i])\n",
    "        ks.append(k)\n",
    "    return ks   \n",
    "\n",
    "def restore_layers(savers, ks, logdir, bottom=0):\n",
    "    for i in xrange(bottom, n_layers):\n",
    "        path = \"{}model-{}\".format(logdir, \n",
    "                                   history_steps[ks[i]])\n",
    "        savers[i].restore(sess, path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# [5, 238, 43, 72]\n",
    "# [5, 266, 45, 63]\n",
    "# [8, 268, 125, 136]\n",
    "# [8, 39, 51, 115]\n",
    "sess = tf.Session(config=sess_config)\n",
    "# initialize all the parameters\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "feed_dict = {d: r for d, r in zip(model.dilations, [5, 238, 43, 72])}  \n",
    "\n",
    "batch_size = 64\n",
    "losses = []\n",
    "\n",
    "start = clock()\n",
    "for step in range(3000):\n",
    "    X, Y = mnist.train.next_batch(batch_size)\n",
    "    inputs_test, target_test = make_noisy_mnist(X, Y, 1000, batch_size)\n",
    "    feed_dict[model.inputs] = inputs_test\n",
    "    feed_dict[model.labels] = target_test\n",
    "        \n",
    "    _, loss_value, accuracy = sess.run([model.weights_train_op, model.loss_for_w, model.accuracy], \n",
    "                                       feed_dict=feed_dict)\n",
    "    loss_value = sess.run(model.loss_for_w, feed_dict=feed_dict)\n",
    "    assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "    losses.append(loss_value)\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        #model.saver_for_w.save(sess, \"{}model\".format('/mnt/hdd1/kqian3/rl_struct/'), global_step=step)\n",
    "        print('Step {}, loss = {}, accuracy = {}'.format(step, loss_value, accuracy))\n",
    "print clock()-start        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_1 = np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l_1)\n",
    "plt.plot(l_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=sess_config) as sess:\n",
    "    # initialize all the parameters\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    model.saver_for_w.restore(sess, \"{}model-100\".format('/mnt/hdd1/kqian3/rl_struct/'))\n",
    "    \n",
    "    \n",
    "    for step in range(1000):\n",
    "        #seq = bernoulli.rvs(0.5, size=(100,32,1))\n",
    "        feed_dict = {model.inputs: seq,\n",
    "                     model.labels: seq[0,:,0]}     \n",
    "        \n",
    "        if np.mod(step, 10) < 5:\n",
    "            _, loss_value = sess.run([model.weights_train_op, model.loss_for_w], \n",
    "                                     feed_dict=feed_dict)\n",
    "        else:\n",
    "            sess.run(model.struct_train_op, feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        if step == 0:\n",
    "            sess.run(tf.assign(model.b, loss_value))\n",
    "        else:\n",
    "            sess.run(tf.assign(model.b, (lambda_b*model.b+(1-lambda_b)*loss_value)))\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            struct_params, rates, b, accuracy = \\\n",
    "            sess.run([model.struct_vars, model.rates, model.b, model.accuracy],\n",
    "                    feed_dict=feed_dict)\n",
    "            print('Step {}, struct params {},\\n Rates {}, b = {}, accuracy = {}'.format(\n",
    "                step, struct_params, rates, b, accuracy))\n",
    "            \n",
    "            #sess.run(model.struct_clip_op, feed_dict={model.inputs: seq})\n",
    "            #struct_params = sess.run(model.struct_vars)\n",
    "            #\n",
    "            #print('After clip, struct params {}'.format(struct_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "sess = tf.Session(config=sess_config)\n",
    "# initialize all the parameters\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "num_w_op = 10\n",
    "history_rates = [[] for _ in xrange(n_layers)]\n",
    "history_steps = []\n",
    "\n",
    "for step in xrange(100000):\n",
    "    seq =  make_sequence(T=2000)      \n",
    "    \n",
    "    if step % num_w_op == 0:\n",
    "        \n",
    "        if step != 0:\n",
    "            loss_ = sess.run(model.loss_for_w, feed_dict=feed_dict)\n",
    "            if step == num_w_op:\n",
    "                sess.run(tf.assign(model.b, loss_))\n",
    "            else:\n",
    "                sess.run(tf.assign(model.b, (lambda_b*model.b+(1-lambda_b)*loss_)))\n",
    "                \n",
    "            model.saver_for_w.save(sess, \n",
    "                                   \"{}model\".format('/mnt/hdd1/kqian3/rl_struct/'), \n",
    "                                   global_step=step)\n",
    "            list_enqueue_batch(rates, history_rates)\n",
    "            list_enqueue(step, history_steps)\n",
    "                        \n",
    "            \n",
    "        if step >= 2*num_w_op:\n",
    "            sess.run(model.struct_train_op, feed_dict=feed_dict)    \n",
    "            \n",
    "            \n",
    "        picks = sess.run(model.picks)\n",
    "        rates = sess.run(model.dilations, feed_dict={s: p for s, p in zip(model.selections, picks)})\n",
    "        if len(history_steps) >= 1:\n",
    "            ks = find_closest_element_batch(rates, history_rates)\n",
    "            print 'Step {}, Draw = {},\\n history_rates = {},\\n Replace = {}'.format(step, rates, history_rates, ks)\n",
    "            restore_layers(model.savers, ks)\n",
    "        \n",
    "        \n",
    "    feed_dict = {d: r for d, r in zip(model.selections, picks)}    \n",
    "    feed_dict[model.inputs] = seq\n",
    "    feed_dict[model.labels] = seq[0:10,:,0]\n",
    "        \n",
    "    sess.run(model.weights_train_op, feed_dict=feed_dict)\n",
    "    \n",
    "    if step % num_w_op == num_w_op-1:\n",
    "        struct_vars, b, loss_value, accuracy = \\\n",
    "        sess.run([model.struct_vars, \n",
    "                  model.b, model.loss_for_w, model.accuracy],\n",
    "                 feed_dict=feed_dict)\n",
    "        print('Step {}, Rates {}, b = {}, loss = {}, accuracy = {}\\n'.format(\n",
    "            step, rates, b, loss_value, accuracy))\n",
    "        if step % 100 == 99:\n",
    "            plt.plot(struct_vars[0][0])\n",
    "            plt.show()\n",
    "            plt.plot(struct_vars[1][0])\n",
    "            plt.show()\n",
    "        if loss_value < 1e-2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf = sess.run(tf.nn.softmax(model.struct_vars[-1]), feed_dict=feed_dict_w)\n",
    "hdst.savemat('/mnt/hdd1/kqian3/rl_struct/pmf1',{'pmf':pmf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 9, Rates [111, 177, 13, 252, 570], b = 0.0, loss = 2.16296339035, accuracy = 0.1875\n",
      " Entropy = [5.283203, 5.6903586, 6.0958247, 6.50129, 6.907755]\n",
      "\n",
      "Step 10, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[111], [177], [13], [252], [570]],\n",
      " Replace = [0, 0, 0, 0, 0]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-10\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-10\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-10\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-10\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-10\n",
      "\n",
      " Step 19, Rates [1, 1, 1, 1, 1], b = 2.16296339035, loss = 2.31535315514, accuracy = 0.140625\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 20, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[111, 1], [177, 1], [13, 1], [252, 1], [570, 1]],\n",
      " Replace = [1, 1, 1, 1, 1]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-20\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-20\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-20\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-20\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-20\n",
      "\n",
      " Step 29, Rates [1, 1, 1, 1, 1], b = 2.17820215225, loss = 2.39249372482, accuracy = 0.125\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 30, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[111, 1, 1], [177, 1, 1], [13, 1, 1], [252, 1, 1], [570, 1, 1]],\n",
      " Replace = [2, 2, 2, 2, 2]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-30\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-30\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-30\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-30\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-30\n",
      "\n",
      " Step 39, Rates [1, 1, 1, 1, 1], b = 2.19963121414, loss = 2.31146550179, accuracy = 0.140625\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 40, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[111, 1, 1, 1], [177, 1, 1, 1], [13, 1, 1, 1], [252, 1, 1, 1], [570, 1, 1, 1]],\n",
      " Replace = [3, 3, 3, 3, 3]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-40\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-40\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-40\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-40\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-40\n",
      "\n",
      " Step 49, Rates [1, 1, 1, 1, 1], b = 2.21081447601, loss = 2.30081582069, accuracy = 0.0625\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 50, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[111, 1, 1, 1, 1], [177, 1, 1, 1, 1], [13, 1, 1, 1, 1], [252, 1, 1, 1, 1], [570, 1, 1, 1, 1]],\n",
      " Replace = [4, 4, 4, 4, 4]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-50\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-50\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-50\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-50\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-50\n",
      "\n",
      " Step 59, Rates [1, 1, 1, 1, 1], b = 2.21981453896, loss = 2.3499007225, accuracy = 0.078125\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 60, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[111, 1, 1, 1, 1, 1], [177, 1, 1, 1, 1, 1], [13, 1, 1, 1, 1, 1], [252, 1, 1, 1, 1, 1], [570, 1, 1, 1, 1, 1]],\n",
      " Replace = [5, 5, 5, 5, 5]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-60\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-60\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-60\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-60\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-60\n",
      "\n",
      " Step 69, Rates [1, 1, 1, 1, 1], b = 2.23282313347, loss = 2.30956530571, accuracy = 0.140625\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 70, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[111, 1, 1, 1, 1, 1, 1], [177, 1, 1, 1, 1, 1, 1], [13, 1, 1, 1, 1, 1, 1], [252, 1, 1, 1, 1, 1, 1], [570, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [6, 6, 6, 6, 6]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-70\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-70\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-70\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-70\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-70\n",
      "\n",
      " Step 79, Rates [1, 1, 1, 1, 1], b = 2.24049735069, loss = 2.28285312653, accuracy = 0.171875\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 80, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[111, 1, 1, 1, 1, 1, 1, 1], [177, 1, 1, 1, 1, 1, 1, 1], [13, 1, 1, 1, 1, 1, 1, 1], [252, 1, 1, 1, 1, 1, 1, 1], [570, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [7, 7, 7, 7, 7]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-80\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-80\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-80\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-80\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-80\n",
      "\n",
      " Step 89, Rates [1, 1, 1, 1, 1], b = 2.24473285675, loss = 2.33725476265, accuracy = 0.15625\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 90, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[111, 1, 1, 1, 1, 1, 1, 1, 1], [177, 1, 1, 1, 1, 1, 1, 1, 1], [13, 1, 1, 1, 1, 1, 1, 1, 1], [252, 1, 1, 1, 1, 1, 1, 1, 1], [570, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [8, 8, 8, 8, 8]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-90\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-90\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-90\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-90\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-90\n",
      "\n",
      " Step 99, Rates [1, 1, 1, 1, 1], b = 2.25398516655, loss = 2.31611299515, accuracy = 0.078125\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 100, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[111, 1, 1, 1, 1, 1, 1, 1, 1, 1], [177, 1, 1, 1, 1, 1, 1, 1, 1, 1], [13, 1, 1, 1, 1, 1, 1, 1, 1, 1], [252, 1, 1, 1, 1, 1, 1, 1, 1, 1], [570, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-100\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-100\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-100\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-100\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-100\n",
      "\n",
      " Step 109, Rates [1, 1, 1, 1, 1], b = 2.26019787788, loss = 2.29324936867, accuracy = 0.109375\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 110, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-110\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-110\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-110\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-110\n",
      "\n",
      " Step 119, Rates [1, 1, 1, 1, 1], b = 2.26350307465, loss = 2.31544446945, accuracy = 0.09375\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 120, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-120\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-120\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-120\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-120\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-120\n",
      "\n",
      " Step 129, Rates [1, 1, 1, 1, 1], b = 2.26869726181, loss = 2.29253816605, accuracy = 0.125\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 130, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-130\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-130\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-130\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-130\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-130\n",
      "\n",
      " Step 139, Rates [1, 1, 1, 1, 1], b = 2.27108120918, loss = 2.27709102631, accuracy = 0.140625\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 140, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-140\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-140\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-140\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-140\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-140\n",
      "\n",
      " Step 149, Rates [1, 1, 1, 1, 1], b = 2.271682024, loss = 2.30656790733, accuracy = 0.078125\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 150, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-150\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-150\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-150\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-150\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-150\n",
      "\n",
      " Step 159, Rates [1, 1, 1, 1, 1], b = 2.27517056465, loss = 2.3199441433, accuracy = 0.09375\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 160, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-160\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-160\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-160\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-160\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-160\n",
      "\n",
      " Step 169, Rates [1, 1, 1, 1, 1], b = 2.27964782715, loss = 2.28444814682, accuracy = 0.15625\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 170, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-170\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-170\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-170\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-170\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-170\n",
      "\n",
      " Step 179, Rates [1, 1, 1, 1, 1], b = 2.28012776375, loss = 2.30011534691, accuracy = 0.125\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 180, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-180\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-180\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-180\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-180\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-180\n",
      "\n",
      " Step 189, Rates [1, 1, 1, 1, 1], b = 2.2821264267, loss = 2.3189804554, accuracy = 0.078125\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 190, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-190\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-190\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-190\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-190\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-190\n",
      "\n",
      " Step 199, Rates [1, 1, 1, 1, 1], b = 2.28581190109, loss = 2.27847719193, accuracy = 0.140625\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 200, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-200\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-200\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-200\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-200\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-200\n",
      "\n",
      " Step 209, Rates [1, 1, 1, 1, 1], b = 2.28507852554, loss = 2.29746317863, accuracy = 0.09375\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 210, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-210\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-210\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-210\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-210\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-210\n",
      "\n",
      " Step 219, Rates [1, 1, 1, 1, 1], b = 2.28631687164, loss = 2.31641364098, accuracy = 0.046875\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 220, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-220\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-220\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-220\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-220\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-220\n",
      "\n",
      " Step 229, Rates [1, 1, 1, 1, 1], b = 2.28932642937, loss = 2.29322123528, accuracy = 0.078125\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 230, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-230\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-230\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-230\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-230\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-230\n",
      "\n",
      " Step 239, Rates [1, 1, 1, 1, 1], b = 2.28971600533, loss = 2.30536055565, accuracy = 0.125\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 240, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-240\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-240\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-240\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-240\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-240\n",
      "\n",
      " Step 249, Rates [1, 1, 1, 1, 1], b = 2.29128026962, loss = 2.31148004532, accuracy = 0.140625\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 250, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-250\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-250\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-250\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-250\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-250\n",
      "\n",
      " Step 259, Rates [1, 1, 1, 1, 1], b = 2.29330015182, loss = 2.28726601601, accuracy = 0.125\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 260, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-260\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-260\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-260\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-260\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-260\n",
      "\n",
      " Step 269, Rates [1, 1, 1, 1, 1], b = 2.2926967144, loss = 2.32119059563, accuracy = 0.09375\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 270, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-270\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-270\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-270\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-270\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-270\n",
      "\n",
      " Step 279, Rates [1, 1, 1, 1, 1], b = 2.29554605484, loss = 2.28500843048, accuracy = 0.109375\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 280, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-280\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-280\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-280\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-280\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-280\n",
      "\n",
      " Step 289, Rates [1, 1, 1, 1, 1], b = 2.29449224472, loss = 2.26225399971, accuracy = 0.1875\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 290, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-290\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-290\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-290\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-290\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-290\n",
      "\n",
      " Step 299, Rates [1, 1, 1, 1, 1], b = 2.29126834869, loss = 2.30436491966, accuracy = 0.15625\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 300, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-300\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-300\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-300\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-300\n",
      "\n",
      " Step 309, Rates [1, 1, 1, 1, 1], b = 2.29257798195, loss = 2.32418489456, accuracy = 0.171875\n",
      " Entropy = [nan, nan, nan, nan, nan]\n",
      "\n",
      "Step 310, Draw = [1, 1, 1, 1, 1],\n",
      " history_rates = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      " Replace = [9, 9, 9, 9, 9]\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-310\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-310\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-310\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-310\n",
      "INFO:tensorflow:Restoring parameters from /mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/model-310\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-170aa80eeab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_train_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum_w_op\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_w_op\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/logos/envs/prob_dropout/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/logos/envs/prob_dropout/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/logos/envs/prob_dropout/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/logos/envs/prob_dropout/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/logos/envs/prob_dropout/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# noisy mnist\n",
    "\n",
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "sess = tf.Session(config=sess_config)\n",
    "# initialize all the parameters\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "logdir = '/mnt/hdd1/kqian3/rl_struct/noisy_mnist_5_1000/'\n",
    "bottom = 0\n",
    "num_w_op = 10\n",
    "history_rates = [[] for _ in xrange(n_layers)]\n",
    "history_steps = []\n",
    "feed_dict = {}\n",
    "\n",
    "masks = [np.full((1,support[i][1]),-np.inf) for i in xrange(n_layers)]\n",
    "\n",
    "for step in xrange(1000000):\n",
    "    X, Y = mnist.train.next_batch(64)\n",
    "    inputs_train, target_train = make_noisy_mnist(X, Y, 1000)    \n",
    "    \n",
    "    if step % num_w_op == 0:\n",
    "        if step != 0:\n",
    "            #X, Y = mnist.validation.next_batch(64)\n",
    "            #inputs_valid, target_valid = make_noisy_mnist(X, Y, 2000, 64)\n",
    "            #feed_dict[model.inputs] = inputs_valid\n",
    "            #feed_dict[model.labels] = target_valid\n",
    "            \n",
    "            loss_ = sess.run(model.loss_for_w, feed_dict=feed_dict)\n",
    "            if step == num_w_op:\n",
    "                sess.run(tf.assign(model.b, loss_))\n",
    "            else:\n",
    "                sess.run(tf.assign(model.b, (lambda_b*model.b+(1-lambda_b)*loss_)))\n",
    "                \n",
    "            model.saver_for_w.save(sess, \n",
    "                                     \"{}model\".format(logdir), \n",
    "                                     global_step=step)\n",
    "            list_enqueue_batch(rates, history_rates)\n",
    "            list_enqueue(step, history_steps)\n",
    "                        \n",
    "            \n",
    "        if step >= 2*num_w_op:\n",
    "            sess.run(model.struct_train_ops, feed_dict=feed_dict)    \n",
    "            \n",
    "            \n",
    "        picks = sess.run(model.picks, feed_dict=feed_dict)\n",
    "        rates = sess.run(model.dilations, feed_dict={s: p for s, p in zip(model.selections, picks)})\n",
    "        if len(history_steps) >= 1:\n",
    "            ks = find_closest_element_batch(rates, history_rates)\n",
    "            print 'Step {}, Draw = {},\\n history_rates = {},\\n Replace = {}'.format(step, rates, history_rates, ks)\n",
    "            restore_layers(model.savers, ks, logdir, bottom)\n",
    "            \n",
    "        \n",
    "    for d, r in zip(model.selections, picks):\n",
    "        feed_dict[d] = r\n",
    "    feed_dict[model.inputs] = inputs_train\n",
    "    feed_dict[model.labels] = target_train\n",
    "        \n",
    "    sess.run(model.weights_train_op, feed_dict=feed_dict)\n",
    "    \n",
    "    if step % num_w_op == num_w_op-1:\n",
    "        #feed_dict[model.inputs] = inputs_valid\n",
    "        #feed_dict[model.labels] = target_valid\n",
    "        struct_vars, entropy, b, loss_value, accuracy = \\\n",
    "        sess.run([model.struct_vars, model.entropy,\n",
    "                  model.b, model.loss_for_w, model.accuracy],\n",
    "                 feed_dict=feed_dict)\n",
    "        print('\\n Step {}, Rates {}, b = {}, loss = {}, accuracy = {}\\n Entropy = {}\\n'.format(\n",
    "            step, rates, b, loss_value, accuracy, entropy))\n",
    "        # check entropy\n",
    "        for l in xrange(n_layers):\n",
    "            if entropy[l] > 1.5 and not np.isnan(entropy[l]):\n",
    "                model.struct_train_ops[l] = tf.no_op('Stop')\n",
    "                masks[l][0,np.argmax(struct_vars[l])] = 0.0\n",
    "                feed_dict[model.struct_vars[l]] = masks[l]\n",
    "        # save logits        \n",
    "        if step % 100 == 99:\n",
    "            for k in xrange(bottom, n_layers):\n",
    "                hdst.savemat('{}pmf_{}_{}'.format(logdir,step,k),\n",
    "                             {'pmf':struct_vars[k][0]})\n",
    "        if loss_value < 1e-6:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loss = []\n",
    "for rate in range(0,525,5):\n",
    "    if rate == 0: rate = 1\n",
    "    with tf.Session(config=sess_config) as sess:\n",
    "        # initialize all the parameters\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for step in range(500):\n",
    "            feed_dict = {model.inputs: seq,\n",
    "                         model.labels: np.transpose(seq[0:10,:,0],[1,0]),\n",
    "                         model.rates[-1]: rate}\n",
    "            sess.run(model.weights_train_op, feed_dict=feed_dict)\n",
    "                    \n",
    "        loss_value = sess.run(model.loss_for_w, feed_dict=feed_dict)\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "        #loss.append(loss_value)\n",
    "        print 'Rate = {}, loss = {}'.format(rate, loss_value)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(loss))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdst.savemat('/mnt/hdd1/kqian3/rl_struct/loss1_1',{'loss':np.array(loss)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print feed_dict_w[model.rates[-1]]\n",
    "feed_dict_w[model.b] = 1.3\n",
    "with tf.Session() as sess:\n",
    "    # initialize all the parameters\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    model.saver_for_w.restore(sess, \"{}model-100\".format('/mnt/hdd1/kqian3/rl_struct/'))\n",
    "    \n",
    "    print sess.run(model.loss_per_example, feed_dict = feed_dict_w)\n",
    "    print sess.run(model.b, feed_dict = feed_dict_w)\n",
    "    print sess.run(model.struct_param, feed_dict = feed_dict_w)\n",
    "    \n",
    "    print sess.run(tf.gradients(model.loss_for_pi, model.struct_param), feed_dict = feed_dict_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(tf.gradients(model.loss_for_pi, model.struct_vars[1]), feed_dict = feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print model.sess.run(model.loss_per_example, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "paddings = tf.constant([[0, 0], [0, 3]])\n",
    "with tf.Session():\n",
    "    print tf.pad(t, paddings, constant_values=0.0).eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "init_params=[(1.0,0.5),(2.0,2.0)]\n",
    "dilations = []\n",
    "for l in xrange(2):\n",
    "    with tf.variable_scope('struct_layer_{}'.format(l)):\n",
    "        mu = tf.get_variable('mu', initializer=tf.constant(init_params[l][0]))\n",
    "        sigma = tf.get_variable('sigma', initializer=tf.constant(init_params[l][1]))\n",
    "                \n",
    "    rates = tf.range(tf.ceil(tf.maximum(mu-sigma,0.5)), \n",
    "                     tf.ceil(tf.minimum(mu+sigma,20)))\n",
    "    probs = triangular_pmf(rates, mu, sigma, 20)\n",
    "    probs = tf.expand_dims(probs, 0)\n",
    "    idx = tf.multinomial(tf.log(probs), 1)\n",
    "    rates = tf.cast(rates, tf.int32)\n",
    "    dilations.append(rates[idx[0][0]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print sess.run(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([1])\n",
    "b = a;\n",
    "c = b;\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print sess.run(c, feed_dict = {b: [2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdrnn import drnn_classification, _contruct_cells\n",
    "from pdrnn import dRNN, multi_dRNN_with_dilations\n",
    "# build the network\n",
    "tf.reset_default_graph()\n",
    "\n",
    "dilations = []\n",
    "for l in xrange(3):\n",
    "    #d = tf.placeholder_with_default(tf.constant(l+1), [])\n",
    "    d = tf.placeholder(tf.int32, [])\n",
    "    dilations.append(d)\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, shape = [None, None, 1], name = 'inputs')\n",
    "hidden_structs=[4]*3\n",
    "\n",
    "# construct a list of cells\n",
    "cells = _contruct_cells(hidden_structs=hidden_structs, cell_type='LSTM')\n",
    "\n",
    "logits = multi_dRNN_with_dilations(cells, inputs, hidden_structs, dilations)\n",
    "#logits = dRNN(cells[0], inputs, dilations[0], 1, scope='default')\n",
    "\n",
    "#logits = drnn_classification(x=inputs,\n",
    "#                               hidden_structs=hidden_structs,\n",
    "#                               dilations=dilations,\n",
    "#                               n_classes=2,\n",
    "#                               input_dims=1,\n",
    "#                               cell_type='RNN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pred = sess.run(logits, feed_dict={inputs: np.random.uniform(size=[100,32,1])})\n",
    "    print pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdrnn import _construct_cells\n",
    "tf.reset_default_graph()\n",
    "empty_inputs = [tf.zeros([1,3]) for _ in xrange(3)]\n",
    "    \n",
    "cell = tf.nn.rnn_cell.BasicLSTMCell(10)\n",
    "outputs, _ = tf.nn.static_rnn(cell, \n",
    "                              empty_inputs, \n",
    "                              dtype=tf.float32,\n",
    "                              scope='policy_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=tf.stack(outputs, axis=1)\n",
    "logpmfs = tf.layers.conv1d(inputs=h[:,1:,:],\n",
    "                               filters=1000,\n",
    "                               kernel_size=1,\n",
    "                               kernel_initializer=tf.zeros_initializer(),\n",
    "                               bias_initializer=tf.constant_initializer(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logpmfs[:,1,:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
