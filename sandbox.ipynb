{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from StochasticDropoutNet import StochasticDropoutNet\n",
    "from util import xor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = StochasticDropoutNet(min_dropout_rate = 0.001, max_dropout_rate = 0.001, num_weight_train_steps = 64)\n",
    "model = StochasticDropoutNet(min_dropout_rate = 0.001, \n",
    "                             max_dropout_rate = 0.001,\n",
    "                             num_weight_train_steps = 32,\n",
    "                             valid_batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, weight train batch: 0, step:0, loss before: 0.713041782379, loss after: 0.707847356796.\n",
      "Epoch:0, weight train batch: 0, step:1, loss before: 0.911797046661, loss after: 0.905594468117.\n",
      "Epoch:0, weight train batch: 0, step:2, loss before: 1.04302442074, loss after: 1.03586018085.\n",
      "Epoch:0, weight train batch: 0, step:3, loss before: 1.15347242355, loss after: 1.14597606659.\n",
      "Epoch:0, weight train batch: 0, step:4, loss before: 1.1003755331, loss after: 1.09301662445.\n",
      "Epoch:0, weight train batch: 0, step:5, loss before: 0.943966567516, loss after: 0.938011109829.\n",
      "Epoch:0, weight train batch: 0, step:6, loss before: 0.999662637711, loss after: 0.993598878384.\n",
      "Epoch:0, weight train batch: 0, step:7, loss before: 0.87547314167, loss after: 0.870490312576.\n",
      "Epoch:0, weight train batch: 0, step:8, loss before: 1.06927800179, loss after: 1.06280708313.\n",
      "Epoch:0, weight train batch: 0, step:9, loss before: 0.882185995579, loss after: 0.877114415169.\n",
      "Epoch:0, weight train batch: 0, step:10, loss before: 0.87322729826, loss after: 0.868028700352.\n",
      "Epoch:0, weight train batch: 0, step:11, loss before: 0.880653858185, loss after: 0.875284433365.\n",
      "Epoch:0, weight train batch: 0, step:12, loss before: 0.804705500603, loss after: 0.799939930439.\n",
      "Epoch:0, weight train batch: 0, step:13, loss before: 0.876107275486, loss after: 0.870595932007.\n",
      "Epoch:0, weight train batch: 0, step:14, loss before: 0.915931105614, loss after: 0.910370826721.\n",
      "Epoch:0, weight train batch: 0, step:15, loss before: 0.977271556854, loss after: 0.971466481686.\n",
      "Epoch:0, weight train batch: 0, step:16, loss before: 0.780483067036, loss after: 0.77575480938.\n",
      "Epoch:0, weight train batch: 0, step:17, loss before: 1.05742287636, loss after: 1.05116415024.\n",
      "Epoch:0, weight train batch: 0, step:18, loss before: 0.893250524998, loss after: 0.888442099094.\n",
      "Epoch:0, weight train batch: 0, step:19, loss before: 0.7613915205, loss after: 0.756838202477.\n",
      "Epoch:0, weight train batch: 0, step:20, loss before: 0.938976943493, loss after: 0.933709859848.\n",
      "Epoch:0, weight train batch: 0, step:21, loss before: 0.966358959675, loss after: 0.961334466934.\n",
      "Epoch:0, weight train batch: 0, step:22, loss before: 0.841376066208, loss after: 0.836993813515.\n",
      "Epoch:0, weight train batch: 0, step:23, loss before: 0.935467123985, loss after: 0.93067073822.\n",
      "Epoch:0, weight train batch: 0, step:24, loss before: 0.755680680275, loss after: 0.751261174679.\n",
      "Epoch:0, weight train batch: 0, step:25, loss before: 0.945731282234, loss after: 0.94036847353.\n",
      "Epoch:0, weight train batch: 0, step:26, loss before: 0.775860786438, loss after: 0.771600902081.\n",
      "Epoch:0, weight train batch: 0, step:27, loss before: 0.781470835209, loss after: 0.77704501152.\n",
      "Epoch:0, weight train batch: 0, step:28, loss before: 0.787960529327, loss after: 0.783575296402.\n",
      "Epoch:0, weight train batch: 0, step:29, loss before: 0.898085474968, loss after: 0.89298593998.\n",
      "Epoch:0, weight train batch: 0, step:30, loss before: 0.929712533951, loss after: 0.924458146095.\n",
      "Epoch:0, weight train batch: 0, step:31, loss before: 0.839302420616, loss after: 0.834736824036.\n",
      "Epoch:0, weight train batch: 1, step:0, loss before: 0.941176772118, loss after: 0.93508118391.\n",
      "Epoch:0, weight train batch: 1, step:1, loss before: 0.759987950325, loss after: 0.754845678806.\n",
      "Epoch:0, weight train batch: 1, step:2, loss before: 0.753965377808, loss after: 0.748989880085.\n",
      "Epoch:0, weight train batch: 1, step:3, loss before: 0.837804019451, loss after: 0.83208668232.\n",
      "Epoch:0, weight train batch: 1, step:4, loss before: 0.882639169693, loss after: 0.878009676933.\n",
      "Epoch:0, weight train batch: 1, step:5, loss before: 0.923818826675, loss after: 0.91898560524.\n",
      "Epoch:0, weight train batch: 1, step:6, loss before: 0.890985012054, loss after: 0.886165857315.\n",
      "Epoch:0, weight train batch: 1, step:7, loss before: 0.802850008011, loss after: 0.798007667065.\n",
      "Epoch:0, weight train batch: 1, step:8, loss before: 0.772183179855, loss after: 0.767836391926.\n",
      "Epoch:0, weight train batch: 1, step:9, loss before: 0.803032517433, loss after: 0.798380970955.\n",
      "Epoch:0, weight train batch: 1, step:10, loss before: 0.85290825367, loss after: 0.847875416279.\n",
      "Epoch:0, weight train batch: 1, step:11, loss before: 0.856569707394, loss after: 0.850892424583.\n",
      "Epoch:0, weight train batch: 1, step:12, loss before: 0.757124304771, loss after: 0.752658307552.\n",
      "Epoch:0, weight train batch: 1, step:13, loss before: 0.722157239914, loss after: 0.71788752079.\n",
      "Epoch:0, weight train batch: 1, step:14, loss before: 0.79148042202, loss after: 0.786436200142.\n",
      "Epoch:0, weight train batch: 1, step:15, loss before: 0.714548945427, loss after: 0.710267901421.\n",
      "Epoch:0, weight train batch: 1, step:16, loss before: 0.851972699165, loss after: 0.84737443924.\n",
      "Epoch:0, weight train batch: 1, step:17, loss before: 0.818873047829, loss after: 0.813782036304.\n",
      "Epoch:0, weight train batch: 1, step:18, loss before: 0.744680047035, loss after: 0.740218997002.\n",
      "Epoch:0, weight train batch: 1, step:19, loss before: 0.769124388695, loss after: 0.764711380005.\n",
      "Epoch:0, weight train batch: 1, step:20, loss before: 0.754378020763, loss after: 0.749896228313.\n",
      "Epoch:0, weight train batch: 1, step:21, loss before: 0.8678201437, loss after: 0.86259251833.\n",
      "Epoch:0, weight train batch: 1, step:22, loss before: 0.765348553658, loss after: 0.761009216309.\n",
      "Epoch:0, weight train batch: 1, step:23, loss before: 0.64208483696, loss after: 0.638490498066.\n",
      "Epoch:0, weight train batch: 1, step:24, loss before: 0.597347378731, loss after: 0.5934035182.\n",
      "Epoch:0, weight train batch: 1, step:25, loss before: 0.570518493652, loss after: 0.5671697855.\n",
      "Epoch:0, weight train batch: 1, step:26, loss before: 0.68555778265, loss after: 0.681258440018.\n",
      "Epoch:0, weight train batch: 1, step:27, loss before: 0.710287690163, loss after: 0.706181287766.\n",
      "Epoch:0, weight train batch: 1, step:28, loss before: 0.592151999474, loss after: 0.588295161724.\n",
      "Epoch:0, weight train batch: 1, step:29, loss before: 0.652482628822, loss after: 0.648405969143.\n",
      "Epoch:0, weight train batch: 1, step:30, loss before: 0.698793292046, loss after: 0.693859696388.\n",
      "Epoch:0, weight train batch: 1, step:31, loss before: 0.741341233253, loss after: 0.737080454826.\n",
      "Epoch:0, weight train batch: 2, step:0, loss before: 0.682749927044, loss after: 0.678756892681.\n",
      "Epoch:0, weight train batch: 2, step:1, loss before: 0.702419281006, loss after: 0.69839656353.\n",
      "Epoch:0, weight train batch: 2, step:2, loss before: 0.65159368515, loss after: 0.646484375.\n",
      "Epoch:0, weight train batch: 2, step:3, loss before: 0.638011932373, loss after: 0.633845925331.\n",
      "Epoch:0, weight train batch: 2, step:4, loss before: 0.740353226662, loss after: 0.736166894436.\n",
      "Epoch:0, weight train batch: 2, step:5, loss before: 0.604391694069, loss after: 0.601146697998.\n",
      "Epoch:0, weight train batch: 2, step:6, loss before: 0.679886102676, loss after: 0.676220715046.\n",
      "Epoch:0, weight train batch: 2, step:7, loss before: 0.628628015518, loss after: 0.624927520752.\n",
      "Epoch:0, weight train batch: 2, step:8, loss before: 0.618322253227, loss after: 0.614613771439.\n",
      "Epoch:0, weight train batch: 2, step:9, loss before: 0.629420340061, loss after: 0.62524920702.\n",
      "Epoch:0, weight train batch: 2, step:10, loss before: 0.624132990837, loss after: 0.620282590389.\n",
      "Epoch:0, weight train batch: 2, step:11, loss before: 0.788019180298, loss after: 0.783304333687.\n",
      "Epoch:0, weight train batch: 2, step:12, loss before: 0.66796040535, loss after: 0.663935661316.\n",
      "Epoch:0, weight train batch: 2, step:13, loss before: 0.53673940897, loss after: 0.532935321331.\n",
      "Epoch:0, weight train batch: 2, step:14, loss before: 0.582640767097, loss after: 0.579325318336.\n",
      "Epoch:0, weight train batch: 2, step:15, loss before: 0.573683142662, loss after: 0.569784283638.\n",
      "Epoch:0, weight train batch: 2, step:16, loss before: 0.665349602699, loss after: 0.661967396736.\n",
      "Epoch:0, weight train batch: 2, step:17, loss before: 0.593892931938, loss after: 0.590428054333.\n",
      "Epoch:0, weight train batch: 2, step:18, loss before: 0.706139802933, loss after: 0.70239174366.\n",
      "Epoch:0, weight train batch: 2, step:19, loss before: 0.558505296707, loss after: 0.554963707924.\n",
      "Epoch:0, weight train batch: 2, step:20, loss before: 0.620381951332, loss after: 0.616553008556.\n",
      "Epoch:0, weight train batch: 2, step:21, loss before: 0.551355719566, loss after: 0.547860145569.\n",
      "Epoch:0, weight train batch: 2, step:22, loss before: 0.573761582375, loss after: 0.57059943676.\n",
      "Epoch:0, weight train batch: 2, step:23, loss before: 0.64138096571, loss after: 0.637607753277.\n",
      "Epoch:0, weight train batch: 2, step:24, loss before: 0.534891486168, loss after: 0.531549155712.\n",
      "Epoch:0, weight train batch: 2, step:25, loss before: 0.516427755356, loss after: 0.512832164764.\n",
      "Epoch:0, weight train batch: 2, step:26, loss before: 0.613391458988, loss after: 0.609632730484.\n",
      "Epoch:0, weight train batch: 2, step:27, loss before: 0.590451538563, loss after: 0.586628079414.\n",
      "Epoch:0, weight train batch: 2, step:28, loss before: 0.598185002804, loss after: 0.594189763069.\n",
      "Epoch:0, weight train batch: 2, step:29, loss before: 0.567753553391, loss after: 0.564274907112.\n",
      "Epoch:0, weight train batch: 2, step:30, loss before: 0.584401428699, loss after: 0.580933570862.\n",
      "Epoch:0, weight train batch: 2, step:31, loss before: 0.49907797575, loss after: 0.495967686176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, weight train batch: 3, step:0, loss before: 0.60911488533, loss after: 0.605535030365.\n",
      "Epoch:0, weight train batch: 3, step:1, loss before: 0.580479800701, loss after: 0.577144145966.\n",
      "Epoch:0, weight train batch: 3, step:2, loss before: 0.417099952698, loss after: 0.413886249065.\n",
      "Epoch:0, weight train batch: 3, step:3, loss before: 0.653076052666, loss after: 0.648624002934.\n",
      "Epoch:0, weight train batch: 3, step:4, loss before: 0.512839198112, loss after: 0.509360074997.\n",
      "Epoch:0, weight train batch: 3, step:5, loss before: 0.623608410358, loss after: 0.619855582714.\n",
      "Epoch:0, weight train batch: 3, step:6, loss before: 0.489282786846, loss after: 0.48604080081.\n",
      "Epoch:0, weight train batch: 3, step:7, loss before: 0.558459401131, loss after: 0.554847002029.\n",
      "Epoch:0, weight train batch: 3, step:8, loss before: 0.528888404369, loss after: 0.52534031868.\n",
      "Epoch:0, weight train batch: 3, step:9, loss before: 0.513733506203, loss after: 0.509608209133.\n",
      "Epoch:0, weight train batch: 3, step:10, loss before: 0.442857146263, loss after: 0.440104305744.\n",
      "Epoch:0, weight train batch: 3, step:11, loss before: 0.55447191, loss after: 0.550775289536.\n",
      "Epoch:0, weight train batch: 3, step:12, loss before: 0.523817002773, loss after: 0.520388841629.\n",
      "Epoch:0, weight train batch: 3, step:13, loss before: 0.413891673088, loss after: 0.410492688417.\n",
      "Epoch:0, weight train batch: 3, step:14, loss before: 0.480118662119, loss after: 0.476961731911.\n",
      "Epoch:0, weight train batch: 3, step:15, loss before: 0.497848510742, loss after: 0.494357705116.\n",
      "Epoch:0, weight train batch: 3, step:16, loss before: 0.503758072853, loss after: 0.499853432178.\n",
      "Epoch:0, weight train batch: 3, step:17, loss before: 0.56819498539, loss after: 0.564217507839.\n",
      "Epoch:0, weight train batch: 3, step:18, loss before: 0.454850822687, loss after: 0.451983451843.\n",
      "Epoch:0, weight train batch: 3, step:19, loss before: 0.462833166122, loss after: 0.45992821455.\n",
      "Epoch:0, weight train batch: 3, step:20, loss before: 0.433097302914, loss after: 0.430256158113.\n",
      "Epoch:0, weight train batch: 3, step:21, loss before: 0.495771199465, loss after: 0.492476224899.\n",
      "Epoch:0, weight train batch: 3, step:22, loss before: 0.505864024162, loss after: 0.502535223961.\n",
      "Epoch:0, weight train batch: 3, step:23, loss before: 0.503032684326, loss after: 0.500005125999.\n",
      "Epoch:0, weight train batch: 3, step:24, loss before: 0.535095095634, loss after: 0.531881034374.\n",
      "Epoch:0, weight train batch: 3, step:25, loss before: 0.5820748806, loss after: 0.578487873077.\n",
      "Epoch:0, weight train batch: 3, step:26, loss before: 0.515385091305, loss after: 0.511861562729.\n",
      "Epoch:0, weight train batch: 3, step:27, loss before: 0.442853331566, loss after: 0.439851164818.\n",
      "Epoch:0, weight train batch: 3, step:28, loss before: 0.46004113555, loss after: 0.457002043724.\n",
      "Epoch:0, weight train batch: 3, step:29, loss before: 0.446903377771, loss after: 0.44398868084.\n",
      "Epoch:0, weight train batch: 3, step:30, loss before: 0.493453502655, loss after: 0.490056186914.\n",
      "Epoch:0, weight train batch: 3, step:31, loss before: 0.507444381714, loss after: 0.504053354263.\n",
      "Epoch:0, weight train batch: 4, step:0, loss before: 0.523907423019, loss after: 0.520393908024.\n",
      "Epoch:0, weight train batch: 4, step:1, loss before: 0.454502463341, loss after: 0.451253294945.\n",
      "Epoch:0, weight train batch: 4, step:2, loss before: 0.378370881081, loss after: 0.375672131777.\n",
      "Epoch:0, weight train batch: 4, step:3, loss before: 0.399573743343, loss after: 0.396741330624.\n",
      "Epoch:0, weight train batch: 4, step:4, loss before: 0.503060936928, loss after: 0.499389082193.\n",
      "Epoch:0, weight train batch: 4, step:5, loss before: 0.486197978258, loss after: 0.482616245747.\n",
      "Epoch:0, weight train batch: 4, step:6, loss before: 0.486472994089, loss after: 0.483072400093.\n",
      "Epoch:0, weight train batch: 4, step:7, loss before: 0.457543343306, loss after: 0.454606920481.\n",
      "Epoch:0, weight train batch: 4, step:8, loss before: 0.40304350853, loss after: 0.400191217661.\n",
      "Epoch:0, weight train batch: 4, step:9, loss before: 0.500084519386, loss after: 0.49679633975.\n",
      "Epoch:0, weight train batch: 4, step:10, loss before: 0.406750321388, loss after: 0.404091089964.\n",
      "Epoch:0, weight train batch: 4, step:11, loss before: 0.542135953903, loss after: 0.538232564926.\n",
      "Epoch:0, weight train batch: 4, step:12, loss before: 0.394628226757, loss after: 0.391830295324.\n",
      "Epoch:0, weight train batch: 4, step:13, loss before: 0.4501285851, loss after: 0.446994125843.\n",
      "Epoch:0, weight train batch: 4, step:14, loss before: 0.400332689285, loss after: 0.397568166256.\n",
      "Epoch:0, weight train batch: 4, step:15, loss before: 0.414677381516, loss after: 0.412124872208.\n",
      "Epoch:0, weight train batch: 4, step:16, loss before: 0.400355160236, loss after: 0.397802084684.\n",
      "Epoch:0, weight train batch: 4, step:17, loss before: 0.377305865288, loss after: 0.374638259411.\n",
      "Epoch:0, weight train batch: 4, step:18, loss before: 0.380155920982, loss after: 0.377516806126.\n",
      "Epoch:0, weight train batch: 4, step:19, loss before: 0.316629588604, loss after: 0.314348578453.\n",
      "Epoch:0, weight train batch: 4, step:20, loss before: 0.378296434879, loss after: 0.375498503447.\n",
      "Epoch:0, weight train batch: 4, step:21, loss before: 0.38649815321, loss after: 0.383805274963.\n",
      "Epoch:0, weight train batch: 4, step:22, loss before: 0.398053109646, loss after: 0.395359218121.\n",
      "Epoch:0, weight train batch: 4, step:23, loss before: 0.278297901154, loss after: 0.276199758053.\n",
      "Epoch:0, weight train batch: 4, step:24, loss before: 0.461668491364, loss after: 0.458603680134.\n",
      "Epoch:0, weight train batch: 4, step:25, loss before: 0.337765872478, loss after: 0.335341215134.\n",
      "Epoch:0, weight train batch: 4, step:26, loss before: 0.350852787495, loss after: 0.34818276763.\n",
      "Epoch:0, weight train batch: 4, step:27, loss before: 0.382120490074, loss after: 0.379726886749.\n",
      "Epoch:0, weight train batch: 4, step:28, loss before: 0.379496872425, loss after: 0.376688182354.\n",
      "Epoch:0, weight train batch: 4, step:29, loss before: 0.418345570564, loss after: 0.415368258953.\n",
      "Epoch:0, weight train batch: 4, step:30, loss before: 0.430086493492, loss after: 0.426839411259.\n",
      "Epoch:0, weight train batch: 4, step:31, loss before: 0.359863698483, loss after: 0.357448458672.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:0, struct parameters train batch: 0, loss before: 0.38953268528, loss after: 0.38953268528.\n",
      "Epoch:0, weight train batch: 5, step:0, loss before: 0.35459625721, loss after: 0.351837873459.\n",
      "Epoch:0, weight train batch: 5, step:1, loss before: 0.335484772921, loss after: 0.333102732897.\n",
      "Epoch:0, weight train batch: 5, step:2, loss before: 0.386864840984, loss after: 0.384017348289.\n",
      "Epoch:0, weight train batch: 5, step:3, loss before: 0.344679385424, loss after: 0.342142283916.\n",
      "Epoch:0, weight train batch: 5, step:4, loss before: 0.360439687967, loss after: 0.357511729002.\n",
      "Epoch:0, weight train batch: 5, step:5, loss before: 0.31191393733, loss after: 0.309464812279.\n",
      "Epoch:0, weight train batch: 5, step:6, loss before: 0.334587872028, loss after: 0.331844061613.\n",
      "Epoch:0, weight train batch: 5, step:7, loss before: 0.279459476471, loss after: 0.277455568314.\n",
      "Epoch:0, weight train batch: 5, step:8, loss before: 0.28394138813, loss after: 0.282003939152.\n",
      "Epoch:0, weight train batch: 5, step:9, loss before: 0.346779227257, loss after: 0.344490230083.\n",
      "Epoch:0, weight train batch: 5, step:10, loss before: 0.340832471848, loss after: 0.33837673068.\n",
      "Epoch:0, weight train batch: 5, step:11, loss before: 0.331593036652, loss after: 0.32925838232.\n",
      "Epoch:0, weight train batch: 5, step:12, loss before: 0.281474530697, loss after: 0.279087722301.\n",
      "Epoch:0, weight train batch: 5, step:13, loss before: 0.373319745064, loss after: 0.370456516743.\n",
      "Epoch:0, weight train batch: 5, step:14, loss before: 0.356043934822, loss after: 0.353082209826.\n",
      "Epoch:0, weight train batch: 5, step:15, loss before: 0.276316225529, loss after: 0.274257451296.\n",
      "Epoch:0, weight train batch: 5, step:16, loss before: 0.29894593358, loss after: 0.296677708626.\n",
      "Epoch:0, weight train batch: 5, step:17, loss before: 0.341551959515, loss after: 0.338866233826.\n",
      "Epoch:0, weight train batch: 5, step:18, loss before: 0.227143570781, loss after: 0.225271806121.\n",
      "Epoch:0, weight train batch: 5, step:19, loss before: 0.323082566261, loss after: 0.320764064789.\n",
      "Epoch:0, weight train batch: 5, step:20, loss before: 0.337209373713, loss after: 0.334551930428.\n",
      "Epoch:0, weight train batch: 5, step:21, loss before: 0.26420122385, loss after: 0.262224733829.\n",
      "Epoch:0, weight train batch: 5, step:22, loss before: 0.374871253967, loss after: 0.372435301542.\n",
      "Epoch:0, weight train batch: 5, step:23, loss before: 0.224042713642, loss after: 0.222247183323.\n",
      "Epoch:0, weight train batch: 5, step:24, loss before: 0.342909425497, loss after: 0.340604871511.\n",
      "Epoch:0, weight train batch: 5, step:25, loss before: 0.315097928047, loss after: 0.312758535147.\n",
      "Epoch:0, weight train batch: 5, step:26, loss before: 0.322388201952, loss after: 0.319984823465.\n",
      "Epoch:0, weight train batch: 5, step:27, loss before: 0.242500215769, loss after: 0.240585505962.\n",
      "Epoch:0, weight train batch: 5, step:28, loss before: 0.225549578667, loss after: 0.223882421851.\n",
      "Epoch:0, weight train batch: 5, step:29, loss before: 0.264687001705, loss after: 0.262835264206.\n",
      "Epoch:0, weight train batch: 5, step:30, loss before: 0.226705849171, loss after: 0.224922895432.\n",
      "Epoch:0, weight train batch: 5, step:31, loss before: 0.290863364935, loss after: 0.288678467274.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:0, struct parameters train batch: 1, loss before: 0.287350058556, loss after: 0.286311388016.\n",
      "Epoch:0, weight train batch: 6, step:0, loss before: 0.26775854826, loss after: 0.265517294407.\n",
      "Epoch:0, weight train batch: 6, step:1, loss before: 0.275080859661, loss after: 0.272947907448.\n",
      "Epoch:0, weight train batch: 6, step:2, loss before: 0.334597587585, loss after: 0.3320941329.\n",
      "Epoch:0, weight train batch: 6, step:3, loss before: 0.236023798585, loss after: 0.234122216702.\n",
      "Epoch:0, weight train batch: 6, step:4, loss before: 0.254800826311, loss after: 0.252674967051.\n",
      "Epoch:0, weight train batch: 6, step:5, loss before: 0.269965469837, loss after: 0.268046438694.\n",
      "Epoch:0, weight train batch: 6, step:6, loss before: 0.291533201933, loss after: 0.289510667324.\n",
      "Epoch:0, weight train batch: 6, step:7, loss before: 0.279474139214, loss after: 0.277450948954.\n",
      "Epoch:0, weight train batch: 6, step:8, loss before: 0.289707928896, loss after: 0.287336736917.\n",
      "Epoch:0, weight train batch: 6, step:9, loss before: 0.313356429338, loss after: 0.310898780823.\n",
      "Epoch:0, weight train batch: 6, step:10, loss before: 0.25908434391, loss after: 0.257013678551.\n",
      "Epoch:0, weight train batch: 6, step:11, loss before: 0.237941324711, loss after: 0.236038148403.\n",
      "Epoch:0, weight train batch: 6, step:12, loss before: 0.23990893364, loss after: 0.23801921308.\n",
      "Epoch:0, weight train batch: 6, step:13, loss before: 0.274333953857, loss after: 0.272160351276.\n",
      "Epoch:0, weight train batch: 6, step:14, loss before: 0.2188372612, loss after: 0.216894820333.\n",
      "Epoch:0, weight train batch: 6, step:15, loss before: 0.255065500736, loss after: 0.253151535988.\n",
      "Epoch:0, weight train batch: 6, step:16, loss before: 0.250459730625, loss after: 0.248406141996.\n",
      "Epoch:0, weight train batch: 6, step:17, loss before: 0.271715402603, loss after: 0.269519597292.\n",
      "Epoch:0, weight train batch: 6, step:18, loss before: 0.265797317028, loss after: 0.26374745369.\n",
      "Epoch:0, weight train batch: 6, step:19, loss before: 0.246464192867, loss after: 0.244525238872.\n",
      "Epoch:0, weight train batch: 6, step:20, loss before: 0.297776669264, loss after: 0.295265614986.\n",
      "Epoch:0, weight train batch: 6, step:21, loss before: 0.211169213057, loss after: 0.209475442767.\n",
      "Epoch:0, weight train batch: 6, step:22, loss before: 0.232039049268, loss after: 0.230116099119.\n",
      "Epoch:0, weight train batch: 6, step:23, loss before: 0.200321882963, loss after: 0.19874791801.\n",
      "Epoch:0, weight train batch: 6, step:24, loss before: 0.222439393401, loss after: 0.220602989197.\n",
      "Epoch:0, weight train batch: 6, step:25, loss before: 0.211602285504, loss after: 0.209847673774.\n",
      "Epoch:0, weight train batch: 6, step:26, loss before: 0.237643241882, loss after: 0.235771507025.\n",
      "Epoch:0, weight train batch: 6, step:27, loss before: 0.222621649504, loss after: 0.221021667123.\n",
      "Epoch:0, weight train batch: 6, step:28, loss before: 0.186712563038, loss after: 0.18524646759.\n",
      "Epoch:0, weight train batch: 6, step:29, loss before: 0.247597306967, loss after: 0.245602309704.\n",
      "Epoch:0, weight train batch: 6, step:30, loss before: 0.268365502357, loss after: 0.266003489494.\n",
      "Epoch:0, weight train batch: 6, step:31, loss before: 0.243278309703, loss after: 0.24113753438.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:0, struct parameters train batch: 2, loss before: 0.238243311644, loss after: 0.238289028406.\n",
      "Epoch:0, weight train batch: 7, step:0, loss before: 0.248495042324, loss after: 0.246288746595.\n",
      "Epoch:0, weight train batch: 7, step:1, loss before: 0.221262931824, loss after: 0.219503670931.\n",
      "Epoch:0, weight train batch: 7, step:2, loss before: 0.229217454791, loss after: 0.227536946535.\n",
      "Epoch:0, weight train batch: 7, step:3, loss before: 0.252485245466, loss after: 0.250339597464.\n",
      "Epoch:0, weight train batch: 7, step:4, loss before: 0.248238861561, loss after: 0.246114403009.\n",
      "Epoch:0, weight train batch: 7, step:5, loss before: 0.232979491353, loss after: 0.230907171965.\n",
      "Epoch:0, weight train batch: 7, step:6, loss before: 0.229397714138, loss after: 0.227710872889.\n",
      "Epoch:0, weight train batch: 7, step:7, loss before: 0.234573036432, loss after: 0.232403576374.\n",
      "Epoch:0, weight train batch: 7, step:8, loss before: 0.221419647336, loss after: 0.219427466393.\n",
      "Epoch:0, weight train batch: 7, step:9, loss before: 0.152626827359, loss after: 0.151680529118.\n",
      "Epoch:0, weight train batch: 7, step:10, loss before: 0.225098341703, loss after: 0.223119407892.\n",
      "Epoch:0, weight train batch: 7, step:11, loss before: 0.188213944435, loss after: 0.18663290143.\n",
      "Epoch:0, weight train batch: 7, step:12, loss before: 0.186830505729, loss after: 0.185213699937.\n",
      "Epoch:0, weight train batch: 7, step:13, loss before: 0.169922292233, loss after: 0.168684512377.\n",
      "Epoch:0, weight train batch: 7, step:14, loss before: 0.186764955521, loss after: 0.18518742919.\n",
      "Epoch:0, weight train batch: 7, step:15, loss before: 0.230113312602, loss after: 0.228691756725.\n",
      "Epoch:0, weight train batch: 7, step:16, loss before: 0.175622418523, loss after: 0.174155279994.\n",
      "Epoch:0, weight train batch: 7, step:17, loss before: 0.151496380568, loss after: 0.150272101164.\n",
      "Epoch:0, weight train batch: 7, step:18, loss before: 0.194392025471, loss after: 0.192924529314.\n",
      "Epoch:0, weight train batch: 7, step:19, loss before: 0.187553808093, loss after: 0.186117887497.\n",
      "Epoch:0, weight train batch: 7, step:20, loss before: 0.155881002545, loss after: 0.154644787312.\n",
      "Epoch:0, weight train batch: 7, step:21, loss before: 0.207491248846, loss after: 0.205918878317.\n",
      "Epoch:0, weight train batch: 7, step:22, loss before: 0.176634520292, loss after: 0.175143361092.\n",
      "Epoch:0, weight train batch: 7, step:23, loss before: 0.186614438891, loss after: 0.185029536486.\n",
      "Epoch:0, weight train batch: 7, step:24, loss before: 0.167543545365, loss after: 0.166142508388.\n",
      "Epoch:0, weight train batch: 7, step:25, loss before: 0.185701772571, loss after: 0.184232935309.\n",
      "Epoch:0, weight train batch: 7, step:26, loss before: 0.225281521678, loss after: 0.223643869162.\n",
      "Epoch:0, weight train batch: 7, step:27, loss before: 0.21123072505, loss after: 0.209446966648.\n",
      "Epoch:0, weight train batch: 7, step:28, loss before: 0.156419724226, loss after: 0.155248880386.\n",
      "Epoch:0, weight train batch: 7, step:29, loss before: 0.156885325909, loss after: 0.155679613352.\n",
      "Epoch:0, weight train batch: 7, step:30, loss before: 0.16545984149, loss after: 0.164090886712.\n",
      "Epoch:0, weight train batch: 7, step:31, loss before: 0.158654555678, loss after: 0.157350212336.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:0, struct parameters train batch: 3, loss before: 0.161972165108, loss after: 0.161949843168.\n",
      "Epoch:0, weight train batch: 8, step:0, loss before: 0.140078336, loss after: 0.138978645205.\n",
      "Epoch:0, weight train batch: 8, step:1, loss before: 0.130873292685, loss after: 0.129875317216.\n",
      "Epoch:0, weight train batch: 8, step:2, loss before: 0.156167030334, loss after: 0.154959276319.\n",
      "Epoch:0, weight train batch: 8, step:3, loss before: 0.195701554418, loss after: 0.194156870246.\n",
      "Epoch:0, weight train batch: 8, step:4, loss before: 0.191041886806, loss after: 0.189610674977.\n",
      "Epoch:0, weight train batch: 8, step:5, loss before: 0.193823099136, loss after: 0.192274391651.\n",
      "Epoch:0, weight train batch: 8, step:6, loss before: 0.152520313859, loss after: 0.151260778308.\n",
      "Epoch:0, weight train batch: 8, step:7, loss before: 0.159879043698, loss after: 0.158544480801.\n",
      "Epoch:0, weight train batch: 8, step:8, loss before: 0.142939403653, loss after: 0.14181381464.\n",
      "Epoch:0, weight train batch: 8, step:9, loss before: 0.192261993885, loss after: 0.190676629543.\n",
      "Epoch:0, weight train batch: 8, step:10, loss before: 0.194503366947, loss after: 0.192886382341.\n",
      "Epoch:0, weight train batch: 8, step:11, loss before: 0.148308157921, loss after: 0.147173717618.\n",
      "Epoch:0, weight train batch: 8, step:12, loss before: 0.15897539258, loss after: 0.157702803612.\n",
      "Epoch:0, weight train batch: 8, step:13, loss before: 0.178601503372, loss after: 0.177133381367.\n",
      "Epoch:0, weight train batch: 8, step:14, loss before: 0.181733772159, loss after: 0.180211663246.\n",
      "Epoch:0, weight train batch: 8, step:15, loss before: 0.17098736763, loss after: 0.169453367591.\n",
      "Epoch:0, weight train batch: 8, step:16, loss before: 0.156425863504, loss after: 0.155039161444.\n",
      "Epoch:0, weight train batch: 8, step:17, loss before: 0.155100375414, loss after: 0.153725236654.\n",
      "Epoch:0, weight train batch: 8, step:18, loss before: 0.142611041665, loss after: 0.141345083714.\n",
      "Epoch:0, weight train batch: 8, step:19, loss before: 0.127422615886, loss after: 0.126285985112.\n",
      "Epoch:0, weight train batch: 8, step:20, loss before: 0.156833276153, loss after: 0.155546560884.\n",
      "Epoch:0, weight train batch: 8, step:21, loss before: 0.15432587266, loss after: 0.153022184968.\n",
      "Epoch:0, weight train batch: 8, step:22, loss before: 0.165821611881, loss after: 0.164451494813.\n",
      "Epoch:0, weight train batch: 8, step:23, loss before: 0.124681614339, loss after: 0.123611062765.\n",
      "Epoch:0, weight train batch: 8, step:24, loss before: 0.165289759636, loss after: 0.163797661662.\n",
      "Epoch:0, weight train batch: 8, step:25, loss before: 0.124685779214, loss after: 0.123583339155.\n",
      "Epoch:0, weight train batch: 8, step:26, loss before: 0.131801828742, loss after: 0.130716457963.\n",
      "Epoch:0, weight train batch: 8, step:27, loss before: 0.139254748821, loss after: 0.138073712587.\n",
      "Epoch:0, weight train batch: 8, step:28, loss before: 0.136556684971, loss after: 0.13539493084.\n",
      "Epoch:0, weight train batch: 8, step:29, loss before: 0.108378790319, loss after: 0.1075091362.\n",
      "Epoch:0, weight train batch: 8, step:30, loss before: 0.129014536738, loss after: 0.12791274488.\n",
      "Epoch:0, weight train batch: 8, step:31, loss before: 0.124517098069, loss after: 0.123545750976.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:0, struct parameters train batch: 4, loss before: 0.127134680748, loss after: 0.12718847394.\n",
      "Epoch:0, weight train batch: 9, step:0, loss before: 0.0930177569389, loss after: 0.092306047678.\n",
      "Epoch:0, weight train batch: 9, step:1, loss before: 0.108092024922, loss after: 0.107149027288.\n",
      "Epoch:0, weight train batch: 9, step:2, loss before: 0.122135706246, loss after: 0.12119691819.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, weight train batch: 9, step:3, loss before: 0.0990065559745, loss after: 0.0982153266668.\n",
      "Epoch:0, weight train batch: 9, step:4, loss before: 0.110268473625, loss after: 0.10937140882.\n",
      "Epoch:0, weight train batch: 9, step:5, loss before: 0.116987504065, loss after: 0.11610930413.\n",
      "Epoch:0, weight train batch: 9, step:6, loss before: 0.145770654082, loss after: 0.144696503878.\n",
      "Epoch:0, weight train batch: 9, step:7, loss before: 0.125864237547, loss after: 0.12490862608.\n",
      "Epoch:0, weight train batch: 9, step:8, loss before: 0.100979551673, loss after: 0.10016182065.\n",
      "Epoch:0, weight train batch: 9, step:9, loss before: 0.167567580938, loss after: 0.166238754988.\n",
      "Epoch:0, weight train batch: 9, step:10, loss before: 0.116101630032, loss after: 0.115140497684.\n",
      "Epoch:0, weight train batch: 9, step:11, loss before: 0.117645263672, loss after: 0.116742923856.\n",
      "Epoch:0, weight train batch: 9, step:12, loss before: 0.107724748552, loss after: 0.10690279305.\n",
      "Epoch:0, weight train batch: 9, step:13, loss before: 0.116630636156, loss after: 0.115772023797.\n",
      "Epoch:0, weight train batch: 9, step:14, loss before: 0.12667003274, loss after: 0.125681385398.\n",
      "Epoch:0, weight train batch: 9, step:15, loss before: 0.128327012062, loss after: 0.127332776785.\n",
      "Epoch:0, weight train batch: 9, step:16, loss before: 0.114096730947, loss after: 0.113146312535.\n",
      "Epoch:0, weight train batch: 9, step:17, loss before: 0.112932786345, loss after: 0.111994430423.\n",
      "Epoch:0, weight train batch: 9, step:18, loss before: 0.0980818942189, loss after: 0.0973136425018.\n",
      "Epoch:0, weight train batch: 9, step:19, loss before: 0.122428551316, loss after: 0.121463268995.\n",
      "Epoch:0, weight train batch: 9, step:20, loss before: 0.11713706702, loss after: 0.116249442101.\n",
      "Epoch:0, weight train batch: 9, step:21, loss before: 0.0945117250085, loss after: 0.0937901437283.\n",
      "Epoch:0, weight train batch: 9, step:22, loss before: 0.147261768579, loss after: 0.146043002605.\n",
      "Epoch:0, weight train batch: 9, step:23, loss before: 0.0970088839531, loss after: 0.0962298810482.\n",
      "Epoch:0, weight train batch: 9, step:24, loss before: 0.116977788508, loss after: 0.116038091481.\n",
      "Epoch:0, weight train batch: 9, step:25, loss before: 0.121595181525, loss after: 0.120581328869.\n",
      "Epoch:0, weight train batch: 9, step:26, loss before: 0.0935591012239, loss after: 0.0927985906601.\n",
      "Epoch:0, weight train batch: 9, step:27, loss before: 0.0846636071801, loss after: 0.083990432322.\n",
      "Epoch:0, weight train batch: 9, step:28, loss before: 0.124362319708, loss after: 0.123349092901.\n",
      "Epoch:0, weight train batch: 9, step:29, loss before: 0.0958238840103, loss after: 0.0950392261147.\n",
      "Epoch:0, weight train batch: 9, step:30, loss before: 0.120893031359, loss after: 0.119902685285.\n",
      "Epoch:0, weight train batch: 9, step:31, loss before: 0.101586520672, loss after: 0.100745968521.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:0, struct parameters train batch: 5, loss before: 0.0944629013538, loss after: 0.0943150445819.\n",
      "Epoch:0, weight train batch: 10, step:0, loss before: 0.101758375764, loss after: 0.100983373821.\n",
      "Epoch:0, weight train batch: 10, step:1, loss before: 0.098581880331, loss after: 0.0977928414941.\n",
      "Epoch:0, weight train batch: 10, step:2, loss before: 0.0949717089534, loss after: 0.0942010655999.\n",
      "Epoch:0, weight train batch: 10, step:3, loss before: 0.0910460799932, loss after: 0.0903510004282.\n",
      "Epoch:0, weight train batch: 10, step:4, loss before: 0.100400209427, loss after: 0.0996483713388.\n",
      "Epoch:0, weight train batch: 10, step:5, loss before: 0.107033655047, loss after: 0.10618583858.\n",
      "Epoch:0, weight train batch: 10, step:6, loss before: 0.10339551419, loss after: 0.102546028793.\n",
      "Epoch:0, weight train batch: 10, step:7, loss before: 0.0824701115489, loss after: 0.0818440839648.\n",
      "Epoch:0, weight train batch: 10, step:8, loss before: 0.107128560543, loss after: 0.106268972158.\n",
      "Epoch:0, weight train batch: 10, step:9, loss before: 0.089845508337, loss after: 0.0891252532601.\n",
      "Epoch:0, weight train batch: 10, step:10, loss before: 0.0834845155478, loss after: 0.0828178226948.\n",
      "Epoch:0, weight train batch: 10, step:11, loss before: 0.0882232040167, loss after: 0.087529078126.\n",
      "Epoch:0, weight train batch: 10, step:12, loss before: 0.0916147530079, loss after: 0.0909377634525.\n",
      "Epoch:0, weight train batch: 10, step:13, loss before: 0.0735381394625, loss after: 0.0729923546314.\n",
      "Epoch:0, weight train batch: 10, step:14, loss before: 0.0902560427785, loss after: 0.0895887091756.\n",
      "Epoch:0, weight train batch: 10, step:15, loss before: 0.112383618951, loss after: 0.111503303051.\n",
      "Epoch:0, weight train batch: 10, step:16, loss before: 0.0981510356069, loss after: 0.0973446816206.\n",
      "Epoch:0, weight train batch: 10, step:17, loss before: 0.103943400085, loss after: 0.103051066399.\n",
      "Epoch:0, weight train batch: 10, step:18, loss before: 0.114704802632, loss after: 0.113760232925.\n",
      "Epoch:0, weight train batch: 10, step:19, loss before: 0.10087145865, loss after: 0.100061774254.\n",
      "Epoch:0, weight train batch: 10, step:20, loss before: 0.0912110507488, loss after: 0.0904830694199.\n",
      "Epoch:0, weight train batch: 10, step:21, loss before: 0.106786973774, loss after: 0.105865955353.\n",
      "Epoch:0, weight train batch: 10, step:22, loss before: 0.113319918513, loss after: 0.112275347114.\n",
      "Epoch:0, weight train batch: 10, step:23, loss before: 0.0857528075576, loss after: 0.0850400477648.\n",
      "Epoch:0, weight train batch: 10, step:24, loss before: 0.103960350156, loss after: 0.102999977767.\n",
      "Epoch:0, weight train batch: 10, step:25, loss before: 0.0718315392733, loss after: 0.071234151721.\n",
      "Epoch:0, weight train batch: 10, step:26, loss before: 0.0842782631516, loss after: 0.0835463926196.\n",
      "Epoch:0, weight train batch: 10, step:27, loss before: 0.0683759003878, loss after: 0.0678411871195.\n",
      "Epoch:0, weight train batch: 10, step:28, loss before: 0.073715724051, loss after: 0.0731408298016.\n",
      "Epoch:0, weight train batch: 10, step:29, loss before: 0.0719009786844, loss after: 0.0713341087103.\n",
      "Epoch:0, weight train batch: 10, step:30, loss before: 0.0824754312634, loss after: 0.0818062722683.\n",
      "Epoch:0, weight train batch: 10, step:31, loss before: 0.092192992568, loss after: 0.0914974808693.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:0, struct parameters train batch: 6, loss before: 0.0796683430672, loss after: 0.0781326591969.\n",
      "Epoch:0, weight train batch: 11, step:0, loss before: 0.0837078019977, loss after: 0.0830579400063.\n",
      "Epoch:0, weight train batch: 11, step:1, loss before: 0.0843063890934, loss after: 0.0836597532034.\n",
      "Epoch:0, weight train batch: 11, step:2, loss before: 0.0888609662652, loss after: 0.0881125107408.\n",
      "Epoch:0, weight train batch: 11, step:3, loss before: 0.0818956568837, loss after: 0.0811966061592.\n",
      "Epoch:0, weight train batch: 11, step:4, loss before: 0.0806712284684, loss after: 0.0800030529499.\n",
      "Epoch:0, weight train batch: 11, step:5, loss before: 0.0695679634809, loss after: 0.0690339654684.\n",
      "Epoch:0, weight train batch: 11, step:6, loss before: 0.0838214606047, loss after: 0.083167642355.\n",
      "Epoch:0, weight train batch: 11, step:7, loss before: 0.0717737823725, loss after: 0.071234613657.\n",
      "Epoch:0, weight train batch: 11, step:8, loss before: 0.0694365724921, loss after: 0.068911999464.\n",
      "Epoch:0, weight train batch: 11, step:9, loss before: 0.0988753736019, loss after: 0.0980282574892.\n",
      "Epoch:0, weight train batch: 11, step:10, loss before: 0.0729691982269, loss after: 0.0723735541105.\n",
      "Epoch:0, weight train batch: 11, step:11, loss before: 0.07832236588, loss after: 0.0776575356722.\n",
      "Epoch:0, weight train batch: 11, step:12, loss before: 0.0648170039058, loss after: 0.0642991214991.\n",
      "Epoch:0, weight train batch: 11, step:13, loss before: 0.104406796396, loss after: 0.10346531868.\n",
      "Epoch:0, weight train batch: 11, step:14, loss before: 0.0685742124915, loss after: 0.0679964572191.\n",
      "Epoch:0, weight train batch: 11, step:15, loss before: 0.0714469701052, loss after: 0.070891559124.\n",
      "Epoch:0, weight train batch: 11, step:16, loss before: 0.0640210956335, loss after: 0.0635259598494.\n",
      "Epoch:0, weight train batch: 11, step:17, loss before: 0.0686824545264, loss after: 0.0681515932083.\n",
      "Epoch:0, weight train batch: 11, step:18, loss before: 0.0682242512703, loss after: 0.0676574185491.\n",
      "Epoch:0, weight train batch: 11, step:19, loss before: 0.0560727678239, loss after: 0.0556209906936.\n",
      "Epoch:0, weight train batch: 11, step:20, loss before: 0.0508030354977, loss after: 0.0504434667528.\n",
      "Epoch:0, weight train batch: 11, step:21, loss before: 0.0624510012567, loss after: 0.0620056428015.\n",
      "Epoch:0, weight train batch: 11, step:22, loss before: 0.059299685061, loss after: 0.0588934011757.\n",
      "Epoch:0, weight train batch: 11, step:23, loss before: 0.0599379017949, loss after: 0.059526078403.\n",
      "Epoch:0, weight train batch: 11, step:24, loss before: 0.0582485720515, loss after: 0.0578344129026.\n",
      "Epoch:0, weight train batch: 11, step:25, loss before: 0.0612153448164, loss after: 0.060783341527.\n",
      "Epoch:0, weight train batch: 11, step:26, loss before: 0.0651824399829, loss after: 0.0646975338459.\n",
      "Epoch:0, weight train batch: 11, step:27, loss before: 0.0717749521136, loss after: 0.071281477809.\n",
      "Epoch:0, weight train batch: 11, step:28, loss before: 0.0520129539073, loss after: 0.0516612753272.\n",
      "Epoch:0, weight train batch: 11, step:29, loss before: 0.0617426671088, loss after: 0.0613252297044.\n",
      "Epoch:0, weight train batch: 11, step:30, loss before: 0.0738441348076, loss after: 0.0733356773853.\n",
      "Epoch:0, weight train batch: 11, step:31, loss before: 0.0491565205157, loss after: 0.0488119795918.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, struct parameters train batch: 7, loss before: 0.0798564255238, loss after: 0.0621404275298.\n",
      "Epoch:0, weight train batch: 12, step:0, loss before: 0.0573305115104, loss after: 0.0569249764085.\n",
      "Epoch:0, weight train batch: 12, step:1, loss before: 0.0644714534283, loss after: 0.0640314146876.\n",
      "Epoch:0, weight train batch: 12, step:2, loss before: 0.124241158366, loss after: 0.123694196343.\n",
      "Epoch:0, weight train batch: 12, step:3, loss before: 0.0574683062732, loss after: 0.0570511855185.\n",
      "Epoch:0, weight train batch: 12, step:4, loss before: 0.0617401152849, loss after: 0.0612883232534.\n",
      "Epoch:0, weight train batch: 12, step:5, loss before: 0.0406597740948, loss after: 0.0403650067747.\n",
      "Epoch:0, weight train batch: 12, step:6, loss before: 0.0555719509721, loss after: 0.0552181862295.\n",
      "Epoch:0, weight train batch: 12, step:7, loss before: 0.0686665922403, loss after: 0.0682238787413.\n",
      "Epoch:0, weight train batch: 12, step:8, loss before: 0.0640740916133, loss after: 0.0636371895671.\n",
      "Epoch:0, weight train batch: 12, step:9, loss before: 0.0583974868059, loss after: 0.0579813942313.\n",
      "Epoch:0, weight train batch: 12, step:10, loss before: 0.0582014508545, loss after: 0.0577993020415.\n",
      "Epoch:0, weight train batch: 12, step:11, loss before: 0.0550325028598, loss after: 0.0546448454261.\n",
      "Epoch:0, weight train batch: 12, step:12, loss before: 0.0674227625132, loss after: 0.066948890686.\n",
      "Epoch:0, weight train batch: 12, step:13, loss before: 0.0635452121496, loss after: 0.0630920231342.\n",
      "Epoch:0, weight train batch: 12, step:14, loss before: 0.0529952943325, loss after: 0.0526179783046.\n",
      "Epoch:0, weight train batch: 12, step:15, loss before: 0.0510274022818, loss after: 0.0506756044924.\n",
      "Epoch:0, weight train batch: 12, step:16, loss before: 0.063733227551, loss after: 0.0632821843028.\n",
      "Epoch:0, weight train batch: 12, step:17, loss before: 0.10707051307, loss after: 0.106648229063.\n",
      "Epoch:0, weight train batch: 12, step:18, loss before: 0.0485053919256, loss after: 0.0481689944863.\n",
      "Epoch:0, weight train batch: 12, step:19, loss before: 0.0440061278641, loss after: 0.0437053143978.\n",
      "Epoch:0, weight train batch: 12, step:20, loss before: 0.0562534108758, loss after: 0.0558697730303.\n",
      "Epoch:0, weight train batch: 12, step:21, loss before: 0.0481693670154, loss after: 0.0478369370103.\n",
      "Epoch:0, weight train batch: 12, step:22, loss before: 0.050261169672, loss after: 0.0499337874353.\n",
      "Epoch:0, weight train batch: 12, step:23, loss before: 0.0481716990471, loss after: 0.0478531420231.\n",
      "Epoch:0, weight train batch: 12, step:24, loss before: 0.0415725782514, loss after: 0.0412904843688.\n",
      "Epoch:0, weight train batch: 12, step:25, loss before: 0.0420717447996, loss after: 0.0417751930654.\n",
      "Epoch:0, weight train batch: 12, step:26, loss before: 0.0798306316137, loss after: 0.0794705748558.\n",
      "Epoch:0, weight train batch: 12, step:27, loss before: 0.040724106133, loss after: 0.0404635220766.\n",
      "Epoch:0, weight train batch: 12, step:28, loss before: 0.048369590193, loss after: 0.0480632334948.\n",
      "Epoch:0, weight train batch: 12, step:29, loss before: 0.0473692268133, loss after: 0.0470853820443.\n",
      "Epoch:0, weight train batch: 12, step:30, loss before: 0.0546466931701, loss after: 0.0543312877417.\n",
      "Epoch:0, weight train batch: 12, step:31, loss before: 0.053511235863, loss after: 0.0531862825155.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:0, struct parameters train batch: 8, loss before: 0.0500456169248, loss after: 0.0500973835588.\n",
      "Epoch:0, weight train batch: 13, step:0, loss before: 0.0508084483445, loss after: 0.0504853315651.\n",
      "Epoch:0, weight train batch: 13, step:1, loss before: 0.0489583164454, loss after: 0.0486628897488.\n",
      "Epoch:0, weight train batch: 13, step:2, loss before: 0.0476408973336, loss after: 0.0473416447639.\n",
      "Epoch:0, weight train batch: 13, step:3, loss before: 0.0388125404716, loss after: 0.0385714024305.\n",
      "Epoch:0, weight train batch: 13, step:4, loss before: 0.0462023466825, loss after: 0.0459188558161.\n",
      "Epoch:0, weight train batch: 13, step:5, loss before: 0.0528927370906, loss after: 0.0525617785752.\n",
      "Epoch:0, weight train batch: 13, step:6, loss before: 0.0495967976749, loss after: 0.0492742843926.\n",
      "Epoch:0, weight train batch: 13, step:7, loss before: 0.0497496761382, loss after: 0.0494173429906.\n",
      "Epoch:0, weight train batch: 13, step:8, loss before: 0.0856532603502, loss after: 0.0854168832302.\n",
      "Epoch:0, weight train batch: 13, step:9, loss before: 0.0512139573693, loss after: 0.0509148612618.\n",
      "Epoch:0, weight train batch: 13, step:10, loss before: 0.0501514784992, loss after: 0.0498419031501.\n",
      "Epoch:0, weight train batch: 13, step:11, loss before: 0.0407769493759, loss after: 0.0405283868313.\n",
      "Epoch:0, weight train batch: 13, step:12, loss before: 0.0398792177439, loss after: 0.0396301522851.\n",
      "Epoch:0, weight train batch: 13, step:13, loss before: 0.0509005226195, loss after: 0.0505881272256.\n",
      "Epoch:0, weight train batch: 13, step:14, loss before: 0.0547846481204, loss after: 0.0544313341379.\n",
      "Epoch:0, weight train batch: 13, step:15, loss before: 0.0385732091963, loss after: 0.038341127336.\n",
      "Epoch:0, weight train batch: 13, step:16, loss before: 0.0450292229652, loss after: 0.0447496064007.\n",
      "Epoch:0, weight train batch: 13, step:17, loss before: 0.0502354092896, loss after: 0.0499143227935.\n",
      "Epoch:0, weight train batch: 13, step:18, loss before: 0.0438336879015, loss after: 0.043554328382.\n",
      "Epoch:0, weight train batch: 13, step:19, loss before: 0.047936078161, loss after: 0.0476375073195.\n",
      "Epoch:0, weight train batch: 13, step:20, loss before: 0.0399374775589, loss after: 0.0396968200803.\n",
      "Epoch:0, weight train batch: 13, step:21, loss before: 0.0540982447565, loss after: 0.0537302494049.\n",
      "Epoch:0, weight train batch: 13, step:22, loss before: 0.0478505976498, loss after: 0.0475244708359.\n",
      "Epoch:0, weight train batch: 13, step:23, loss before: 0.0451339334249, loss after: 0.0448419377208.\n",
      "Epoch:0, weight train batch: 13, step:24, loss before: 0.0406007170677, loss after: 0.0403231829405.\n",
      "Epoch:0, weight train batch: 13, step:25, loss before: 0.030211398378, loss after: 0.0300363786519.\n",
      "Epoch:0, weight train batch: 13, step:26, loss before: 0.0465576760471, loss after: 0.046260766685.\n",
      "Epoch:0, weight train batch: 13, step:27, loss before: 0.0412513241172, loss after: 0.0409856624901.\n",
      "Epoch:0, weight train batch: 13, step:28, loss before: 0.0387466922402, loss after: 0.0385177209973.\n",
      "Epoch:0, weight train batch: 13, step:29, loss before: 0.0405016988516, loss after: 0.0402621589601.\n",
      "Epoch:0, weight train batch: 13, step:30, loss before: 0.045836340636, loss after: 0.0455478429794.\n",
      "Epoch:0, weight train batch: 13, step:31, loss before: 0.0368256568909, loss after: 0.0365988537669.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:0, struct parameters train batch: 9, loss before: 0.0454299077392, loss after: 0.0576115846634.\n",
      "Epoch:0, weight train batch: 14, step:0, loss before: 0.0392727702856, loss after: 0.0390455499291.\n",
      "Epoch:0, weight train batch: 14, step:1, loss before: 0.0405956469476, loss after: 0.0403531417251.\n",
      "Epoch:0, weight train batch: 14, step:2, loss before: 0.0409696213901, loss after: 0.0407305881381.\n",
      "Epoch:0, weight train batch: 14, step:3, loss before: 0.040792606771, loss after: 0.0405531488359.\n",
      "Epoch:0, weight train batch: 14, step:4, loss before: 0.0354202762246, loss after: 0.0352070219815.\n",
      "Epoch:0, weight train batch: 14, step:5, loss before: 0.0355085581541, loss after: 0.0353017747402.\n",
      "Epoch:0, weight train batch: 14, step:6, loss before: 0.0404802337289, loss after: 0.0402541644871.\n",
      "Epoch:0, weight train batch: 14, step:7, loss before: 0.0470771044493, loss after: 0.0467924177647.\n",
      "Epoch:0, weight train batch: 14, step:8, loss before: 0.0496935136616, loss after: 0.04938865453.\n",
      "Epoch:0, weight train batch: 14, step:9, loss before: 0.0323216058314, loss after: 0.0321363583207.\n",
      "Epoch:0, weight train batch: 14, step:10, loss before: 0.0329450294375, loss after: 0.0327545963228.\n",
      "Epoch:0, weight train batch: 14, step:11, loss before: 0.0378236323595, loss after: 0.0375984348357.\n",
      "Epoch:0, weight train batch: 14, step:12, loss before: 0.042054887861, loss after: 0.0417972318828.\n",
      "Epoch:0, weight train batch: 14, step:13, loss before: 0.0353701338172, loss after: 0.0351509824395.\n",
      "Epoch:0, weight train batch: 14, step:14, loss before: 0.0398331098258, loss after: 0.0395911037922.\n",
      "Epoch:0, weight train batch: 14, step:15, loss before: 0.041073359549, loss after: 0.0408399030566.\n",
      "Epoch:0, weight train batch: 14, step:16, loss before: 0.0526566319168, loss after: 0.0523091256618.\n",
      "Epoch:0, weight train batch: 14, step:17, loss before: 0.0354276522994, loss after: 0.0352092459798.\n",
      "Epoch:0, weight train batch: 14, step:18, loss before: 0.0367235429585, loss after: 0.0364955663681.\n",
      "Epoch:0, weight train batch: 14, step:19, loss before: 0.0333184450865, loss after: 0.0331231504679.\n",
      "Epoch:0, weight train batch: 14, step:20, loss before: 0.0355696976185, loss after: 0.0353466235101.\n",
      "Epoch:0, weight train batch: 14, step:21, loss before: 0.0421420112252, loss after: 0.0418774783611.\n",
      "Epoch:0, weight train batch: 14, step:22, loss before: 0.0353437326849, loss after: 0.0351216308773.\n",
      "Epoch:0, weight train batch: 14, step:23, loss before: 0.0302393473685, loss after: 0.0300597809255.\n",
      "Epoch:0, weight train batch: 14, step:24, loss before: 0.0316622853279, loss after: 0.0314802080393.\n",
      "Epoch:0, weight train batch: 14, step:25, loss before: 0.0330902971327, loss after: 0.0328855514526.\n",
      "Epoch:0, weight train batch: 14, step:26, loss before: 0.0313053205609, loss after: 0.0311185009778.\n",
      "Epoch:0, weight train batch: 14, step:27, loss before: 0.038621969521, loss after: 0.0384037718177.\n",
      "Epoch:0, weight train batch: 14, step:28, loss before: 0.0433821380138, loss after: 0.0431085564196.\n",
      "Epoch:0, weight train batch: 14, step:29, loss before: 0.0323044732213, loss after: 0.0321070998907.\n",
      "Epoch:0, weight train batch: 14, step:30, loss before: 0.0266130939126, loss after: 0.0264698956162.\n",
      "Epoch:0, weight train batch: 14, step:31, loss before: 0.0360829159617, loss after: 0.0358735062182.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:0, struct parameters train batch: 10, loss before: 0.032944098115, loss after: 0.0331674292684.\n",
      "Epoch:0, weight train batch: 15, step:0, loss before: 0.0229066126049, loss after: 0.0227926373482.\n",
      "Epoch:0, weight train batch: 15, step:1, loss before: 0.0315949544311, loss after: 0.0314257740974.\n",
      "Epoch:0, weight train batch: 15, step:2, loss before: 0.0305341202766, loss after: 0.0303727611899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, weight train batch: 15, step:3, loss before: 0.046346526593, loss after: 0.0461662486196.\n",
      "Epoch:0, weight train batch: 15, step:4, loss before: 0.0337199307978, loss after: 0.0335361920297.\n",
      "Epoch:0, weight train batch: 15, step:5, loss before: 0.0345172807574, loss after: 0.0343213640153.\n",
      "Epoch:0, weight train batch: 15, step:6, loss before: 0.0415218025446, loss after: 0.0412752106786.\n",
      "Epoch:0, weight train batch: 15, step:7, loss before: 0.0279697142541, loss after: 0.0278126075864.\n",
      "Epoch:0, weight train batch: 15, step:8, loss before: 0.0362059548497, loss after: 0.0360013768077.\n",
      "Epoch:0, weight train batch: 15, step:9, loss before: 0.0317966528237, loss after: 0.0316281467676.\n",
      "Epoch:0, weight train batch: 15, step:10, loss before: 0.0336704552174, loss after: 0.0334763601422.\n",
      "Epoch:0, weight train batch: 15, step:11, loss before: 0.034680467099, loss after: 0.0344855375588.\n",
      "Epoch:0, weight train batch: 15, step:12, loss before: 0.0270207002759, loss after: 0.0268682129681.\n",
      "Epoch:0, weight train batch: 15, step:13, loss before: 0.0352162048221, loss after: 0.0350131802261.\n",
      "Epoch:0, weight train batch: 15, step:14, loss before: 0.0331675074995, loss after: 0.0329689793289.\n",
      "Epoch:0, weight train batch: 15, step:15, loss before: 0.032519813627, loss after: 0.0323436297476.\n",
      "Epoch:0, weight train batch: 15, step:16, loss before: 0.03298683092, loss after: 0.0327967554331.\n",
      "Epoch:0, weight train batch: 15, step:17, loss before: 0.0304558519274, loss after: 0.0302823837847.\n",
      "Epoch:0, weight train batch: 15, step:18, loss before: 0.0316739454865, loss after: 0.0314931422472.\n",
      "Epoch:0, weight train batch: 15, step:19, loss before: 0.0272276382893, loss after: 0.0270768217742.\n",
      "Epoch:0, weight train batch: 15, step:20, loss before: 0.0258357971907, loss after: 0.0256921108812.\n",
      "Epoch:0, weight train batch: 15, step:21, loss before: 0.0344338566065, loss after: 0.0342400893569.\n",
      "Epoch:0, weight train batch: 15, step:22, loss before: 0.0330965816975, loss after: 0.0329104401171.\n",
      "Epoch:0, weight train batch: 15, step:23, loss before: 0.0315750166774, loss after: 0.0314031466842.\n",
      "Epoch:0, weight train batch: 15, step:24, loss before: 0.033241327852, loss after: 0.0330509319901.\n",
      "Epoch:0, weight train batch: 15, step:25, loss before: 0.0271822921932, loss after: 0.0270349979401.\n",
      "Epoch:0, weight train batch: 15, step:26, loss before: 0.0323279201984, loss after: 0.0321531295776.\n",
      "Epoch:0, weight train batch: 15, step:27, loss before: 0.0274029206485, loss after: 0.0272592455149.\n",
      "Epoch:0, weight train batch: 15, step:28, loss before: 0.0247243568301, loss after: 0.0245935823768.\n",
      "Epoch:0, weight train batch: 15, step:29, loss before: 0.0257867537439, loss after: 0.0256487186998.\n",
      "Epoch:0, weight train batch: 15, step:30, loss before: 0.0330948457122, loss after: 0.0329140499234.\n",
      "Epoch:0, weight train batch: 15, step:31, loss before: 0.0287226252258, loss after: 0.0285695381463.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:0, struct parameters train batch: 11, loss before: 0.0268133375794, loss after: 0.0274590812624.\n",
      "Epoch:0, weight train batch: 16, step:0, loss before: 0.0296682454646, loss after: 0.0295018181205.\n",
      "Epoch:0, weight train batch: 16, step:1, loss before: 0.0251138564199, loss after: 0.0249827485532.\n",
      "Epoch:0, weight train batch: 16, step:2, loss before: 0.0263881459832, loss after: 0.0262488890439.\n",
      "Epoch:0, weight train batch: 16, step:3, loss before: 0.0239296834916, loss after: 0.02380932495.\n",
      "Epoch:0, weight train batch: 16, step:4, loss before: 0.0279726162553, loss after: 0.0278290007263.\n",
      "Epoch:0, weight train batch: 16, step:5, loss before: 0.0304844323546, loss after: 0.0303227491677.\n",
      "Epoch:0, weight train batch: 16, step:6, loss before: 0.0270043946803, loss after: 0.0268603097647.\n",
      "Epoch:0, weight train batch: 16, step:7, loss before: 0.0262994766235, loss after: 0.026165317744.\n",
      "Epoch:0, weight train batch: 16, step:8, loss before: 0.025579828769, loss after: 0.0254490971565.\n",
      "Epoch:0, weight train batch: 16, step:9, loss before: 0.0242267008871, loss after: 0.0241025388241.\n",
      "Epoch:0, weight train batch: 16, step:10, loss before: 0.0227613784373, loss after: 0.0226443968713.\n",
      "Epoch:0, weight train batch: 16, step:11, loss before: 0.0263222195208, loss after: 0.0261911004782.\n",
      "Epoch:0, weight train batch: 16, step:12, loss before: 0.0280112624168, loss after: 0.0278765335679.\n",
      "Epoch:0, weight train batch: 16, step:13, loss before: 0.0225477293134, loss after: 0.0224365126342.\n",
      "Epoch:0, weight train batch: 16, step:14, loss before: 0.0272629838437, loss after: 0.0271240472794.\n",
      "Epoch:0, weight train batch: 16, step:15, loss before: 0.024342155084, loss after: 0.024218166247.\n",
      "Epoch:0, weight train batch: 16, step:16, loss before: 0.0314095467329, loss after: 0.0312544852495.\n",
      "Epoch:0, weight train batch: 16, step:17, loss before: 0.0246399622411, loss after: 0.0245130881667.\n",
      "Epoch:0, weight train batch: 16, step:18, loss before: 0.0268484726548, loss after: 0.0267093405128.\n",
      "Epoch:0, weight train batch: 16, step:19, loss before: 0.0255921259522, loss after: 0.0254647191614.\n",
      "Epoch:0, weight train batch: 16, step:20, loss before: 0.0243147350848, loss after: 0.0241923611611.\n",
      "Epoch:0, weight train batch: 16, step:21, loss before: 0.0269026830792, loss after: 0.0267624016851.\n",
      "Epoch:0, weight train batch: 16, step:22, loss before: 0.0253722332418, loss after: 0.0252403449267.\n",
      "Epoch:0, weight train batch: 16, step:23, loss before: 0.0204950273037, loss after: 0.0203941930085.\n",
      "Epoch:0, weight train batch: 16, step:24, loss before: 0.0214026402682, loss after: 0.0212994478643.\n",
      "Epoch:0, weight train batch: 16, step:25, loss before: 0.0267046391964, loss after: 0.0265745967627.\n",
      "Epoch:0, weight train batch: 16, step:26, loss before: 0.0278648417443, loss after: 0.02772555314.\n",
      "Epoch:0, weight train batch: 16, step:27, loss before: 0.0248701814562, loss after: 0.0247429125011.\n",
      "Epoch:0, weight train batch: 16, step:28, loss before: 0.0232473555952, loss after: 0.0231313649565.\n",
      "Epoch:0, weight train batch: 16, step:29, loss before: 0.0291705969721, loss after: 0.0290191844106.\n",
      "Epoch:0, weight train batch: 16, step:30, loss before: 0.0268134362996, loss after: 0.0266830381006.\n",
      "Epoch:0, weight train batch: 16, step:31, loss before: 0.0226162821054, loss after: 0.0225045867264.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:0, struct parameters train batch: 12, loss before: 0.0257721878588, loss after: 0.0257721878588.\n",
      "Epoch:0, weight train batch: 17, step:0, loss before: 0.0233055856079, loss after: 0.0231913942844.\n",
      "Epoch:0, weight train batch: 17, step:1, loss before: 0.0223442967981, loss after: 0.0222352668643.\n",
      "Epoch:0, weight train batch: 17, step:2, loss before: 0.0276829563081, loss after: 0.0275394581258.\n",
      "Epoch:0, weight train batch: 17, step:3, loss before: 0.0257992018014, loss after: 0.0256741140038.\n",
      "Epoch:0, weight train batch: 17, step:4, loss before: 0.0245250761509, loss after: 0.0243975222111.\n",
      "Epoch:0, weight train batch: 17, step:5, loss before: 0.0243067406118, loss after: 0.0241847708821.\n",
      "Epoch:0, weight train batch: 17, step:6, loss before: 0.0241786632687, loss after: 0.0240560751408.\n",
      "Epoch:0, weight train batch: 17, step:7, loss before: 0.0267448872328, loss after: 0.0266045816243.\n",
      "Epoch:0, weight train batch: 17, step:8, loss before: 0.0225724186748, loss after: 0.0224550999701.\n",
      "Epoch:0, weight train batch: 17, step:9, loss before: 0.0209223739803, loss after: 0.0208141561598.\n",
      "Epoch:0, weight train batch: 17, step:10, loss before: 0.0214662626386, loss after: 0.0213672090322.\n",
      "Epoch:0, weight train batch: 17, step:11, loss before: 0.022456843406, loss after: 0.0223452281207.\n",
      "Epoch:0, weight train batch: 17, step:12, loss before: 0.023450743407, loss after: 0.0233332961798.\n",
      "Epoch:0, weight train batch: 17, step:13, loss before: 0.0209798850119, loss after: 0.0208832398057.\n",
      "Epoch:0, weight train batch: 17, step:14, loss before: 0.0270303729922, loss after: 0.0268996432424.\n",
      "Epoch:0, weight train batch: 17, step:15, loss before: 0.0233637373894, loss after: 0.0232469402254.\n",
      "Epoch:0, weight train batch: 17, step:16, loss before: 0.0254084840417, loss after: 0.0252782348543.\n",
      "Epoch:0, weight train batch: 17, step:17, loss before: 0.0195887796581, loss after: 0.0194968301803.\n",
      "Epoch:0, weight train batch: 17, step:18, loss before: 0.0217917263508, loss after: 0.021691609174.\n",
      "Epoch:0, weight train batch: 17, step:19, loss before: 0.0176429711282, loss after: 0.0175601057708.\n",
      "Epoch:0, weight train batch: 17, step:20, loss before: 0.0217672996223, loss after: 0.0216639656574.\n",
      "Epoch:0, weight train batch: 17, step:21, loss before: 0.023377077654, loss after: 0.0232641976327.\n",
      "Epoch:0, weight train batch: 17, step:22, loss before: 0.0189745053649, loss after: 0.0188842974603.\n",
      "Epoch:0, weight train batch: 17, step:23, loss before: 0.022681478411, loss after: 0.0225783400238.\n",
      "Epoch:0, weight train batch: 17, step:24, loss before: 0.0240473598242, loss after: 0.0239347815514.\n",
      "Epoch:0, weight train batch: 17, step:25, loss before: 0.0181211661547, loss after: 0.0180364251137.\n",
      "Epoch:0, weight train batch: 17, step:26, loss before: 0.0214081890881, loss after: 0.0213061086833.\n",
      "Epoch:0, weight train batch: 17, step:27, loss before: 0.0229992065579, loss after: 0.0228885933757.\n",
      "Epoch:0, weight train batch: 17, step:28, loss before: 0.0182631257921, loss after: 0.0181787218899.\n",
      "Epoch:0, weight train batch: 17, step:29, loss before: 0.0188214182854, loss after: 0.0187362525612.\n",
      "Epoch:0, weight train batch: 17, step:30, loss before: 0.0200093388557, loss after: 0.0199197567999.\n",
      "Epoch:0, weight train batch: 17, step:31, loss before: 0.0232370458543, loss after: 0.0231302492321.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, struct parameters train batch: 13, loss before: 0.0203977134079, loss after: 0.0199557375163.\n",
      "Epoch:0, weight train batch: 18, step:0, loss before: 0.0205800533295, loss after: 0.020485367626.\n",
      "Epoch:0, weight train batch: 18, step:1, loss before: 0.0190774407238, loss after: 0.0189901832491.\n",
      "Epoch:0, weight train batch: 18, step:2, loss before: 0.0224477276206, loss after: 0.0223448239267.\n",
      "Epoch:0, weight train batch: 18, step:3, loss before: 0.0192315429449, loss after: 0.0191435702145.\n",
      "Epoch:0, weight train batch: 18, step:4, loss before: 0.0214742235839, loss after: 0.0213741734624.\n",
      "Epoch:0, weight train batch: 18, step:5, loss before: 0.0233977232128, loss after: 0.0232844166458.\n",
      "Epoch:0, weight train batch: 18, step:6, loss before: 0.0204277411103, loss after: 0.0203365273774.\n",
      "Epoch:0, weight train batch: 18, step:7, loss before: 0.0234342534095, loss after: 0.0233213976026.\n",
      "Epoch:0, weight train batch: 18, step:8, loss before: 0.0179013572633, loss after: 0.0178189557046.\n",
      "Epoch:0, weight train batch: 18, step:9, loss before: 0.0202801711857, loss after: 0.0201830975711.\n",
      "Epoch:0, weight train batch: 18, step:10, loss before: 0.0201830975711, loss after: 0.020084682852.\n",
      "Epoch:0, weight train batch: 18, step:11, loss before: 0.0210190378129, loss after: 0.0209193062037.\n",
      "Epoch:0, weight train batch: 18, step:12, loss before: 0.0233047958463, loss after: 0.0231999643147.\n",
      "Epoch:0, weight train batch: 18, step:13, loss before: 0.0219411309808, loss after: 0.0218325853348.\n",
      "Epoch:0, weight train batch: 18, step:14, loss before: 0.0215611979365, loss after: 0.021454628557.\n",
      "Epoch:0, weight train batch: 18, step:15, loss before: 0.0201185755432, loss after: 0.0200192518532.\n",
      "Epoch:0, weight train batch: 18, step:16, loss before: 0.0160650648177, loss after: 0.0159882102162.\n",
      "Epoch:0, weight train batch: 18, step:17, loss before: 0.0202378891408, loss after: 0.0201379600912.\n",
      "Epoch:0, weight train batch: 18, step:18, loss before: 0.0184968709946, loss after: 0.0184134282172.\n",
      "Epoch:0, weight train batch: 18, step:19, loss before: 0.0158300809562, loss after: 0.015761770308.\n",
      "Epoch:0, weight train batch: 18, step:20, loss before: 0.022942347452, loss after: 0.0228395331651.\n",
      "Epoch:0, weight train batch: 18, step:21, loss before: 0.0183390472084, loss after: 0.0182587970048.\n",
      "Epoch:0, weight train batch: 18, step:22, loss before: 0.0163561813533, loss after: 0.0162847563624.\n",
      "Epoch:0, weight train batch: 18, step:23, loss before: 0.0193277895451, loss after: 0.019238723442.\n",
      "Epoch:0, weight train batch: 18, step:24, loss before: 0.0182799901813, loss after: 0.0181992277503.\n",
      "Epoch:0, weight train batch: 18, step:25, loss before: 0.0430297255516, loss after: 0.042914506048.\n",
      "Epoch:0, weight train batch: 18, step:26, loss before: 0.0165278185159, loss after: 0.0164584815502.\n",
      "Epoch:0, weight train batch: 18, step:27, loss before: 0.0178739000112, loss after: 0.0177943259478.\n",
      "Epoch:0, weight train batch: 18, step:28, loss before: 0.0169750116765, loss after: 0.0169027857482.\n",
      "Epoch:0, weight train batch: 18, step:29, loss before: 0.0158195793629, loss after: 0.0157527588308.\n",
      "Epoch:0, weight train batch: 18, step:30, loss before: 0.0179136693478, loss after: 0.0178360417485.\n",
      "Epoch:0, weight train batch: 18, step:31, loss before: 0.0173718538135, loss after: 0.0172976385802.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:0, struct parameters train batch: 14, loss before: 0.0192878730595, loss after: 0.018499173224.\n",
      "Epoch:0, weight train batch: 19, step:0, loss before: 0.0143755683675, loss after: 0.0143141653389.\n",
      "Epoch:0, weight train batch: 19, step:1, loss before: 0.0176956653595, loss after: 0.0176215916872.\n",
      "Epoch:0, weight train batch: 19, step:2, loss before: 0.0188250876963, loss after: 0.0187430344522.\n",
      "Epoch:0, weight train batch: 19, step:3, loss before: 0.0185123942792, loss after: 0.0184326656163.\n",
      "Epoch:0, weight train batch: 19, step:4, loss before: 0.0180592015386, loss after: 0.0179810021073.\n",
      "Epoch:0, weight train batch: 19, step:5, loss before: 0.0175353698432, loss after: 0.0174604095519.\n",
      "Epoch:0, weight train batch: 19, step:6, loss before: 0.016693353653, loss after: 0.0166198499501.\n",
      "Epoch:0, weight train batch: 19, step:7, loss before: 0.0168920177966, loss after: 0.0168200694025.\n",
      "Epoch:0, weight train batch: 19, step:8, loss before: 0.0175095163286, loss after: 0.0174349471927.\n",
      "Epoch:0, weight train batch: 19, step:9, loss before: 0.016885029152, loss after: 0.0168101377785.\n",
      "Epoch:0, weight train batch: 19, step:10, loss before: 0.0149693284184, loss after: 0.0149074885994.\n",
      "Epoch:0, weight train batch: 19, step:11, loss before: 0.017934050411, loss after: 0.0178540274501.\n",
      "Epoch:0, weight train batch: 19, step:12, loss before: 0.0160247255117, loss after: 0.0159567184746.\n",
      "Epoch:0, weight train batch: 19, step:13, loss before: 0.0165683329105, loss after: 0.0164994318038.\n",
      "Epoch:0, weight train batch: 19, step:14, loss before: 0.0159442834556, loss after: 0.0158766303211.\n",
      "Epoch:0, weight train batch: 19, step:15, loss before: 0.0201514810324, loss after: 0.0200624652207.\n",
      "Epoch:0, weight train batch: 19, step:16, loss before: 0.0187896378338, loss after: 0.018708223477.\n",
      "Epoch:0, weight train batch: 19, step:17, loss before: 0.0149553827941, loss after: 0.0148880835623.\n",
      "Epoch:0, weight train batch: 19, step:18, loss before: 0.0152781484649, loss after: 0.0152104608715.\n",
      "Epoch:0, weight train batch: 19, step:19, loss before: 0.0138652240857, loss after: 0.0138076283038.\n",
      "Epoch:0, weight train batch: 19, step:20, loss before: 0.0187239069492, loss after: 0.018644861877.\n",
      "Epoch:0, weight train batch: 19, step:21, loss before: 0.0141639783978, loss after: 0.0141112804413.\n",
      "Epoch:0, weight train batch: 19, step:22, loss before: 0.0161291323602, loss after: 0.0160618126392.\n",
      "Epoch:0, weight train batch: 19, step:23, loss before: 0.0169910620898, loss after: 0.0169196501374.\n",
      "Epoch:0, weight train batch: 19, step:24, loss before: 0.0154466023669, loss after: 0.0153832389042.\n",
      "Epoch:0, weight train batch: 19, step:25, loss before: 0.0150279020891, loss after: 0.0149680003524.\n",
      "Epoch:0, weight train batch: 19, step:26, loss before: 0.015072115697, loss after: 0.0150101156905.\n",
      "Epoch:0, weight train batch: 19, step:27, loss before: 0.0156416036189, loss after: 0.0155806560069.\n",
      "Epoch:0, weight train batch: 19, step:28, loss before: 0.0117345219478, loss after: 0.0116889737546.\n",
      "Epoch:0, weight train batch: 19, step:29, loss before: 0.0182459522039, loss after: 0.0181734673679.\n",
      "Epoch:0, weight train batch: 19, step:30, loss before: 0.0261378698051, loss after: 0.0260568968952.\n",
      "Epoch:0, weight train batch: 19, step:31, loss before: 0.0213592946529, loss after: 0.0212778262794.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:0, struct parameters train batch: 15, loss before: 0.0160667896271, loss after: 0.0159343741834.\n",
      "Epoch:1, weight train batch: 20, step:0, loss before: 0.012443558313, loss after: 0.0123956128955.\n",
      "Epoch:1, weight train batch: 20, step:1, loss before: 0.014342488721, loss after: 0.0142860561609.\n",
      "Epoch:1, weight train batch: 20, step:2, loss before: 0.0166030116379, loss after: 0.0165358651429.\n",
      "Epoch:1, weight train batch: 20, step:3, loss before: 0.0153185911477, loss after: 0.0152566898614.\n",
      "Epoch:1, weight train batch: 20, step:4, loss before: 0.0150796500966, loss after: 0.0150181595236.\n",
      "Epoch:1, weight train batch: 20, step:5, loss before: 0.0143071617931, loss after: 0.0142486859113.\n",
      "Epoch:1, weight train batch: 20, step:6, loss before: 0.0211156737059, loss after: 0.0210601463914.\n",
      "Epoch:1, weight train batch: 20, step:7, loss before: 0.0159129649401, loss after: 0.0158493798226.\n",
      "Epoch:1, weight train batch: 20, step:8, loss before: 0.0156736299396, loss after: 0.0156123815104.\n",
      "Epoch:1, weight train batch: 20, step:9, loss before: 0.0145904244855, loss after: 0.0145299099386.\n",
      "Epoch:1, weight train batch: 20, step:10, loss before: 0.0135261518881, loss after: 0.013472693041.\n",
      "Epoch:1, weight train batch: 20, step:11, loss before: 0.0141347888857, loss after: 0.0140804480761.\n",
      "Epoch:1, weight train batch: 20, step:12, loss before: 0.014224762097, loss after: 0.014169478789.\n",
      "Epoch:1, weight train batch: 20, step:13, loss before: 0.0146390432492, loss after: 0.01458356902.\n",
      "Epoch:1, weight train batch: 20, step:14, loss before: 0.0135872680694, loss after: 0.0135342478752.\n",
      "Epoch:1, weight train batch: 20, step:15, loss before: 0.0133975846693, loss after: 0.0133443297818.\n",
      "Epoch:1, weight train batch: 20, step:16, loss before: 0.0150134032592, loss after: 0.0149531587958.\n",
      "Epoch:1, weight train batch: 20, step:17, loss before: 0.0127963274717, loss after: 0.0127447945997.\n",
      "Epoch:1, weight train batch: 20, step:18, loss before: 0.015214596875, loss after: 0.015155389905.\n",
      "Epoch:1, weight train batch: 20, step:19, loss before: 0.013378395699, loss after: 0.013325762935.\n",
      "Epoch:1, weight train batch: 20, step:20, loss before: 0.014145786874, loss after: 0.0140931634232.\n",
      "Epoch:1, weight train batch: 20, step:21, loss before: 0.0167209506035, loss after: 0.0166583620012.\n",
      "Epoch:1, weight train batch: 20, step:22, loss before: 0.0128688830882, loss after: 0.0128198396415.\n",
      "Epoch:1, weight train batch: 20, step:23, loss before: 0.0139746908098, loss after: 0.0139207979664.\n",
      "Epoch:1, weight train batch: 20, step:24, loss before: 0.017102625221, loss after: 0.0170351304114.\n",
      "Epoch:1, weight train batch: 20, step:25, loss before: 0.0168504975736, loss after: 0.0167884640396.\n",
      "Epoch:1, weight train batch: 20, step:26, loss before: 0.0123490318656, loss after: 0.012298675254.\n",
      "Epoch:1, weight train batch: 20, step:27, loss before: 0.0134112611413, loss after: 0.0133567862213.\n",
      "Epoch:1, weight train batch: 20, step:28, loss before: 0.0156620536, loss after: 0.015602373518.\n",
      "Epoch:1, weight train batch: 20, step:29, loss before: 0.0130015900359, loss after: 0.0129511989653.\n",
      "Epoch:1, weight train batch: 20, step:30, loss before: 0.0137624349445, loss after: 0.0137094315141.\n",
      "Epoch:1, weight train batch: 20, step:31, loss before: 0.0140599673614, loss after: 0.0140067450702.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 16, loss before: 0.0148048019037, loss after: 0.014099762775.\n",
      "Epoch:1, weight train batch: 21, step:0, loss before: 0.0157214533538, loss after: 0.0156603921205.\n",
      "Epoch:1, weight train batch: 21, step:1, loss before: 0.0154641438276, loss after: 0.0154000110924.\n",
      "Epoch:1, weight train batch: 21, step:2, loss before: 0.0118105625734, loss after: 0.0117645421997.\n",
      "Epoch:1, weight train batch: 21, step:3, loss before: 0.0128995114937, loss after: 0.012849714607.\n",
      "Epoch:1, weight train batch: 21, step:4, loss before: 0.0166924428195, loss after: 0.016627073288.\n",
      "Epoch:1, weight train batch: 21, step:5, loss before: 0.0132634816691, loss after: 0.0132101755589.\n",
      "Epoch:1, weight train batch: 21, step:6, loss before: 0.0115764150396, loss after: 0.0115307029337.\n",
      "Epoch:1, weight train batch: 21, step:7, loss before: 0.0128438659012, loss after: 0.0127945821732.\n",
      "Epoch:1, weight train batch: 21, step:8, loss before: 0.0150547865778, loss after: 0.0149988280609.\n",
      "Epoch:1, weight train batch: 21, step:9, loss before: 0.0150138428435, loss after: 0.0149559862912.\n",
      "Epoch:1, weight train batch: 21, step:10, loss before: 0.0119229396805, loss after: 0.0118770990521.\n",
      "Epoch:1, weight train batch: 21, step:11, loss before: 0.0128203267232, loss after: 0.0127707049251.\n",
      "Epoch:1, weight train batch: 21, step:12, loss before: 0.0123480111361, loss after: 0.0123004727066.\n",
      "Epoch:1, weight train batch: 21, step:13, loss before: 0.011409278959, loss after: 0.0113656111062.\n",
      "Epoch:1, weight train batch: 21, step:14, loss before: 0.0140028605238, loss after: 0.0139502696693.\n",
      "Epoch:1, weight train batch: 21, step:15, loss before: 0.013959386386, loss after: 0.013906929642.\n",
      "Epoch:1, weight train batch: 21, step:16, loss before: 0.0139907263219, loss after: 0.0139387156814.\n",
      "Epoch:1, weight train batch: 21, step:17, loss before: 0.0660148635507, loss after: 0.0658927634358.\n",
      "Epoch:1, weight train batch: 21, step:18, loss before: 0.0131854247302, loss after: 0.0131409969181.\n",
      "Epoch:1, weight train batch: 21, step:19, loss before: 0.0140061164275, loss after: 0.0139508228749.\n",
      "Epoch:1, weight train batch: 21, step:20, loss before: 0.0134224090725, loss after: 0.0133728254586.\n",
      "Epoch:1, weight train batch: 21, step:21, loss before: 0.0123918671161, loss after: 0.0123472744599.\n",
      "Epoch:1, weight train batch: 21, step:22, loss before: 0.0118071008474, loss after: 0.0117630492896.\n",
      "Epoch:1, weight train batch: 21, step:23, loss before: 0.0131920091808, loss after: 0.0131431091577.\n",
      "Epoch:1, weight train batch: 21, step:24, loss before: 0.0134384408593, loss after: 0.0133863072842.\n",
      "Epoch:1, weight train batch: 21, step:25, loss before: 0.0122217321768, loss after: 0.0121737197042.\n",
      "Epoch:1, weight train batch: 21, step:26, loss before: 0.0126777840778, loss after: 0.0126293711364.\n",
      "Epoch:1, weight train batch: 21, step:27, loss before: 0.0128240231425, loss after: 0.012773072347.\n",
      "Epoch:1, weight train batch: 21, step:28, loss before: 0.0118396412581, loss after: 0.0117923934013.\n",
      "Epoch:1, weight train batch: 21, step:29, loss before: 0.0123656606302, loss after: 0.0123173277825.\n",
      "Epoch:1, weight train batch: 21, step:30, loss before: 0.0147018237039, loss after: 0.014644516632.\n",
      "Epoch:1, weight train batch: 21, step:31, loss before: 0.0141705926508, loss after: 0.0141119789332.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 17, loss before: 0.0125608164817, loss after: 0.0125608164817.\n",
      "Epoch:1, weight train batch: 22, step:0, loss before: 0.0123111018911, loss after: 0.0122624691576.\n",
      "Epoch:1, weight train batch: 22, step:1, loss before: 0.0113548850641, loss after: 0.0113139655441.\n",
      "Epoch:1, weight train batch: 22, step:2, loss before: 0.00980230234563, loss after: 0.00976753793657.\n",
      "Epoch:1, weight train batch: 22, step:3, loss before: 0.0115406885743, loss after: 0.0114996489137.\n",
      "Epoch:1, weight train batch: 22, step:4, loss before: 0.0113428067416, loss after: 0.0113021880388.\n",
      "Epoch:1, weight train batch: 22, step:5, loss before: 0.0125670917332, loss after: 0.0125221535563.\n",
      "Epoch:1, weight train batch: 22, step:6, loss before: 0.0110107529908, loss after: 0.0109706325457.\n",
      "Epoch:1, weight train batch: 22, step:7, loss before: 0.0101268878207, loss after: 0.0100904405117.\n",
      "Epoch:1, weight train batch: 22, step:8, loss before: 0.0118599589914, loss after: 0.011817894876.\n",
      "Epoch:1, weight train batch: 22, step:9, loss before: 0.0114491702989, loss after: 0.0114080198109.\n",
      "Epoch:1, weight train batch: 22, step:10, loss before: 0.0126361418515, loss after: 0.0125923715532.\n",
      "Epoch:1, weight train batch: 22, step:11, loss before: 0.0114510729909, loss after: 0.0114093739539.\n",
      "Epoch:1, weight train batch: 22, step:12, loss before: 0.0110756801441, loss after: 0.0110366530716.\n",
      "Epoch:1, weight train batch: 22, step:13, loss before: 0.0131314117461, loss after: 0.0130838155746.\n",
      "Epoch:1, weight train batch: 22, step:14, loss before: 0.0137530975044, loss after: 0.0137013681233.\n",
      "Epoch:1, weight train batch: 22, step:15, loss before: 0.0140364086255, loss after: 0.0139833688736.\n",
      "Epoch:1, weight train batch: 22, step:16, loss before: 0.0124666858464, loss after: 0.0124195422977.\n",
      "Epoch:1, weight train batch: 22, step:17, loss before: 0.0132419615984, loss after: 0.0131991561502.\n",
      "Epoch:1, weight train batch: 22, step:18, loss before: 0.0124264992774, loss after: 0.0123795941472.\n",
      "Epoch:1, weight train batch: 22, step:19, loss before: 0.0112767629325, loss after: 0.0112337293103.\n",
      "Epoch:1, weight train batch: 22, step:20, loss before: 0.00943488813937, loss after: 0.00940097589046.\n",
      "Epoch:1, weight train batch: 22, step:21, loss before: 0.0107820108533, loss after: 0.0107441954315.\n",
      "Epoch:1, weight train batch: 22, step:22, loss before: 0.0135420626029, loss after: 0.0134911462665.\n",
      "Epoch:1, weight train batch: 22, step:23, loss before: 0.0117162577808, loss after: 0.0116689819843.\n",
      "Epoch:1, weight train batch: 22, step:24, loss before: 0.00970770604908, loss after: 0.00967547297478.\n",
      "Epoch:1, weight train batch: 22, step:25, loss before: 0.0106778461486, loss after: 0.0106391776353.\n",
      "Epoch:1, weight train batch: 22, step:26, loss before: 0.0113550107926, loss after: 0.0113137206063.\n",
      "Epoch:1, weight train batch: 22, step:27, loss before: 0.0127584151924, loss after: 0.0127101549879.\n",
      "Epoch:1, weight train batch: 22, step:28, loss before: 0.0105149494484, loss after: 0.0104761794209.\n",
      "Epoch:1, weight train batch: 22, step:29, loss before: 0.0112693607807, loss after: 0.0112305665389.\n",
      "Epoch:1, weight train batch: 22, step:30, loss before: 0.0100571550429, loss after: 0.0100195463747.\n",
      "Epoch:1, weight train batch: 22, step:31, loss before: 0.0132366614416, loss after: 0.0131865823641.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 18, loss before: 0.0114552089944, loss after: 0.0114607438445.\n",
      "Epoch:1, weight train batch: 23, step:0, loss before: 0.0101778823882, loss after: 0.0101420711726.\n",
      "Epoch:1, weight train batch: 23, step:1, loss before: 0.0118241496384, loss after: 0.0117820072919.\n",
      "Epoch:1, weight train batch: 23, step:2, loss before: 0.0116736590862, loss after: 0.0116322459653.\n",
      "Epoch:1, weight train batch: 23, step:3, loss before: 0.0114027466625, loss after: 0.0113604273647.\n",
      "Epoch:1, weight train batch: 23, step:4, loss before: 0.0123522169888, loss after: 0.012305509299.\n",
      "Epoch:1, weight train batch: 23, step:5, loss before: 0.0129425451159, loss after: 0.012892560102.\n",
      "Epoch:1, weight train batch: 23, step:6, loss before: 0.0125122107565, loss after: 0.0124630536884.\n",
      "Epoch:1, weight train batch: 23, step:7, loss before: 0.0104372482747, loss after: 0.0104004237801.\n",
      "Epoch:1, weight train batch: 23, step:8, loss before: 0.0110734459013, loss after: 0.0110329501331.\n",
      "Epoch:1, weight train batch: 23, step:9, loss before: 0.0102529516444, loss after: 0.0102144246921.\n",
      "Epoch:1, weight train batch: 23, step:10, loss before: 0.00928532052785, loss after: 0.00925127230585.\n",
      "Epoch:1, weight train batch: 23, step:11, loss before: 0.0104137323797, loss after: 0.0103737488389.\n",
      "Epoch:1, weight train batch: 23, step:12, loss before: 0.00972276367247, loss after: 0.00968737248331.\n",
      "Epoch:1, weight train batch: 23, step:13, loss before: 0.00889430753887, loss after: 0.0088632972911.\n",
      "Epoch:1, weight train batch: 23, step:14, loss before: 0.0102158561349, loss after: 0.0101794973016.\n",
      "Epoch:1, weight train batch: 23, step:15, loss before: 0.0103051625192, loss after: 0.0102703105658.\n",
      "Epoch:1, weight train batch: 23, step:16, loss before: 0.00997199676931, loss after: 0.00993742607534.\n",
      "Epoch:1, weight train batch: 23, step:17, loss before: 0.00983534380794, loss after: 0.00980358757079.\n",
      "Epoch:1, weight train batch: 23, step:18, loss before: 0.00989531073719, loss after: 0.00986284110695.\n",
      "Epoch:1, weight train batch: 23, step:19, loss before: 0.010267984122, loss after: 0.0102338651195.\n",
      "Epoch:1, weight train batch: 23, step:20, loss before: 0.00837065186352, loss after: 0.00834291800857.\n",
      "Epoch:1, weight train batch: 23, step:21, loss before: 0.00929575413465, loss after: 0.00926497392356.\n",
      "Epoch:1, weight train batch: 23, step:22, loss before: 0.00973423197865, loss after: 0.00970168132335.\n",
      "Epoch:1, weight train batch: 23, step:23, loss before: 0.0106672989205, loss after: 0.0106304334477.\n",
      "Epoch:1, weight train batch: 23, step:24, loss before: 0.00970000401139, loss after: 0.00966804288328.\n",
      "Epoch:1, weight train batch: 23, step:25, loss before: 0.00950613245368, loss after: 0.00947513990104.\n",
      "Epoch:1, weight train batch: 23, step:26, loss before: 0.00987489707768, loss after: 0.00984222441912.\n",
      "Epoch:1, weight train batch: 23, step:27, loss before: 0.00969805195928, loss after: 0.00966635346413.\n",
      "Epoch:1, weight train batch: 23, step:28, loss before: 0.00901122204959, loss after: 0.00898183323443.\n",
      "Epoch:1, weight train batch: 23, step:29, loss before: 0.0109226740897, loss after: 0.010888167657.\n",
      "Epoch:1, weight train batch: 23, step:30, loss before: 0.00985257327557, loss after: 0.00981961749494.\n",
      "Epoch:1, weight train batch: 23, step:31, loss before: 0.0104912035167, loss after: 0.0104549909011.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 19, loss before: 0.0102135101333, loss after: 0.00999654363841.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, weight train batch: 24, step:0, loss before: 0.0101884566247, loss after: 0.0101549718529.\n",
      "Epoch:1, weight train batch: 24, step:1, loss before: 0.00941018387675, loss after: 0.00937870983034.\n",
      "Epoch:1, weight train batch: 24, step:2, loss before: 0.00983320176601, loss after: 0.00980032235384.\n",
      "Epoch:1, weight train batch: 24, step:3, loss before: 0.0100324936211, loss after: 0.00999917089939.\n",
      "Epoch:1, weight train batch: 24, step:4, loss before: 0.00778713729233, loss after: 0.00776141136885.\n",
      "Epoch:1, weight train batch: 24, step:5, loss before: 0.00744626484811, loss after: 0.00742186047137.\n",
      "Epoch:1, weight train batch: 24, step:6, loss before: 0.00989504437894, loss after: 0.00986316986382.\n",
      "Epoch:1, weight train batch: 24, step:7, loss before: 0.00811082683504, loss after: 0.00808335840702.\n",
      "Epoch:1, weight train batch: 24, step:8, loss before: 0.0089456634596, loss after: 0.00891873613.\n",
      "Epoch:1, weight train batch: 24, step:9, loss before: 0.00876363366842, loss after: 0.00873594731092.\n",
      "Epoch:1, weight train batch: 24, step:10, loss before: 0.00981164909899, loss after: 0.00978127121925.\n",
      "Epoch:1, weight train batch: 24, step:11, loss before: 0.00852470472455, loss after: 0.00849690008909.\n",
      "Epoch:1, weight train batch: 24, step:12, loss before: 0.0605316013098, loss after: 0.0604725405574.\n",
      "Epoch:1, weight train batch: 24, step:13, loss before: 0.00781175168231, loss after: 0.00778684252873.\n",
      "Epoch:1, weight train batch: 24, step:14, loss before: 0.010066033341, loss after: 0.0100328577682.\n",
      "Epoch:1, weight train batch: 24, step:15, loss before: 0.0116382176057, loss after: 0.0116060459986.\n",
      "Epoch:1, weight train batch: 24, step:16, loss before: 0.00861716456711, loss after: 0.00859194248915.\n",
      "Epoch:1, weight train batch: 24, step:17, loss before: 0.00937978457659, loss after: 0.0093496479094.\n",
      "Epoch:1, weight train batch: 24, step:18, loss before: 0.00983603671193, loss after: 0.00980189535767.\n",
      "Epoch:1, weight train batch: 24, step:19, loss before: 0.00727700348943, loss after: 0.00725284218788.\n",
      "Epoch:1, weight train batch: 24, step:20, loss before: 0.010126623325, loss after: 0.0100952852517.\n",
      "Epoch:1, weight train batch: 24, step:21, loss before: 0.00899815745652, loss after: 0.00896994769573.\n",
      "Epoch:1, weight train batch: 24, step:22, loss before: 0.00855819694698, loss after: 0.00853132270277.\n",
      "Epoch:1, weight train batch: 24, step:23, loss before: 0.00918287970126, loss after: 0.00915412418544.\n",
      "Epoch:1, weight train batch: 24, step:24, loss before: 0.00978475995362, loss after: 0.00975378416479.\n",
      "Epoch:1, weight train batch: 24, step:25, loss before: 0.00815610960126, loss after: 0.00813004374504.\n",
      "Epoch:1, weight train batch: 24, step:26, loss before: 0.00832096114755, loss after: 0.00829468201846.\n",
      "Epoch:1, weight train batch: 24, step:27, loss before: 0.00867916084826, loss after: 0.00865164957941.\n",
      "Epoch:1, weight train batch: 24, step:28, loss before: 0.00830187648535, loss after: 0.00827513821423.\n",
      "Epoch:1, weight train batch: 24, step:29, loss before: 0.00867400877178, loss after: 0.00864671729505.\n",
      "Epoch:1, weight train batch: 24, step:30, loss before: 0.00929894670844, loss after: 0.0092690801248.\n",
      "Epoch:1, weight train batch: 24, step:31, loss before: 0.00789822824299, loss after: 0.00787323713303.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 20, loss before: 0.00901077874005, loss after: 0.00838620215654.\n",
      "Epoch:1, weight train batch: 25, step:0, loss before: 0.00865912530571, loss after: 0.00863183289766.\n",
      "Epoch:1, weight train batch: 25, step:1, loss before: 0.0187501180917, loss after: 0.0187149010599.\n",
      "Epoch:1, weight train batch: 25, step:2, loss before: 0.00736955273896, loss after: 0.00734643358737.\n",
      "Epoch:1, weight train batch: 25, step:3, loss before: 0.00870468467474, loss after: 0.00867761019617.\n",
      "Epoch:1, weight train batch: 25, step:4, loss before: 0.00781299546361, loss after: 0.0077891536057.\n",
      "Epoch:1, weight train batch: 25, step:5, loss before: 0.010021481663, loss after: 0.0099906520918.\n",
      "Epoch:1, weight train batch: 25, step:6, loss before: 0.00770181324333, loss after: 0.00767736183479.\n",
      "Epoch:1, weight train batch: 25, step:7, loss before: 0.00792463868856, loss after: 0.00790032185614.\n",
      "Epoch:1, weight train batch: 25, step:8, loss before: 0.00792914070189, loss after: 0.00790423434228.\n",
      "Epoch:1, weight train batch: 25, step:9, loss before: 0.00812914408743, loss after: 0.00810278393328.\n",
      "Epoch:1, weight train batch: 25, step:10, loss before: 0.00911324936897, loss after: 0.00908483378589.\n",
      "Epoch:1, weight train batch: 25, step:11, loss before: 0.0083926897496, loss after: 0.00836676731706.\n",
      "Epoch:1, weight train batch: 25, step:12, loss before: 0.00851532071829, loss after: 0.00849034450948.\n",
      "Epoch:1, weight train batch: 25, step:13, loss before: 0.00947744771838, loss after: 0.0094479136169.\n",
      "Epoch:1, weight train batch: 25, step:14, loss before: 0.0090764798224, loss after: 0.00904814433306.\n",
      "Epoch:1, weight train batch: 25, step:15, loss before: 0.00821772031486, loss after: 0.00819167960435.\n",
      "Epoch:1, weight train batch: 25, step:16, loss before: 0.00933348946273, loss after: 0.00930339843035.\n",
      "Epoch:1, weight train batch: 25, step:17, loss before: 0.00936354510486, loss after: 0.00933325011283.\n",
      "Epoch:1, weight train batch: 25, step:18, loss before: 0.00883713830262, loss after: 0.00880965124816.\n",
      "Epoch:1, weight train batch: 25, step:19, loss before: 0.00668567419052, loss after: 0.00666528847069.\n",
      "Epoch:1, weight train batch: 25, step:20, loss before: 0.00828446634114, loss after: 0.00825948081911.\n",
      "Epoch:1, weight train batch: 25, step:21, loss before: 0.0078290887177, loss after: 0.00780485477298.\n",
      "Epoch:1, weight train batch: 25, step:22, loss before: 0.00810609664768, loss after: 0.00808052252978.\n",
      "Epoch:1, weight train batch: 25, step:23, loss before: 0.0077803065069, loss after: 0.00775597477332.\n",
      "Epoch:1, weight train batch: 25, step:24, loss before: 0.00868403259665, loss after: 0.00865717884153.\n",
      "Epoch:1, weight train batch: 25, step:25, loss before: 0.00846994761378, loss after: 0.00844367034733.\n",
      "Epoch:1, weight train batch: 25, step:26, loss before: 0.00897011719644, loss after: 0.00894525647163.\n",
      "Epoch:1, weight train batch: 25, step:27, loss before: 0.00831670779735, loss after: 0.00829123705626.\n",
      "Epoch:1, weight train batch: 25, step:28, loss before: 0.00747612025589, loss after: 0.00745343137532.\n",
      "Epoch:1, weight train batch: 25, step:29, loss before: 0.00823005475104, loss after: 0.00820466689765.\n",
      "Epoch:1, weight train batch: 25, step:30, loss before: 0.00732115888968, loss after: 0.00729933474213.\n",
      "Epoch:1, weight train batch: 25, step:31, loss before: 0.00781780201942, loss after: 0.00779391638935.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 21, loss before: 0.00784614682198, loss after: 0.00766366347671.\n",
      "Epoch:1, weight train batch: 26, step:0, loss before: 0.00765403639525, loss after: 0.00763056240976.\n",
      "Epoch:1, weight train batch: 26, step:1, loss before: 0.0079250773415, loss after: 0.00790050067008.\n",
      "Epoch:1, weight train batch: 26, step:2, loss before: 0.00780414696783, loss after: 0.0077809211798.\n",
      "Epoch:1, weight train batch: 26, step:3, loss before: 0.0081829149276, loss after: 0.00815945118666.\n",
      "Epoch:1, weight train batch: 26, step:4, loss before: 0.00785321369767, loss after: 0.0078295096755.\n",
      "Epoch:1, weight train batch: 26, step:5, loss before: 0.00828464981169, loss after: 0.00825940351933.\n",
      "Epoch:1, weight train batch: 26, step:6, loss before: 0.00836005900055, loss after: 0.00833430141211.\n",
      "Epoch:1, weight train batch: 26, step:7, loss before: 0.00722112692893, loss after: 0.00719953374937.\n",
      "Epoch:1, weight train batch: 26, step:8, loss before: 0.00679797073826, loss after: 0.00677714124322.\n",
      "Epoch:1, weight train batch: 26, step:9, loss before: 0.00844446290284, loss after: 0.0084187630564.\n",
      "Epoch:1, weight train batch: 26, step:10, loss before: 0.00810473132879, loss after: 0.00808064080775.\n",
      "Epoch:1, weight train batch: 26, step:11, loss before: 0.00630898028612, loss after: 0.00629084743559.\n",
      "Epoch:1, weight train batch: 26, step:12, loss before: 0.00730354851112, loss after: 0.00728195626289.\n",
      "Epoch:1, weight train batch: 26, step:13, loss before: 0.00654418952763, loss after: 0.00652507226914.\n",
      "Epoch:1, weight train batch: 26, step:14, loss before: 0.00668833451346, loss after: 0.00666883634403.\n",
      "Epoch:1, weight train batch: 26, step:15, loss before: 0.00905452203006, loss after: 0.00902765803039.\n",
      "Epoch:1, weight train batch: 26, step:16, loss before: 0.0080079799518, loss after: 0.00798301678151.\n",
      "Epoch:1, weight train batch: 26, step:17, loss before: 0.0060856374912, loss after: 0.00606817472726.\n",
      "Epoch:1, weight train batch: 26, step:18, loss before: 0.0079437000677, loss after: 0.0079212281853.\n",
      "Epoch:1, weight train batch: 26, step:19, loss before: 0.00694526685402, loss after: 0.00692591164261.\n",
      "Epoch:1, weight train batch: 26, step:20, loss before: 0.00814217980951, loss after: 0.00811868906021.\n",
      "Epoch:1, weight train batch: 26, step:21, loss before: 0.00716912001371, loss after: 0.00714787468314.\n",
      "Epoch:1, weight train batch: 26, step:22, loss before: 0.00847072992474, loss after: 0.00844396091998.\n",
      "Epoch:1, weight train batch: 26, step:23, loss before: 0.00696704071015, loss after: 0.00694554019719.\n",
      "Epoch:1, weight train batch: 26, step:24, loss before: 0.00632779765874, loss after: 0.00631002197042.\n",
      "Epoch:1, weight train batch: 26, step:25, loss before: 0.00696418527514, loss after: 0.00694522727281.\n",
      "Epoch:1, weight train batch: 26, step:26, loss before: 0.00588482106104, loss after: 0.00586804701015.\n",
      "Epoch:1, weight train batch: 26, step:27, loss before: 0.00718895532191, loss after: 0.00716835260391.\n",
      "Epoch:1, weight train batch: 26, step:28, loss before: 0.00729597639292, loss after: 0.00727487169206.\n",
      "Epoch:1, weight train batch: 26, step:29, loss before: 0.00794239994138, loss after: 0.00792037881911.\n",
      "Epoch:1, weight train batch: 26, step:30, loss before: 0.00680144783109, loss after: 0.00678190821782.\n",
      "Epoch:1, weight train batch: 26, step:31, loss before: 0.0087965792045, loss after: 0.00877059437335.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, struct parameters train batch: 22, loss before: 0.00843098852783, loss after: 0.00665060430765.\n",
      "Epoch:1, weight train batch: 27, step:0, loss before: 0.00720528978854, loss after: 0.00718463677913.\n",
      "Epoch:1, weight train batch: 27, step:1, loss before: 0.007891879417, loss after: 0.00786877702922.\n",
      "Epoch:1, weight train batch: 27, step:2, loss before: 0.0075647206977, loss after: 0.00754209514707.\n",
      "Epoch:1, weight train batch: 27, step:3, loss before: 0.0063388296403, loss after: 0.00632089702412.\n",
      "Epoch:1, weight train batch: 27, step:4, loss before: 0.00800461135805, loss after: 0.00798220280558.\n",
      "Epoch:1, weight train batch: 27, step:5, loss before: 0.00761906569824, loss after: 0.00759746041149.\n",
      "Epoch:1, weight train batch: 27, step:6, loss before: 0.00692350044847, loss after: 0.00690322136506.\n",
      "Epoch:1, weight train batch: 27, step:7, loss before: 0.00664178933948, loss after: 0.00662217941135.\n",
      "Epoch:1, weight train batch: 27, step:8, loss before: 0.00685101049021, loss after: 0.00683108437806.\n",
      "Epoch:1, weight train batch: 27, step:9, loss before: 0.0075292987749, loss after: 0.00750714819878.\n",
      "Epoch:1, weight train batch: 27, step:10, loss before: 0.00727807870135, loss after: 0.00725624524057.\n",
      "Epoch:1, weight train batch: 27, step:11, loss before: 0.00661018304527, loss after: 0.00659135077149.\n",
      "Epoch:1, weight train batch: 27, step:12, loss before: 0.00663529755548, loss after: 0.00661684107035.\n",
      "Epoch:1, weight train batch: 27, step:13, loss before: 0.00727107562125, loss after: 0.00725069735199.\n",
      "Epoch:1, weight train batch: 27, step:14, loss before: 0.00636891508475, loss after: 0.00635085627437.\n",
      "Epoch:1, weight train batch: 27, step:15, loss before: 0.00720595940948, loss after: 0.00718480022624.\n",
      "Epoch:1, weight train batch: 27, step:16, loss before: 0.00613601272926, loss after: 0.00611842796206.\n",
      "Epoch:1, weight train batch: 27, step:17, loss before: 0.00697302212939, loss after: 0.0069532818161.\n",
      "Epoch:1, weight train batch: 27, step:18, loss before: 0.00925235264003, loss after: 0.00922832544893.\n",
      "Epoch:1, weight train batch: 27, step:19, loss before: 0.00773476902395, loss after: 0.00771283637732.\n",
      "Epoch:1, weight train batch: 27, step:20, loss before: 0.00694128824398, loss after: 0.00692086946219.\n",
      "Epoch:1, weight train batch: 27, step:21, loss before: 0.00617101695389, loss after: 0.00615232810378.\n",
      "Epoch:1, weight train batch: 27, step:22, loss before: 0.00826010666788, loss after: 0.00823453068733.\n",
      "Epoch:1, weight train batch: 27, step:23, loss before: 0.0067821117118, loss after: 0.00676309224218.\n",
      "Epoch:1, weight train batch: 27, step:24, loss before: 0.00787229277194, loss after: 0.00785396248102.\n",
      "Epoch:1, weight train batch: 27, step:25, loss before: 0.00741233956069, loss after: 0.0073911100626.\n",
      "Epoch:1, weight train batch: 27, step:26, loss before: 0.0073900623247, loss after: 0.00736883003265.\n",
      "Epoch:1, weight train batch: 27, step:27, loss before: 0.00598302483559, loss after: 0.00596546754241.\n",
      "Epoch:1, weight train batch: 27, step:28, loss before: 0.00722175231203, loss after: 0.00720127858222.\n",
      "Epoch:1, weight train batch: 27, step:29, loss before: 0.0066692372784, loss after: 0.00665027834475.\n",
      "Epoch:1, weight train batch: 27, step:30, loss before: 0.00668066740036, loss after: 0.00666122045368.\n",
      "Epoch:1, weight train batch: 27, step:31, loss before: 0.00650628330186, loss after: 0.00648756651208.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 23, loss before: 0.00645804218948, loss after: 0.00646196398884.\n",
      "Epoch:1, weight train batch: 28, step:0, loss before: 0.00648925313726, loss after: 0.00647082133219.\n",
      "Epoch:1, weight train batch: 28, step:1, loss before: 0.00557247502729, loss after: 0.00555689167231.\n",
      "Epoch:1, weight train batch: 28, step:2, loss before: 0.00609703967348, loss after: 0.00607961788774.\n",
      "Epoch:1, weight train batch: 28, step:3, loss before: 0.00750712351874, loss after: 0.00748628890142.\n",
      "Epoch:1, weight train batch: 28, step:4, loss before: 0.00568071193993, loss after: 0.00566519796848.\n",
      "Epoch:1, weight train batch: 28, step:5, loss before: 0.0055057676509, loss after: 0.00548996450379.\n",
      "Epoch:1, weight train batch: 28, step:6, loss before: 0.00610598362982, loss after: 0.00608936930075.\n",
      "Epoch:1, weight train batch: 28, step:7, loss before: 0.00618977705017, loss after: 0.00617256527767.\n",
      "Epoch:1, weight train batch: 28, step:8, loss before: 0.0066755656153, loss after: 0.0066569307819.\n",
      "Epoch:1, weight train batch: 28, step:9, loss before: 0.0070993588306, loss after: 0.00707837147638.\n",
      "Epoch:1, weight train batch: 28, step:10, loss before: 0.00702392263338, loss after: 0.00700547918677.\n",
      "Epoch:1, weight train batch: 28, step:11, loss before: 0.0058777499944, loss after: 0.00586184859276.\n",
      "Epoch:1, weight train batch: 28, step:12, loss before: 0.00621565058827, loss after: 0.0061981738545.\n",
      "Epoch:1, weight train batch: 28, step:13, loss before: 0.00635003019124, loss after: 0.00633225403726.\n",
      "Epoch:1, weight train batch: 28, step:14, loss before: 0.00617870129645, loss after: 0.00616225879639.\n",
      "Epoch:1, weight train batch: 28, step:15, loss before: 0.00607183156535, loss after: 0.00605549011379.\n",
      "Epoch:1, weight train batch: 28, step:16, loss before: 0.00630689132959, loss after: 0.00629020435736.\n",
      "Epoch:1, weight train batch: 28, step:17, loss before: 0.00663474015892, loss after: 0.00661640055478.\n",
      "Epoch:1, weight train batch: 28, step:18, loss before: 0.00599423423409, loss after: 0.00597754586488.\n",
      "Epoch:1, weight train batch: 28, step:19, loss before: 0.0058975177817, loss after: 0.00588104967028.\n",
      "Epoch:1, weight train batch: 28, step:20, loss before: 0.00607815291733, loss after: 0.00606144592166.\n",
      "Epoch:1, weight train batch: 28, step:21, loss before: 0.00664682453498, loss after: 0.00662892218679.\n",
      "Epoch:1, weight train batch: 28, step:22, loss before: 0.00588567648083, loss after: 0.00586980907246.\n",
      "Epoch:1, weight train batch: 28, step:23, loss before: 0.00654806476086, loss after: 0.00653065601364.\n",
      "Epoch:1, weight train batch: 28, step:24, loss before: 0.00656272470951, loss after: 0.00654453830793.\n",
      "Epoch:1, weight train batch: 28, step:25, loss before: 0.0138524863869, loss after: 0.0138310305774.\n",
      "Epoch:1, weight train batch: 28, step:26, loss before: 0.00601788051426, loss after: 0.00600150041282.\n",
      "Epoch:1, weight train batch: 28, step:27, loss before: 0.00639006868005, loss after: 0.00637163408101.\n",
      "Epoch:1, weight train batch: 28, step:28, loss before: 0.00544486194849, loss after: 0.00543005485088.\n",
      "Epoch:1, weight train batch: 28, step:29, loss before: 0.00669122952968, loss after: 0.00667186826468.\n",
      "Epoch:1, weight train batch: 28, step:30, loss before: 0.00528829544783, loss after: 0.00527434702963.\n",
      "Epoch:1, weight train batch: 28, step:31, loss before: 0.00556441303343, loss after: 0.00555005809292.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 24, loss before: 0.00572648085654, loss after: 0.00580842653289.\n",
      "Epoch:1, weight train batch: 29, step:0, loss before: 0.0061063892208, loss after: 0.00609034625813.\n",
      "Epoch:1, weight train batch: 29, step:1, loss before: 0.00531034916639, loss after: 0.00529619585723.\n",
      "Epoch:1, weight train batch: 29, step:2, loss before: 0.00577240157872, loss after: 0.00575689179823.\n",
      "Epoch:1, weight train batch: 29, step:3, loss before: 0.00625437218696, loss after: 0.00623724283651.\n",
      "Epoch:1, weight train batch: 29, step:4, loss before: 0.00617938302457, loss after: 0.0061626159586.\n",
      "Epoch:1, weight train batch: 29, step:5, loss before: 0.00632275315002, loss after: 0.00630536675453.\n",
      "Epoch:1, weight train batch: 29, step:6, loss before: 0.0058655301109, loss after: 0.005849564448.\n",
      "Epoch:1, weight train batch: 29, step:7, loss before: 0.0059650875628, loss after: 0.00594905391335.\n",
      "Epoch:1, weight train batch: 29, step:8, loss before: 0.0056085861288, loss after: 0.00559364864603.\n",
      "Epoch:1, weight train batch: 29, step:9, loss before: 0.00658035837114, loss after: 0.00656212214381.\n",
      "Epoch:1, weight train batch: 29, step:10, loss before: 0.00617258716375, loss after: 0.00615541543812.\n",
      "Epoch:1, weight train batch: 29, step:11, loss before: 0.00596261024475, loss after: 0.0059463661164.\n",
      "Epoch:1, weight train batch: 29, step:12, loss before: 0.00598236778751, loss after: 0.00596693065017.\n",
      "Epoch:1, weight train batch: 29, step:13, loss before: 0.00589454825968, loss after: 0.00587852997705.\n",
      "Epoch:1, weight train batch: 29, step:14, loss before: 0.00634348904714, loss after: 0.00632599182427.\n",
      "Epoch:1, weight train batch: 29, step:15, loss before: 0.00547147169709, loss after: 0.00545710511506.\n",
      "Epoch:1, weight train batch: 29, step:16, loss before: 0.00534820882604, loss after: 0.0053340299055.\n",
      "Epoch:1, weight train batch: 29, step:17, loss before: 0.00614761048928, loss after: 0.00613082246855.\n",
      "Epoch:1, weight train batch: 29, step:18, loss before: 0.00470864959061, loss after: 0.00469607673585.\n",
      "Epoch:1, weight train batch: 29, step:19, loss before: 0.00578911788762, loss after: 0.00577345723286.\n",
      "Epoch:1, weight train batch: 29, step:20, loss before: 0.00578968599439, loss after: 0.00577466888353.\n",
      "Epoch:1, weight train batch: 29, step:21, loss before: 0.00475673936307, loss after: 0.00474421819672.\n",
      "Epoch:1, weight train batch: 29, step:22, loss before: 0.00599721446633, loss after: 0.00598181877285.\n",
      "Epoch:1, weight train batch: 29, step:23, loss before: 0.00659871660173, loss after: 0.00658502103761.\n",
      "Epoch:1, weight train batch: 29, step:24, loss before: 0.00538928061724, loss after: 0.00537534616888.\n",
      "Epoch:1, weight train batch: 29, step:25, loss before: 0.00624538352713, loss after: 0.00622935360298.\n",
      "Epoch:1, weight train batch: 29, step:26, loss before: 0.00546437967569, loss after: 0.00545019377023.\n",
      "Epoch:1, weight train batch: 29, step:27, loss before: 0.0055560967885, loss after: 0.00554174371064.\n",
      "Epoch:1, weight train batch: 29, step:28, loss before: 0.00539712468162, loss after: 0.00538333132863.\n",
      "Epoch:1, weight train batch: 29, step:29, loss before: 0.00503967981786, loss after: 0.00502651790157.\n",
      "Epoch:1, weight train batch: 29, step:30, loss before: 0.00553491292521, loss after: 0.00552086392418.\n",
      "Epoch:1, weight train batch: 29, step:31, loss before: 0.00616210978478, loss after: 0.00614596065134.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 25, loss before: 0.00546143529937, loss after: 0.00560919102281.\n",
      "Epoch:1, weight train batch: 30, step:0, loss before: 0.00578578468412, loss after: 0.00577070284635.\n",
      "Epoch:1, weight train batch: 30, step:1, loss before: 0.00527778733522, loss after: 0.00526468735188.\n",
      "Epoch:1, weight train batch: 30, step:2, loss before: 0.00505980616435, loss after: 0.00504684075713.\n",
      "Epoch:1, weight train batch: 30, step:3, loss before: 0.00503969658166, loss after: 0.00502662127838.\n",
      "Epoch:1, weight train batch: 30, step:4, loss before: 0.00592630822212, loss after: 0.00591093953699.\n",
      "Epoch:1, weight train batch: 30, step:5, loss before: 0.00619103293866, loss after: 0.0061748912558.\n",
      "Epoch:1, weight train batch: 30, step:6, loss before: 0.00627792766318, loss after: 0.00626223534346.\n",
      "Epoch:1, weight train batch: 30, step:7, loss before: 0.00475120591, loss after: 0.00473910849541.\n",
      "Epoch:1, weight train batch: 30, step:8, loss before: 0.006576243788, loss after: 0.00655922899023.\n",
      "Epoch:1, weight train batch: 30, step:9, loss before: 0.00465395115316, loss after: 0.00464183650911.\n",
      "Epoch:1, weight train batch: 30, step:10, loss before: 0.00600574351847, loss after: 0.00599026307464.\n",
      "Epoch:1, weight train batch: 30, step:11, loss before: 0.00555400596932, loss after: 0.00553961703554.\n",
      "Epoch:1, weight train batch: 30, step:12, loss before: 0.00500136194751, loss after: 0.00498842773959.\n",
      "Epoch:1, weight train batch: 30, step:13, loss before: 0.00586641114205, loss after: 0.00585059355944.\n",
      "Epoch:1, weight train batch: 30, step:14, loss before: 0.00531341647729, loss after: 0.0052990950644.\n",
      "Epoch:1, weight train batch: 30, step:15, loss before: 0.00440928060561, loss after: 0.00439846236259.\n",
      "Epoch:1, weight train batch: 30, step:16, loss before: 0.00600285641849, loss after: 0.00598726421595.\n",
      "Epoch:1, weight train batch: 30, step:17, loss before: 0.00582847371697, loss after: 0.00581315532327.\n",
      "Epoch:1, weight train batch: 30, step:18, loss before: 0.00481442408636, loss after: 0.00480170641094.\n",
      "Epoch:1, weight train batch: 30, step:19, loss before: 0.00531478226185, loss after: 0.00530038634315.\n",
      "Epoch:1, weight train batch: 30, step:20, loss before: 0.00672832503915, loss after: 0.00671290885657.\n",
      "Epoch:1, weight train batch: 30, step:21, loss before: 0.0049875904806, loss after: 0.0049751913175.\n",
      "Epoch:1, weight train batch: 30, step:22, loss before: 0.00541419163346, loss after: 0.0054005747661.\n",
      "Epoch:1, weight train batch: 30, step:23, loss before: 0.00451886560768, loss after: 0.00450721848756.\n",
      "Epoch:1, weight train batch: 30, step:24, loss before: 0.00518164969981, loss after: 0.00516942515969.\n",
      "Epoch:1, weight train batch: 30, step:25, loss before: 0.00542267691344, loss after: 0.0054090982303.\n",
      "Epoch:1, weight train batch: 30, step:26, loss before: 0.00524447392672, loss after: 0.0052313064225.\n",
      "Epoch:1, weight train batch: 30, step:27, loss before: 0.00500818016008, loss after: 0.00499560218304.\n",
      "Epoch:1, weight train batch: 30, step:28, loss before: 0.0048038624227, loss after: 0.0047919829376.\n",
      "Epoch:1, weight train batch: 30, step:29, loss before: 0.00413642078638, loss after: 0.00412627495825.\n",
      "Epoch:1, weight train batch: 30, step:30, loss before: 0.00501994555816, loss after: 0.00500754453242.\n",
      "Epoch:1, weight train batch: 30, step:31, loss before: 0.0048165358603, loss after: 0.00480452692136.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 26, loss before: 0.00523435417563, loss after: 0.00513807032257.\n",
      "Epoch:1, weight train batch: 31, step:0, loss before: 0.00520437350497, loss after: 0.00519116595387.\n",
      "Epoch:1, weight train batch: 31, step:1, loss before: 0.00512602971867, loss after: 0.00511384941638.\n",
      "Epoch:1, weight train batch: 31, step:2, loss before: 0.00580642698333, loss after: 0.00579219870269.\n",
      "Epoch:1, weight train batch: 31, step:3, loss before: 0.00504361838102, loss after: 0.00503124529496.\n",
      "Epoch:1, weight train batch: 31, step:4, loss before: 0.00518385414034, loss after: 0.00517103727907.\n",
      "Epoch:1, weight train batch: 31, step:5, loss before: 0.00458636879921, loss after: 0.00457500154153.\n",
      "Epoch:1, weight train batch: 31, step:6, loss before: 0.00384203740396, loss after: 0.003832164919.\n",
      "Epoch:1, weight train batch: 31, step:7, loss before: 0.00533165549859, loss after: 0.00531836785376.\n",
      "Epoch:1, weight train batch: 31, step:8, loss before: 0.00458994088694, loss after: 0.00457872496918.\n",
      "Epoch:1, weight train batch: 31, step:9, loss before: 0.00447613745928, loss after: 0.0044658430852.\n",
      "Epoch:1, weight train batch: 31, step:10, loss before: 0.00499605759978, loss after: 0.00498386286199.\n",
      "Epoch:1, weight train batch: 31, step:11, loss before: 0.00519884796813, loss after: 0.00518663460389.\n",
      "Epoch:1, weight train batch: 31, step:12, loss before: 0.0075173615478, loss after: 0.00750113185495.\n",
      "Epoch:1, weight train batch: 31, step:13, loss before: 0.0049695908092, loss after: 0.00495731690899.\n",
      "Epoch:1, weight train batch: 31, step:14, loss before: 0.0048748748377, loss after: 0.00486269965768.\n",
      "Epoch:1, weight train batch: 31, step:15, loss before: 0.00444046128541, loss after: 0.00442936085165.\n",
      "Epoch:1, weight train batch: 31, step:16, loss before: 0.00737500889227, loss after: 0.00735926628113.\n",
      "Epoch:1, weight train batch: 31, step:17, loss before: 0.00439829099923, loss after: 0.00438756262884.\n",
      "Epoch:1, weight train batch: 31, step:18, loss before: 0.00502852816135, loss after: 0.00501632178202.\n",
      "Epoch:1, weight train batch: 31, step:19, loss before: 0.00528861675411, loss after: 0.00527567742392.\n",
      "Epoch:1, weight train batch: 31, step:20, loss before: 0.00418383907527, loss after: 0.00417329184711.\n",
      "Epoch:1, weight train batch: 31, step:21, loss before: 0.00456271925941, loss after: 0.00455127842724.\n",
      "Epoch:1, weight train batch: 31, step:22, loss before: 0.00451432960108, loss after: 0.00450302334502.\n",
      "Epoch:1, weight train batch: 31, step:23, loss before: 0.00395284593105, loss after: 0.0039430251345.\n",
      "Epoch:1, weight train batch: 31, step:24, loss before: 0.00494585605338, loss after: 0.00493448600173.\n",
      "Epoch:1, weight train batch: 31, step:25, loss before: 0.00486176321283, loss after: 0.0048504890874.\n",
      "Epoch:1, weight train batch: 31, step:26, loss before: 0.00592138431966, loss after: 0.00590898003429.\n",
      "Epoch:1, weight train batch: 31, step:27, loss before: 0.00447383429855, loss after: 0.00446319300681.\n",
      "Epoch:1, weight train batch: 31, step:28, loss before: 0.00523623451591, loss after: 0.00522333662957.\n",
      "Epoch:1, weight train batch: 31, step:29, loss before: 0.00445223785937, loss after: 0.00444143731147.\n",
      "Epoch:1, weight train batch: 31, step:30, loss before: 0.00481111556292, loss after: 0.00479945726693.\n",
      "Epoch:1, weight train batch: 31, step:31, loss before: 0.00415173824877, loss after: 0.00414191186428.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 27, loss before: 0.00497467350215, loss after: 0.00471258442849.\n",
      "Epoch:1, weight train batch: 32, step:0, loss before: 0.00439991429448, loss after: 0.0043892916292.\n",
      "Epoch:1, weight train batch: 32, step:1, loss before: 0.00502616912127, loss after: 0.00501370243728.\n",
      "Epoch:1, weight train batch: 32, step:2, loss before: 0.00430754898116, loss after: 0.0042974697426.\n",
      "Epoch:1, weight train batch: 32, step:3, loss before: 0.00500177592039, loss after: 0.00499016325921.\n",
      "Epoch:1, weight train batch: 32, step:4, loss before: 0.00496260030195, loss after: 0.00495126424357.\n",
      "Epoch:1, weight train batch: 32, step:5, loss before: 0.0041203671135, loss after: 0.00411046342924.\n",
      "Epoch:1, weight train batch: 32, step:6, loss before: 0.00441004289314, loss after: 0.00439976342022.\n",
      "Epoch:1, weight train batch: 32, step:7, loss before: 0.00483220536262, loss after: 0.00482070539147.\n",
      "Epoch:1, weight train batch: 32, step:8, loss before: 0.00424858834594, loss after: 0.00423836521804.\n",
      "Epoch:1, weight train batch: 32, step:9, loss before: 0.00486049801111, loss after: 0.00484884157777.\n",
      "Epoch:1, weight train batch: 32, step:10, loss before: 0.00510452734306, loss after: 0.00509262690321.\n",
      "Epoch:1, weight train batch: 32, step:11, loss before: 0.00425233924761, loss after: 0.00424259575084.\n",
      "Epoch:1, weight train batch: 32, step:12, loss before: 0.00495570618659, loss after: 0.00494405860081.\n",
      "Epoch:1, weight train batch: 32, step:13, loss before: 0.00418084207922, loss after: 0.00417105760425.\n",
      "Epoch:1, weight train batch: 32, step:14, loss before: 0.00403494853526, loss after: 0.00402558036149.\n",
      "Epoch:1, weight train batch: 32, step:15, loss before: 0.0218586288393, loss after: 0.0218400470912.\n",
      "Epoch:1, weight train batch: 32, step:16, loss before: 0.00488588400185, loss after: 0.00487369485199.\n",
      "Epoch:1, weight train batch: 32, step:17, loss before: 0.00472073163837, loss after: 0.00470901373774.\n",
      "Epoch:1, weight train batch: 32, step:18, loss before: 0.00491109164432, loss after: 0.00489865476266.\n",
      "Epoch:1, weight train batch: 32, step:19, loss before: 0.00467069027945, loss after: 0.00465893093497.\n",
      "Epoch:1, weight train batch: 32, step:20, loss before: 0.00447773747146, loss after: 0.00446648150682.\n",
      "Epoch:1, weight train batch: 32, step:21, loss before: 0.00379051687196, loss after: 0.00378153799102.\n",
      "Epoch:1, weight train batch: 32, step:22, loss before: 0.00454238243401, loss after: 0.0045316843316.\n",
      "Epoch:1, weight train batch: 32, step:23, loss before: 0.00457288511097, loss after: 0.00456227594987.\n",
      "Epoch:1, weight train batch: 32, step:24, loss before: 0.00497240992263, loss after: 0.00496033299714.\n",
      "Epoch:1, weight train batch: 32, step:25, loss before: 0.00466971751302, loss after: 0.0046580247581.\n",
      "Epoch:1, weight train batch: 32, step:26, loss before: 0.00525913294405, loss after: 0.00524757988751.\n",
      "Epoch:1, weight train batch: 32, step:27, loss before: 0.00433246837929, loss after: 0.00432189693674.\n",
      "Epoch:1, weight train batch: 32, step:28, loss before: 0.00377681013197, loss after: 0.00376793416217.\n",
      "Epoch:1, weight train batch: 32, step:29, loss before: 0.00407269783318, loss after: 0.00406338181347.\n",
      "Epoch:1, weight train batch: 32, step:30, loss before: 0.00413695164025, loss after: 0.00412742560729.\n",
      "Epoch:1, weight train batch: 32, step:31, loss before: 0.00383404199965, loss after: 0.00382534391247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 28, loss before: 0.00414568791166, loss after: 0.00393957272172.\n",
      "Epoch:1, weight train batch: 33, step:0, loss before: 0.00651355041191, loss after: 0.00649951398373.\n",
      "Epoch:1, weight train batch: 33, step:1, loss before: 0.0045361276716, loss after: 0.00452534342185.\n",
      "Epoch:1, weight train batch: 33, step:2, loss before: 0.00670721149072, loss after: 0.00669407472014.\n",
      "Epoch:1, weight train batch: 33, step:3, loss before: 0.00390324997716, loss after: 0.00389372440986.\n",
      "Epoch:1, weight train batch: 33, step:4, loss before: 0.00434560794383, loss after: 0.00433505699039.\n",
      "Epoch:1, weight train batch: 33, step:5, loss before: 0.0038993076887, loss after: 0.00388999190181.\n",
      "Epoch:1, weight train batch: 33, step:6, loss before: 0.00409135315567, loss after: 0.00408172886819.\n",
      "Epoch:1, weight train batch: 33, step:7, loss before: 0.00403379648924, loss after: 0.00402408652008.\n",
      "Epoch:1, weight train batch: 33, step:8, loss before: 0.00454504322261, loss after: 0.00453444896266.\n",
      "Epoch:1, weight train batch: 33, step:9, loss before: 0.00520993489772, loss after: 0.00519931782037.\n",
      "Epoch:1, weight train batch: 33, step:10, loss before: 0.0044992826879, loss after: 0.00448877550662.\n",
      "Epoch:1, weight train batch: 33, step:11, loss before: 0.00439850287512, loss after: 0.00438801711425.\n",
      "Epoch:1, weight train batch: 33, step:12, loss before: 0.00436131143942, loss after: 0.00435091229156.\n",
      "Epoch:1, weight train batch: 33, step:13, loss before: 0.00426587369293, loss after: 0.00425611855462.\n",
      "Epoch:1, weight train batch: 33, step:14, loss before: 0.00448808353394, loss after: 0.00447769509628.\n",
      "Epoch:1, weight train batch: 33, step:15, loss before: 0.0034876766149, loss after: 0.00347954942845.\n",
      "Epoch:1, weight train batch: 33, step:16, loss before: 0.0551050491631, loss after: 0.0550450012088.\n",
      "Epoch:1, weight train batch: 33, step:17, loss before: 0.00522225443274, loss after: 0.00521413376555.\n",
      "Epoch:1, weight train batch: 33, step:18, loss before: 0.00421460391954, loss after: 0.004206945654.\n",
      "Epoch:1, weight train batch: 33, step:19, loss before: 0.00424740742892, loss after: 0.00423983996734.\n",
      "Epoch:1, weight train batch: 33, step:20, loss before: 0.00369188399054, loss after: 0.00368385249749.\n",
      "Epoch:1, weight train batch: 33, step:21, loss before: 0.00425540003926, loss after: 0.00424691103399.\n",
      "Epoch:1, weight train batch: 33, step:22, loss before: 0.00424140039831, loss after: 0.00423138029873.\n",
      "Epoch:1, weight train batch: 33, step:23, loss before: 0.00412840861827, loss after: 0.00411814916879.\n",
      "Epoch:1, weight train batch: 33, step:24, loss before: 0.00384628796019, loss after: 0.00383729417808.\n",
      "Epoch:1, weight train batch: 33, step:25, loss before: 0.00404961872846, loss after: 0.00404031714424.\n",
      "Epoch:1, weight train batch: 33, step:26, loss before: 0.00396239710972, loss after: 0.00395357236266.\n",
      "Epoch:1, weight train batch: 33, step:27, loss before: 0.00433644000441, loss after: 0.0043269447051.\n",
      "Epoch:1, weight train batch: 33, step:28, loss before: 0.00452942214906, loss after: 0.00451929308474.\n",
      "Epoch:1, weight train batch: 33, step:29, loss before: 0.00410235952586, loss after: 0.00409302953631.\n",
      "Epoch:1, weight train batch: 33, step:30, loss before: 0.00342774111778, loss after: 0.00342000974342.\n",
      "Epoch:1, weight train batch: 33, step:31, loss before: 0.0039049400948, loss after: 0.00389602314681.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 29, loss before: 0.00373875978403, loss after: 0.00367596466094.\n",
      "Epoch:1, weight train batch: 34, step:0, loss before: 0.0104524688795, loss after: 0.0104413423687.\n",
      "Epoch:1, weight train batch: 34, step:1, loss before: 0.00422019138932, loss after: 0.00421032775193.\n",
      "Epoch:1, weight train batch: 34, step:2, loss before: 0.00392240704969, loss after: 0.00391311757267.\n",
      "Epoch:1, weight train batch: 34, step:3, loss before: 0.00484058447182, loss after: 0.00482907239348.\n",
      "Epoch:1, weight train batch: 34, step:4, loss before: 0.00366950896569, loss after: 0.00366051355377.\n",
      "Epoch:1, weight train batch: 34, step:5, loss before: 0.00417880434543, loss after: 0.00416904408485.\n",
      "Epoch:1, weight train batch: 34, step:6, loss before: 0.00384676503018, loss after: 0.00383777497336.\n",
      "Epoch:1, weight train batch: 34, step:7, loss before: 0.00423596613109, loss after: 0.00422596093267.\n",
      "Epoch:1, weight train batch: 34, step:8, loss before: 0.00370044307783, loss after: 0.00369174033403.\n",
      "Epoch:1, weight train batch: 34, step:9, loss before: 0.00362513144501, loss after: 0.00361636443995.\n",
      "Epoch:1, weight train batch: 34, step:10, loss before: 0.00359456846491, loss after: 0.00358621543273.\n",
      "Epoch:1, weight train batch: 34, step:11, loss before: 0.00410008151084, loss after: 0.00409054430202.\n",
      "Epoch:1, weight train batch: 34, step:12, loss before: 0.00361600099131, loss after: 0.00360757019371.\n",
      "Epoch:1, weight train batch: 34, step:13, loss before: 0.0104518700391, loss after: 0.0104395477101.\n",
      "Epoch:1, weight train batch: 34, step:14, loss before: 0.00413324031979, loss after: 0.00412339251488.\n",
      "Epoch:1, weight train batch: 34, step:15, loss before: 0.00374056841247, loss after: 0.00373265706003.\n",
      "Epoch:1, weight train batch: 34, step:16, loss before: 0.00360562792048, loss after: 0.00359757989645.\n",
      "Epoch:1, weight train batch: 34, step:17, loss before: 0.0042981216684, loss after: 0.00428890297189.\n",
      "Epoch:1, weight train batch: 34, step:18, loss before: 0.00388989504427, loss after: 0.00388147984631.\n",
      "Epoch:1, weight train batch: 34, step:19, loss before: 0.0038445990067, loss after: 0.00383635400794.\n",
      "Epoch:1, weight train batch: 34, step:20, loss before: 0.00381856504828, loss after: 0.00380957429297.\n",
      "Epoch:1, weight train batch: 34, step:21, loss before: 0.00401565572247, loss after: 0.00400681979954.\n",
      "Epoch:1, weight train batch: 34, step:22, loss before: 0.00370589992963, loss after: 0.00369782419875.\n",
      "Epoch:1, weight train batch: 34, step:23, loss before: 0.00338268070482, loss after: 0.00337529205717.\n",
      "Epoch:1, weight train batch: 34, step:24, loss before: 0.00407599937171, loss after: 0.00406661909074.\n",
      "Epoch:1, weight train batch: 34, step:25, loss before: 0.00409505655989, loss after: 0.00408559385687.\n",
      "Epoch:1, weight train batch: 34, step:26, loss before: 0.00322516867891, loss after: 0.00321812322363.\n",
      "Epoch:1, weight train batch: 34, step:27, loss before: 0.00348098110408, loss after: 0.00347329140641.\n",
      "Epoch:1, weight train batch: 34, step:28, loss before: 0.00393215101212, loss after: 0.00392370019108.\n",
      "Epoch:1, weight train batch: 34, step:29, loss before: 0.00467013008893, loss after: 0.0046610860154.\n",
      "Epoch:1, weight train batch: 34, step:30, loss before: 0.0036129814107, loss after: 0.00360497739166.\n",
      "Epoch:1, weight train batch: 34, step:31, loss before: 0.00342783005908, loss after: 0.0034202428069.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 30, loss before: 0.00399612821639, loss after: 0.00387158896774.\n",
      "Epoch:1, weight train batch: 35, step:0, loss before: 0.00430503394455, loss after: 0.00429545342922.\n",
      "Epoch:1, weight train batch: 35, step:1, loss before: 0.00464418064803, loss after: 0.00463404273614.\n",
      "Epoch:1, weight train batch: 35, step:2, loss before: 0.00384539645165, loss after: 0.00383651722223.\n",
      "Epoch:1, weight train batch: 35, step:3, loss before: 0.00383017212152, loss after: 0.00382141163573.\n",
      "Epoch:1, weight train batch: 35, step:4, loss before: 0.00406975019723, loss after: 0.00406023999676.\n",
      "Epoch:1, weight train batch: 35, step:5, loss before: 0.00368655845523, loss after: 0.00367862265557.\n",
      "Epoch:1, weight train batch: 35, step:6, loss before: 0.00392922572792, loss after: 0.00392084382474.\n",
      "Epoch:1, weight train batch: 35, step:7, loss before: 0.00378946750425, loss after: 0.00378105859272.\n",
      "Epoch:1, weight train batch: 35, step:8, loss before: 0.0541116967797, loss after: 0.0540559142828.\n",
      "Epoch:1, weight train batch: 35, step:9, loss before: 0.00322904624045, loss after: 0.00322289206088.\n",
      "Epoch:1, weight train batch: 35, step:10, loss before: 0.00416757259518, loss after: 0.00415864866227.\n",
      "Epoch:1, weight train batch: 35, step:11, loss before: 0.00368036003783, loss after: 0.00367268035188.\n",
      "Epoch:1, weight train batch: 35, step:12, loss before: 0.00391840888187, loss after: 0.00390997063369.\n",
      "Epoch:1, weight train batch: 35, step:13, loss before: 0.00401087710634, loss after: 0.0040020281449.\n",
      "Epoch:1, weight train batch: 35, step:14, loss before: 0.00356916803867, loss after: 0.00356153771281.\n",
      "Epoch:1, weight train batch: 35, step:15, loss before: 0.00348225003108, loss after: 0.00347488932312.\n",
      "Epoch:1, weight train batch: 35, step:16, loss before: 0.00342816533521, loss after: 0.00342052290216.\n",
      "Epoch:1, weight train batch: 35, step:17, loss before: 0.00342856324278, loss after: 0.00342079508118.\n",
      "Epoch:1, weight train batch: 35, step:18, loss before: 0.00411395542324, loss after: 0.00410511996597.\n",
      "Epoch:1, weight train batch: 35, step:19, loss before: 0.00400193035603, loss after: 0.00399327464402.\n",
      "Epoch:1, weight train batch: 35, step:20, loss before: 0.0529577732086, loss after: 0.052866127342.\n",
      "Epoch:1, weight train batch: 35, step:21, loss before: 0.00309056416154, loss after: 0.00308384560049.\n",
      "Epoch:1, weight train batch: 35, step:22, loss before: 0.00370033178478, loss after: 0.00369361951016.\n",
      "Epoch:1, weight train batch: 35, step:23, loss before: 0.0033483626321, loss after: 0.00334238004871.\n",
      "Epoch:1, weight train batch: 35, step:24, loss before: 0.00444477703422, loss after: 0.00443685799837.\n",
      "Epoch:1, weight train batch: 35, step:25, loss before: 0.00380166014656, loss after: 0.00379375577904.\n",
      "Epoch:1, weight train batch: 35, step:26, loss before: 0.00406239647418, loss after: 0.00405303994194.\n",
      "Epoch:1, weight train batch: 35, step:27, loss before: 0.0031073205173, loss after: 0.00310080032796.\n",
      "Epoch:1, weight train batch: 35, step:28, loss before: 0.00344120967202, loss after: 0.00343435979448.\n",
      "Epoch:1, weight train batch: 35, step:29, loss before: 0.00411579804495, loss after: 0.0041072005406.\n",
      "Epoch:1, weight train batch: 35, step:30, loss before: 0.00336968596093, loss after: 0.00336241163313.\n",
      "Epoch:1, weight train batch: 35, step:31, loss before: 0.00319430651143, loss after: 0.00318793370388.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 31, loss before: 0.0037185610272, loss after: 0.00391353107989.\n",
      "Epoch:1, weight train batch: 36, step:0, loss before: 0.00391801306978, loss after: 0.00390930939466.\n",
      "Epoch:1, weight train batch: 36, step:1, loss before: 0.0037439391017, loss after: 0.0037356892135.\n",
      "Epoch:1, weight train batch: 36, step:2, loss before: 0.00320436758921, loss after: 0.00319758336991.\n",
      "Epoch:1, weight train batch: 36, step:3, loss before: 0.00348370755091, loss after: 0.00347619410604.\n",
      "Epoch:1, weight train batch: 36, step:4, loss before: 0.00334131717682, loss after: 0.003333886154.\n",
      "Epoch:1, weight train batch: 36, step:5, loss before: 0.00303050596267, loss after: 0.00302390800789.\n",
      "Epoch:1, weight train batch: 36, step:6, loss before: 0.00423826090991, loss after: 0.0042290231213.\n",
      "Epoch:1, weight train batch: 36, step:7, loss before: 0.00333261024207, loss after: 0.00332520133816.\n",
      "Epoch:1, weight train batch: 36, step:8, loss before: 0.00361720565706, loss after: 0.00360910384916.\n",
      "Epoch:1, weight train batch: 36, step:9, loss before: 0.00317668938078, loss after: 0.00316963205114.\n",
      "Epoch:1, weight train batch: 36, step:10, loss before: 0.00367453950457, loss after: 0.00366634968668.\n",
      "Epoch:1, weight train batch: 36, step:11, loss before: 0.00348926335573, loss after: 0.00348143372685.\n",
      "Epoch:1, weight train batch: 36, step:12, loss before: 0.00327525963075, loss after: 0.0032680076547.\n",
      "Epoch:1, weight train batch: 36, step:13, loss before: 0.00342067889869, loss after: 0.00341290934011.\n",
      "Epoch:1, weight train batch: 36, step:14, loss before: 0.00372906168923, loss after: 0.00372067699209.\n",
      "Epoch:1, weight train batch: 36, step:15, loss before: 0.00364277511835, loss after: 0.00363412522711.\n",
      "Epoch:1, weight train batch: 36, step:16, loss before: 0.00295751728117, loss after: 0.00295089208521.\n",
      "Epoch:1, weight train batch: 36, step:17, loss before: 0.00313590979204, loss after: 0.00312902545556.\n",
      "Epoch:1, weight train batch: 36, step:18, loss before: 0.003729687538, loss after: 0.00372140295804.\n",
      "Epoch:1, weight train batch: 36, step:19, loss before: 0.00327822123654, loss after: 0.00327091221698.\n",
      "Epoch:1, weight train batch: 36, step:20, loss before: 0.00308451941237, loss after: 0.00307784439065.\n",
      "Epoch:1, weight train batch: 36, step:21, loss before: 0.00352060049772, loss after: 0.00351275107823.\n",
      "Epoch:1, weight train batch: 36, step:22, loss before: 0.0036468016915, loss after: 0.00363875483163.\n",
      "Epoch:1, weight train batch: 36, step:23, loss before: 0.00408705323935, loss after: 0.00407821591944.\n",
      "Epoch:1, weight train batch: 36, step:24, loss before: 0.00395180471241, loss after: 0.00394323654473.\n",
      "Epoch:1, weight train batch: 36, step:25, loss before: 0.00325065595098, loss after: 0.0032433567103.\n",
      "Epoch:1, weight train batch: 36, step:26, loss before: 0.00301902531646, loss after: 0.00301308045164.\n",
      "Epoch:1, weight train batch: 36, step:27, loss before: 0.00373708689585, loss after: 0.00372928287834.\n",
      "Epoch:1, weight train batch: 36, step:28, loss before: 0.00352173042484, loss after: 0.00351390638389.\n",
      "Epoch:1, weight train batch: 36, step:29, loss before: 0.00352766364813, loss after: 0.00351968314499.\n",
      "Epoch:1, weight train batch: 36, step:30, loss before: 0.00332889799029, loss after: 0.00332156848162.\n",
      "Epoch:1, weight train batch: 36, step:31, loss before: 0.00290100974962, loss after: 0.0028947503306.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 32, loss before: 0.00320539157838, loss after: 0.00745078641921.\n",
      "Epoch:1, weight train batch: 37, step:0, loss before: 0.00315636186861, loss after: 0.00314909592271.\n",
      "Epoch:1, weight train batch: 37, step:1, loss before: 0.00281195319258, loss after: 0.00280645675957.\n",
      "Epoch:1, weight train batch: 37, step:2, loss before: 0.00288245338015, loss after: 0.00287654949352.\n",
      "Epoch:1, weight train batch: 37, step:3, loss before: 0.00297088874504, loss after: 0.00296478834935.\n",
      "Epoch:1, weight train batch: 37, step:4, loss before: 0.00270955637097, loss after: 0.00270388484932.\n",
      "Epoch:1, weight train batch: 37, step:5, loss before: 0.00371848093346, loss after: 0.00371028250083.\n",
      "Epoch:1, weight train batch: 37, step:6, loss before: 0.00314984587021, loss after: 0.00314317946322.\n",
      "Epoch:1, weight train batch: 37, step:7, loss before: 0.0032617286779, loss after: 0.00325533188879.\n",
      "Epoch:1, weight train batch: 37, step:8, loss before: 0.00268346210942, loss after: 0.00267785834149.\n",
      "Epoch:1, weight train batch: 37, step:9, loss before: 0.00299999210984, loss after: 0.00299384375103.\n",
      "Epoch:1, weight train batch: 37, step:10, loss before: 0.00304063619114, loss after: 0.00303453905508.\n",
      "Epoch:1, weight train batch: 37, step:11, loss before: 0.00285799894482, loss after: 0.00285217165947.\n",
      "Epoch:1, weight train batch: 37, step:12, loss before: 0.00337608437985, loss after: 0.00336959026754.\n",
      "Epoch:1, weight train batch: 37, step:13, loss before: 0.00326266512275, loss after: 0.00325602805242.\n",
      "Epoch:1, weight train batch: 37, step:14, loss before: 0.00289129535668, loss after: 0.00288542709313.\n",
      "Epoch:1, weight train batch: 37, step:15, loss before: 0.00308079086244, loss after: 0.00307453097776.\n",
      "Epoch:1, weight train batch: 37, step:16, loss before: 0.00320078153163, loss after: 0.00319448090158.\n",
      "Epoch:1, weight train batch: 37, step:17, loss before: 0.00365858362056, loss after: 0.00365155097097.\n",
      "Epoch:1, weight train batch: 37, step:18, loss before: 0.00311911152676, loss after: 0.00311268842779.\n",
      "Epoch:1, weight train batch: 37, step:19, loss before: 0.00298080127686, loss after: 0.00297465291806.\n",
      "Epoch:1, weight train batch: 37, step:20, loss before: 0.00312116043642, loss after: 0.00311465840787.\n",
      "Epoch:1, weight train batch: 37, step:21, loss before: 0.00358682102524, loss after: 0.0035794924479.\n",
      "Epoch:1, weight train batch: 37, step:22, loss before: 0.00372660090216, loss after: 0.00372036779299.\n",
      "Epoch:1, weight train batch: 37, step:23, loss before: 0.00325530627742, loss after: 0.0032484983094.\n",
      "Epoch:1, weight train batch: 37, step:24, loss before: 0.00291023775935, loss after: 0.00290480954573.\n",
      "Epoch:1, weight train batch: 37, step:25, loss before: 0.00288973422721, loss after: 0.00288384011947.\n",
      "Epoch:1, weight train batch: 37, step:26, loss before: 0.00393241783604, loss after: 0.00392552278936.\n",
      "Epoch:1, weight train batch: 37, step:27, loss before: 0.00342760211788, loss after: 0.00342058949172.\n",
      "Epoch:1, weight train batch: 37, step:28, loss before: 0.00327257718891, loss after: 0.0032657799311.\n",
      "Epoch:1, weight train batch: 37, step:29, loss before: 0.00289167044684, loss after: 0.00288590276614.\n",
      "Epoch:1, weight train batch: 37, step:30, loss before: 0.00254049664363, loss after: 0.00253558019176.\n",
      "Epoch:1, weight train batch: 37, step:31, loss before: 0.00326281087473, loss after: 0.00325637310743.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 33, loss before: 0.00300331180915, loss after: 0.0153809674084.\n",
      "Epoch:1, weight train batch: 38, step:0, loss before: 0.00361783523113, loss after: 0.00361019116826.\n",
      "Epoch:1, weight train batch: 38, step:1, loss before: 0.0029976980295, loss after: 0.00299154128879.\n",
      "Epoch:1, weight train batch: 38, step:2, loss before: 0.00310891261324, loss after: 0.00310241593979.\n",
      "Epoch:1, weight train batch: 38, step:3, loss before: 0.00298190582544, loss after: 0.00297587527893.\n",
      "Epoch:1, weight train batch: 38, step:4, loss before: 0.00281137693673, loss after: 0.00280577153899.\n",
      "Epoch:1, weight train batch: 38, step:5, loss before: 0.00355201889761, loss after: 0.00354439741932.\n",
      "Epoch:1, weight train batch: 38, step:6, loss before: 0.00282533094287, loss after: 0.00281973718666.\n",
      "Epoch:1, weight train batch: 38, step:7, loss before: 0.00361282238737, loss after: 0.0036057473626.\n",
      "Epoch:1, weight train batch: 38, step:8, loss before: 0.00330311991274, loss after: 0.00329653033987.\n",
      "Epoch:1, weight train batch: 38, step:9, loss before: 0.00289533147588, loss after: 0.00288948277012.\n",
      "Epoch:1, weight train batch: 38, step:10, loss before: 0.00342367123812, loss after: 0.00341681600548.\n",
      "Epoch:1, weight train batch: 38, step:11, loss before: 0.0038170167245, loss after: 0.00380923366174.\n",
      "Epoch:1, weight train batch: 38, step:12, loss before: 0.00314798648469, loss after: 0.00314145768061.\n",
      "Epoch:1, weight train batch: 38, step:13, loss before: 0.00292590050958, loss after: 0.00291982432827.\n",
      "Epoch:1, weight train batch: 38, step:14, loss before: 0.00380222685635, loss after: 0.00379521306604.\n",
      "Epoch:1, weight train batch: 38, step:15, loss before: 0.00329560646787, loss after: 0.00328909372911.\n",
      "Epoch:1, weight train batch: 38, step:16, loss before: 0.00234490958974, loss after: 0.0023401665967.\n",
      "Epoch:1, weight train batch: 38, step:17, loss before: 0.00318877841346, loss after: 0.00318248569965.\n",
      "Epoch:1, weight train batch: 38, step:18, loss before: 0.0034670252353, loss after: 0.00345956161618.\n",
      "Epoch:1, weight train batch: 38, step:19, loss before: 0.00289069651626, loss after: 0.00288493954577.\n",
      "Epoch:1, weight train batch: 38, step:20, loss before: 0.00329498527572, loss after: 0.00328782922588.\n",
      "Epoch:1, weight train batch: 38, step:21, loss before: 0.0036937512923, loss after: 0.00368617870845.\n",
      "Epoch:1, weight train batch: 38, step:22, loss before: 0.00257915910333, loss after: 0.00257391668856.\n",
      "Epoch:1, weight train batch: 38, step:23, loss before: 0.00269772531465, loss after: 0.00269173504785.\n",
      "Epoch:1, weight train batch: 38, step:24, loss before: 0.00264722318389, loss after: 0.00264201825485.\n",
      "Epoch:1, weight train batch: 38, step:25, loss before: 0.00320710241795, loss after: 0.00320058618672.\n",
      "Epoch:1, weight train batch: 38, step:26, loss before: 0.00265838787891, loss after: 0.00265285698697.\n",
      "Epoch:1, weight train batch: 38, step:27, loss before: 0.00314324954525, loss after: 0.00313664460555.\n",
      "Epoch:1, weight train batch: 38, step:28, loss before: 0.00308874528855, loss after: 0.00308264093474.\n",
      "Epoch:1, weight train batch: 38, step:29, loss before: 0.00280315591954, loss after: 0.00279726274312.\n",
      "Epoch:1, weight train batch: 38, step:30, loss before: 0.00927121285349, loss after: 0.00926272943616.\n",
      "Epoch:1, weight train batch: 38, step:31, loss before: 0.00243337848224, loss after: 0.00242870673537.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 34, loss before: 0.00303014251404, loss after: 0.0030301422812.\n",
      "Epoch:1, weight train batch: 39, step:0, loss before: 0.00267186528072, loss after: 0.00266658421606.\n",
      "Epoch:1, weight train batch: 39, step:1, loss before: 0.00263707828708, loss after: 0.00263168802485.\n",
      "Epoch:1, weight train batch: 39, step:2, loss before: 0.00271595246159, loss after: 0.00271036755294.\n",
      "Epoch:1, weight train batch: 39, step:3, loss before: 0.00295824557543, loss after: 0.00295264041051.\n",
      "Epoch:1, weight train batch: 39, step:4, loss before: 0.00262937508523, loss after: 0.00262432987802.\n",
      "Epoch:1, weight train batch: 39, step:5, loss before: 0.00253635412082, loss after: 0.00253164884634.\n",
      "Epoch:1, weight train batch: 39, step:6, loss before: 0.00290725775994, loss after: 0.0029015573673.\n",
      "Epoch:1, weight train batch: 39, step:7, loss before: 0.00257087987848, loss after: 0.00256589706987.\n",
      "Epoch:1, weight train batch: 39, step:8, loss before: 0.00293939420953, loss after: 0.00293409638107.\n",
      "Epoch:1, weight train batch: 39, step:9, loss before: 0.00261253817007, loss after: 0.00260748155415.\n",
      "Epoch:1, weight train batch: 39, step:10, loss before: 0.00297193787992, loss after: 0.00296631758101.\n",
      "Epoch:1, weight train batch: 39, step:11, loss before: 0.00243884976953, loss after: 0.00243413727731.\n",
      "Epoch:1, weight train batch: 39, step:12, loss before: 0.00249421782792, loss after: 0.00248952372931.\n",
      "Epoch:1, weight train batch: 39, step:13, loss before: 0.00263644196093, loss after: 0.00263153621927.\n",
      "Epoch:1, weight train batch: 39, step:14, loss before: 0.00292252749205, loss after: 0.00291702337563.\n",
      "Epoch:1, weight train batch: 39, step:15, loss before: 0.00320260017179, loss after: 0.00319648580626.\n",
      "Epoch:1, weight train batch: 39, step:16, loss before: 0.00320282392204, loss after: 0.00319650443271.\n",
      "Epoch:1, weight train batch: 39, step:17, loss before: 0.00257427431643, loss after: 0.00256942491978.\n",
      "Epoch:1, weight train batch: 39, step:18, loss before: 0.00268703373149, loss after: 0.00268164370209.\n",
      "Epoch:1, weight train batch: 39, step:19, loss before: 0.00279515469447, loss after: 0.00278998655267.\n",
      "Epoch:1, weight train batch: 39, step:20, loss before: 0.00283636734821, loss after: 0.0028308252804.\n",
      "Epoch:1, weight train batch: 39, step:21, loss before: 0.0027075598482, loss after: 0.00270248483866.\n",
      "Epoch:1, weight train batch: 39, step:22, loss before: 0.00295434473082, loss after: 0.00294842827134.\n",
      "Epoch:1, weight train batch: 39, step:23, loss before: 0.00229949853383, loss after: 0.00229515321553.\n",
      "Epoch:1, weight train batch: 39, step:24, loss before: 0.00299286679365, loss after: 0.0029870250728.\n",
      "Epoch:1, weight train batch: 39, step:25, loss before: 0.00446403305978, loss after: 0.00445590820163.\n",
      "Epoch:1, weight train batch: 39, step:26, loss before: 0.00250559300184, loss after: 0.00250077666715.\n",
      "Epoch:1, weight train batch: 39, step:27, loss before: 0.00278327497654, loss after: 0.00277778063901.\n",
      "Epoch:1, weight train batch: 39, step:28, loss before: 0.00273844623007, loss after: 0.00273317471147.\n",
      "Epoch:1, weight train batch: 39, step:29, loss before: 0.0026390212588, loss after: 0.0026337900199.\n",
      "Epoch:1, weight train batch: 39, step:30, loss before: 0.00236348621547, loss after: 0.00235911435448.\n",
      "Epoch:1, weight train batch: 39, step:31, loss before: 0.00264040427282, loss after: 0.00263535790145.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:1, struct parameters train batch: 35, loss before: 0.00293583073653, loss after: 0.00285109947436.\n",
      "Epoch:2, weight train batch: 40, step:0, loss before: 0.00291088945232, loss after: 0.00290532410145.\n",
      "Epoch:2, weight train batch: 40, step:1, loss before: 0.00245978543535, loss after: 0.00245489133522.\n",
      "Epoch:2, weight train batch: 40, step:2, loss before: 0.00255791447125, loss after: 0.00255303480662.\n",
      "Epoch:2, weight train batch: 40, step:3, loss before: 0.0031041491311, loss after: 0.00309832533821.\n",
      "Epoch:2, weight train batch: 40, step:4, loss before: 0.00258146249689, loss after: 0.00257672090083.\n",
      "Epoch:2, weight train batch: 40, step:5, loss before: 0.00293188448995, loss after: 0.0029262858443.\n",
      "Epoch:2, weight train batch: 40, step:6, loss before: 0.00266999704763, loss after: 0.00266468012705.\n",
      "Epoch:2, weight train batch: 40, step:7, loss before: 0.00288271810859, loss after: 0.00287687894888.\n",
      "Epoch:2, weight train batch: 40, step:8, loss before: 0.00260568782687, loss after: 0.00260066287592.\n",
      "Epoch:2, weight train batch: 40, step:9, loss before: 0.00234231958166, loss after: 0.00233804783784.\n",
      "Epoch:2, weight train batch: 40, step:10, loss before: 0.00271035730839, loss after: 0.00270508462563.\n",
      "Epoch:2, weight train batch: 40, step:11, loss before: 0.00246741622686, loss after: 0.00246284436435.\n",
      "Epoch:2, weight train batch: 40, step:12, loss before: 0.00244576507248, loss after: 0.00244122627191.\n",
      "Epoch:2, weight train batch: 40, step:13, loss before: 0.0029271626845, loss after: 0.00292172795162.\n",
      "Epoch:2, weight train batch: 40, step:14, loss before: 0.0021905573085, loss after: 0.00218651583418.\n",
      "Epoch:2, weight train batch: 40, step:15, loss before: 0.00267792236991, loss after: 0.00267283106223.\n",
      "Epoch:2, weight train batch: 40, step:16, loss before: 0.00316781224683, loss after: 0.00316211022437.\n",
      "Epoch:2, weight train batch: 40, step:17, loss before: 0.0027568989899, loss after: 0.00275168963708.\n",
      "Epoch:2, weight train batch: 40, step:18, loss before: 0.00250059692189, loss after: 0.00249581318349.\n",
      "Epoch:2, weight train batch: 40, step:19, loss before: 0.00282462267205, loss after: 0.00281929550692.\n",
      "Epoch:2, weight train batch: 40, step:20, loss before: 0.00262734410353, loss after: 0.00262232823297.\n",
      "Epoch:2, weight train batch: 40, step:21, loss before: 0.00220570713282, loss after: 0.00220162095502.\n",
      "Epoch:2, weight train batch: 40, step:22, loss before: 0.00267228321172, loss after: 0.00266718189232.\n",
      "Epoch:2, weight train batch: 40, step:23, loss before: 0.00263034831733, loss after: 0.00262545375153.\n",
      "Epoch:2, weight train batch: 40, step:24, loss before: 0.00265932572074, loss after: 0.00265440973453.\n",
      "Epoch:2, weight train batch: 40, step:25, loss before: 0.00289088231511, loss after: 0.0028853546828.\n",
      "Epoch:2, weight train batch: 40, step:26, loss before: 0.00259057898074, loss after: 0.00258554471657.\n",
      "Epoch:2, weight train batch: 40, step:27, loss before: 0.00259159505367, loss after: 0.00258676055819.\n",
      "Epoch:2, weight train batch: 40, step:28, loss before: 0.00267118634656, loss after: 0.00266617024317.\n",
      "Epoch:2, weight train batch: 40, step:29, loss before: 0.00259140925482, loss after: 0.00258656707592.\n",
      "Epoch:2, weight train batch: 40, step:30, loss before: 0.00260419165716, loss after: 0.00259923469275.\n",
      "Epoch:2, weight train batch: 40, step:31, loss before: 0.00254835514352, loss after: 0.00254350481555.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 36, loss before: 0.0024314976763, loss after: 0.0144976284355.\n",
      "Epoch:2, weight train batch: 41, step:0, loss before: 0.00303316302598, loss after: 0.0030272314325.\n",
      "Epoch:2, weight train batch: 41, step:1, loss before: 0.00225492566824, loss after: 0.00225070305169.\n",
      "Epoch:2, weight train batch: 41, step:2, loss before: 0.00253648729995, loss after: 0.00253167841583.\n",
      "Epoch:2, weight train batch: 41, step:3, loss before: 0.00239061517641, loss after: 0.00238612829708.\n",
      "Epoch:2, weight train batch: 41, step:4, loss before: 0.00263530667871, loss after: 0.00263039488345.\n",
      "Epoch:2, weight train batch: 41, step:5, loss before: 0.00282829627395, loss after: 0.0028230836615.\n",
      "Epoch:2, weight train batch: 41, step:6, loss before: 0.00218714098446, loss after: 0.00218318821862.\n",
      "Epoch:2, weight train batch: 41, step:7, loss before: 0.00231848051772, loss after: 0.0023142604623.\n",
      "Epoch:2, weight train batch: 41, step:8, loss before: 0.0021599768661, loss after: 0.00215600663796.\n",
      "Epoch:2, weight train batch: 41, step:9, loss before: 0.00239300285466, loss after: 0.00238849874586.\n",
      "Epoch:2, weight train batch: 41, step:10, loss before: 0.00221435166895, loss after: 0.00221029575914.\n",
      "Epoch:2, weight train batch: 41, step:11, loss before: 0.0022890586406, loss after: 0.00228507630527.\n",
      "Epoch:2, weight train batch: 41, step:12, loss before: 0.00244188331999, loss after: 0.00243745697662.\n",
      "Epoch:2, weight train batch: 41, step:13, loss before: 0.00243114167824, loss after: 0.00242661871016.\n",
      "Epoch:2, weight train batch: 41, step:14, loss before: 0.002475758316, loss after: 0.00247124629095.\n",
      "Epoch:2, weight train batch: 41, step:15, loss before: 0.00270273513161, loss after: 0.00269784103148.\n",
      "Epoch:2, weight train batch: 41, step:16, loss before: 0.00256669381633, loss after: 0.00256194500253.\n",
      "Epoch:2, weight train batch: 41, step:17, loss before: 0.00249498267658, loss after: 0.00249058939517.\n",
      "Epoch:2, weight train batch: 41, step:18, loss before: 0.00242886738852, loss after: 0.00242441054434.\n",
      "Epoch:2, weight train batch: 41, step:19, loss before: 0.0193939693272, loss after: 0.0193781834096.\n",
      "Epoch:2, weight train batch: 41, step:20, loss before: 0.00247353827581, loss after: 0.00246835080907.\n",
      "Epoch:2, weight train batch: 41, step:21, loss before: 0.00238622631878, loss after: 0.00238159112632.\n",
      "Epoch:2, weight train batch: 41, step:22, loss before: 0.00423397775739, loss after: 0.00422726385295.\n",
      "Epoch:2, weight train batch: 41, step:23, loss before: 0.00272055296227, loss after: 0.00271480251104.\n",
      "Epoch:2, weight train batch: 41, step:24, loss before: 0.00247853016481, loss after: 0.00247358647175.\n",
      "Epoch:2, weight train batch: 41, step:25, loss before: 0.00246367859654, loss after: 0.00245866575278.\n",
      "Epoch:2, weight train batch: 41, step:26, loss before: 0.00266966596246, loss after: 0.00266460096464.\n",
      "Epoch:2, weight train batch: 41, step:27, loss before: 0.00247966940515, loss after: 0.00247484841384.\n",
      "Epoch:2, weight train batch: 41, step:28, loss before: 0.00238705798984, loss after: 0.00238232593983.\n",
      "Epoch:2, weight train batch: 41, step:29, loss before: 0.00250315689482, loss after: 0.00249838083982.\n",
      "Epoch:2, weight train batch: 41, step:30, loss before: 0.00255101779476, loss after: 0.00254585966468.\n",
      "Epoch:2, weight train batch: 41, step:31, loss before: 0.00275888200849, loss after: 0.00275334622711.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2, struct parameters train batch: 37, loss before: 0.00255698384717, loss after: 0.0146344890818.\n",
      "Epoch:2, weight train batch: 42, step:0, loss before: 0.00237956782803, loss after: 0.00237486953847.\n",
      "Epoch:2, weight train batch: 42, step:1, loss before: 0.00227039749734, loss after: 0.00226598838344.\n",
      "Epoch:2, weight train batch: 42, step:2, loss before: 0.00224968791008, loss after: 0.00224549369887.\n",
      "Epoch:2, weight train batch: 42, step:3, loss before: 0.0024582692422, loss after: 0.00245373416692.\n",
      "Epoch:2, weight train batch: 42, step:4, loss before: 0.00261730910279, loss after: 0.00261236960068.\n",
      "Epoch:2, weight train batch: 42, step:5, loss before: 0.00245860917494, loss after: 0.00245388085023.\n",
      "Epoch:2, weight train batch: 42, step:6, loss before: 0.0025698505342, loss after: 0.0025649452582.\n",
      "Epoch:2, weight train batch: 42, step:7, loss before: 0.00209397589788, loss after: 0.00209011975676.\n",
      "Epoch:2, weight train batch: 42, step:8, loss before: 0.00241925101727, loss after: 0.00241471244954.\n",
      "Epoch:2, weight train batch: 42, step:9, loss before: 0.00220489013009, loss after: 0.00220090383664.\n",
      "Epoch:2, weight train batch: 42, step:10, loss before: 0.00234015192837, loss after: 0.00233585061505.\n",
      "Epoch:2, weight train batch: 42, step:11, loss before: 0.00229361932725, loss after: 0.00228949496523.\n",
      "Epoch:2, weight train batch: 42, step:12, loss before: 0.00216603092849, loss after: 0.00216215616092.\n",
      "Epoch:2, weight train batch: 42, step:13, loss before: 0.00218853866681, loss after: 0.00218461547047.\n",
      "Epoch:2, weight train batch: 42, step:14, loss before: 0.00229194317944, loss after: 0.00228800950572.\n",
      "Epoch:2, weight train batch: 42, step:15, loss before: 0.00231340387836, loss after: 0.00230932515115.\n",
      "Epoch:2, weight train batch: 42, step:16, loss before: 0.0023748788517, loss after: 0.00237068883143.\n",
      "Epoch:2, weight train batch: 42, step:17, loss before: 0.00207338063046, loss after: 0.00206971727312.\n",
      "Epoch:2, weight train batch: 42, step:18, loss before: 0.00325625762343, loss after: 0.00325118238106.\n",
      "Epoch:2, weight train batch: 42, step:19, loss before: 0.0023868533317, loss after: 0.00238250009716.\n",
      "Epoch:2, weight train batch: 42, step:20, loss before: 0.00214549014345, loss after: 0.0021416854579.\n",
      "Epoch:2, weight train batch: 42, step:21, loss before: 0.00230522733182, loss after: 0.00230115279555.\n",
      "Epoch:2, weight train batch: 42, step:22, loss before: 0.00232375971973, loss after: 0.00231974106282.\n",
      "Epoch:2, weight train batch: 42, step:23, loss before: 0.00233511906117, loss after: 0.00233090715483.\n",
      "Epoch:2, weight train batch: 42, step:24, loss before: 0.00207359902561, loss after: 0.00206982437521.\n",
      "Epoch:2, weight train batch: 42, step:25, loss before: 0.00233622593805, loss after: 0.00233209459111.\n",
      "Epoch:2, weight train batch: 42, step:26, loss before: 0.00229974696413, loss after: 0.00229566823691.\n",
      "Epoch:2, weight train batch: 42, step:27, loss before: 0.00229622796178, loss after: 0.00229214853607.\n",
      "Epoch:2, weight train batch: 42, step:28, loss before: 0.00239229877479, loss after: 0.00238800165243.\n",
      "Epoch:2, weight train batch: 42, step:29, loss before: 0.00226699141786, loss after: 0.00226289452985.\n",
      "Epoch:2, weight train batch: 42, step:30, loss before: 0.00241380836815, loss after: 0.00240946235135.\n",
      "Epoch:2, weight train batch: 42, step:31, loss before: 0.00242985552177, loss after: 0.00242545781657.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 38, loss before: 0.0024262117222, loss after: 0.00223226752132.\n",
      "Epoch:2, weight train batch: 43, step:0, loss before: 0.00236441241577, loss after: 0.00236005964689.\n",
      "Epoch:2, weight train batch: 43, step:1, loss before: 0.00212813168764, loss after: 0.00212425738573.\n",
      "Epoch:2, weight train batch: 43, step:2, loss before: 0.00202478072606, loss after: 0.0020211469382.\n",
      "Epoch:2, weight train batch: 43, step:3, loss before: 0.00224399613217, loss after: 0.0022399474401.\n",
      "Epoch:2, weight train batch: 43, step:4, loss before: 0.00225001620129, loss after: 0.00224597426131.\n",
      "Epoch:2, weight train batch: 43, step:5, loss before: 0.00186656077858, loss after: 0.00186334992759.\n",
      "Epoch:2, weight train batch: 43, step:6, loss before: 0.00203856616281, loss after: 0.00203503994271.\n",
      "Epoch:2, weight train batch: 43, step:7, loss before: 0.00836779829115, loss after: 0.00836224388331.\n",
      "Epoch:2, weight train batch: 43, step:8, loss before: 0.00197542225942, loss after: 0.00197195541114.\n",
      "Epoch:2, weight train batch: 43, step:9, loss before: 0.00237262295559, loss after: 0.00236851093359.\n",
      "Epoch:2, weight train batch: 43, step:10, loss before: 0.00231613731012, loss after: 0.00231204391457.\n",
      "Epoch:2, weight train batch: 43, step:11, loss before: 0.00237831426784, loss after: 0.00237412075512.\n",
      "Epoch:2, weight train batch: 43, step:12, loss before: 0.00226846616715, loss after: 0.00226427568123.\n",
      "Epoch:2, weight train batch: 43, step:13, loss before: 0.0019214557251, loss after: 0.00191819807515.\n",
      "Epoch:2, weight train batch: 43, step:14, loss before: 0.00206350442022, loss after: 0.00205984083004.\n",
      "Epoch:2, weight train batch: 43, step:15, loss before: 0.00237097009085, loss after: 0.0023666464258.\n",
      "Epoch:2, weight train batch: 43, step:16, loss before: 0.00238247262314, loss after: 0.00237824930809.\n",
      "Epoch:2, weight train batch: 43, step:17, loss before: 0.00171966594644, loss after: 0.00171683717053.\n",
      "Epoch:2, weight train batch: 43, step:18, loss before: 0.00223399302922, loss after: 0.00223018880934.\n",
      "Epoch:2, weight train batch: 43, step:19, loss before: 0.0021549554076, loss after: 0.00215116282925.\n",
      "Epoch:2, weight train batch: 43, step:20, loss before: 0.00175751931965, loss after: 0.00175455329008.\n",
      "Epoch:2, weight train batch: 43, step:21, loss before: 0.00222251052037, loss after: 0.00221865065396.\n",
      "Epoch:2, weight train batch: 43, step:22, loss before: 0.00253897043876, loss after: 0.00253446912393.\n",
      "Epoch:2, weight train batch: 43, step:23, loss before: 0.00206192815676, loss after: 0.00205831276253.\n",
      "Epoch:2, weight train batch: 43, step:24, loss before: 0.0018515214324, loss after: 0.00184836587869.\n",
      "Epoch:2, weight train batch: 43, step:25, loss before: 0.00218245759606, loss after: 0.00217871251516.\n",
      "Epoch:2, weight train batch: 43, step:26, loss before: 0.00223368755542, loss after: 0.00222983863205.\n",
      "Epoch:2, weight train batch: 43, step:27, loss before: 0.00198372639716, loss after: 0.00198026699945.\n",
      "Epoch:2, weight train batch: 43, step:28, loss before: 0.00227774726227, loss after: 0.00227372022346.\n",
      "Epoch:2, weight train batch: 43, step:29, loss before: 0.00233313231729, loss after: 0.00232905708253.\n",
      "Epoch:2, weight train batch: 43, step:30, loss before: 0.00194352224935, loss after: 0.00194021896459.\n",
      "Epoch:2, weight train batch: 43, step:31, loss before: 0.00213320879266, loss after: 0.00212944531813.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 39, loss before: 0.00212484039366, loss after: 0.00212484039366.\n",
      "Epoch:2, weight train batch: 44, step:0, loss before: 0.00203490443528, loss after: 0.00203125947155.\n",
      "Epoch:2, weight train batch: 44, step:1, loss before: 0.00190215324983, loss after: 0.0018987194635.\n",
      "Epoch:2, weight train batch: 44, step:2, loss before: 0.00239085499197, loss after: 0.00238660536706.\n",
      "Epoch:2, weight train batch: 44, step:3, loss before: 0.00216655666009, loss after: 0.00216292240657.\n",
      "Epoch:2, weight train batch: 44, step:4, loss before: 0.00226149638183, loss after: 0.00225769588724.\n",
      "Epoch:2, weight train batch: 44, step:5, loss before: 0.00209501059726, loss after: 0.00209169974551.\n",
      "Epoch:2, weight train batch: 44, step:6, loss before: 0.00212943460792, loss after: 0.00212590815499.\n",
      "Epoch:2, weight train batch: 44, step:7, loss before: 0.00222692987882, loss after: 0.00222308840603.\n",
      "Epoch:2, weight train batch: 44, step:8, loss before: 0.0022932048887, loss after: 0.00228937203065.\n",
      "Epoch:2, weight train batch: 44, step:9, loss before: 0.00212716707028, loss after: 0.0021233772859.\n",
      "Epoch:2, weight train batch: 44, step:10, loss before: 0.00201515387744, loss after: 0.00201169005595.\n",
      "Epoch:2, weight train batch: 44, step:11, loss before: 0.00186979747377, loss after: 0.00186659418978.\n",
      "Epoch:2, weight train batch: 44, step:12, loss before: 0.00263667106628, loss after: 0.00263234786689.\n",
      "Epoch:2, weight train batch: 44, step:13, loss before: 0.00210004695691, loss after: 0.00209653913043.\n",
      "Epoch:2, weight train batch: 44, step:14, loss before: 0.00217655021697, loss after: 0.00217279000208.\n",
      "Epoch:2, weight train batch: 44, step:15, loss before: 0.00210422324017, loss after: 0.00210051494651.\n",
      "Epoch:2, weight train batch: 44, step:16, loss before: 0.00329165137373, loss after: 0.00328626250848.\n",
      "Epoch:2, weight train batch: 44, step:17, loss before: 0.00206337030977, loss after: 0.00205971393734.\n",
      "Epoch:2, weight train batch: 44, step:18, loss before: 0.00216600275598, loss after: 0.00216231681406.\n",
      "Epoch:2, weight train batch: 44, step:19, loss before: 0.00210478459485, loss after: 0.0021011501085.\n",
      "Epoch:2, weight train batch: 44, step:20, loss before: 0.00198419904336, loss after: 0.00198081741109.\n",
      "Epoch:2, weight train batch: 44, step:21, loss before: 0.00198422092944, loss after: 0.00198080949485.\n",
      "Epoch:2, weight train batch: 44, step:22, loss before: 0.0022357837297, loss after: 0.00223197997548.\n",
      "Epoch:2, weight train batch: 44, step:23, loss before: 0.00181600323413, loss after: 0.00181289215107.\n",
      "Epoch:2, weight train batch: 44, step:24, loss before: 0.00171871483326, loss after: 0.00171577814035.\n",
      "Epoch:2, weight train batch: 44, step:25, loss before: 0.00211398862302, loss after: 0.00211044726893.\n",
      "Epoch:2, weight train batch: 44, step:26, loss before: 0.0177471078932, loss after: 0.017733450979.\n",
      "Epoch:2, weight train batch: 44, step:27, loss before: 0.00211742939427, loss after: 0.00211339443922.\n",
      "Epoch:2, weight train batch: 44, step:28, loss before: 0.00196022563614, loss after: 0.00195663608611.\n",
      "Epoch:2, weight train batch: 44, step:29, loss before: 0.00205315020867, loss after: 0.0020492603071.\n",
      "Epoch:2, weight train batch: 44, step:30, loss before: 0.00209045503289, loss after: 0.00208645733073.\n",
      "Epoch:2, weight train batch: 44, step:31, loss before: 0.00205297209322, loss after: 0.0020490300376.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 40, loss before: 0.00227770861238, loss after: 0.00221133884043.\n",
      "Epoch:2, weight train batch: 45, step:0, loss before: 0.00198641465977, loss after: 0.00198267679662.\n",
      "Epoch:2, weight train batch: 45, step:1, loss before: 0.00203458569013, loss after: 0.00203099264763.\n",
      "Epoch:2, weight train batch: 45, step:2, loss before: 0.00204476085491, loss after: 0.00204091519117.\n",
      "Epoch:2, weight train batch: 45, step:3, loss before: 0.050983581692, loss after: 0.0509375818074.\n",
      "Epoch:2, weight train batch: 45, step:4, loss before: 0.0017417112831, loss after: 0.00173964188434.\n",
      "Epoch:2, weight train batch: 45, step:5, loss before: 0.00178646482527, loss after: 0.00178437307477.\n",
      "Epoch:2, weight train batch: 45, step:6, loss before: 0.00207966146991, loss after: 0.00207702303305.\n",
      "Epoch:2, weight train batch: 45, step:7, loss before: 0.00199380586855, loss after: 0.00199113413692.\n",
      "Epoch:2, weight train batch: 45, step:8, loss before: 0.00166832259856, loss after: 0.00166629301384.\n",
      "Epoch:2, weight train batch: 45, step:9, loss before: 0.00213915877976, loss after: 0.00213648704812.\n",
      "Epoch:2, weight train batch: 45, step:10, loss before: 0.00215722271241, loss after: 0.00215420266613.\n",
      "Epoch:2, weight train batch: 45, step:11, loss before: 0.00227248505689, loss after: 0.00226952461526.\n",
      "Epoch:2, weight train batch: 45, step:12, loss before: 0.00243556499481, loss after: 0.00243204785511.\n",
      "Epoch:2, weight train batch: 45, step:13, loss before: 0.001921240706, loss after: 0.00191824976355.\n",
      "Epoch:2, weight train batch: 45, step:14, loss before: 0.00319947116077, loss after: 0.00319415237755.\n",
      "Epoch:2, weight train batch: 45, step:15, loss before: 0.00190479110461, loss after: 0.00190161366481.\n",
      "Epoch:2, weight train batch: 45, step:16, loss before: 0.00236385595053, loss after: 0.00235936441459.\n",
      "Epoch:2, weight train batch: 45, step:17, loss before: 0.00170647213235, loss after: 0.00170374743175.\n",
      "Epoch:2, weight train batch: 45, step:18, loss before: 0.00212955265306, loss after: 0.00212591118179.\n",
      "Epoch:2, weight train batch: 45, step:19, loss before: 0.00200072862208, loss after: 0.00199746945873.\n",
      "Epoch:2, weight train batch: 45, step:20, loss before: 0.00202087080106, loss after: 0.00201753713191.\n",
      "Epoch:2, weight train batch: 45, step:21, loss before: 0.0020578824915, loss after: 0.00205431925133.\n",
      "Epoch:2, weight train batch: 45, step:22, loss before: 0.00188561889809, loss after: 0.00188233726658.\n",
      "Epoch:2, weight train batch: 45, step:23, loss before: 0.0016812493559, loss after: 0.00167844281532.\n",
      "Epoch:2, weight train batch: 45, step:24, loss before: 0.00206450326368, loss after: 0.00206098426133.\n",
      "Epoch:2, weight train batch: 45, step:25, loss before: 0.00212896754965, loss after: 0.00212551723234.\n",
      "Epoch:2, weight train batch: 45, step:26, loss before: 0.00218072161078, loss after: 0.00217703869566.\n",
      "Epoch:2, weight train batch: 45, step:27, loss before: 0.00180608883966, loss after: 0.00180292967707.\n",
      "Epoch:2, weight train batch: 45, step:28, loss before: 0.00241900025867, loss after: 0.00241494551301.\n",
      "Epoch:2, weight train batch: 45, step:29, loss before: 0.0022267322056, loss after: 0.00222287187353.\n",
      "Epoch:2, weight train batch: 45, step:30, loss before: 0.00205410667695, loss after: 0.00205035251565.\n",
      "Epoch:2, weight train batch: 45, step:31, loss before: 0.00192943809088, loss after: 0.00192607869394.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 41, loss before: 0.0140141732991, loss after: 0.00190481217578.\n",
      "Epoch:2, weight train batch: 46, step:0, loss before: 0.00200475775637, loss after: 0.00200114911422.\n",
      "Epoch:2, weight train batch: 46, step:1, loss before: 0.00199505873024, loss after: 0.00199145358056.\n",
      "Epoch:2, weight train batch: 46, step:2, loss before: 0.00215712562203, loss after: 0.00215326109901.\n",
      "Epoch:2, weight train batch: 46, step:3, loss before: 0.00179777853191, loss after: 0.00179445906542.\n",
      "Epoch:2, weight train batch: 46, step:4, loss before: 0.00229579978622, loss after: 0.00229173852131.\n",
      "Epoch:2, weight train batch: 46, step:5, loss before: 0.00192050635815, loss after: 0.00191699829884.\n",
      "Epoch:2, weight train batch: 46, step:6, loss before: 0.0503765977919, loss after: 0.050343438983.\n",
      "Epoch:2, weight train batch: 46, step:7, loss before: 0.00183909421321, loss after: 0.00183591549285.\n",
      "Epoch:2, weight train batch: 46, step:8, loss before: 0.00178886461072, loss after: 0.00178665958811.\n",
      "Epoch:2, weight train batch: 46, step:9, loss before: 0.00220072362572, loss after: 0.0021982556209.\n",
      "Epoch:2, weight train batch: 46, step:10, loss before: 0.00196030316874, loss after: 0.00195734808221.\n",
      "Epoch:2, weight train batch: 46, step:11, loss before: 0.00199740333483, loss after: 0.00199441891164.\n",
      "Epoch:2, weight train batch: 46, step:12, loss before: 0.00197188835591, loss after: 0.0019687442109.\n",
      "Epoch:2, weight train batch: 46, step:13, loss before: 0.0020663223695, loss after: 0.00206301501021.\n",
      "Epoch:2, weight train batch: 46, step:14, loss before: 0.00189775042236, loss after: 0.00189454643987.\n",
      "Epoch:2, weight train batch: 46, step:15, loss before: 0.00194973917678, loss after: 0.00194660224952.\n",
      "Epoch:2, weight train batch: 46, step:16, loss before: 0.00185231934302, loss after: 0.00184920825996.\n",
      "Epoch:2, weight train batch: 46, step:17, loss before: 0.00189626251813, loss after: 0.00189289927948.\n",
      "Epoch:2, weight train batch: 46, step:18, loss before: 0.00218401965685, loss after: 0.00217974325642.\n",
      "Epoch:2, weight train batch: 46, step:19, loss before: 0.00200174027123, loss after: 0.00199758401141.\n",
      "Epoch:2, weight train batch: 46, step:20, loss before: 0.00188541819807, loss after: 0.00188180222176.\n",
      "Epoch:2, weight train batch: 46, step:21, loss before: 0.00183986406773, loss after: 0.00183658930473.\n",
      "Epoch:2, weight train batch: 46, step:22, loss before: 0.00145211257041, loss after: 0.00144959846511.\n",
      "Epoch:2, weight train batch: 46, step:23, loss before: 0.00190180132631, loss after: 0.00189865299035.\n",
      "Epoch:2, weight train batch: 46, step:24, loss before: 0.00162672589067, loss after: 0.00162393017672.\n",
      "Epoch:2, weight train batch: 46, step:25, loss before: 0.00183983135503, loss after: 0.00183700653724.\n",
      "Epoch:2, weight train batch: 46, step:26, loss before: 0.00184868590441, loss after: 0.00184568273835.\n",
      "Epoch:2, weight train batch: 46, step:27, loss before: 0.00186358601786, loss after: 0.00186075770762.\n",
      "Epoch:2, weight train batch: 46, step:28, loss before: 0.00194825732615, loss after: 0.00194520235527.\n",
      "Epoch:2, weight train batch: 46, step:29, loss before: 0.00180166098289, loss after: 0.00179892138112.\n",
      "Epoch:2, weight train batch: 46, step:30, loss before: 0.00178456364665, loss after: 0.00178183161188.\n",
      "Epoch:2, weight train batch: 46, step:31, loss before: 0.00189304840751, loss after: 0.00189000088722.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 42, loss before: 0.00182991358452, loss after: 0.00190356560051.\n",
      "Epoch:2, weight train batch: 47, step:0, loss before: 0.00161975389346, loss after: 0.00161728158128.\n",
      "Epoch:2, weight train batch: 47, step:1, loss before: 0.00183880934492, loss after: 0.00183598068543.\n",
      "Epoch:2, weight train batch: 47, step:2, loss before: 0.00223909411579, loss after: 0.00223557651043.\n",
      "Epoch:2, weight train batch: 47, step:3, loss before: 0.00205811997876, loss after: 0.00205480121076.\n",
      "Epoch:2, weight train batch: 47, step:4, loss before: 0.00217842869461, loss after: 0.00217460514978.\n",
      "Epoch:2, weight train batch: 47, step:5, loss before: 0.00193697400391, loss after: 0.00193365151063.\n",
      "Epoch:2, weight train batch: 47, step:6, loss before: 0.00172747066244, loss after: 0.00172450824175.\n",
      "Epoch:2, weight train batch: 47, step:7, loss before: 0.00155117362738, loss after: 0.00154864182696.\n",
      "Epoch:2, weight train batch: 47, step:8, loss before: 0.00171578326263, loss after: 0.00171301397495.\n",
      "Epoch:2, weight train batch: 47, step:9, loss before: 0.00186739733908, loss after: 0.00186427170411.\n",
      "Epoch:2, weight train batch: 47, step:10, loss before: 0.00172418332659, loss after: 0.0017212620005.\n",
      "Epoch:2, weight train batch: 47, step:11, loss before: 0.00185034796596, loss after: 0.00184733769856.\n",
      "Epoch:2, weight train batch: 47, step:12, loss before: 0.00201320974156, loss after: 0.00200967933051.\n",
      "Epoch:2, weight train batch: 47, step:13, loss before: 0.0498415529728, loss after: 0.04978806898.\n",
      "Epoch:2, weight train batch: 47, step:14, loss before: 0.00169513002038, loss after: 0.00169375515543.\n",
      "Epoch:2, weight train batch: 47, step:15, loss before: 0.00161481485702, loss after: 0.00161287083756.\n",
      "Epoch:2, weight train batch: 47, step:16, loss before: 0.00219796504825, loss after: 0.0021963166073.\n",
      "Epoch:2, weight train batch: 47, step:17, loss before: 0.00167236209381, loss after: 0.00167070794851.\n",
      "Epoch:2, weight train batch: 47, step:18, loss before: 0.00169182335958, loss after: 0.0016905630473.\n",
      "Epoch:2, weight train batch: 47, step:19, loss before: 0.00156712241005, loss after: 0.00156588037498.\n",
      "Epoch:2, weight train batch: 47, step:20, loss before: 0.00178353080992, loss after: 0.00178170204163.\n",
      "Epoch:2, weight train batch: 47, step:21, loss before: 0.00198212871328, loss after: 0.00197945232503.\n",
      "Epoch:2, weight train batch: 47, step:22, loss before: 0.00161759078037, loss after: 0.00161539739929.\n",
      "Epoch:2, weight train batch: 47, step:23, loss before: 0.00177519838326, loss after: 0.00177267822437.\n",
      "Epoch:2, weight train batch: 47, step:24, loss before: 0.00162213528529, loss after: 0.00161972246133.\n",
      "Epoch:2, weight train batch: 47, step:25, loss before: 0.00165799120441, loss after: 0.00165537791327.\n",
      "Epoch:2, weight train batch: 47, step:26, loss before: 0.00190930976532, loss after: 0.00190603150986.\n",
      "Epoch:2, weight train batch: 47, step:27, loss before: 0.00167641334701, loss after: 0.00167354382575.\n",
      "Epoch:2, weight train batch: 47, step:28, loss before: 0.00159524870105, loss after: 0.00159277615603.\n",
      "Epoch:2, weight train batch: 47, step:29, loss before: 0.00186689547263, loss after: 0.00186395528726.\n",
      "Epoch:2, weight train batch: 47, step:30, loss before: 0.00172628904693, loss after: 0.00172356446274.\n",
      "Epoch:2, weight train batch: 47, step:31, loss before: 0.00161681883037, loss after: 0.00161429855507.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 43, loss before: 0.00183730968274, loss after: 0.00183671258856.\n",
      "Epoch:2, weight train batch: 48, step:0, loss before: 0.00189422455151, loss after: 0.00189134769607.\n",
      "Epoch:2, weight train batch: 48, step:1, loss before: 0.00154154188931, loss after: 0.00153919588774.\n",
      "Epoch:2, weight train batch: 48, step:2, loss before: 0.00162028358318, loss after: 0.00161774805747.\n",
      "Epoch:2, weight train batch: 48, step:3, loss before: 0.00179398432374, loss after: 0.00179128930904.\n",
      "Epoch:2, weight train batch: 48, step:4, loss before: 0.00140893063508, loss after: 0.00140679976903.\n",
      "Epoch:2, weight train batch: 48, step:5, loss before: 0.00216572219506, loss after: 0.00216247630306.\n",
      "Epoch:2, weight train batch: 48, step:6, loss before: 0.00171404459979, loss after: 0.00171131582465.\n",
      "Epoch:2, weight train batch: 48, step:7, loss before: 0.00146595807746, loss after: 0.00146360811777.\n",
      "Epoch:2, weight train batch: 48, step:8, loss before: 0.00182836770546, loss after: 0.00182557594962.\n",
      "Epoch:2, weight train batch: 48, step:9, loss before: 0.00171302561648, loss after: 0.00171023746952.\n",
      "Epoch:2, weight train batch: 48, step:10, loss before: 0.00195423653349, loss after: 0.00195109203923.\n",
      "Epoch:2, weight train batch: 48, step:11, loss before: 0.00156207079999, loss after: 0.00155954249203.\n",
      "Epoch:2, weight train batch: 48, step:12, loss before: 0.00129530299455, loss after: 0.00129325746093.\n",
      "Epoch:2, weight train batch: 48, step:13, loss before: 0.00190224009566, loss after: 0.00189931085333.\n",
      "Epoch:2, weight train batch: 48, step:14, loss before: 0.00186226051301, loss after: 0.00185934919864.\n",
      "Epoch:2, weight train batch: 48, step:15, loss before: 0.00181360938586, loss after: 0.00181072531268.\n",
      "Epoch:2, weight train batch: 48, step:16, loss before: 0.00204910500906, loss after: 0.00204592081718.\n",
      "Epoch:2, weight train batch: 48, step:17, loss before: 0.00182804500218, loss after: 0.00182499329094.\n",
      "Epoch:2, weight train batch: 48, step:18, loss before: 0.00166953832377, loss after: 0.00166682805866.\n",
      "Epoch:2, weight train batch: 48, step:19, loss before: 0.00166682805866, loss after: 0.00166408065706.\n",
      "Epoch:2, weight train batch: 48, step:20, loss before: 0.00159716722555, loss after: 0.00159449351486.\n",
      "Epoch:2, weight train batch: 48, step:21, loss before: 0.00165322667453, loss after: 0.00165053876117.\n",
      "Epoch:2, weight train batch: 48, step:22, loss before: 0.00160787149798, loss after: 0.0016052168794.\n",
      "Epoch:2, weight train batch: 48, step:23, loss before: 0.0017611507792, loss after: 0.00175826996565.\n",
      "Epoch:2, weight train batch: 48, step:24, loss before: 0.00177788012661, loss after: 0.00177489884663.\n",
      "Epoch:2, weight train batch: 48, step:25, loss before: 0.00126775470562, loss after: 0.00126569427084.\n",
      "Epoch:2, weight train batch: 48, step:26, loss before: 0.00162560120225, loss after: 0.00162305426784.\n",
      "Epoch:2, weight train batch: 48, step:27, loss before: 0.00169245782308, loss after: 0.00168981822208.\n",
      "Epoch:2, weight train batch: 48, step:28, loss before: 0.00161464838311, loss after: 0.00161202764139.\n",
      "Epoch:2, weight train batch: 48, step:29, loss before: 0.00177900982089, loss after: 0.00177605054341.\n",
      "Epoch:2, weight train batch: 48, step:30, loss before: 0.00165783800185, loss after: 0.00165492366068.\n",
      "Epoch:2, weight train batch: 48, step:31, loss before: 0.0015998610761, loss after: 0.0015972473193.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 44, loss before: 0.00172048946843, loss after: 0.00172048946843.\n",
      "Epoch:2, weight train batch: 49, step:0, loss before: 0.00168476556428, loss after: 0.00168207730167.\n",
      "Epoch:2, weight train batch: 49, step:1, loss before: 0.001964955125, loss after: 0.00196167593822.\n",
      "Epoch:2, weight train batch: 49, step:2, loss before: 0.00166865822393, loss after: 0.00166600337252.\n",
      "Epoch:2, weight train batch: 49, step:3, loss before: 0.00163515994791, loss after: 0.00163250917103.\n",
      "Epoch:2, weight train batch: 49, step:4, loss before: 0.00136589165777, loss after: 0.00136364926584.\n",
      "Epoch:2, weight train batch: 49, step:5, loss before: 0.00191924278624, loss after: 0.00191624718718.\n",
      "Epoch:2, weight train batch: 49, step:6, loss before: 0.00178649206646, loss after: 0.00178366689943.\n",
      "Epoch:2, weight train batch: 49, step:7, loss before: 0.00160628219601, loss after: 0.00160359055735.\n",
      "Epoch:2, weight train batch: 49, step:8, loss before: 0.00152112159412, loss after: 0.00151877128519.\n",
      "Epoch:2, weight train batch: 49, step:9, loss before: 0.0015631148126, loss after: 0.00156075006817.\n",
      "Epoch:2, weight train batch: 49, step:10, loss before: 0.0017955689691, loss after: 0.00179280689918.\n",
      "Epoch:2, weight train batch: 49, step:11, loss before: 0.00155807822011, loss after: 0.00155583617743.\n",
      "Epoch:2, weight train batch: 49, step:12, loss before: 0.00178633199539, loss after: 0.00178356631659.\n",
      "Epoch:2, weight train batch: 49, step:13, loss before: 0.00155119458213, loss after: 0.00154889700934.\n",
      "Epoch:2, weight train batch: 49, step:14, loss before: 0.0166442599148, loss after: 0.0166306383908.\n",
      "Epoch:2, weight train batch: 49, step:15, loss before: 0.00171724380925, loss after: 0.00171448558103.\n",
      "Epoch:2, weight train batch: 49, step:16, loss before: 0.0017183261225, loss after: 0.00171555322595.\n",
      "Epoch:2, weight train batch: 49, step:17, loss before: 0.00149363954552, loss after: 0.00149095570669.\n",
      "Epoch:2, weight train batch: 49, step:18, loss before: 0.00130440166686, loss after: 0.00130249746144.\n",
      "Epoch:2, weight train batch: 49, step:19, loss before: 0.00169021158945, loss after: 0.0016873232089.\n",
      "Epoch:2, weight train batch: 49, step:20, loss before: 0.00160768209025, loss after: 0.00160496076569.\n",
      "Epoch:2, weight train batch: 49, step:21, loss before: 0.00143347424455, loss after: 0.00143128028139.\n",
      "Epoch:2, weight train batch: 49, step:22, loss before: 0.00150855677202, loss after: 0.00150614697486.\n",
      "Epoch:2, weight train batch: 49, step:23, loss before: 0.00169527647085, loss after: 0.00169249577448.\n",
      "Epoch:2, weight train batch: 49, step:24, loss before: 0.00163732212968, loss after: 0.00163453398272.\n",
      "Epoch:2, weight train batch: 49, step:25, loss before: 0.0014984109439, loss after: 0.0014962204732.\n",
      "Epoch:2, weight train batch: 49, step:26, loss before: 0.00182207929902, loss after: 0.00181898288429.\n",
      "Epoch:2, weight train batch: 49, step:27, loss before: 0.00157825276256, loss after: 0.00157569476869.\n",
      "Epoch:2, weight train batch: 49, step:28, loss before: 0.00187299354002, loss after: 0.00186984520406.\n",
      "Epoch:2, weight train batch: 49, step:29, loss before: 0.00173475407064, loss after: 0.00173179525882.\n",
      "Epoch:2, weight train batch: 49, step:30, loss before: 0.00139101198874, loss after: 0.00138876982965.\n",
      "Epoch:2, weight train batch: 49, step:31, loss before: 0.00170173984952, loss after: 0.00169898127206.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 45, loss before: 0.00145273003727, loss after: 0.00165100640152.\n",
      "Epoch:2, weight train batch: 50, step:0, loss before: 0.00146812538151, loss after: 0.00146582373418.\n",
      "Epoch:2, weight train batch: 50, step:1, loss before: 0.00154924520757, loss after: 0.00154685077723.\n",
      "Epoch:2, weight train batch: 50, step:2, loss before: 0.00148608000018, loss after: 0.00148380431347.\n",
      "Epoch:2, weight train batch: 50, step:3, loss before: 0.0015299996594, loss after: 0.00152770546265.\n",
      "Epoch:2, weight train batch: 50, step:4, loss before: 0.00160231231712, loss after: 0.00159986573271.\n",
      "Epoch:2, weight train batch: 50, step:5, loss before: 0.00139394565485, loss after: 0.00139184074942.\n",
      "Epoch:2, weight train batch: 50, step:6, loss before: 0.00158558122348, loss after: 0.00158310844563.\n",
      "Epoch:2, weight train batch: 50, step:7, loss before: 0.00152078550309, loss after: 0.00151844671927.\n",
      "Epoch:2, weight train batch: 50, step:8, loss before: 0.00186382455286, loss after: 0.00186110171489.\n",
      "Epoch:2, weight train batch: 50, step:9, loss before: 0.00148601899855, loss after: 0.00148378044832.\n",
      "Epoch:2, weight train batch: 50, step:10, loss before: 0.00167049001902, loss after: 0.00166797311977.\n",
      "Epoch:2, weight train batch: 50, step:11, loss before: 0.00155819696374, loss after: 0.0015558693558.\n",
      "Epoch:2, weight train batch: 50, step:12, loss before: 0.00155526865274, loss after: 0.00155291857664.\n",
      "Epoch:2, weight train batch: 50, step:13, loss before: 0.00143691315316, loss after: 0.0014347564429.\n",
      "Epoch:2, weight train batch: 50, step:14, loss before: 0.0012492055539, loss after: 0.00124738679733.\n",
      "Epoch:2, weight train batch: 50, step:15, loss before: 0.00121849332936, loss after: 0.0012166260276.\n",
      "Epoch:2, weight train batch: 50, step:16, loss before: 0.00160079135094, loss after: 0.00159850460477.\n",
      "Epoch:2, weight train batch: 50, step:17, loss before: 0.00163155444898, loss after: 0.00162918574642.\n",
      "Epoch:2, weight train batch: 50, step:18, loss before: 0.00141739763785, loss after: 0.00141533778515.\n",
      "Epoch:2, weight train batch: 50, step:19, loss before: 0.00163765938487, loss after: 0.00163519033231.\n",
      "Epoch:2, weight train batch: 50, step:20, loss before: 0.00151877012104, loss after: 0.00151650200132.\n",
      "Epoch:2, weight train batch: 50, step:21, loss before: 0.00165449886117, loss after: 0.00165204505902.\n",
      "Epoch:2, weight train batch: 50, step:22, loss before: 0.00259908847511, loss after: 0.00259568192996.\n",
      "Epoch:2, weight train batch: 50, step:23, loss before: 0.0492363497615, loss after: 0.0491962656379.\n",
      "Epoch:2, weight train batch: 50, step:24, loss before: 0.00157185527496, loss after: 0.00157207483426.\n",
      "Epoch:2, weight train batch: 50, step:25, loss before: 0.00156808388419, loss after: 0.00156672322191.\n",
      "Epoch:2, weight train batch: 50, step:26, loss before: 0.0015518075088, loss after: 0.00155126128811.\n",
      "Epoch:2, weight train batch: 50, step:27, loss before: 0.00144617119804, loss after: 0.00144518248271.\n",
      "Epoch:2, weight train batch: 50, step:28, loss before: 0.00196051714011, loss after: 0.00195936881937.\n",
      "Epoch:2, weight train batch: 50, step:29, loss before: 0.00144884223118, loss after: 0.00144773791544.\n",
      "Epoch:2, weight train batch: 50, step:30, loss before: 0.00149371218868, loss after: 0.00149197201245.\n",
      "Epoch:2, weight train batch: 50, step:31, loss before: 0.00144895352423, loss after: 0.0014471388422.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 46, loss before: 0.0016275405651, loss after: 0.00146581209265.\n",
      "Epoch:2, weight train batch: 51, step:0, loss before: 0.00156335392967, loss after: 0.00156140187755.\n",
      "Epoch:2, weight train batch: 51, step:1, loss before: 0.00160076888278, loss after: 0.00159853452351.\n",
      "Epoch:2, weight train batch: 51, step:2, loss before: 0.00161701161414, loss after: 0.00161492626648.\n",
      "Epoch:2, weight train batch: 51, step:3, loss before: 0.00154261547141, loss after: 0.00154023966752.\n",
      "Epoch:2, weight train batch: 51, step:4, loss before: 0.00153981009498, loss after: 0.00153734150808.\n",
      "Epoch:2, weight train batch: 51, step:5, loss before: 0.00145909702405, loss after: 0.00145688094199.\n",
      "Epoch:2, weight train batch: 51, step:6, loss before: 0.00139609386679, loss after: 0.0013939817436.\n",
      "Epoch:2, weight train batch: 51, step:7, loss before: 0.00145687977783, loss after: 0.00145472341683.\n",
      "Epoch:2, weight train batch: 51, step:8, loss before: 0.00177618255839, loss after: 0.00177349708974.\n",
      "Epoch:2, weight train batch: 51, step:9, loss before: 0.00122802006081, loss after: 0.00122618628666.\n",
      "Epoch:2, weight train batch: 51, step:10, loss before: 0.00151606532745, loss after: 0.00151382293552.\n",
      "Epoch:2, weight train batch: 51, step:11, loss before: 0.00124514405616, loss after: 0.00124320609029.\n",
      "Epoch:2, weight train batch: 51, step:12, loss before: 0.00149565143511, loss after: 0.00149346480612.\n",
      "Epoch:2, weight train batch: 51, step:13, loss before: 0.00143227027729, loss after: 0.0014301094925.\n",
      "Epoch:2, weight train batch: 51, step:14, loss before: 0.00152805168182, loss after: 0.00152578321286.\n",
      "Epoch:2, weight train batch: 51, step:15, loss before: 0.00151723914314, loss after: 0.00151485169772.\n",
      "Epoch:2, weight train batch: 51, step:16, loss before: 0.00132928788662, loss after: 0.00132722361013.\n",
      "Epoch:2, weight train batch: 51, step:17, loss before: 0.00155346910469, loss after: 0.00155114918016.\n",
      "Epoch:2, weight train batch: 51, step:18, loss before: 0.00168946781196, loss after: 0.0016868612729.\n",
      "Epoch:2, weight train batch: 51, step:19, loss before: 0.00145900866482, loss after: 0.00145682948641.\n",
      "Epoch:2, weight train batch: 51, step:20, loss before: 0.00142555159982, loss after: 0.00142324948683.\n",
      "Epoch:2, weight train batch: 51, step:21, loss before: 0.00156189745758, loss after: 0.00155944679864.\n",
      "Epoch:2, weight train batch: 51, step:22, loss before: 0.00140209996607, loss after: 0.00139995047357.\n",
      "Epoch:2, weight train batch: 51, step:23, loss before: 0.00135084614158, loss after: 0.00134862191044.\n",
      "Epoch:2, weight train batch: 51, step:24, loss before: 0.00154076574836, loss after: 0.0015382966958.\n",
      "Epoch:2, weight train batch: 51, step:25, loss before: 0.00142804114148, loss after: 0.0014257801231.\n",
      "Epoch:2, weight train batch: 51, step:26, loss before: 0.00146592210513, loss after: 0.00146361999214.\n",
      "Epoch:2, weight train batch: 51, step:27, loss before: 0.00128208100796, loss after: 0.00127996085212.\n",
      "Epoch:2, weight train batch: 51, step:28, loss before: 0.00128148472868, loss after: 0.00127941323444.\n",
      "Epoch:2, weight train batch: 51, step:29, loss before: 0.00144158175681, loss after: 0.00143931689672.\n",
      "Epoch:2, weight train batch: 51, step:30, loss before: 0.001480468316, loss after: 0.00147821847349.\n",
      "Epoch:2, weight train batch: 51, step:31, loss before: 0.00148324691691, loss after: 0.00148094492033.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 47, loss before: 0.00144288316369, loss after: 0.00146808044519.\n",
      "Epoch:2, weight train batch: 52, step:0, loss before: 0.00136715429835, loss after: 0.00136490049772.\n",
      "Epoch:2, weight train batch: 52, step:1, loss before: 0.001503725769, loss after: 0.00150144984946.\n",
      "Epoch:2, weight train batch: 52, step:2, loss before: 0.00153066311032, loss after: 0.0015282795066.\n",
      "Epoch:2, weight train batch: 52, step:3, loss before: 0.00119690480642, loss after: 0.00119489966892.\n",
      "Epoch:2, weight train batch: 52, step:4, loss before: 0.00155156722758, loss after: 0.00154907931574.\n",
      "Epoch:2, weight train batch: 52, step:5, loss before: 0.00127938308287, loss after: 0.00127725931816.\n",
      "Epoch:2, weight train batch: 52, step:6, loss before: 0.00133053027093, loss after: 0.00132833560929.\n",
      "Epoch:2, weight train batch: 52, step:7, loss before: 0.00161239411682, loss after: 0.00160988047719.\n",
      "Epoch:2, weight train batch: 52, step:8, loss before: 0.00146255502477, loss after: 0.00146024185233.\n",
      "Epoch:2, weight train batch: 52, step:9, loss before: 0.00137805612758, loss after: 0.00137580966111.\n",
      "Epoch:2, weight train batch: 52, step:10, loss before: 0.00130011560395, loss after: 0.00129812932573.\n",
      "Epoch:2, weight train batch: 52, step:11, loss before: 0.00145441573113, loss after: 0.0014522401616.\n",
      "Epoch:2, weight train batch: 52, step:12, loss before: 0.00158229796216, loss after: 0.00158007792197.\n",
      "Epoch:2, weight train batch: 52, step:13, loss before: 0.0012589036487, loss after: 0.00125698070042.\n",
      "Epoch:2, weight train batch: 52, step:14, loss before: 0.00152366724797, loss after: 0.00152138015255.\n",
      "Epoch:2, weight train batch: 52, step:15, loss before: 0.00162005261518, loss after: 0.00161757972091.\n",
      "Epoch:2, weight train batch: 52, step:16, loss before: 0.00178665213753, loss after: 0.00178398285061.\n",
      "Epoch:2, weight train batch: 52, step:17, loss before: 0.00150201038923, loss after: 0.0014995818492.\n",
      "Epoch:2, weight train batch: 52, step:18, loss before: 0.00202137278393, loss after: 0.00201846216805.\n",
      "Epoch:2, weight train batch: 52, step:19, loss before: 0.00120403198525, loss after: 0.00120217190124.\n",
      "Epoch:2, weight train batch: 52, step:20, loss before: 0.00175788952038, loss after: 0.00175532023422.\n",
      "Epoch:2, weight train batch: 52, step:21, loss before: 0.00152657669969, loss after: 0.00152426736895.\n",
      "Epoch:2, weight train batch: 52, step:22, loss before: 0.00134188123047, loss after: 0.00133974617347.\n",
      "Epoch:2, weight train batch: 52, step:23, loss before: 0.00137410848401, loss after: 0.00137188087683.\n",
      "Epoch:2, weight train batch: 52, step:24, loss before: 0.00127562647685, loss after: 0.00127356208395.\n",
      "Epoch:2, weight train batch: 52, step:25, loss before: 0.00120345526375, loss after: 0.0012016214896.\n",
      "Epoch:2, weight train batch: 52, step:26, loss before: 0.0013731981162, loss after: 0.00137107062619.\n",
      "Epoch:2, weight train batch: 52, step:27, loss before: 0.00143312010914, loss after: 0.00143094081432.\n",
      "Epoch:2, weight train batch: 52, step:28, loss before: 0.00147059303708, loss after: 0.00146834307816.\n",
      "Epoch:2, weight train batch: 52, step:29, loss before: 0.00144878600258, loss after: 0.00144675548654.\n",
      "Epoch:2, weight train batch: 52, step:30, loss before: 0.00138231669553, loss after: 0.00138026406057.\n",
      "Epoch:2, weight train batch: 52, step:31, loss before: 0.00151599780656, loss after: 0.00151382980403.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 48, loss before: 0.00135579949711, loss after: 0.00154238473624.\n",
      "Epoch:2, weight train batch: 53, step:0, loss before: 0.00140322139487, loss after: 0.00140124291647.\n",
      "Epoch:2, weight train batch: 53, step:1, loss before: 0.00131215155125, loss after: 0.00131027342286.\n",
      "Epoch:2, weight train batch: 53, step:2, loss before: 0.00124884606339, loss after: 0.00124709063675.\n",
      "Epoch:2, weight train batch: 53, step:3, loss before: 0.00144591834396, loss after: 0.00144375418313.\n",
      "Epoch:2, weight train batch: 53, step:4, loss before: 0.00132643559482, loss after: 0.00132450903766.\n",
      "Epoch:2, weight train batch: 53, step:5, loss before: 0.00145816442091, loss after: 0.00145616196096.\n",
      "Epoch:2, weight train batch: 53, step:6, loss before: 0.00121799041517, loss after: 0.00121615640819.\n",
      "Epoch:2, weight train batch: 53, step:7, loss before: 0.00112054985948, loss after: 0.00111894647125.\n",
      "Epoch:2, weight train batch: 53, step:8, loss before: 0.00143714132719, loss after: 0.00143521546852.\n",
      "Epoch:2, weight train batch: 53, step:9, loss before: 0.00136566674337, loss after: 0.00136376265436.\n",
      "Epoch:2, weight train batch: 53, step:10, loss before: 0.00132726447191, loss after: 0.00132537132595.\n",
      "Epoch:2, weight train batch: 53, step:11, loss before: 0.00121354591101, loss after: 0.00121181993745.\n",
      "Epoch:2, weight train batch: 53, step:12, loss before: 0.00130439037457, loss after: 0.00130255660042.\n",
      "Epoch:2, weight train batch: 53, step:13, loss before: 0.0156658105552, loss after: 0.0156547427177.\n",
      "Epoch:2, weight train batch: 53, step:14, loss before: 0.00139514845796, loss after: 0.00139290990774.\n",
      "Epoch:2, weight train batch: 53, step:15, loss before: 0.00126643851399, loss after: 0.00126453489065.\n",
      "Epoch:2, weight train batch: 53, step:16, loss before: 0.00130796583835, loss after: 0.00130592798814.\n",
      "Epoch:2, weight train batch: 53, step:17, loss before: 0.00175753841177, loss after: 0.00175495666917.\n",
      "Epoch:2, weight train batch: 53, step:18, loss before: 0.00136623089202, loss after: 0.00136395497248.\n",
      "Epoch:2, weight train batch: 53, step:19, loss before: 0.00134075595997, loss after: 0.00133862881921.\n",
      "Epoch:2, weight train batch: 53, step:20, loss before: 0.00147121027112, loss after: 0.00146881188266.\n",
      "Epoch:2, weight train batch: 53, step:21, loss before: 0.00131137459539, loss after: 0.00130921020173.\n",
      "Epoch:2, weight train batch: 53, step:22, loss before: 0.00132248434238, loss after: 0.00132049829699.\n",
      "Epoch:2, weight train batch: 53, step:23, loss before: 0.001635902212, loss after: 0.00163359171711.\n",
      "Epoch:2, weight train batch: 53, step:24, loss before: 0.0012713924516, loss after: 0.00126940244809.\n",
      "Epoch:2, weight train batch: 53, step:25, loss before: 0.00126140308566, loss after: 0.00125944311731.\n",
      "Epoch:2, weight train batch: 53, step:26, loss before: 0.00118616002146, loss after: 0.00118426280096.\n",
      "Epoch:2, weight train batch: 53, step:27, loss before: 0.00136400852352, loss after: 0.00136191467755.\n",
      "Epoch:2, weight train batch: 53, step:28, loss before: 0.00136338546872, loss after: 0.00136135471985.\n",
      "Epoch:2, weight train batch: 53, step:29, loss before: 0.00146707810927, loss after: 0.00146494829096.\n",
      "Epoch:2, weight train batch: 53, step:30, loss before: 0.0014034032356, loss after: 0.00140140065923.\n",
      "Epoch:2, weight train batch: 53, step:31, loss before: 0.00145406485535, loss after: 0.00145189708564.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 49, loss before: 0.00131965719629, loss after: 0.0012320515234.\n",
      "Epoch:2, weight train batch: 54, step:0, loss before: 0.00138443894684, loss after: 0.00138247734867.\n",
      "Epoch:2, weight train batch: 54, step:1, loss before: 0.00124225101899, loss after: 0.00124040234368.\n",
      "Epoch:2, weight train batch: 54, step:2, loss before: 0.00117684039287, loss after: 0.00117503281217.\n",
      "Epoch:2, weight train batch: 54, step:3, loss before: 0.00108523794916, loss after: 0.00108355632983.\n",
      "Epoch:2, weight train batch: 54, step:4, loss before: 0.00112909672316, loss after: 0.00112751568668.\n",
      "Epoch:2, weight train batch: 54, step:5, loss before: 0.00688001187518, loss after: 0.00687697343528.\n",
      "Epoch:2, weight train batch: 54, step:6, loss before: 0.00131834391505, loss after: 0.00131638767198.\n",
      "Epoch:2, weight train batch: 54, step:7, loss before: 0.00119477196131, loss after: 0.00119303108659.\n",
      "Epoch:2, weight train batch: 54, step:8, loss before: 0.00150542403571, loss after: 0.00150317046791.\n",
      "Epoch:2, weight train batch: 54, step:9, loss before: 0.00123754190281, loss after: 0.00123580498621.\n",
      "Epoch:2, weight train batch: 54, step:10, loss before: 0.0012969977688, loss after: 0.001295119524.\n",
      "Epoch:2, weight train batch: 54, step:11, loss before: 0.00123744260054, loss after: 0.00123567960691.\n",
      "Epoch:2, weight train batch: 54, step:12, loss before: 0.00129853701219, loss after: 0.00129662174731.\n",
      "Epoch:2, weight train batch: 54, step:13, loss before: 0.0010774632683, loss after: 0.00107600854244.\n",
      "Epoch:2, weight train batch: 54, step:14, loss before: 0.00125671783462, loss after: 0.00125496229157.\n",
      "Epoch:2, weight train batch: 54, step:15, loss before: 0.00136052852031, loss after: 0.0013585423585.\n",
      "Epoch:2, weight train batch: 54, step:16, loss before: 0.00112570170313, loss after: 0.00112410215661.\n",
      "Epoch:2, weight train batch: 54, step:17, loss before: 0.00112856295891, loss after: 0.00112694501877.\n",
      "Epoch:2, weight train batch: 54, step:18, loss before: 0.0488798208535, loss after: 0.0488341934979.\n",
      "Epoch:2, weight train batch: 54, step:19, loss before: 0.00127327395603, loss after: 0.00127342296764.\n",
      "Epoch:2, weight train batch: 54, step:20, loss before: 0.00141013553366, loss after: 0.00140963750891.\n",
      "Epoch:2, weight train batch: 54, step:21, loss before: 0.00699955038726, loss after: 0.00699771707878.\n",
      "Epoch:2, weight train batch: 54, step:22, loss before: 0.00140410196036, loss after: 0.00140309100971.\n",
      "Epoch:2, weight train batch: 54, step:23, loss before: 0.00126105779782, loss after: 0.00126057094894.\n",
      "Epoch:2, weight train batch: 54, step:24, loss before: 0.00133038859349, loss after: 0.00132935121655.\n",
      "Epoch:2, weight train batch: 54, step:25, loss before: 0.00123803783208, loss after: 0.00123698159587.\n",
      "Epoch:2, weight train batch: 54, step:26, loss before: 0.00133923115209, loss after: 0.00133769889362.\n",
      "Epoch:2, weight train batch: 54, step:27, loss before: 0.00136809702963, loss after: 0.00136639364064.\n",
      "Epoch:2, weight train batch: 54, step:28, loss before: 0.00150911603123, loss after: 0.00150768004823.\n",
      "Epoch:2, weight train batch: 54, step:29, loss before: 0.00120274326764, loss after: 0.00120124069508.\n",
      "Epoch:2, weight train batch: 54, step:30, loss before: 0.00194401200861, loss after: 0.00194145878777.\n",
      "Epoch:2, weight train batch: 54, step:31, loss before: 0.00110731041059, loss after: 0.00110568851233.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 50, loss before: 0.00133629119955, loss after: 0.00130409980193.\n",
      "Epoch:2, weight train batch: 55, step:0, loss before: 0.00102976337075, loss after: 0.00102827511728.\n",
      "Epoch:2, weight train batch: 55, step:1, loss before: 0.00131726078689, loss after: 0.00131534878165.\n",
      "Epoch:2, weight train batch: 55, step:2, loss before: 0.00124116439838, loss after: 0.00123940117192.\n",
      "Epoch:2, weight train batch: 55, step:3, loss before: 0.00139853754081, loss after: 0.00139666779432.\n",
      "Epoch:2, weight train batch: 55, step:4, loss before: 0.00120465783402, loss after: 0.00120288715698.\n",
      "Epoch:2, weight train batch: 55, step:5, loss before: 0.00104904989712, loss after: 0.00104747596197.\n",
      "Epoch:2, weight train batch: 55, step:6, loss before: 0.00117948651314, loss after: 0.00117780489381.\n",
      "Epoch:2, weight train batch: 55, step:7, loss before: 0.00112412916496, loss after: 0.00112241774332.\n",
      "Epoch:2, weight train batch: 55, step:8, loss before: 0.00118847156409, loss after: 0.00118664093316.\n",
      "Epoch:2, weight train batch: 55, step:9, loss before: 0.00117481756024, loss after: 0.00117305410095.\n",
      "Epoch:2, weight train batch: 55, step:10, loss before: 0.00121165404562, loss after: 0.00120972690638.\n",
      "Epoch:2, weight train batch: 55, step:11, loss before: 0.00110205484089, loss after: 0.0011004662374.\n",
      "Epoch:2, weight train batch: 55, step:12, loss before: 0.00129277107771, loss after: 0.00129095953889.\n",
      "Epoch:2, weight train batch: 55, step:13, loss before: 0.00139868992846, loss after: 0.00139643123839.\n",
      "Epoch:2, weight train batch: 55, step:14, loss before: 0.00123128481209, loss after: 0.00122954009566.\n",
      "Epoch:2, weight train batch: 55, step:15, loss before: 0.00109121529385, loss after: 0.00108950375579.\n",
      "Epoch:2, weight train batch: 55, step:16, loss before: 0.00118054565974, loss after: 0.00117876729928.\n",
      "Epoch:2, weight train batch: 55, step:17, loss before: 0.00123530253768, loss after: 0.00123355793767.\n",
      "Epoch:2, weight train batch: 55, step:18, loss before: 0.00101262389217, loss after: 0.00101104634814.\n",
      "Epoch:2, weight train batch: 55, step:19, loss before: 0.00132695608772, loss after: 0.00132506259251.\n",
      "Epoch:2, weight train batch: 55, step:20, loss before: 0.00148023618385, loss after: 0.00147813849617.\n",
      "Epoch:2, weight train batch: 55, step:21, loss before: 0.00123655144125, loss after: 0.00123464665376.\n",
      "Epoch:2, weight train batch: 55, step:22, loss before: 0.00150391389616, loss after: 0.00150158093311.\n",
      "Epoch:2, weight train batch: 55, step:23, loss before: 0.00139335659333, loss after: 0.00139129243325.\n",
      "Epoch:2, weight train batch: 55, step:24, loss before: 0.00116257136688, loss after: 0.0011606591288.\n",
      "Epoch:2, weight train batch: 55, step:25, loss before: 0.0480240546167, loss after: 0.0479817166924.\n",
      "Epoch:2, weight train batch: 55, step:26, loss before: 0.00194852659479, loss after: 0.00194664474111.\n",
      "Epoch:2, weight train batch: 55, step:27, loss before: 0.00115561718121, loss after: 0.00115386839025.\n",
      "Epoch:2, weight train batch: 55, step:28, loss before: 0.00118823489174, loss after: 0.00118686200585.\n",
      "Epoch:2, weight train batch: 55, step:29, loss before: 0.00129991816357, loss after: 0.00129838159773.\n",
      "Epoch:2, weight train batch: 55, step:30, loss before: 0.00120101193897, loss after: 0.00119995884597.\n",
      "Epoch:2, weight train batch: 55, step:31, loss before: 0.00125125062186, loss after: 0.00124962849077.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 51, loss before: 0.00114669208415, loss after: 0.00109868717846.\n",
      "Epoch:2, weight train batch: 56, step:0, loss before: 0.00116301793605, loss after: 0.00116144039202.\n",
      "Epoch:2, weight train batch: 56, step:1, loss before: 0.00112306885421, loss after: 0.00112151750363.\n",
      "Epoch:2, weight train batch: 56, step:2, loss before: 0.00128933857195, loss after: 0.00128771306481.\n",
      "Epoch:2, weight train batch: 56, step:3, loss before: 0.00110443937592, loss after: 0.00110291386954.\n",
      "Epoch:2, weight train batch: 56, step:4, loss before: 0.00105356960557, loss after: 0.00105204421561.\n",
      "Epoch:2, weight train batch: 56, step:5, loss before: 0.00119815859944, loss after: 0.00119644007646.\n",
      "Epoch:2, weight train batch: 56, step:6, loss before: 0.00113437871914, loss after: 0.0011328200344.\n",
      "Epoch:2, weight train batch: 56, step:7, loss before: 0.00108556076884, loss after: 0.00108387949876.\n",
      "Epoch:2, weight train batch: 56, step:8, loss before: 0.00112767308019, loss after: 0.00112585024908.\n",
      "Epoch:2, weight train batch: 56, step:9, loss before: 0.00103691942059, loss after: 0.00103536795359.\n",
      "Epoch:2, weight train batch: 56, step:10, loss before: 0.00100184802432, loss after: 0.00100042298436.\n",
      "Epoch:2, weight train batch: 56, step:11, loss before: 0.00120702583808, loss after: 0.00120538903866.\n",
      "Epoch:2, weight train batch: 56, step:12, loss before: 0.00120878941379, loss after: 0.00120715261437.\n",
      "Epoch:2, weight train batch: 56, step:13, loss before: 0.00115863152314, loss after: 0.0011570021743.\n",
      "Epoch:2, weight train batch: 56, step:14, loss before: 0.0010851349216, loss after: 0.00108364294283.\n",
      "Epoch:2, weight train batch: 56, step:15, loss before: 0.00119902135339, loss after: 0.00119735486805.\n",
      "Epoch:2, weight train batch: 56, step:16, loss before: 0.00128970597871, loss after: 0.00128790549934.\n",
      "Epoch:2, weight train batch: 56, step:17, loss before: 0.00123333372176, loss after: 0.00123161892407.\n",
      "Epoch:2, weight train batch: 56, step:18, loss before: 0.00118916016072, loss after: 0.00118750100955.\n",
      "Epoch:2, weight train batch: 56, step:19, loss before: 0.0010434712749, loss after: 0.00104196812026.\n",
      "Epoch:2, weight train batch: 56, step:20, loss before: 0.00118648633361, loss after: 0.00118480855599.\n",
      "Epoch:2, weight train batch: 56, step:21, loss before: 0.00144760799594, loss after: 0.00144569692202.\n",
      "Epoch:2, weight train batch: 56, step:22, loss before: 0.00109138875268, loss after: 0.0010897887405.\n",
      "Epoch:2, weight train batch: 56, step:23, loss before: 0.00163604819681, loss after: 0.00163371604867.\n",
      "Epoch:2, weight train batch: 56, step:24, loss before: 0.00126414268743, loss after: 0.0012622193899.\n",
      "Epoch:2, weight train batch: 56, step:25, loss before: 0.00132007990032, loss after: 0.00131836929359.\n",
      "Epoch:2, weight train batch: 56, step:26, loss before: 0.0151611594483, loss after: 0.0151492441073.\n",
      "Epoch:2, weight train batch: 56, step:27, loss before: 0.00132834468968, loss after: 0.0013262842549.\n",
      "Epoch:2, weight train batch: 56, step:28, loss before: 0.00116640212946, loss after: 0.00116467231419.\n",
      "Epoch:2, weight train batch: 56, step:29, loss before: 0.00122311781161, loss after: 0.00122115784325.\n",
      "Epoch:2, weight train batch: 56, step:30, loss before: 0.00117749790661, loss after: 0.00117583503015.\n",
      "Epoch:2, weight train batch: 56, step:31, loss before: 0.0014034510823, loss after: 0.00140130938962.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 52, loss before: 0.00109820556827, loss after: 0.00119354319759.\n",
      "Epoch:2, weight train batch: 57, step:0, loss before: 0.00108242605347, loss after: 0.00108085991815.\n",
      "Epoch:2, weight train batch: 57, step:1, loss before: 0.00104105472565, loss after: 0.00103960745037.\n",
      "Epoch:2, weight train batch: 57, step:2, loss before: 0.00133439677302, loss after: 0.0013322395971.\n",
      "Epoch:2, weight train batch: 57, step:3, loss before: 0.0010487085674, loss after: 0.00104707165156.\n",
      "Epoch:2, weight train batch: 57, step:4, loss before: 0.00108552421443, loss after: 0.00108385761268.\n",
      "Epoch:2, weight train batch: 57, step:5, loss before: 0.000954790681135, loss after: 0.000953376875259.\n",
      "Epoch:2, weight train batch: 57, step:6, loss before: 0.000944032741245, loss after: 0.000942782615311.\n",
      "Epoch:2, weight train batch: 57, step:7, loss before: 0.00106188096106, loss after: 0.00106024404522.\n",
      "Epoch:2, weight train batch: 57, step:8, loss before: 0.00111262535211, loss after: 0.00111098843627.\n",
      "Epoch:2, weight train batch: 57, step:9, loss before: 0.00105043174699, loss after: 0.001048988197.\n",
      "Epoch:2, weight train batch: 57, step:10, loss before: 0.00120218435768, loss after: 0.00120047305245.\n",
      "Epoch:2, weight train batch: 57, step:11, loss before: 0.00103164615575, loss after: 0.00103018409573.\n",
      "Epoch:2, weight train batch: 57, step:12, loss before: 0.00123502395581, loss after: 0.00123333139345.\n",
      "Epoch:2, weight train batch: 57, step:13, loss before: 0.00107390619814, loss after: 0.0010723399464.\n",
      "Epoch:2, weight train batch: 57, step:14, loss before: 0.00106585142203, loss after: 0.0010643186979.\n",
      "Epoch:2, weight train batch: 57, step:15, loss before: 0.00108180707321, loss after: 0.00108035618905.\n",
      "Epoch:2, weight train batch: 57, step:16, loss before: 0.00671007903293, loss after: 0.00670677330345.\n",
      "Epoch:2, weight train batch: 57, step:17, loss before: 0.00092229701113, loss after: 0.000920998281799.\n",
      "Epoch:2, weight train batch: 57, step:18, loss before: 0.000992641202174, loss after: 0.000991123379208.\n",
      "Epoch:2, weight train batch: 57, step:19, loss before: 0.00177106738556, loss after: 0.00176920834929.\n",
      "Epoch:2, weight train batch: 57, step:20, loss before: 0.00113127485383, loss after: 0.00112969754264.\n",
      "Epoch:2, weight train batch: 57, step:21, loss before: 0.00101501191966, loss after: 0.00101375440136.\n",
      "Epoch:2, weight train batch: 57, step:22, loss before: 0.00113392085768, loss after: 0.00113243272062.\n",
      "Epoch:2, weight train batch: 57, step:23, loss before: 0.00106829812285, loss after: 0.00106692523696.\n",
      "Epoch:2, weight train batch: 57, step:24, loss before: 0.00105970352888, loss after: 0.00105833064299.\n",
      "Epoch:2, weight train batch: 57, step:25, loss before: 0.00122647278477, loss after: 0.00122486776672.\n",
      "Epoch:2, weight train batch: 57, step:26, loss before: 0.000949327484705, loss after: 0.000948069791775.\n",
      "Epoch:2, weight train batch: 57, step:27, loss before: 0.000990964472294, loss after: 0.000989639782347.\n",
      "Epoch:2, weight train batch: 57, step:28, loss before: 0.000985213555396, loss after: 0.00098384427838.\n",
      "Epoch:2, weight train batch: 57, step:29, loss before: 0.00116779562086, loss after: 0.00116628920659.\n",
      "Epoch:2, weight train batch: 57, step:30, loss before: 0.00116316089407, loss after: 0.00116155750584.\n",
      "Epoch:2, weight train batch: 57, step:31, loss before: 0.0010638711974, loss after: 0.00106252916157.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 53, loss before: 0.00111574970651, loss after: 0.00111574877519.\n",
      "Epoch:2, weight train batch: 58, step:0, loss before: 0.00107337534428, loss after: 0.00107204704545.\n",
      "Epoch:2, weight train batch: 58, step:1, loss before: 0.0011035494972, loss after: 0.00110212818254.\n",
      "Epoch:2, weight train batch: 58, step:2, loss before: 0.00187683501281, loss after: 0.00187399890274.\n",
      "Epoch:2, weight train batch: 58, step:3, loss before: 0.00111357995775, loss after: 0.0011122180149.\n",
      "Epoch:2, weight train batch: 58, step:4, loss before: 0.00113797630183, loss after: 0.00113650667481.\n",
      "Epoch:2, weight train batch: 58, step:5, loss before: 0.00122180441394, loss after: 0.00122020114213.\n",
      "Epoch:2, weight train batch: 58, step:6, loss before: 0.00106833851896, loss after: 0.00106693955604.\n",
      "Epoch:2, weight train batch: 58, step:7, loss before: 0.00110216182657, loss after: 0.00110064016189.\n",
      "Epoch:2, weight train batch: 58, step:8, loss before: 0.00112822186202, loss after: 0.00112675619312.\n",
      "Epoch:2, weight train batch: 58, step:9, loss before: 0.00129711697809, loss after: 0.00129535037559.\n",
      "Epoch:2, weight train batch: 58, step:10, loss before: 0.00113444286399, loss after: 0.00113286916167.\n",
      "Epoch:2, weight train batch: 58, step:11, loss before: 0.000907944282517, loss after: 0.000906764646061.\n",
      "Epoch:2, weight train batch: 58, step:12, loss before: 0.00102240347769, loss after: 0.00102106039412.\n",
      "Epoch:2, weight train batch: 58, step:13, loss before: 0.000935792049859, loss after: 0.000934579002205.\n",
      "Epoch:2, weight train batch: 58, step:14, loss before: 0.001040750416, loss after: 0.00103940733243.\n",
      "Epoch:2, weight train batch: 58, step:15, loss before: 0.000872541277204, loss after: 0.000871398835443.\n",
      "Epoch:2, weight train batch: 58, step:16, loss before: 0.00169425632339, loss after: 0.00169214443304.\n",
      "Epoch:2, weight train batch: 58, step:17, loss before: 0.00110857258551, loss after: 0.00110715907067.\n",
      "Epoch:2, weight train batch: 58, step:18, loss before: 0.00101496977732, loss after: 0.00101368979085.\n",
      "Epoch:2, weight train batch: 58, step:19, loss before: 0.0011603878811, loss after: 0.00115896482021.\n",
      "Epoch:2, weight train batch: 58, step:20, loss before: 0.00100659066811, loss after: 0.00100530334748.\n",
      "Epoch:2, weight train batch: 58, step:21, loss before: 0.000997797120363, loss after: 0.000996543210931.\n",
      "Epoch:2, weight train batch: 58, step:22, loss before: 0.00108850945253, loss after: 0.00108715891838.\n",
      "Epoch:2, weight train batch: 58, step:23, loss before: 0.000999858602881, loss after: 0.00099854497239.\n",
      "Epoch:2, weight train batch: 58, step:24, loss before: 0.00112340017222, loss after: 0.00112196046393.\n",
      "Epoch:2, weight train batch: 58, step:25, loss before: 0.00214064912871, loss after: 0.00213853223249.\n",
      "Epoch:2, weight train batch: 58, step:26, loss before: 0.00290276482701, loss after: 0.00289977481589.\n",
      "Epoch:2, weight train batch: 58, step:27, loss before: 0.00100234407, loss after: 0.0010009376565.\n",
      "Epoch:2, weight train batch: 58, step:28, loss before: 0.000911788316444, loss after: 0.000910541857593.\n",
      "Epoch:2, weight train batch: 58, step:29, loss before: 0.00098889763467, loss after: 0.000987491104752.\n",
      "Epoch:2, weight train batch: 58, step:30, loss before: 0.000992692890577, loss after: 0.000991394277662.\n",
      "Epoch:2, weight train batch: 58, step:31, loss before: 0.00111644552089, loss after: 0.0011149685597.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 54, loss before: 0.00130173296202, loss after: 0.00102263595909.\n",
      "Epoch:2, weight train batch: 59, step:0, loss before: 0.000971919798758, loss after: 0.000970639754087.\n",
      "Epoch:2, weight train batch: 59, step:1, loss before: 0.00131672667339, loss after: 0.00131482211873.\n",
      "Epoch:2, weight train batch: 59, step:2, loss before: 0.00125839211978, loss after: 0.00125664426014.\n",
      "Epoch:2, weight train batch: 59, step:3, loss before: 0.00128249055706, loss after: 0.00128077936824.\n",
      "Epoch:2, weight train batch: 59, step:4, loss before: 0.000918045232538, loss after: 0.000916802324355.\n",
      "Epoch:2, weight train batch: 59, step:5, loss before: 0.0010383662302, loss after: 0.00103699334431.\n",
      "Epoch:2, weight train batch: 59, step:6, loss before: 0.00103061203845, loss after: 0.00102920923382.\n",
      "Epoch:2, weight train batch: 59, step:7, loss before: 0.00109799113125, loss after: 0.00109649566002.\n",
      "Epoch:2, weight train batch: 59, step:8, loss before: 0.00103511265479, loss after: 0.00103377329651.\n",
      "Epoch:2, weight train batch: 59, step:9, loss before: 0.000931729795411, loss after: 0.000930453650653.\n",
      "Epoch:2, weight train batch: 59, step:10, loss before: 0.00102986837737, loss after: 0.00102850282565.\n",
      "Epoch:2, weight train batch: 59, step:11, loss before: 0.00121000851505, loss after: 0.0012084771879.\n",
      "Epoch:2, weight train batch: 59, step:12, loss before: 0.00106159888674, loss after: 0.00106018513907.\n",
      "Epoch:2, weight train batch: 59, step:13, loss before: 0.00112469529267, loss after: 0.00112315150909.\n",
      "Epoch:2, weight train batch: 59, step:14, loss before: 0.00109955575317, loss after: 0.00109808624256.\n",
      "Epoch:2, weight train batch: 59, step:15, loss before: 0.000878163205925, loss after: 0.000877002195921.\n",
      "Epoch:2, weight train batch: 59, step:16, loss before: 0.00100624165498, loss after: 0.00100489845499.\n",
      "Epoch:2, weight train batch: 59, step:17, loss before: 0.00116734683979, loss after: 0.00116584380157.\n",
      "Epoch:2, weight train batch: 59, step:18, loss before: 0.00106701266486, loss after: 0.00106560997665.\n",
      "Epoch:2, weight train batch: 59, step:19, loss before: 0.00108547043055, loss after: 0.00108405295759.\n",
      "Epoch:2, weight train batch: 59, step:20, loss before: 0.00101897050627, loss after: 0.00101764232386.\n",
      "Epoch:2, weight train batch: 59, step:21, loss before: 0.000974722206593, loss after: 0.00097345712129.\n",
      "Epoch:2, weight train batch: 59, step:22, loss before: 0.000928339257371, loss after: 0.000927159795538.\n",
      "Epoch:2, weight train batch: 59, step:23, loss before: 0.000945019943174, loss after: 0.000943803228438.\n",
      "Epoch:2, weight train batch: 59, step:24, loss before: 0.000944064115174, loss after: 0.000942873419262.\n",
      "Epoch:2, weight train batch: 59, step:25, loss before: 0.0010503930971, loss after: 0.00104899413418.\n",
      "Epoch:2, weight train batch: 59, step:26, loss before: 0.00101345521398, loss after: 0.00101222353987.\n",
      "Epoch:2, weight train batch: 59, step:27, loss before: 0.000889171264134, loss after: 0.000888088252395.\n",
      "Epoch:2, weight train batch: 59, step:28, loss before: 0.00102616776712, loss after: 0.00102489907295.\n",
      "Epoch:2, weight train batch: 59, step:29, loss before: 0.000993867055513, loss after: 0.00099264679011.\n",
      "Epoch:2, weight train batch: 59, step:30, loss before: 0.000921630416997, loss after: 0.00092043587938.\n",
      "Epoch:2, weight train batch: 59, step:31, loss before: 0.000989194493741, loss after: 0.000988018815406.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:2, struct parameters train batch: 55, loss before: 0.000975775532424, loss after: 0.000975775532424.\n",
      "Epoch:3, weight train batch: 60, step:0, loss before: 0.000945690961089, loss after: 0.00094450393226.\n",
      "Epoch:3, weight train batch: 60, step:1, loss before: 0.000922619714402, loss after: 0.000921469938476.\n",
      "Epoch:3, weight train batch: 60, step:2, loss before: 0.000874890596606, loss after: 0.000873826269526.\n",
      "Epoch:3, weight train batch: 60, step:3, loss before: 0.00117875309661, loss after: 0.00117725017481.\n",
      "Epoch:3, weight train batch: 60, step:4, loss before: 0.000991785665974, loss after: 0.000990580068901.\n",
      "Epoch:3, weight train batch: 60, step:5, loss before: 0.00103938835673, loss after: 0.00103813805617.\n",
      "Epoch:3, weight train batch: 60, step:6, loss before: 0.000980975455604, loss after: 0.000979740172625.\n",
      "Epoch:3, weight train batch: 60, step:7, loss before: 0.0477202162147, loss after: 0.0476742386818.\n",
      "Epoch:3, weight train batch: 60, step:8, loss before: 0.000852303171996, loss after: 0.000852616038173.\n",
      "Epoch:3, weight train batch: 60, step:9, loss before: 0.00106298562605, loss after: 0.00106335012242.\n",
      "Epoch:3, weight train batch: 60, step:10, loss before: 0.000948860892095, loss after: 0.000948756933212.\n",
      "Epoch:3, weight train batch: 60, step:11, loss before: 0.0010677461978, loss after: 0.00106765329838.\n",
      "Epoch:3, weight train batch: 60, step:12, loss before: 0.0144980354235, loss after: 0.0144905205816.\n",
      "Epoch:3, weight train batch: 60, step:13, loss before: 0.00100373837631, loss after: 0.00100326980464.\n",
      "Epoch:3, weight train batch: 60, step:14, loss before: 0.000983814708889, loss after: 0.000983156380244.\n",
      "Epoch:3, weight train batch: 60, step:15, loss before: 0.000991298817098, loss after: 0.000990547472611.\n",
      "Epoch:3, weight train batch: 60, step:16, loss before: 0.000989892985672, loss after: 0.000988929416053.\n",
      "Epoch:3, weight train batch: 60, step:17, loss before: 0.00109740486369, loss after: 0.00109630380757.\n",
      "Epoch:3, weight train batch: 60, step:18, loss before: 0.000996041460894, loss after: 0.00099488440901.\n",
      "Epoch:3, weight train batch: 60, step:19, loss before: 0.0011469181627, loss after: 0.00114537810441.\n",
      "Epoch:3, weight train batch: 60, step:20, loss before: 0.000889517134055, loss after: 0.000888516253326.\n",
      "Epoch:3, weight train batch: 60, step:21, loss before: 0.000901835272089, loss after: 0.00090075249318.\n",
      "Epoch:3, weight train batch: 60, step:22, loss before: 0.000993317225948, loss after: 0.000991985434666.\n",
      "Epoch:3, weight train batch: 60, step:23, loss before: 0.000907032866962, loss after: 0.000905782566406.\n",
      "Epoch:3, weight train batch: 60, step:24, loss before: 0.00100527226459, loss after: 0.00100362789817.\n",
      "Epoch:3, weight train batch: 60, step:25, loss before: 0.00102117669303, loss after: 0.00101960287429.\n",
      "Epoch:3, weight train batch: 60, step:26, loss before: 0.00114985601977, loss after: 0.00114810024388.\n",
      "Epoch:3, weight train batch: 60, step:27, loss before: 0.000928941299208, loss after: 0.000927646527998.\n",
      "Epoch:3, weight train batch: 60, step:28, loss before: 0.00186032301281, loss after: 0.00185723532923.\n",
      "Epoch:3, weight train batch: 60, step:29, loss before: 0.000989317544736, loss after: 0.000987765961327.\n",
      "Epoch:3, weight train batch: 60, step:30, loss before: 0.000954260351136, loss after: 0.000952924485318.\n",
      "Epoch:3, weight train batch: 60, step:31, loss before: 0.00107477698475, loss after: 0.00107337045483.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 56, loss before: 0.00100603117608, loss after: 0.00110449024942.\n",
      "Epoch:3, weight train batch: 61, step:0, loss before: 0.000965943327174, loss after: 0.000964640930761.\n",
      "Epoch:3, weight train batch: 61, step:1, loss before: 0.00122534669936, loss after: 0.00122361234389.\n",
      "Epoch:3, weight train batch: 61, step:2, loss before: 0.0473178550601, loss after: 0.0472856238484.\n",
      "Epoch:3, weight train batch: 61, step:3, loss before: 0.000975729548372, loss after: 0.000974940601736.\n",
      "Epoch:3, weight train batch: 61, step:4, loss before: 0.000879891740624, loss after: 0.000878898077644.\n",
      "Epoch:3, weight train batch: 61, step:5, loss before: 0.00122660247143, loss after: 0.00122547883075.\n",
      "Epoch:3, weight train batch: 61, step:6, loss before: 0.000939540856052, loss after: 0.000938826240599.\n",
      "Epoch:3, weight train batch: 61, step:7, loss before: 0.000893160060514, loss after: 0.000892263080459.\n",
      "Epoch:3, weight train batch: 61, step:8, loss before: 0.000979113858193, loss after: 0.000978109193966.\n",
      "Epoch:3, weight train batch: 61, step:9, loss before: 0.000983220525086, loss after: 0.000982267782092.\n",
      "Epoch:3, weight train batch: 61, step:10, loss before: 0.00102647824679, loss after: 0.00102541036904.\n",
      "Epoch:3, weight train batch: 61, step:11, loss before: 0.000909404596314, loss after: 0.000908325309865.\n",
      "Epoch:3, weight train batch: 61, step:12, loss before: 0.000994235393591, loss after: 0.000993066933006.\n",
      "Epoch:3, weight train batch: 61, step:13, loss before: 0.000854420475662, loss after: 0.000853192294016.\n",
      "Epoch:3, weight train batch: 61, step:14, loss before: 0.00103522697464, loss after: 0.00103391718585.\n",
      "Epoch:3, weight train batch: 61, step:15, loss before: 0.000968683394603, loss after: 0.000967381172813.\n",
      "Epoch:3, weight train batch: 61, step:16, loss before: 0.000848050345667, loss after: 0.000846725481097.\n",
      "Epoch:3, weight train batch: 61, step:17, loss before: 0.000883993634488, loss after: 0.000882598164026.\n",
      "Epoch:3, weight train batch: 61, step:18, loss before: 0.000982007477432, loss after: 0.000980515731499.\n",
      "Epoch:3, weight train batch: 61, step:19, loss before: 0.000906094617676, loss after: 0.000904695480131.\n",
      "Epoch:3, weight train batch: 61, step:20, loss before: 0.001016844064, loss after: 0.0010154126212.\n",
      "Epoch:3, weight train batch: 61, step:21, loss before: 0.00100156164262, loss after: 0.00100015499629.\n",
      "Epoch:3, weight train batch: 61, step:22, loss before: 0.000971426663455, loss after: 0.000970187713392.\n",
      "Epoch:3, weight train batch: 61, step:23, loss before: 0.000974755384959, loss after: 0.000973519927356.\n",
      "Epoch:3, weight train batch: 61, step:24, loss before: 0.00096744496841, loss after: 0.000966179766692.\n",
      "Epoch:3, weight train batch: 61, step:25, loss before: 0.000863562105224, loss after: 0.000862374901772.\n",
      "Epoch:3, weight train batch: 61, step:26, loss before: 0.00105895916931, loss after: 0.00105759350117.\n",
      "Epoch:3, weight train batch: 61, step:27, loss before: 0.000931354239583, loss after: 0.000930025591515.\n",
      "Epoch:3, weight train batch: 61, step:28, loss before: 0.00101341493428, loss after: 0.00101205322426.\n",
      "Epoch:3, weight train batch: 61, step:29, loss before: 0.000998790026642, loss after: 0.000997431692667.\n",
      "Epoch:3, weight train batch: 61, step:30, loss before: 0.0008397026686, loss after: 0.000838429958094.\n",
      "Epoch:3, weight train batch: 61, step:31, loss before: 0.000986157101579, loss after: 0.000984880840406.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 57, loss before: 0.000964195118286, loss after: 0.000924899883103.\n",
      "Epoch:3, weight train batch: 62, step:0, loss before: 0.000825401279144, loss after: 0.000824277289212.\n",
      "Epoch:3, weight train batch: 62, step:1, loss before: 0.000891896139365, loss after: 0.000890809576958.\n",
      "Epoch:3, weight train batch: 62, step:2, loss before: 0.00100825238042, loss after: 0.00100696110167.\n",
      "Epoch:3, weight train batch: 62, step:3, loss before: 0.000978841679171, loss after: 0.000977680669166.\n",
      "Epoch:3, weight train batch: 62, step:4, loss before: 0.000880868115928, loss after: 0.000879658735357.\n",
      "Epoch:3, weight train batch: 62, step:5, loss before: 0.00161354790907, loss after: 0.00161160784774.\n",
      "Epoch:3, weight train batch: 62, step:6, loss before: 0.000937508360948, loss after: 0.00093630264746.\n",
      "Epoch:3, weight train batch: 62, step:7, loss before: 0.000903625797946, loss after: 0.000902382889763.\n",
      "Epoch:3, weight train batch: 62, step:8, loss before: 0.000762328621931, loss after: 0.000761312549002.\n",
      "Epoch:3, weight train batch: 62, step:9, loss before: 0.00107720657252, loss after: 0.0010758045828.\n",
      "Epoch:3, weight train batch: 62, step:10, loss before: 0.000857146224007, loss after: 0.00085602235049.\n",
      "Epoch:3, weight train batch: 62, step:11, loss before: 0.000948086497374, loss after: 0.00094681000337.\n",
      "Epoch:3, weight train batch: 62, step:12, loss before: 0.000971147557721, loss after: 0.000969942018855.\n",
      "Epoch:3, weight train batch: 62, step:13, loss before: 0.000840054999571, loss after: 0.000838931184262.\n",
      "Epoch:3, weight train batch: 62, step:14, loss before: 0.000842696637847, loss after: 0.000841695466079.\n",
      "Epoch:3, weight train batch: 62, step:15, loss before: 0.000967545667663, loss after: 0.000966310151853.\n",
      "Epoch:3, weight train batch: 62, step:16, loss before: 0.000937598349992, loss after: 0.000936381460633.\n",
      "Epoch:3, weight train batch: 62, step:17, loss before: 0.00082637462765, loss after: 0.000825295399409.\n",
      "Epoch:3, weight train batch: 62, step:18, loss before: 0.000939049990848, loss after: 0.000937978329603.\n",
      "Epoch:3, weight train batch: 62, step:19, loss before: 0.000810690049548, loss after: 0.000809610704891.\n",
      "Epoch:3, weight train batch: 62, step:20, loss before: 0.00100678601302, loss after: 0.00100549869239.\n",
      "Epoch:3, weight train batch: 62, step:21, loss before: 0.000981889315881, loss after: 0.000980586977676.\n",
      "Epoch:3, weight train batch: 62, step:22, loss before: 0.000836293329485, loss after: 0.000835240120068.\n",
      "Epoch:3, weight train batch: 62, step:23, loss before: 0.000963005470112, loss after: 0.000961770128924.\n",
      "Epoch:3, weight train batch: 62, step:24, loss before: 0.000993474386632, loss after: 0.00099220185075.\n",
      "Epoch:3, weight train batch: 62, step:25, loss before: 0.000880567531567, loss after: 0.000879462400917.\n",
      "Epoch:3, weight train batch: 62, step:26, loss before: 0.000895689241588, loss after: 0.000894587719813.\n",
      "Epoch:3, weight train batch: 62, step:27, loss before: 0.000907899462618, loss after: 0.000906745903194.\n",
      "Epoch:3, weight train batch: 62, step:28, loss before: 0.000898654805496, loss after: 0.00089753838256.\n",
      "Epoch:3, weight train batch: 62, step:29, loss before: 0.00107735337224, loss after: 0.00107592449058.\n",
      "Epoch:3, weight train batch: 62, step:30, loss before: 0.000872637028806, loss after: 0.000871539290529.\n",
      "Epoch:3, weight train batch: 62, step:31, loss before: 0.00101879122667, loss after: 0.00101744057611.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 58, loss before: 0.000903033534996, loss after: 0.000903033534996.\n",
      "Epoch:3, weight train batch: 63, step:0, loss before: 0.000953870243393, loss after: 0.000952549336944.\n",
      "Epoch:3, weight train batch: 63, step:1, loss before: 0.000984293525107, loss after: 0.000982920639217.\n",
      "Epoch:3, weight train batch: 63, step:2, loss before: 0.000716126523912, loss after: 0.0007151364116.\n",
      "Epoch:3, weight train batch: 63, step:3, loss before: 0.000895765377209, loss after: 0.000894656404853.\n",
      "Epoch:3, weight train batch: 63, step:4, loss before: 0.000795286672655, loss after: 0.000794281833805.\n",
      "Epoch:3, weight train batch: 63, step:5, loss before: 0.000811533711385, loss after: 0.000810439581983.\n",
      "Epoch:3, weight train batch: 63, step:6, loss before: 0.000939095742069, loss after: 0.000937856559176.\n",
      "Epoch:3, weight train batch: 63, step:7, loss before: 0.000865620211698, loss after: 0.000864481378812.\n",
      "Epoch:3, weight train batch: 63, step:8, loss before: 0.000828290125355, loss after: 0.000827270443551.\n",
      "Epoch:3, weight train batch: 63, step:9, loss before: 0.000776906381361, loss after: 0.000775834429078.\n",
      "Epoch:3, weight train batch: 63, step:10, loss before: 0.000898369238712, loss after: 0.000897342106327.\n",
      "Epoch:3, weight train batch: 63, step:11, loss before: 0.00101371842902, loss after: 0.00101252784953.\n",
      "Epoch:3, weight train batch: 63, step:12, loss before: 0.000940966652706, loss after: 0.000939898658544.\n",
      "Epoch:3, weight train batch: 63, step:13, loss before: 0.000890635536052, loss after: 0.000889638147783.\n",
      "Epoch:3, weight train batch: 63, step:14, loss before: 0.00103013578337, loss after: 0.001028826111.\n",
      "Epoch:3, weight train batch: 63, step:15, loss before: 0.000782518705819, loss after: 0.000781640526839.\n",
      "Epoch:3, weight train batch: 63, step:16, loss before: 0.000975787523203, loss after: 0.000974637747277.\n",
      "Epoch:3, weight train batch: 63, step:17, loss before: 0.000951735768467, loss after: 0.000950530171394.\n",
      "Epoch:3, weight train batch: 63, step:18, loss before: 0.000874712597579, loss after: 0.000873693148606.\n",
      "Epoch:3, weight train batch: 63, step:19, loss before: 0.000814162776805, loss after: 0.000813150545582.\n",
      "Epoch:3, weight train batch: 63, step:20, loss before: 0.000832418154459, loss after: 0.0008314580773.\n",
      "Epoch:3, weight train batch: 63, step:21, loss before: 0.000870777759701, loss after: 0.000869676121511.\n",
      "Epoch:3, weight train batch: 63, step:22, loss before: 0.000926164910197, loss after: 0.000925070955418.\n",
      "Epoch:3, weight train batch: 63, step:23, loss before: 0.00090378371533, loss after: 0.000902630097698.\n",
      "Epoch:3, weight train batch: 63, step:24, loss before: 0.0016608578153, loss after: 0.00165868108161.\n",
      "Epoch:3, weight train batch: 63, step:25, loss before: 0.000711223867256, loss after: 0.000710252439603.\n",
      "Epoch:3, weight train batch: 63, step:26, loss before: 0.000826666364446, loss after: 0.000825579685625.\n",
      "Epoch:3, weight train batch: 63, step:27, loss before: 0.000897240650374, loss after: 0.000896157813258.\n",
      "Epoch:3, weight train batch: 63, step:28, loss before: 0.000783947587479, loss after: 0.000782916671596.\n",
      "Epoch:3, weight train batch: 63, step:29, loss before: 0.000943270279095, loss after: 0.000942157756072.\n",
      "Epoch:3, weight train batch: 63, step:30, loss before: 0.000915264477953, loss after: 0.00091411836911.\n",
      "Epoch:3, weight train batch: 63, step:31, loss before: 0.000748102436773, loss after: 0.000747164594941.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 59, loss before: 0.000904641579837, loss after: 0.000868184026331.\n",
      "Epoch:3, weight train batch: 64, step:0, loss before: 0.000816729618236, loss after: 0.000815702485852.\n",
      "Epoch:3, weight train batch: 64, step:1, loss before: 0.000875059864484, loss after: 0.000874006946106.\n",
      "Epoch:3, weight train batch: 64, step:2, loss before: 0.000883317901753, loss after: 0.00088231312111.\n",
      "Epoch:3, weight train batch: 64, step:3, loss before: 0.000955220661126, loss after: 0.000954033515882.\n",
      "Epoch:3, weight train batch: 64, step:4, loss before: 0.000943080405705, loss after: 0.000941904552747.\n",
      "Epoch:3, weight train batch: 64, step:5, loss before: 0.000901466351934, loss after: 0.000900338753127.\n",
      "Epoch:3, weight train batch: 64, step:6, loss before: 0.000745774130337, loss after: 0.000744888326153.\n",
      "Epoch:3, weight train batch: 64, step:7, loss before: 0.000839132233523, loss after: 0.000838127511088.\n",
      "Epoch:3, weight train batch: 64, step:8, loss before: 0.000808925717138, loss after: 0.000807954347692.\n",
      "Epoch:3, weight train batch: 64, step:9, loss before: 0.000809194752946, loss after: 0.000808241951745.\n",
      "Epoch:3, weight train batch: 64, step:10, loss before: 0.000925082538743, loss after: 0.000923940096982.\n",
      "Epoch:3, weight train batch: 64, step:11, loss before: 0.000860981410369, loss after: 0.000859909690917.\n",
      "Epoch:3, weight train batch: 64, step:12, loss before: 0.000797246932052, loss after: 0.000796346284915.\n",
      "Epoch:3, weight train batch: 64, step:13, loss before: 0.000756881432608, loss after: 0.000756070076022.\n",
      "Epoch:3, weight train batch: 64, step:14, loss before: 0.000787981727626, loss after: 0.000787081080489.\n",
      "Epoch:3, weight train batch: 64, step:15, loss before: 0.000883413711563, loss after: 0.000882394087967.\n",
      "Epoch:3, weight train batch: 64, step:16, loss before: 0.000784139498137, loss after: 0.000783283554483.\n",
      "Epoch:3, weight train batch: 64, step:17, loss before: 0.000743846409023, loss after: 0.00074297178071.\n",
      "Epoch:3, weight train batch: 64, step:18, loss before: 0.00089078390738, loss after: 0.000889734423254.\n",
      "Epoch:3, weight train batch: 64, step:19, loss before: 0.000862252665684, loss after: 0.00086127029499.\n",
      "Epoch:3, weight train batch: 64, step:20, loss before: 0.000782536983024, loss after: 0.000781576847658.\n",
      "Epoch:3, weight train batch: 64, step:21, loss before: 0.000881816202309, loss after: 0.00088076677639.\n",
      "Epoch:3, weight train batch: 64, step:22, loss before: 0.000788331846707, loss after: 0.000787431257777.\n",
      "Epoch:3, weight train batch: 64, step:23, loss before: 0.000987850828096, loss after: 0.000986663857475.\n",
      "Epoch:3, weight train batch: 64, step:24, loss before: 0.000858802697621, loss after: 0.000857812876347.\n",
      "Epoch:3, weight train batch: 64, step:25, loss before: 0.000878899241798, loss after: 0.000877846090589.\n",
      "Epoch:3, weight train batch: 64, step:26, loss before: 0.000754158594646, loss after: 0.000753287691623.\n",
      "Epoch:3, weight train batch: 64, step:27, loss before: 0.000818090338726, loss after: 0.000817100517452.\n",
      "Epoch:3, weight train batch: 64, step:28, loss before: 0.0145207652822, loss after: 0.0145090566948.\n",
      "Epoch:3, weight train batch: 64, step:29, loss before: 0.000761966162827, loss after: 0.000760630180594.\n",
      "Epoch:3, weight train batch: 64, step:30, loss before: 0.000859667256009, loss after: 0.000858264393173.\n",
      "Epoch:3, weight train batch: 64, step:31, loss before: 0.000827745592687, loss after: 0.000826376141049.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 60, loss before: 0.000910081085749, loss after: 0.000857923005242.\n",
      "Epoch:3, weight train batch: 65, step:0, loss before: 0.000838534382638, loss after: 0.000837418017909.\n",
      "Epoch:3, weight train batch: 65, step:1, loss before: 0.000766064273193, loss after: 0.000765111413784.\n",
      "Epoch:3, weight train batch: 65, step:2, loss before: 0.000768784084357, loss after: 0.000767727033235.\n",
      "Epoch:3, weight train batch: 65, step:3, loss before: 0.000821112655103, loss after: 0.000820040877443.\n",
      "Epoch:3, weight train batch: 65, step:4, loss before: 0.000888656242751, loss after: 0.000887476548087.\n",
      "Epoch:3, weight train batch: 65, step:5, loss before: 0.000872511242051, loss after: 0.000871294294484.\n",
      "Epoch:3, weight train batch: 65, step:6, loss before: 0.000879323866684, loss after: 0.000878099584952.\n",
      "Epoch:3, weight train batch: 65, step:7, loss before: 0.000811084057204, loss after: 0.00080991932191.\n",
      "Epoch:3, weight train batch: 65, step:8, loss before: 0.000860999920405, loss after: 0.000859850086272.\n",
      "Epoch:3, weight train batch: 65, step:9, loss before: 0.000906523375306, loss after: 0.000905265740585.\n",
      "Epoch:3, weight train batch: 65, step:10, loss before: 0.000881805259269, loss after: 0.00088068516925.\n",
      "Epoch:3, weight train batch: 65, step:11, loss before: 0.000851974647958, loss after: 0.000850731739774.\n",
      "Epoch:3, weight train batch: 65, step:12, loss before: 0.000643046631012, loss after: 0.000642372877337.\n",
      "Epoch:3, weight train batch: 65, step:13, loss before: 0.000761347298976, loss after: 0.000760532100685.\n",
      "Epoch:3, weight train batch: 65, step:14, loss before: 0.000794668390881, loss after: 0.000793671002612.\n",
      "Epoch:3, weight train batch: 65, step:15, loss before: 0.000838429899886, loss after: 0.000837425177451.\n",
      "Epoch:3, weight train batch: 65, step:16, loss before: 0.00094179995358, loss after: 0.000940672820434.\n",
      "Epoch:3, weight train batch: 65, step:17, loss before: 0.000684427563101, loss after: 0.000683623598889.\n",
      "Epoch:3, weight train batch: 65, step:18, loss before: 0.000700609933119, loss after: 0.000699772499502.\n",
      "Epoch:3, weight train batch: 65, step:19, loss before: 0.000736697111279, loss after: 0.000735803856514.\n",
      "Epoch:3, weight train batch: 65, step:20, loss before: 0.000751018757001, loss after: 0.00075017020572.\n",
      "Epoch:3, weight train batch: 65, step:21, loss before: 0.000704875099473, loss after: 0.000704086036421.\n",
      "Epoch:3, weight train batch: 65, step:22, loss before: 0.000993150402792, loss after: 0.000992019777186.\n",
      "Epoch:3, weight train batch: 65, step:23, loss before: 0.000838970241603, loss after: 0.000837984029204.\n",
      "Epoch:3, weight train batch: 65, step:24, loss before: 0.000768395082559, loss after: 0.00076755770715.\n",
      "Epoch:3, weight train batch: 65, step:25, loss before: 0.000738835311495, loss after: 0.000737941940315.\n",
      "Epoch:3, weight train batch: 65, step:26, loss before: 0.000797609449364, loss after: 0.000796742213424.\n",
      "Epoch:3, weight train batch: 65, step:27, loss before: 0.00137949583586, loss after: 0.00137820211239.\n",
      "Epoch:3, weight train batch: 65, step:28, loss before: 0.000885799468961, loss after: 0.000884698005393.\n",
      "Epoch:3, weight train batch: 65, step:29, loss before: 0.000812461366877, loss after: 0.000811494537629.\n",
      "Epoch:3, weight train batch: 65, step:30, loss before: 0.000898906437214, loss after: 0.000897842110135.\n",
      "Epoch:3, weight train batch: 65, step:31, loss before: 0.000800404755864, loss after: 0.000799493049271.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 61, loss before: 0.000771856866777, loss after: 0.00077178014908.\n",
      "Epoch:3, weight train batch: 66, step:0, loss before: 0.000851659220643, loss after: 0.000850695301779.\n",
      "Epoch:3, weight train batch: 66, step:1, loss before: 0.000683970400132, loss after: 0.000683151534759.\n",
      "Epoch:3, weight train batch: 66, step:2, loss before: 0.000716613722034, loss after: 0.00071572791785.\n",
      "Epoch:3, weight train batch: 66, step:3, loss before: 0.000774945016019, loss after: 0.000773984764237.\n",
      "Epoch:3, weight train batch: 66, step:4, loss before: 0.000744528020732, loss after: 0.000743657001294.\n",
      "Epoch:3, weight train batch: 66, step:5, loss before: 0.000809613440651, loss after: 0.00080869422527.\n",
      "Epoch:3, weight train batch: 66, step:6, loss before: 0.000876015052199, loss after: 0.000874991645105.\n",
      "Epoch:3, weight train batch: 66, step:7, loss before: 0.00076446053572, loss after: 0.000763582182117.\n",
      "Epoch:3, weight train batch: 66, step:8, loss before: 0.000918563338928, loss after: 0.000917454482988.\n",
      "Epoch:3, weight train batch: 66, step:9, loss before: 0.000644499901682, loss after: 0.000643807637971.\n",
      "Epoch:3, weight train batch: 66, step:10, loss before: 0.000680673168972, loss after: 0.00067988038063.\n",
      "Epoch:3, weight train batch: 66, step:11, loss before: 0.000774732849095, loss after: 0.000773891690187.\n",
      "Epoch:3, weight train batch: 66, step:12, loss before: 0.000664342369419, loss after: 0.000663545797579.\n",
      "Epoch:3, weight train batch: 66, step:13, loss before: 0.000951708760113, loss after: 0.000950671092141.\n",
      "Epoch:3, weight train batch: 66, step:14, loss before: 0.000787418335676, loss after: 0.000786473043263.\n",
      "Epoch:3, weight train batch: 66, step:15, loss before: 0.000772033818066, loss after: 0.000771140563302.\n",
      "Epoch:3, weight train batch: 66, step:16, loss before: 0.000807336240541, loss after: 0.000806361262221.\n",
      "Epoch:3, weight train batch: 66, step:17, loss before: 0.000770055281464, loss after: 0.000769203004893.\n",
      "Epoch:3, weight train batch: 66, step:18, loss before: 0.0007902411744, loss after: 0.000789325567894.\n",
      "Epoch:3, weight train batch: 66, step:19, loss before: 0.000761080649681, loss after: 0.000760232098401.\n",
      "Epoch:3, weight train batch: 66, step:20, loss before: 0.0007597063086, loss after: 0.000758835463785.\n",
      "Epoch:3, weight train batch: 66, step:21, loss before: 0.000664817693178, loss after: 0.000664058374241.\n",
      "Epoch:3, weight train batch: 66, step:22, loss before: 0.0007436327287, loss after: 0.000742780568544.\n",
      "Epoch:3, weight train batch: 66, step:23, loss before: 0.0062198122032, loss after: 0.0062168398872.\n",
      "Epoch:3, weight train batch: 66, step:24, loss before: 0.000900625134818, loss after: 0.000899586942978.\n",
      "Epoch:3, weight train batch: 66, step:25, loss before: 0.000654648407362, loss after: 0.000653896597214.\n",
      "Epoch:3, weight train batch: 66, step:26, loss before: 0.000761670293286, loss after: 0.000760843977332.\n",
      "Epoch:3, weight train batch: 66, step:27, loss before: 0.000739339331631, loss after: 0.000738461036235.\n",
      "Epoch:3, weight train batch: 66, step:28, loss before: 0.00146813946776, loss after: 0.00146608357318.\n",
      "Epoch:3, weight train batch: 66, step:29, loss before: 0.000730648986064, loss after: 0.000729815335944.\n",
      "Epoch:3, weight train batch: 66, step:30, loss before: 0.000887263275217, loss after: 0.00088610954117.\n",
      "Epoch:3, weight train batch: 66, step:31, loss before: 0.000843489600811, loss after: 0.000842507113703.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 62, loss before: 0.000715379661415, loss after: 0.000715376867447.\n",
      "Epoch:3, weight train batch: 67, step:0, loss before: 0.000792160921264, loss after: 0.000791133730672.\n",
      "Epoch:3, weight train batch: 67, step:1, loss before: 0.000747766753193, loss after: 0.000746747013181.\n",
      "Epoch:3, weight train batch: 67, step:2, loss before: 0.000754423905164, loss after: 0.000753560452722.\n",
      "Epoch:3, weight train batch: 67, step:3, loss before: 0.000724821700715, loss after: 0.000723917211872.\n",
      "Epoch:3, weight train batch: 67, step:4, loss before: 0.000652810151223, loss after: 0.000652013695799.\n",
      "Epoch:3, weight train batch: 67, step:5, loss before: 0.000723038858268, loss after: 0.000722201424651.\n",
      "Epoch:3, weight train batch: 67, step:6, loss before: 0.000944396771956, loss after: 0.000943358929362.\n",
      "Epoch:3, weight train batch: 67, step:7, loss before: 0.00075720413588, loss after: 0.000756336958148.\n",
      "Epoch:3, weight train batch: 67, step:8, loss before: 0.000728053273633, loss after: 0.00072724558413.\n",
      "Epoch:3, weight train batch: 67, step:9, loss before: 0.000713036861271, loss after: 0.000712214270607.\n",
      "Epoch:3, weight train batch: 67, step:10, loss before: 0.00074760906864, loss after: 0.000746730656829.\n",
      "Epoch:3, weight train batch: 67, step:11, loss before: 0.000744583434425, loss after: 0.000743738550227.\n",
      "Epoch:3, weight train batch: 67, step:12, loss before: 0.000695001101121, loss after: 0.000694197136909.\n",
      "Epoch:3, weight train batch: 67, step:13, loss before: 0.000703423924278, loss after: 0.000702649704181.\n",
      "Epoch:3, weight train batch: 67, step:14, loss before: 0.000877566984855, loss after: 0.000876584730577.\n",
      "Epoch:3, weight train batch: 67, step:15, loss before: 0.000686615181621, loss after: 0.000685867038555.\n",
      "Epoch:3, weight train batch: 67, step:16, loss before: 0.00072845001705, loss after: 0.000727631209884.\n",
      "Epoch:3, weight train batch: 67, step:17, loss before: 0.000637836521491, loss after: 0.000637114339042.\n",
      "Epoch:3, weight train batch: 67, step:18, loss before: 0.000844914349727, loss after: 0.000843968999106.\n",
      "Epoch:3, weight train batch: 67, step:19, loss before: 0.000676582043525, loss after: 0.000675833900459.\n",
      "Epoch:3, weight train batch: 67, step:20, loss before: 0.00083615310723, loss after: 0.000835170620121.\n",
      "Epoch:3, weight train batch: 67, step:21, loss before: 0.000793235725723, loss after: 0.000792346545495.\n",
      "Epoch:3, weight train batch: 67, step:22, loss before: 0.000779018213507, loss after: 0.000778162211645.\n",
      "Epoch:3, weight train batch: 67, step:23, loss before: 0.00084806792438, loss after: 0.000847115181386.\n",
      "Epoch:3, weight train batch: 67, step:24, loss before: 0.000716408831067, loss after: 0.000715627218597.\n",
      "Epoch:3, weight train batch: 67, step:25, loss before: 0.000693172623869, loss after: 0.000692357541993.\n",
      "Epoch:3, weight train batch: 67, step:26, loss before: 0.00139577058144, loss after: 0.0013942248188.\n",
      "Epoch:3, weight train batch: 67, step:27, loss before: 0.000803566188551, loss after: 0.000802680617198.\n",
      "Epoch:3, weight train batch: 67, step:28, loss before: 0.000731827225536, loss after: 0.000730945146643.\n",
      "Epoch:3, weight train batch: 67, step:29, loss before: 0.000730945146643, loss after: 0.000730096595362.\n",
      "Epoch:3, weight train batch: 67, step:30, loss before: 0.000656248943415, loss after: 0.000655534211546.\n",
      "Epoch:3, weight train batch: 67, step:31, loss before: 0.000736035464797, loss after: 0.000735242734663.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 63, loss before: 0.000682023353875, loss after: 0.000723963079508.\n",
      "Epoch:3, weight train batch: 68, step:0, loss before: 0.000716694048606, loss after: 0.000715830479749.\n",
      "Epoch:3, weight train batch: 68, step:1, loss before: 0.00081870588474, loss after: 0.000817764201201.\n",
      "Epoch:3, weight train batch: 68, step:2, loss before: 0.000720868003555, loss after: 0.000720071489923.\n",
      "Epoch:3, weight train batch: 68, step:3, loss before: 0.000686149578542, loss after: 0.0006853567902.\n",
      "Epoch:3, weight train batch: 68, step:4, loss before: 0.000709982821718, loss after: 0.000709227286279.\n",
      "Epoch:3, weight train batch: 68, step:5, loss before: 0.000834721955471, loss after: 0.000833750586025.\n",
      "Epoch:3, weight train batch: 68, step:6, loss before: 0.000751044601202, loss after: 0.00075018114876.\n",
      "Epoch:3, weight train batch: 68, step:7, loss before: 0.000832376128528, loss after: 0.00083139364142.\n",
      "Epoch:3, weight train batch: 68, step:8, loss before: 0.000617981597316, loss after: 0.000617266981862.\n",
      "Epoch:3, weight train batch: 68, step:9, loss before: 0.00075797829777, loss after: 0.000757189292926.\n",
      "Epoch:3, weight train batch: 68, step:10, loss before: 0.000802258728072, loss after: 0.000801350688562.\n",
      "Epoch:3, weight train batch: 68, step:11, loss before: 0.000766630168073, loss after: 0.000765714561567.\n",
      "Epoch:3, weight train batch: 68, step:12, loss before: 0.000745640718378, loss after: 0.000744754914194.\n",
      "Epoch:3, weight train batch: 68, step:13, loss before: 0.000841958448291, loss after: 0.000841028057039.\n",
      "Epoch:3, weight train batch: 68, step:14, loss before: 0.0130746858194, loss after: 0.013064709492.\n",
      "Epoch:3, weight train batch: 68, step:15, loss before: 0.000680208671838, loss after: 0.000679054995999.\n",
      "Epoch:3, weight train batch: 68, step:16, loss before: 0.000800625944976, loss after: 0.000799554167315.\n",
      "Epoch:3, weight train batch: 68, step:17, loss before: 0.000747062964365, loss after: 0.000745853525586.\n",
      "Epoch:3, weight train batch: 68, step:18, loss before: 0.000713453104254, loss after: 0.000712440698408.\n",
      "Epoch:3, weight train batch: 68, step:19, loss before: 0.000604335335083, loss after: 0.000603531370871.\n",
      "Epoch:3, weight train batch: 68, step:20, loss before: 0.000719132367522, loss after: 0.000718220486306.\n",
      "Epoch:3, weight train batch: 68, step:21, loss before: 0.000704329111613, loss after: 0.000703368801624.\n",
      "Epoch:3, weight train batch: 68, step:22, loss before: 0.000691819819622, loss after: 0.000690986169502.\n",
      "Epoch:3, weight train batch: 68, step:23, loss before: 0.000709051149897, loss after: 0.000708150386345.\n",
      "Epoch:3, weight train batch: 68, step:24, loss before: 0.00066333176801, loss after: 0.000662557547912.\n",
      "Epoch:3, weight train batch: 68, step:25, loss before: 0.000820405315608, loss after: 0.000819396809675.\n",
      "Epoch:3, weight train batch: 68, step:26, loss before: 0.000647453125566, loss after: 0.000646701315418.\n",
      "Epoch:3, weight train batch: 68, step:27, loss before: 0.000578043109272, loss after: 0.000577358179726.\n",
      "Epoch:3, weight train batch: 68, step:28, loss before: 0.00064475403633, loss after: 0.000644061772618.\n",
      "Epoch:3, weight train batch: 68, step:29, loss before: 0.000729838793632, loss after: 0.000729001360014.\n",
      "Epoch:3, weight train batch: 68, step:30, loss before: 0.000732603250071, loss after: 0.000731643056497.\n",
      "Epoch:3, weight train batch: 68, step:31, loss before: 0.000619509140961, loss after: 0.000618775840849.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 64, loss before: 0.000722514581867, loss after: 0.00204636505805.\n",
      "Epoch:3, weight train batch: 69, step:0, loss before: 0.000617924553808, loss after: 0.000617269426584.\n",
      "Epoch:3, weight train batch: 69, step:1, loss before: 0.00100571615621, loss after: 0.00100461905822.\n",
      "Epoch:3, weight train batch: 69, step:2, loss before: 0.000647303124424, loss after: 0.000646566099022.\n",
      "Epoch:3, weight train batch: 69, step:3, loss before: 0.000743147742469, loss after: 0.000742299074773.\n",
      "Epoch:3, weight train batch: 69, step:4, loss before: 0.000658352626488, loss after: 0.000657615601085.\n",
      "Epoch:3, weight train batch: 69, step:5, loss before: 0.000664258259349, loss after: 0.000663532468025.\n",
      "Epoch:3, weight train batch: 69, step:6, loss before: 0.00063455698546, loss after: 0.000633849645965.\n",
      "Epoch:3, weight train batch: 69, step:7, loss before: 0.000703731377143, loss after: 0.000702945981175.\n",
      "Epoch:3, weight train batch: 69, step:8, loss before: 0.000763552438002, loss after: 0.000762707553804.\n",
      "Epoch:3, weight train batch: 69, step:9, loss before: 0.000718605297152, loss after: 0.000717834802344.\n",
      "Epoch:3, weight train batch: 69, step:10, loss before: 0.000650121713988, loss after: 0.000649384688586.\n",
      "Epoch:3, weight train batch: 69, step:11, loss before: 0.000711298896931, loss after: 0.000710491207428.\n",
      "Epoch:3, weight train batch: 69, step:12, loss before: 0.000618790159933, loss after: 0.000618112739176.\n",
      "Epoch:3, weight train batch: 69, step:13, loss before: 0.000606891466305, loss after: 0.000606228830293.\n",
      "Epoch:3, weight train batch: 69, step:14, loss before: 0.000726982485503, loss after: 0.000726148777176.\n",
      "Epoch:3, weight train batch: 69, step:15, loss before: 0.000704344885889, loss after: 0.000703570665792.\n",
      "Epoch:3, weight train batch: 69, step:16, loss before: 0.000665429979563, loss after: 0.000664759951178.\n",
      "Epoch:3, weight train batch: 69, step:17, loss before: 0.000690226792358, loss after: 0.000689474865794.\n",
      "Epoch:3, weight train batch: 69, step:18, loss before: 0.000672354595736, loss after: 0.000671654881444.\n",
      "Epoch:3, weight train batch: 69, step:19, loss before: 0.000819965498522, loss after: 0.000819146924186.\n",
      "Epoch:3, weight train batch: 69, step:20, loss before: 0.000801293528639, loss after: 0.00080041581532.\n",
      "Epoch:3, weight train batch: 69, step:21, loss before: 0.00065137911588, loss after: 0.000650664442219.\n",
      "Epoch:3, weight train batch: 69, step:22, loss before: 0.000586323905736, loss after: 0.000585694797337.\n",
      "Epoch:3, weight train batch: 69, step:23, loss before: 0.000663658021949, loss after: 0.000662920996547.\n",
      "Epoch:3, weight train batch: 69, step:24, loss before: 0.000605081149843, loss after: 0.000604452099651.\n",
      "Epoch:3, weight train batch: 69, step:25, loss before: 0.000719814794138, loss after: 0.000719062867574.\n",
      "Epoch:3, weight train batch: 69, step:26, loss before: 0.000689400825649, loss after: 0.000688652624376.\n",
      "Epoch:3, weight train batch: 69, step:27, loss before: 0.000701759709045, loss after: 0.000701022800058.\n",
      "Epoch:3, weight train batch: 69, step:28, loss before: 0.000586521520745, loss after: 0.000585855217651.\n",
      "Epoch:3, weight train batch: 69, step:29, loss before: 0.000801412155852, loss after: 0.000800578505732.\n",
      "Epoch:3, weight train batch: 69, step:30, loss before: 0.000676113762893, loss after: 0.000675384188071.\n",
      "Epoch:3, weight train batch: 69, step:31, loss before: 0.000714546767995, loss after: 0.000713742803782.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 65, loss before: 0.000858496059664, loss after: 0.000690875109285.\n",
      "Epoch:3, weight train batch: 70, step:0, loss before: 0.000682156416588, loss after: 0.000681415665895.\n",
      "Epoch:3, weight train batch: 70, step:1, loss before: 0.000674884417094, loss after: 0.000674162292853.\n",
      "Epoch:3, weight train batch: 70, step:2, loss before: 0.000645132502541, loss after: 0.000644402927719.\n",
      "Epoch:3, weight train batch: 70, step:3, loss before: 0.000695375609212, loss after: 0.000694676069543.\n",
      "Epoch:3, weight train batch: 70, step:4, loss before: 0.000708398874849, loss after: 0.000707635772415.\n",
      "Epoch:3, weight train batch: 70, step:5, loss before: 0.000664058432449, loss after: 0.00066333997529.\n",
      "Epoch:3, weight train batch: 70, step:6, loss before: 0.000710701511707, loss after: 0.000709975720383.\n",
      "Epoch:3, weight train batch: 70, step:7, loss before: 0.000829874770716, loss after: 0.000828993041068.\n",
      "Epoch:3, weight train batch: 70, step:8, loss before: 0.000684172846377, loss after: 0.000683406193275.\n",
      "Epoch:3, weight train batch: 70, step:9, loss before: 0.000678244745359, loss after: 0.000677496544085.\n",
      "Epoch:3, weight train batch: 70, step:10, loss before: 0.000699987343978, loss after: 0.000699216849171.\n",
      "Epoch:3, weight train batch: 70, step:11, loss before: 0.000781768001616, loss after: 0.000780908274464.\n",
      "Epoch:3, weight train batch: 70, step:12, loss before: 0.000677105155773, loss after: 0.000676323485095.\n",
      "Epoch:3, weight train batch: 70, step:13, loss before: 0.000611081777606, loss after: 0.000610422925092.\n",
      "Epoch:3, weight train batch: 70, step:14, loss before: 0.000611998315435, loss after: 0.000611305993516.\n",
      "Epoch:3, weight train batch: 70, step:15, loss before: 0.0128337470815, loss after: 0.0128240929917.\n",
      "Epoch:3, weight train batch: 70, step:16, loss before: 0.00055966275977, loss after: 0.000559111940674.\n",
      "Epoch:3, weight train batch: 70, step:17, loss before: 0.00054753391305, loss after: 0.000546956900507.\n",
      "Epoch:3, weight train batch: 70, step:18, loss before: 0.000556911691092, loss after: 0.000556256505661.\n",
      "Epoch:3, weight train batch: 70, step:19, loss before: 0.000796491047367, loss after: 0.000795515952632.\n",
      "Epoch:3, weight train batch: 70, step:20, loss before: 0.000580243417062, loss after: 0.000579528743401.\n",
      "Epoch:3, weight train batch: 70, step:21, loss before: 0.000696901057381, loss after: 0.000695974216796.\n",
      "Epoch:3, weight train batch: 70, step:22, loss before: 0.000710507039912, loss after: 0.00070964731276.\n",
      "Epoch:3, weight train batch: 70, step:23, loss before: 0.000584578723647, loss after: 0.000583886401728.\n",
      "Epoch:3, weight train batch: 70, step:24, loss before: 0.000606663408689, loss after: 0.000606008339673.\n",
      "Epoch:3, weight train batch: 70, step:25, loss before: 0.000677182571962, loss after: 0.000676415802445.\n",
      "Epoch:3, weight train batch: 70, step:26, loss before: 0.000675020506606, loss after: 0.000674253678881.\n",
      "Epoch:3, weight train batch: 70, step:27, loss before: 0.000694748945534, loss after: 0.000693881767802.\n",
      "Epoch:3, weight train batch: 70, step:28, loss before: 0.000608802889474, loss after: 0.000608043512329.\n",
      "Epoch:3, weight train batch: 70, step:29, loss before: 0.000733507389668, loss after: 0.000732688582502.\n",
      "Epoch:3, weight train batch: 70, step:30, loss before: 0.00127979426179, loss after: 0.00127783056814.\n",
      "Epoch:3, weight train batch: 70, step:31, loss before: 0.000571316573769, loss after: 0.000570679956581.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 66, loss before: 0.000644133077003, loss after: 0.000644133077003.\n",
      "Epoch:3, weight train batch: 71, step:0, loss before: 0.000621843500994, loss after: 0.000621076673269.\n",
      "Epoch:3, weight train batch: 71, step:1, loss before: 0.000661022262648, loss after: 0.000660210731439.\n",
      "Epoch:3, weight train batch: 71, step:2, loss before: 0.000642461411189, loss after: 0.000641698308755.\n",
      "Epoch:3, weight train batch: 71, step:3, loss before: 0.00063075684011, loss after: 0.000630027148873.\n",
      "Epoch:3, weight train batch: 71, step:4, loss before: 0.000686065410264, loss after: 0.00068524654489.\n",
      "Epoch:3, weight train batch: 71, step:5, loss before: 0.000665934290737, loss after: 0.000665133993607.\n",
      "Epoch:3, weight train batch: 71, step:6, loss before: 0.000685406615958, loss after: 0.000684587808792.\n",
      "Epoch:3, weight train batch: 71, step:7, loss before: 0.000685413659085, loss after: 0.000684646889567.\n",
      "Epoch:3, weight train batch: 71, step:8, loss before: 0.000864886795171, loss after: 0.000863912282512.\n",
      "Epoch:3, weight train batch: 71, step:9, loss before: 0.000632613024209, loss after: 0.000631879665889.\n",
      "Epoch:3, weight train batch: 71, step:10, loss before: 0.000556108192541, loss after: 0.000555486476514.\n",
      "Epoch:3, weight train batch: 71, step:11, loss before: 0.000733640219551, loss after: 0.000732810120098.\n",
      "Epoch:3, weight train batch: 71, step:12, loss before: 0.000634156982414, loss after: 0.00063348695403.\n",
      "Epoch:3, weight train batch: 71, step:13, loss before: 0.000580436782911, loss after: 0.000579774030484.\n",
      "Epoch:3, weight train batch: 71, step:14, loss before: 0.00071659788955, loss after: 0.000715834903531.\n",
      "Epoch:3, weight train batch: 71, step:15, loss before: 0.000643201172352, loss after: 0.000642501341645.\n",
      "Epoch:3, weight train batch: 71, step:16, loss before: 0.000642232655082, loss after: 0.000641532824375.\n",
      "Epoch:3, weight train batch: 71, step:17, loss before: 0.000621309038252, loss after: 0.000620627892204.\n",
      "Epoch:3, weight train batch: 71, step:18, loss before: 0.000709622749127, loss after: 0.00070885597961.\n",
      "Epoch:3, weight train batch: 71, step:19, loss before: 0.000587459071539, loss after: 0.000586785259657.\n",
      "Epoch:3, weight train batch: 71, step:20, loss before: 0.000722846540157, loss after: 0.000722057418898.\n",
      "Epoch:3, weight train batch: 71, step:21, loss before: 0.000727074337192, loss after: 0.000726210826542.\n",
      "Epoch:3, weight train batch: 71, step:22, loss before: 0.000615256663878, loss after: 0.000614608987235.\n",
      "Epoch:3, weight train batch: 71, step:23, loss before: 0.000503829796799, loss after: 0.00050330121303.\n",
      "Epoch:3, weight train batch: 71, step:24, loss before: 0.000617273384705, loss after: 0.000616603298113.\n",
      "Epoch:3, weight train batch: 71, step:25, loss before: 0.0125456936657, loss after: 0.0125346807763.\n",
      "Epoch:3, weight train batch: 71, step:26, loss before: 0.000777439796366, loss after: 0.00077596353367.\n",
      "Epoch:3, weight train batch: 71, step:27, loss before: 0.000642975908704, loss after: 0.000642097555101.\n",
      "Epoch:3, weight train batch: 71, step:28, loss before: 0.000656906922814, loss after: 0.000655968964566.\n",
      "Epoch:3, weight train batch: 71, step:29, loss before: 0.000603186315857, loss after: 0.000602341373451.\n",
      "Epoch:3, weight train batch: 71, step:30, loss before: 0.00120230694301, loss after: 0.00120089342818.\n",
      "Epoch:3, weight train batch: 71, step:31, loss before: 0.000706429185811, loss after: 0.000705353508238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 67, loss before: 0.000894130615052, loss after: 0.000662694859784.\n",
      "Epoch:3, weight train batch: 72, step:0, loss before: 0.000632960116491, loss after: 0.000632223032881.\n",
      "Epoch:3, weight train batch: 72, step:1, loss before: 0.000706626102328, loss after: 0.000705650891177.\n",
      "Epoch:3, weight train batch: 72, step:2, loss before: 0.000590595183894, loss after: 0.000589768809732.\n",
      "Epoch:3, weight train batch: 72, step:3, loss before: 0.00186193548143, loss after: 0.00186023139395.\n",
      "Epoch:3, weight train batch: 72, step:4, loss before: 0.000643206352834, loss after: 0.000642242317554.\n",
      "Epoch:3, weight train batch: 72, step:5, loss before: 0.000671268615406, loss after: 0.000670282170177.\n",
      "Epoch:3, weight train batch: 72, step:6, loss before: 0.000710537075065, loss after: 0.000709617685061.\n",
      "Epoch:3, weight train batch: 72, step:7, loss before: 0.000655465526506, loss after: 0.000654549803585.\n",
      "Epoch:3, weight train batch: 72, step:8, loss before: 0.000678592245094, loss after: 0.000677821692079.\n",
      "Epoch:3, weight train batch: 72, step:9, loss before: 0.000578319537453, loss after: 0.00057750067208.\n",
      "Epoch:3, weight train batch: 72, step:10, loss before: 0.000691997935064, loss after: 0.000691216206178.\n",
      "Epoch:3, weight train batch: 72, step:11, loss before: 0.000559389824048, loss after: 0.000558689993341.\n",
      "Epoch:3, weight train batch: 72, step:12, loss before: 0.000644920975901, loss after: 0.000644090818241.\n",
      "Epoch:3, weight train batch: 72, step:13, loss before: 0.000652907649055, loss after: 0.000652107293718.\n",
      "Epoch:3, weight train batch: 72, step:14, loss before: 0.0013145999983, loss after: 0.00131311663426.\n",
      "Epoch:3, weight train batch: 72, step:15, loss before: 0.000615655444562, loss after: 0.000614948105067.\n",
      "Epoch:3, weight train batch: 72, step:16, loss before: 0.00052440399304, loss after: 0.000523678027093.\n",
      "Epoch:3, weight train batch: 72, step:17, loss before: 0.000717727001756, loss after: 0.000716829905286.\n",
      "Epoch:3, weight train batch: 72, step:18, loss before: 0.000519620953128, loss after: 0.000518917280715.\n",
      "Epoch:3, weight train batch: 72, step:19, loss before: 0.0123751945794, loss after: 0.0123647414148.\n",
      "Epoch:3, weight train batch: 72, step:20, loss before: 0.00065787951462, loss after: 0.000656714546494.\n",
      "Epoch:3, weight train batch: 72, step:21, loss before: 0.000641417922452, loss after: 0.000640245503746.\n",
      "Epoch:3, weight train batch: 72, step:22, loss before: 0.000620009028353, loss after: 0.00061919761356.\n",
      "Epoch:3, weight train batch: 72, step:23, loss before: 0.000663275422994, loss after: 0.000662348582409.\n",
      "Epoch:3, weight train batch: 72, step:24, loss before: 0.000631271570455, loss after: 0.00063026661519.\n",
      "Epoch:3, weight train batch: 72, step:25, loss before: 0.00059247831814, loss after: 0.00059174495982.\n",
      "Epoch:3, weight train batch: 72, step:26, loss before: 0.000598362996243, loss after: 0.000597454723902.\n",
      "Epoch:3, weight train batch: 72, step:27, loss before: 0.000636395649053, loss after: 0.000635606469586.\n",
      "Epoch:3, weight train batch: 72, step:28, loss before: 0.000618184683844, loss after: 0.0006174253067.\n",
      "Epoch:3, weight train batch: 72, step:29, loss before: 0.0006174253067, loss after: 0.000616643577814.\n",
      "Epoch:3, weight train batch: 72, step:30, loss before: 0.000501698115841, loss after: 0.000501098809764.\n",
      "Epoch:3, weight train batch: 72, step:31, loss before: 0.00056022813078, loss after: 0.000559572945349.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 68, loss before: 0.000648822169751, loss after: 0.000684525235556.\n",
      "Epoch:3, weight train batch: 73, step:0, loss before: 0.000593828503042, loss after: 0.000593143573496.\n",
      "Epoch:3, weight train batch: 73, step:1, loss before: 0.000593020231463, loss after: 0.000592361262534.\n",
      "Epoch:3, weight train batch: 73, step:2, loss before: 0.000629465095699, loss after: 0.000628724345006.\n",
      "Epoch:3, weight train batch: 73, step:3, loss before: 0.000616151432041, loss after: 0.000615488796029.\n",
      "Epoch:3, weight train batch: 73, step:4, loss before: 0.000526335614268, loss after: 0.000525784678757.\n",
      "Epoch:3, weight train batch: 73, step:5, loss before: 0.000648509419989, loss after: 0.000647757435217.\n",
      "Epoch:3, weight train batch: 73, step:6, loss before: 0.000731242820621, loss after: 0.000730431405827.\n",
      "Epoch:3, weight train batch: 73, step:7, loss before: 0.000625627115369, loss after: 0.000624957145192.\n",
      "Epoch:3, weight train batch: 73, step:8, loss before: 0.00065591163002, loss after: 0.000655159761664.\n",
      "Epoch:3, weight train batch: 73, step:9, loss before: 0.000713489134796, loss after: 0.000712655426469.\n",
      "Epoch:3, weight train batch: 73, step:10, loss before: 0.000565254711546, loss after: 0.000564599526115.\n",
      "Epoch:3, weight train batch: 73, step:11, loss before: 0.000564599526115, loss after: 0.000564000220038.\n",
      "Epoch:3, weight train batch: 73, step:12, loss before: 0.000613336218521, loss after: 0.000612666131929.\n",
      "Epoch:3, weight train batch: 73, step:13, loss before: 0.000726462749299, loss after: 0.000725718389731.\n",
      "Epoch:3, weight train batch: 73, step:14, loss before: 0.000618368037976, loss after: 0.000617694284301.\n",
      "Epoch:3, weight train batch: 73, step:15, loss before: 0.000626068969723, loss after: 0.000625361688435.\n",
      "Epoch:3, weight train batch: 73, step:16, loss before: 0.000577026745304, loss after: 0.000576386461034.\n",
      "Epoch:3, weight train batch: 73, step:17, loss before: 0.00065615226049, loss after: 0.000655463605653.\n",
      "Epoch:3, weight train batch: 73, step:18, loss before: 0.000530435645487, loss after: 0.000529873475898.\n",
      "Epoch:3, weight train batch: 73, step:19, loss before: 0.00057756586466, loss after: 0.000576944265049.\n",
      "Epoch:3, weight train batch: 73, step:20, loss before: 0.0006137600285, loss after: 0.000613078824244.\n",
      "Epoch:3, weight train batch: 73, step:21, loss before: 0.00104363274295, loss after: 0.00104273564648.\n",
      "Epoch:3, weight train batch: 73, step:22, loss before: 0.000570501433685, loss after: 0.000569939322304.\n",
      "Epoch:3, weight train batch: 73, step:23, loss before: 0.000736094429158, loss after: 0.000735335692298.\n",
      "Epoch:3, weight train batch: 73, step:24, loss before: 0.000648447079584, loss after: 0.000647788168862.\n",
      "Epoch:3, weight train batch: 73, step:25, loss before: 0.000743739656173, loss after: 0.000742917647585.\n",
      "Epoch:3, weight train batch: 73, step:26, loss before: 0.000591324642301, loss after: 0.000590699259192.\n",
      "Epoch:3, weight train batch: 73, step:27, loss before: 0.000510741141625, loss after: 0.00051016791258.\n",
      "Epoch:3, weight train batch: 73, step:28, loss before: 0.000575926620513, loss after: 0.000575278885663.\n",
      "Epoch:3, weight train batch: 73, step:29, loss before: 0.000755675311666, loss after: 0.000754846027121.\n",
      "Epoch:3, weight train batch: 73, step:30, loss before: 0.000552602054086, loss after: 0.000552080920897.\n",
      "Epoch:3, weight train batch: 73, step:31, loss before: 0.000647799635772, loss after: 0.000647084903903.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 69, loss before: 0.000554427038878, loss after: 0.000554426107556.\n",
      "Epoch:3, weight train batch: 74, step:0, loss before: 0.0005499360268, loss after: 0.000549340387806.\n",
      "Epoch:3, weight train batch: 74, step:1, loss before: 0.000599425751716, loss after: 0.000598781742156.\n",
      "Epoch:3, weight train batch: 74, step:2, loss before: 0.0005217124708, loss after: 0.000521165144164.\n",
      "Epoch:3, weight train batch: 74, step:3, loss before: 0.000577954400796, loss after: 0.000577362487093.\n",
      "Epoch:3, weight train batch: 74, step:4, loss before: 0.00061789015308, loss after: 0.000617264886387.\n",
      "Epoch:3, weight train batch: 74, step:5, loss before: 0.000790108228102, loss after: 0.000789293728303.\n",
      "Epoch:3, weight train batch: 74, step:6, loss before: 0.000581455533393, loss after: 0.000580818974413.\n",
      "Epoch:3, weight train batch: 74, step:7, loss before: 0.000480612361571, loss after: 0.000480094837258.\n",
      "Epoch:3, weight train batch: 74, step:8, loss before: 0.0006708088913, loss after: 0.000670139212161.\n",
      "Epoch:3, weight train batch: 74, step:9, loss before: 0.000553761376068, loss after: 0.000553184421733.\n",
      "Epoch:3, weight train batch: 74, step:10, loss before: 0.000549265823793, loss after: 0.000548703654204.\n",
      "Epoch:3, weight train batch: 74, step:11, loss before: 0.00059773895191, loss after: 0.000597098609433.\n",
      "Epoch:3, weight train batch: 74, step:12, loss before: 0.000643362174742, loss after: 0.000642718630843.\n",
      "Epoch:3, weight train batch: 74, step:13, loss before: 0.000538057647645, loss after: 0.000537454558071.\n",
      "Epoch:3, weight train batch: 74, step:14, loss before: 0.000566902745049, loss after: 0.000566281029023.\n",
      "Epoch:3, weight train batch: 74, step:15, loss before: 0.000487566285301, loss after: 0.000487033859827.\n",
      "Epoch:3, weight train batch: 74, step:16, loss before: 0.000597562873736, loss after: 0.00059694115771.\n",
      "Epoch:3, weight train batch: 74, step:17, loss before: 0.000566068571061, loss after: 0.000565480382647.\n",
      "Epoch:3, weight train batch: 74, step:18, loss before: 0.000526651740074, loss after: 0.000526119372807.\n",
      "Epoch:3, weight train batch: 74, step:19, loss before: 0.0120780076832, loss after: 0.0120672825724.\n",
      "Epoch:3, weight train batch: 74, step:20, loss before: 0.000615751894657, loss after: 0.000614754389971.\n",
      "Epoch:3, weight train batch: 74, step:21, loss before: 0.000640568556264, loss after: 0.000639805570245.\n",
      "Epoch:3, weight train batch: 74, step:22, loss before: 0.000545779417735, loss after: 0.000545187620446.\n",
      "Epoch:3, weight train batch: 74, step:23, loss before: 0.000570836244151, loss after: 0.000570073141716.\n",
      "Epoch:3, weight train batch: 74, step:24, loss before: 0.000609647424426, loss after: 0.00060886197025.\n",
      "Epoch:3, weight train batch: 74, step:25, loss before: 0.000539180764463, loss after: 0.000538484659046.\n",
      "Epoch:3, weight train batch: 74, step:26, loss before: 0.000644042505883, loss after: 0.000643245992251.\n",
      "Epoch:3, weight train batch: 74, step:27, loss before: 0.000616874895059, loss after: 0.000616137869656.\n",
      "Epoch:3, weight train batch: 74, step:28, loss before: 0.000557630555704, loss after: 0.000556908373255.\n",
      "Epoch:3, weight train batch: 74, step:29, loss before: 0.000547751202248, loss after: 0.000547081115656.\n",
      "Epoch:3, weight train batch: 74, step:30, loss before: 0.000645763298962, loss after: 0.000644981511869.\n",
      "Epoch:3, weight train batch: 74, step:31, loss before: 0.000565226422623, loss after: 0.000564545276575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 70, loss before: 0.000569080759306, loss after: 0.000569080759306.\n",
      "Epoch:3, weight train batch: 75, step:0, loss before: 0.000558269675821, loss after: 0.000557599589229.\n",
      "Epoch:3, weight train batch: 75, step:1, loss before: 0.000608954462223, loss after: 0.000608236063272.\n",
      "Epoch:3, weight train batch: 75, step:2, loss before: 0.000536484178156, loss after: 0.000535925792065.\n",
      "Epoch:3, weight train batch: 75, step:3, loss before: 0.000593422213569, loss after: 0.000592778204009.\n",
      "Epoch:3, weight train batch: 75, step:4, loss before: 0.000593475182541, loss after: 0.000592756725382.\n",
      "Epoch:3, weight train batch: 75, step:5, loss before: 0.000697126728483, loss after: 0.000696360366419.\n",
      "Epoch:3, weight train batch: 75, step:6, loss before: 0.000441954820417, loss after: 0.000441426091129.\n",
      "Epoch:3, weight train batch: 75, step:7, loss before: 0.000545434770174, loss after: 0.000544876442291.\n",
      "Epoch:3, weight train batch: 75, step:8, loss before: 0.000487703830004, loss after: 0.000487190030981.\n",
      "Epoch:3, weight train batch: 75, step:9, loss before: 0.000530349439941, loss after: 0.000529776210897.\n",
      "Epoch:3, weight train batch: 75, step:10, loss before: 0.000684100319631, loss after: 0.00068338192068.\n",
      "Epoch:3, weight train batch: 75, step:11, loss before: 0.000507734657731, loss after: 0.000507157528773.\n",
      "Epoch:3, weight train batch: 75, step:12, loss before: 0.000569207186345, loss after: 0.000568600487895.\n",
      "Epoch:3, weight train batch: 75, step:13, loss before: 0.00144952000119, loss after: 0.00144802127033.\n",
      "Epoch:3, weight train batch: 75, step:14, loss before: 0.000555066566449, loss after: 0.000554455968086.\n",
      "Epoch:3, weight train batch: 75, step:15, loss before: 0.000507492281031, loss after: 0.000506952404976.\n",
      "Epoch:3, weight train batch: 75, step:16, loss before: 0.000619745289441, loss after: 0.000619104946963.\n",
      "Epoch:3, weight train batch: 75, step:17, loss before: 0.000508348108269, loss after: 0.000507752411067.\n",
      "Epoch:3, weight train batch: 75, step:18, loss before: 0.000526662450284, loss after: 0.000526055577211.\n",
      "Epoch:3, weight train batch: 75, step:19, loss before: 0.00059606222203, loss after: 0.000595433055423.\n",
      "Epoch:3, weight train batch: 75, step:20, loss before: 0.00107153307181, loss after: 0.00107066170312.\n",
      "Epoch:3, weight train batch: 75, step:21, loss before: 0.000616443227045, loss after: 0.000615698692854.\n",
      "Epoch:3, weight train batch: 75, step:22, loss before: 0.000589959148783, loss after: 0.000589326256886.\n",
      "Epoch:3, weight train batch: 75, step:23, loss before: 0.000553575751837, loss after: 0.000552968936972.\n",
      "Epoch:3, weight train batch: 75, step:24, loss before: 0.000588693423197, loss after: 0.000588049413636.\n",
      "Epoch:3, weight train batch: 75, step:25, loss before: 0.000500311842188, loss after: 0.000499775749631.\n",
      "Epoch:3, weight train batch: 75, step:26, loss before: 0.000466328405309, loss after: 0.000465904013254.\n",
      "Epoch:3, weight train batch: 75, step:27, loss before: 0.000590443611145, loss after: 0.000589795759879.\n",
      "Epoch:3, weight train batch: 75, step:28, loss before: 0.000573573284782, loss after: 0.000572977645788.\n",
      "Epoch:3, weight train batch: 75, step:29, loss before: 0.000590184994508, loss after: 0.000589499948546.\n",
      "Epoch:3, weight train batch: 75, step:30, loss before: 0.000625549058896, loss after: 0.000624834327027.\n",
      "Epoch:3, weight train batch: 75, step:31, loss before: 0.000462436117232, loss after: 0.000461981864646.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 71, loss before: 0.000552066601813, loss after: 0.00055209727725.\n",
      "Epoch:3, weight train batch: 76, step:0, loss before: 0.000443981785793, loss after: 0.000443494063802.\n",
      "Epoch:3, weight train batch: 76, step:1, loss before: 0.000581546220928, loss after: 0.000580999068916.\n",
      "Epoch:3, weight train batch: 76, step:2, loss before: 0.000525208073668, loss after: 0.000524616101757.\n",
      "Epoch:3, weight train batch: 76, step:3, loss before: 0.00057082582498, loss after: 0.000570271047764.\n",
      "Epoch:3, weight train batch: 76, step:4, loss before: 0.000566362577956, loss after: 0.000565766938962.\n",
      "Epoch:3, weight train batch: 76, step:5, loss before: 0.000573500758037, loss after: 0.000572897784878.\n",
      "Epoch:3, weight train batch: 76, step:6, loss before: 0.000564652786124, loss after: 0.000564116693567.\n",
      "Epoch:3, weight train batch: 76, step:7, loss before: 0.000606730522122, loss after: 0.000606108806096.\n",
      "Epoch:3, weight train batch: 76, step:8, loss before: 0.000568826391827, loss after: 0.000568245653994.\n",
      "Epoch:3, weight train batch: 76, step:9, loss before: 0.000593359698541, loss after: 0.000592659809627.\n",
      "Epoch:3, weight train batch: 76, step:10, loss before: 0.00054361182265, loss after: 0.000543116708286.\n",
      "Epoch:3, weight train batch: 76, step:11, loss before: 0.000621641054749, loss after: 0.000621008162852.\n",
      "Epoch:3, weight train batch: 76, step:12, loss before: 0.000494325126056, loss after: 0.000493818777613.\n",
      "Epoch:3, weight train batch: 76, step:13, loss before: 0.00142344040796, loss after: 0.00142151699401.\n",
      "Epoch:3, weight train batch: 76, step:14, loss before: 0.000674218579661, loss after: 0.000673529924825.\n",
      "Epoch:3, weight train batch: 76, step:15, loss before: 0.000548324314877, loss after: 0.00054778077174.\n",
      "Epoch:3, weight train batch: 76, step:16, loss before: 0.00048104551388, loss after: 0.000480505637825.\n",
      "Epoch:3, weight train batch: 76, step:17, loss before: 0.000512904080097, loss after: 0.000512341910508.\n",
      "Epoch:3, weight train batch: 76, step:18, loss before: 0.000585652363952, loss after: 0.000585127505474.\n",
      "Epoch:3, weight train batch: 76, step:19, loss before: 0.000533028505743, loss after: 0.000532507372554.\n",
      "Epoch:3, weight train batch: 76, step:20, loss before: 0.000571584037971, loss after: 0.000570973497815.\n",
      "Epoch:3, weight train batch: 76, step:21, loss before: 0.000485418800963, loss after: 0.000484923570184.\n",
      "Epoch:3, weight train batch: 76, step:22, loss before: 0.000448484817753, loss after: 0.000448034348665.\n",
      "Epoch:3, weight train batch: 76, step:23, loss before: 0.000545723014511, loss after: 0.000545227783732.\n",
      "Epoch:3, weight train batch: 76, step:24, loss before: 0.000495598069392, loss after: 0.000495069427416.\n",
      "Epoch:3, weight train batch: 76, step:25, loss before: 0.000630154798273, loss after: 0.000629518181086.\n",
      "Epoch:3, weight train batch: 76, step:26, loss before: 0.000580215826631, loss after: 0.000579594168812.\n",
      "Epoch:3, weight train batch: 76, step:27, loss before: 0.00109418667853, loss after: 0.00109286804218.\n",
      "Epoch:3, weight train batch: 76, step:28, loss before: 0.000565682305023, loss after: 0.000565082998946.\n",
      "Epoch:3, weight train batch: 76, step:29, loss before: 0.000486899632961, loss after: 0.000486385804834.\n",
      "Epoch:3, weight train batch: 76, step:30, loss before: 0.000518912333064, loss after: 0.000518383691087.\n",
      "Epoch:3, weight train batch: 76, step:31, loss before: 0.000578682054766, loss after: 0.000578075181693.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 72, loss before: 0.000515728315804, loss after: 0.000548227224499.\n",
      "Epoch:3, weight train batch: 77, step:0, loss before: 0.000534006627277, loss after: 0.000533388694748.\n",
      "Epoch:3, weight train batch: 77, step:1, loss before: 0.000612870091572, loss after: 0.000612173927948.\n",
      "Epoch:3, weight train batch: 77, step:2, loss before: 0.000652352580801, loss after: 0.000651630340144.\n",
      "Epoch:3, weight train batch: 77, step:3, loss before: 0.000520141620655, loss after: 0.000519601802807.\n",
      "Epoch:3, weight train batch: 77, step:4, loss before: 0.000487691926537, loss after: 0.000487137178425.\n",
      "Epoch:3, weight train batch: 77, step:5, loss before: 0.000497595989145, loss after: 0.000497041270137.\n",
      "Epoch:3, weight train batch: 77, step:6, loss before: 0.000609844340943, loss after: 0.000609234091826.\n",
      "Epoch:3, weight train batch: 77, step:7, loss before: 0.000499692745507, loss after: 0.000499201298226.\n",
      "Epoch:3, weight train batch: 77, step:8, loss before: 0.000535586907063, loss after: 0.000534968858119.\n",
      "Epoch:3, weight train batch: 77, step:9, loss before: 0.00058988109231, loss after: 0.000589333823882.\n",
      "Epoch:3, weight train batch: 77, step:10, loss before: 0.000553698919248, loss after: 0.000553129357286.\n",
      "Epoch:3, weight train batch: 77, step:11, loss before: 0.000515789492056, loss after: 0.000515186344273.\n",
      "Epoch:3, weight train batch: 77, step:12, loss before: 0.000565497670323, loss after: 0.000564913207199.\n",
      "Epoch:3, weight train batch: 77, step:13, loss before: 0.000601744279265, loss after: 0.000601055566221.\n",
      "Epoch:3, weight train batch: 77, step:14, loss before: 0.000538753112778, loss after: 0.000538213353138.\n",
      "Epoch:3, weight train batch: 77, step:15, loss before: 0.000493330648169, loss after: 0.000492835533805.\n",
      "Epoch:3, weight train batch: 77, step:16, loss before: 0.000664788414724, loss after: 0.000664174440317.\n",
      "Epoch:3, weight train batch: 77, step:17, loss before: 0.000572712742724, loss after: 0.000572131946683.\n",
      "Epoch:3, weight train batch: 77, step:18, loss before: 0.000579857092816, loss after: 0.000579250277951.\n",
      "Epoch:3, weight train batch: 77, step:19, loss before: 0.000509836710989, loss after: 0.000509293167852.\n",
      "Epoch:3, weight train batch: 77, step:20, loss before: 0.000518800399732, loss after: 0.000518226996064.\n",
      "Epoch:3, weight train batch: 77, step:21, loss before: 0.000550675671548, loss after: 0.000550091150217.\n",
      "Epoch:3, weight train batch: 77, step:22, loss before: 0.000490299775265, loss after: 0.000489752506837.\n",
      "Epoch:3, weight train batch: 77, step:23, loss before: 0.000542798719835, loss after: 0.000542255118489.\n",
      "Epoch:3, weight train batch: 77, step:24, loss before: 0.000487046549097, loss after: 0.000486529082991.\n",
      "Epoch:3, weight train batch: 77, step:25, loss before: 0.000513846753165, loss after: 0.000513329170644.\n",
      "Epoch:3, weight train batch: 77, step:26, loss before: 0.000455931323813, loss after: 0.000455506902654.\n",
      "Epoch:3, weight train batch: 77, step:27, loss before: 0.000533960293978, loss after: 0.000533431652002.\n",
      "Epoch:3, weight train batch: 77, step:28, loss before: 0.000508376746438, loss after: 0.00050782575272.\n",
      "Epoch:3, weight train batch: 77, step:29, loss before: 0.000528395001311, loss after: 0.000527899828739.\n",
      "Epoch:3, weight train batch: 77, step:30, loss before: 0.000506361830048, loss after: 0.000505870440975.\n",
      "Epoch:3, weight train batch: 77, step:31, loss before: 0.000496414373629, loss after: 0.000495881948154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 73, loss before: 0.000545636168681, loss after: 0.000471053470392.\n",
      "Epoch:3, weight train batch: 78, step:0, loss before: 0.000526816525962, loss after: 0.000526321353391.\n",
      "Epoch:3, weight train batch: 78, step:1, loss before: 0.000446158257546, loss after: 0.000445681682322.\n",
      "Epoch:3, weight train batch: 78, step:2, loss before: 0.000533541548066, loss after: 0.000533009180799.\n",
      "Epoch:3, weight train batch: 78, step:3, loss before: 0.0480216965079, loss after: 0.0479676574469.\n",
      "Epoch:3, weight train batch: 78, step:4, loss before: 0.000623339205049, loss after: 0.000624225358479.\n",
      "Epoch:3, weight train batch: 78, step:5, loss before: 0.000543075148016, loss after: 0.000543607689906.\n",
      "Epoch:3, weight train batch: 78, step:6, loss before: 0.000544758164324, loss after: 0.000545856542885.\n",
      "Epoch:3, weight train batch: 78, step:7, loss before: 0.000502107664943, loss after: 0.000502610462718.\n",
      "Epoch:3, weight train batch: 78, step:8, loss before: 0.000405948143452, loss after: 0.000406149309129.\n",
      "Epoch:3, weight train batch: 78, step:9, loss before: 0.000598615966737, loss after: 0.000599070161115.\n",
      "Epoch:3, weight train batch: 78, step:10, loss before: 0.000544616836123, loss after: 0.000544724811334.\n",
      "Epoch:3, weight train batch: 78, step:11, loss before: 0.000529947923496, loss after: 0.000529940589331.\n",
      "Epoch:3, weight train batch: 78, step:12, loss before: 0.000516616739333, loss after: 0.000516601954587.\n",
      "Epoch:3, weight train batch: 78, step:13, loss before: 0.000456249515992, loss after: 0.000456461770227.\n",
      "Epoch:3, weight train batch: 78, step:14, loss before: 0.000460463605123, loss after: 0.000460240262328.\n",
      "Epoch:3, weight train batch: 78, step:15, loss before: 0.000514784478582, loss after: 0.000514650484547.\n",
      "Epoch:3, weight train batch: 78, step:16, loss before: 0.000547853007447, loss after: 0.000547495670617.\n",
      "Epoch:3, weight train batch: 78, step:17, loss before: 0.000482494360767, loss after: 0.000482226372696.\n",
      "Epoch:3, weight train batch: 78, step:18, loss before: 0.000508067780174, loss after: 0.000507695542183.\n",
      "Epoch:3, weight train batch: 78, step:19, loss before: 0.000578458537348, loss after: 0.000578019302338.\n",
      "Epoch:3, weight train batch: 78, step:20, loss before: 0.000482482311781, loss after: 0.000482102565002.\n",
      "Epoch:3, weight train batch: 78, step:21, loss before: 0.000536610838026, loss after: 0.000536067353096.\n",
      "Epoch:3, weight train batch: 78, step:22, loss before: 0.000469306076411, loss after: 0.000468855636427.\n",
      "Epoch:3, weight train batch: 78, step:23, loss before: 0.000485072145239, loss after: 0.000484550895635.\n",
      "Epoch:3, weight train batch: 78, step:24, loss before: 0.00049422995653, loss after: 0.000493719941005.\n",
      "Epoch:3, weight train batch: 78, step:25, loss before: 0.000481429742649, loss after: 0.000480912218336.\n",
      "Epoch:3, weight train batch: 78, step:26, loss before: 0.000449605286121, loss after: 0.000449128740001.\n",
      "Epoch:3, weight train batch: 78, step:27, loss before: 0.000558161409572, loss after: 0.000557461520657.\n",
      "Epoch:3, weight train batch: 78, step:28, loss before: 0.000707799685188, loss after: 0.000706866267137.\n",
      "Epoch:3, weight train batch: 78, step:29, loss before: 0.000500328605995, loss after: 0.00049959885655.\n",
      "Epoch:3, weight train batch: 78, step:30, loss before: 0.000560821848921, loss after: 0.000560107117053.\n",
      "Epoch:3, weight train batch: 78, step:31, loss before: 0.000468824815471, loss after: 0.000468266371172.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 74, loss before: 0.000495212618262, loss after: 0.000496542197652.\n",
      "Epoch:3, weight train batch: 79, step:0, loss before: 0.000618950463831, loss after: 0.000618298945483.\n",
      "Epoch:3, weight train batch: 79, step:1, loss before: 0.000601197709329, loss after: 0.000600408471655.\n",
      "Epoch:3, weight train batch: 79, step:2, loss before: 0.000522802816704, loss after: 0.000522162474226.\n",
      "Epoch:3, weight train batch: 79, step:3, loss before: 0.00047114744666, loss after: 0.000470510742161.\n",
      "Epoch:3, weight train batch: 79, step:4, loss before: 0.000501728383824, loss after: 0.000501132686622.\n",
      "Epoch:3, weight train batch: 79, step:5, loss before: 0.000696170900483, loss after: 0.00069537514355.\n",
      "Epoch:3, weight train batch: 79, step:6, loss before: 0.000433126057032, loss after: 0.000432515400462.\n",
      "Epoch:3, weight train batch: 79, step:7, loss before: 0.000520329165738, loss after: 0.000519673922099.\n",
      "Epoch:3, weight train batch: 79, step:8, loss before: 0.000499174697325, loss after: 0.000498519395478.\n",
      "Epoch:3, weight train batch: 79, step:9, loss before: 0.000434427201981, loss after: 0.00043386494508.\n",
      "Epoch:3, weight train batch: 79, step:10, loss before: 0.000485131808091, loss after: 0.000484528660309.\n",
      "Epoch:3, weight train batch: 79, step:11, loss before: 0.000564593356103, loss after: 0.000563975307159.\n",
      "Epoch:3, weight train batch: 79, step:12, loss before: 0.00133945804555, loss after: 0.0013365597697.\n",
      "Epoch:3, weight train batch: 79, step:13, loss before: 0.000477517489344, loss after: 0.000476873334264.\n",
      "Epoch:3, weight train batch: 79, step:14, loss before: 0.000496622116771, loss after: 0.000496056163684.\n",
      "Epoch:3, weight train batch: 79, step:15, loss before: 0.000468582031317, loss after: 0.000467900594231.\n",
      "Epoch:3, weight train batch: 79, step:16, loss before: 0.000510514422785, loss after: 0.000509848003276.\n",
      "Epoch:3, weight train batch: 79, step:17, loss before: 0.000418868206907, loss after: 0.000418264971813.\n",
      "Epoch:3, weight train batch: 79, step:18, loss before: 0.000496223743539, loss after: 0.000495665241033.\n",
      "Epoch:3, weight train batch: 79, step:19, loss before: 0.000503543065861, loss after: 0.000503029325046.\n",
      "Epoch:3, weight train batch: 79, step:20, loss before: 0.000470960221719, loss after: 0.000470330938697.\n",
      "Epoch:3, weight train batch: 79, step:21, loss before: 0.000494600506499, loss after: 0.000494079256896.\n",
      "Epoch:3, weight train batch: 79, step:22, loss before: 0.000551138306037, loss after: 0.000550512806512.\n",
      "Epoch:3, weight train batch: 79, step:23, loss before: 0.000500662950799, loss after: 0.000500074704178.\n",
      "Epoch:3, weight train batch: 79, step:24, loss before: 0.000569156254642, loss after: 0.000568527088035.\n",
      "Epoch:3, weight train batch: 79, step:25, loss before: 0.000437400973169, loss after: 0.000436909496784.\n",
      "Epoch:3, weight train batch: 79, step:26, loss before: 0.000839465297759, loss after: 0.000838797539473.\n",
      "Epoch:3, weight train batch: 79, step:27, loss before: 0.000477695546579, loss after: 0.000477148249047.\n",
      "Epoch:3, weight train batch: 79, step:28, loss before: 0.00046031162492, loss after: 0.000459849950857.\n",
      "Epoch:3, weight train batch: 79, step:29, loss before: 0.000475973414723, loss after: 0.000475478213048.\n",
      "Epoch:3, weight train batch: 79, step:30, loss before: 0.0004807858204, loss after: 0.000480175251141.\n",
      "Epoch:3, weight train batch: 79, step:31, loss before: 0.00047424386139, loss after: 0.000473789667012.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:3, struct parameters train batch: 75, loss before: 0.00170182739384, loss after: 0.000438351358753.\n",
      "Epoch:4, weight train batch: 80, step:0, loss before: 0.000529953278601, loss after: 0.000529387558345.\n",
      "Epoch:4, weight train batch: 80, step:1, loss before: 0.000940798781812, loss after: 0.000940012687352.\n",
      "Epoch:4, weight train batch: 80, step:2, loss before: 0.000439523602836, loss after: 0.000438983697677.\n",
      "Epoch:4, weight train batch: 80, step:3, loss before: 0.000499359739479, loss after: 0.000498808687553.\n",
      "Epoch:4, weight train batch: 80, step:4, loss before: 0.000550137425307, loss after: 0.000549586489797.\n",
      "Epoch:4, weight train batch: 80, step:5, loss before: 0.000439789902885, loss after: 0.0004392612027.\n",
      "Epoch:4, weight train batch: 80, step:6, loss before: 0.000496586028021, loss after: 0.000496049877256.\n",
      "Epoch:4, weight train batch: 80, step:7, loss before: 0.000475502049085, loss after: 0.000474973348901.\n",
      "Epoch:4, weight train batch: 80, step:8, loss before: 0.000671143061481, loss after: 0.000670421519317.\n",
      "Epoch:4, weight train batch: 80, step:9, loss before: 0.000464764219942, loss after: 0.000464224343887.\n",
      "Epoch:4, weight train batch: 80, step:10, loss before: 0.000452609121567, loss after: 0.00045209529344.\n",
      "Epoch:4, weight train batch: 80, step:11, loss before: 0.0114132454619, loss after: 0.011402930133.\n",
      "Epoch:4, weight train batch: 80, step:12, loss before: 0.000482610368636, loss after: 0.000481944007333.\n",
      "Epoch:4, weight train batch: 80, step:13, loss before: 0.000455777102616, loss after: 0.000455021392554.\n",
      "Epoch:4, weight train batch: 80, step:14, loss before: 0.000425170175731, loss after: 0.00042477552779.\n",
      "Epoch:4, weight train batch: 80, step:15, loss before: 0.000509524426889, loss after: 0.000508835713845.\n",
      "Epoch:4, weight train batch: 80, step:16, loss before: 0.000513051461894, loss after: 0.000512318045367.\n",
      "Epoch:4, weight train batch: 80, step:17, loss before: 0.000488250108901, loss after: 0.000487576238811.\n",
      "Epoch:4, weight train batch: 80, step:18, loss before: 0.000449044076959, loss after: 0.000448433449492.\n",
      "Epoch:4, weight train batch: 80, step:19, loss before: 0.000484402640723, loss after: 0.000483814423205.\n",
      "Epoch:4, weight train batch: 80, step:20, loss before: 0.000463101547211, loss after: 0.00046255424968.\n",
      "Epoch:4, weight train batch: 80, step:21, loss before: 0.000539021450095, loss after: 0.000538340653293.\n",
      "Epoch:4, weight train batch: 80, step:22, loss before: 0.000506157055497, loss after: 0.000505579926539.\n",
      "Epoch:4, weight train batch: 80, step:23, loss before: 0.000479173322674, loss after: 0.000478514353745.\n",
      "Epoch:4, weight train batch: 80, step:24, loss before: 0.000500702881254, loss after: 0.000500122085214.\n",
      "Epoch:4, weight train batch: 80, step:25, loss before: 0.000503094750457, loss after: 0.000502454349771.\n",
      "Epoch:4, weight train batch: 80, step:26, loss before: 0.000470028899144, loss after: 0.00046950019896.\n",
      "Epoch:4, weight train batch: 80, step:27, loss before: 0.000474723172374, loss after: 0.000474164698971.\n",
      "Epoch:4, weight train batch: 80, step:28, loss before: 0.000522668880876, loss after: 0.000522054499015.\n",
      "Epoch:4, weight train batch: 80, step:29, loss before: 0.000414077367168, loss after: 0.000413619389292.\n",
      "Epoch:4, weight train batch: 80, step:30, loss before: 0.000523472786881, loss after: 0.00052288454026.\n",
      "Epoch:4, weight train batch: 80, step:31, loss before: 0.000491907296237, loss after: 0.000491285522003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 76, loss before: 0.00188333925325, loss after: 0.00314505724236.\n",
      "Epoch:4, weight train batch: 81, step:0, loss before: 0.000433078064816, loss after: 0.000432616390754.\n",
      "Epoch:4, weight train batch: 81, step:1, loss before: 0.000526577467099, loss after: 0.000525966868736.\n",
      "Epoch:4, weight train batch: 81, step:2, loss before: 0.000492912367918, loss after: 0.00049233896425.\n",
      "Epoch:4, weight train batch: 81, step:3, loss before: 0.00043328240281, loss after: 0.00043280585669.\n",
      "Epoch:4, weight train batch: 81, step:4, loss before: 0.00135236256756, loss after: 0.00135020236485.\n",
      "Epoch:4, weight train batch: 81, step:5, loss before: 0.000496471067891, loss after: 0.000495890213642.\n",
      "Epoch:4, weight train batch: 81, step:6, loss before: 0.00047887704568, loss after: 0.000478311121697.\n",
      "Epoch:4, weight train batch: 81, step:7, loss before: 0.000488332938403, loss after: 0.000487707438879.\n",
      "Epoch:4, weight train batch: 81, step:8, loss before: 0.000459968869109, loss after: 0.000459365663119.\n",
      "Epoch:4, weight train batch: 81, step:9, loss before: 0.000537700718269, loss after: 0.000537116255146.\n",
      "Epoch:4, weight train batch: 81, step:10, loss before: 0.000467058736831, loss after: 0.000466433208203.\n",
      "Epoch:4, weight train batch: 81, step:11, loss before: 0.000516488216817, loss after: 0.000515870167874.\n",
      "Epoch:4, weight train batch: 81, step:12, loss before: 0.00045768826385, loss after: 0.000457155838376.\n",
      "Epoch:4, weight train batch: 81, step:13, loss before: 0.000474085332826, loss after: 0.000473627384054.\n",
      "Epoch:4, weight train batch: 81, step:14, loss before: 0.00045675371075, loss after: 0.000456217559986.\n",
      "Epoch:4, weight train batch: 81, step:15, loss before: 0.000460145121906, loss after: 0.000459556904389.\n",
      "Epoch:4, weight train batch: 81, step:16, loss before: 0.000483245181385, loss after: 0.000482712785015.\n",
      "Epoch:4, weight train batch: 81, step:17, loss before: 0.000443681026809, loss after: 0.000443230557721.\n",
      "Epoch:4, weight train batch: 81, step:18, loss before: 0.000477897090605, loss after: 0.000477375870105.\n",
      "Epoch:4, weight train batch: 81, step:19, loss before: 0.000478609872516, loss after: 0.000478088622913.\n",
      "Epoch:4, weight train batch: 81, step:20, loss before: 0.000475953653222, loss after: 0.000475439825095.\n",
      "Epoch:4, weight train batch: 81, step:21, loss before: 0.000442478311015, loss after: 0.000441971991677.\n",
      "Epoch:4, weight train batch: 81, step:22, loss before: 0.000425034668297, loss after: 0.000424602767453.\n",
      "Epoch:4, weight train batch: 81, step:23, loss before: 0.000454426393844, loss after: 0.00045394236804.\n",
      "Epoch:4, weight train batch: 81, step:24, loss before: 0.000436765316408, loss after: 0.000436325964984.\n",
      "Epoch:4, weight train batch: 81, step:25, loss before: 0.000458791269921, loss after: 0.00045832208707.\n",
      "Epoch:4, weight train batch: 81, step:26, loss before: 0.000965452636592, loss after: 0.000964189181104.\n",
      "Epoch:4, weight train batch: 81, step:27, loss before: 0.000497845234349, loss after: 0.000497372355312.\n",
      "Epoch:4, weight train batch: 81, step:28, loss before: 0.000411218876252, loss after: 0.000410801905673.\n",
      "Epoch:4, weight train batch: 81, step:29, loss before: 0.000410583976191, loss after: 0.000410111038946.\n",
      "Epoch:4, weight train batch: 81, step:30, loss before: 0.000439387571532, loss after: 0.000438985443907.\n",
      "Epoch:4, weight train batch: 81, step:31, loss before: 0.000430854881415, loss after: 0.0004304118047.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 77, loss before: 0.000436601956608, loss after: 0.000436618720414.\n",
      "Epoch:4, weight train batch: 82, step:0, loss before: 0.000409107713494, loss after: 0.000408687046729.\n",
      "Epoch:4, weight train batch: 82, step:1, loss before: 0.000400361197535, loss after: 0.000399944197852.\n",
      "Epoch:4, weight train batch: 82, step:2, loss before: 0.000442458374891, loss after: 0.000441978045274.\n",
      "Epoch:4, weight train batch: 82, step:3, loss before: 0.000435580470366, loss after: 0.000435185764218.\n",
      "Epoch:4, weight train batch: 82, step:4, loss before: 0.000624313775916, loss after: 0.000623674073722.\n",
      "Epoch:4, weight train batch: 82, step:5, loss before: 0.000501267844811, loss after: 0.000500739202835.\n",
      "Epoch:4, weight train batch: 82, step:6, loss before: 0.000443165452452, loss after: 0.00044267764315.\n",
      "Epoch:4, weight train batch: 82, step:7, loss before: 0.000449483690318, loss after: 0.000449059298262.\n",
      "Epoch:4, weight train batch: 82, step:8, loss before: 0.000425340433139, loss after: 0.000424841418862.\n",
      "Epoch:4, weight train batch: 82, step:9, loss before: 0.000517414417118, loss after: 0.000516937929206.\n",
      "Epoch:4, weight train batch: 82, step:10, loss before: 0.000465128425276, loss after: 0.000464670418296.\n",
      "Epoch:4, weight train batch: 82, step:11, loss before: 0.000587964546867, loss after: 0.000587365648244.\n",
      "Epoch:4, weight train batch: 82, step:12, loss before: 0.000481032242533, loss after: 0.000480566814076.\n",
      "Epoch:4, weight train batch: 82, step:13, loss before: 0.000333890900947, loss after: 0.000333488744218.\n",
      "Epoch:4, weight train batch: 82, step:14, loss before: 0.000442137534264, loss after: 0.000441724201664.\n",
      "Epoch:4, weight train batch: 82, step:15, loss before: 0.000413892412325, loss after: 0.000413475441746.\n",
      "Epoch:4, weight train batch: 82, step:16, loss before: 0.000472074723803, loss after: 0.00047156092478.\n",
      "Epoch:4, weight train batch: 82, step:17, loss before: 0.000440987874754, loss after: 0.000440541072749.\n",
      "Epoch:4, weight train batch: 82, step:18, loss before: 0.00038900153595, loss after: 0.000388636661228.\n",
      "Epoch:4, weight train batch: 82, step:19, loss before: 0.000440080533735, loss after: 0.00043962628115.\n",
      "Epoch:4, weight train batch: 82, step:20, loss before: 0.000363252416719, loss after: 0.000362887483789.\n",
      "Epoch:4, weight train batch: 82, step:21, loss before: 0.000419718038756, loss after: 0.000419289804995.\n",
      "Epoch:4, weight train batch: 82, step:22, loss before: 0.000408321327996, loss after: 0.000407949031796.\n",
      "Epoch:4, weight train batch: 82, step:23, loss before: 0.00038141279947, loss after: 0.000381029269192.\n",
      "Epoch:4, weight train batch: 82, step:24, loss before: 0.000397775700549, loss after: 0.000397388503188.\n",
      "Epoch:4, weight train batch: 82, step:25, loss before: 0.000376657932065, loss after: 0.0003763079294.\n",
      "Epoch:4, weight train batch: 82, step:26, loss before: 0.000444017030532, loss after: 0.000443592580268.\n",
      "Epoch:4, weight train batch: 82, step:27, loss before: 0.000466612254968, loss after: 0.000466180383228.\n",
      "Epoch:4, weight train batch: 82, step:28, loss before: 0.000443246826762, loss after: 0.000442840973847.\n",
      "Epoch:4, weight train batch: 82, step:29, loss before: 0.000474475062219, loss after: 0.000474069209304.\n",
      "Epoch:4, weight train batch: 82, step:30, loss before: 0.000427194841905, loss after: 0.000426777813118.\n",
      "Epoch:4, weight train batch: 82, step:31, loss before: 0.000458474212792, loss after: 0.000458034861367.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 78, loss before: 0.000475667940918, loss after: 0.000442544347607.\n",
      "Epoch:4, weight train batch: 83, step:0, loss before: 0.000456661568023, loss after: 0.000456278066849.\n",
      "Epoch:4, weight train batch: 83, step:1, loss before: 0.000413647328969, loss after: 0.000413252681028.\n",
      "Epoch:4, weight train batch: 83, step:2, loss before: 0.000363856262993, loss after: 0.000363562081475.\n",
      "Epoch:4, weight train batch: 83, step:3, loss before: 0.000423930148827, loss after: 0.000423513149144.\n",
      "Epoch:4, weight train batch: 83, step:4, loss before: 0.000412547378801, loss after: 0.000412182474975.\n",
      "Epoch:4, weight train batch: 83, step:5, loss before: 0.000359165132977, loss after: 0.00035878532799.\n",
      "Epoch:4, weight train batch: 83, step:6, loss before: 0.000466517172754, loss after: 0.0004660889972.\n",
      "Epoch:4, weight train batch: 83, step:7, loss before: 0.000397722324124, loss after: 0.000397338793846.\n",
      "Epoch:4, weight train batch: 83, step:8, loss before: 0.000583362416364, loss after: 0.000582852691878.\n",
      "Epoch:4, weight train batch: 83, step:9, loss before: 0.000437924056314, loss after: 0.000437495909864.\n",
      "Epoch:4, weight train batch: 83, step:10, loss before: 0.00039249562542, loss after: 0.000392164220102.\n",
      "Epoch:4, weight train batch: 83, step:11, loss before: 0.000479345821077, loss after: 0.000478910224047.\n",
      "Epoch:4, weight train batch: 83, step:12, loss before: 0.000459866132587, loss after: 0.00045939697884.\n",
      "Epoch:4, weight train batch: 83, step:13, loss before: 0.000414521724451, loss after: 0.000414145673858.\n",
      "Epoch:4, weight train batch: 83, step:14, loss before: 0.000385592982639, loss after: 0.000385228107916.\n",
      "Epoch:4, weight train batch: 83, step:15, loss before: 0.000454178458313, loss after: 0.000453739165096.\n",
      "Epoch:4, weight train batch: 83, step:16, loss before: 0.000861043692566, loss after: 0.000860230531543.\n",
      "Epoch:4, weight train batch: 83, step:17, loss before: 0.000511902151629, loss after: 0.000511455407832.\n",
      "Epoch:4, weight train batch: 83, step:18, loss before: 0.000445097393822, loss after: 0.0004446952953.\n",
      "Epoch:4, weight train batch: 83, step:19, loss before: 0.00049474555999, loss after: 0.000494235486258.\n",
      "Epoch:4, weight train batch: 83, step:20, loss before: 0.000428048108006, loss after: 0.000427631079219.\n",
      "Epoch:4, weight train batch: 83, step:21, loss before: 0.0475424006581, loss after: 0.0474849939346.\n",
      "Epoch:4, weight train batch: 83, step:22, loss before: 0.000457215006463, loss after: 0.000457758666016.\n",
      "Epoch:4, weight train batch: 83, step:23, loss before: 0.000467672478408, loss after: 0.000467545934953.\n",
      "Epoch:4, weight train batch: 83, step:24, loss before: 0.000478845176985, loss after: 0.000478860107251.\n",
      "Epoch:4, weight train batch: 83, step:25, loss before: 0.000385386054404, loss after: 0.000385631865356.\n",
      "Epoch:4, weight train batch: 83, step:26, loss before: 0.000398075615522, loss after: 0.000398198550101.\n",
      "Epoch:4, weight train batch: 83, step:27, loss before: 0.000501399917994, loss after: 0.000501504226122.\n",
      "Epoch:4, weight train batch: 83, step:28, loss before: 0.000412107154261, loss after: 0.000412300782045.\n",
      "Epoch:4, weight train batch: 83, step:29, loss before: 0.000483069714392, loss after: 0.00048312151921.\n",
      "Epoch:4, weight train batch: 83, step:30, loss before: 0.000395484967157, loss after: 0.000395406823372.\n",
      "Epoch:4, weight train batch: 83, step:31, loss before: 0.000420582364313, loss after: 0.000420649419539.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 79, loss before: 0.000431756896432, loss after: 0.000431756896432.\n",
      "Epoch:4, weight train batch: 84, step:0, loss before: 0.000427268794738, loss after: 0.000427216669777.\n",
      "Epoch:4, weight train batch: 84, step:1, loss before: 0.000375831499696, loss after: 0.000375637901016.\n",
      "Epoch:4, weight train batch: 84, step:2, loss before: 0.000404091959354, loss after: 0.000403842510423.\n",
      "Epoch:4, weight train batch: 84, step:3, loss before: 0.000451007537777, loss after: 0.000450802792329.\n",
      "Epoch:4, weight train batch: 84, step:4, loss before: 0.000409946136642, loss after: 0.0004096259363.\n",
      "Epoch:4, weight train batch: 84, step:5, loss before: 0.000452859851066, loss after: 0.000452521024272.\n",
      "Epoch:4, weight train batch: 84, step:6, loss before: 0.000892715528607, loss after: 0.000891821458936.\n",
      "Epoch:4, weight train batch: 84, step:7, loss before: 0.000402260251576, loss after: 0.000401865545427.\n",
      "Epoch:4, weight train batch: 84, step:8, loss before: 0.000443330500275, loss after: 0.000442891119746.\n",
      "Epoch:4, weight train batch: 84, step:9, loss before: 0.000390563043766, loss after: 0.000390179513488.\n",
      "Epoch:4, weight train batch: 84, step:10, loss before: 0.00041197281098, loss after: 0.000411537155742.\n",
      "Epoch:4, weight train batch: 84, step:11, loss before: 0.000414141395595, loss after: 0.000413675967138.\n",
      "Epoch:4, weight train batch: 84, step:12, loss before: 0.000400182500016, loss after: 0.000399761833251.\n",
      "Epoch:4, weight train batch: 84, step:13, loss before: 0.000454149179859, loss after: 0.00045365022379.\n",
      "Epoch:4, weight train batch: 84, step:14, loss before: 0.000420851865783, loss after: 0.000420297088567.\n",
      "Epoch:4, weight train batch: 84, step:15, loss before: 0.00044816971058, loss after: 0.00044768571388.\n",
      "Epoch:4, weight train batch: 84, step:16, loss before: 0.000394398375647, loss after: 0.000393921742216.\n",
      "Epoch:4, weight train batch: 84, step:17, loss before: 0.000436670146883, loss after: 0.000436093076132.\n",
      "Epoch:4, weight train batch: 84, step:18, loss before: 0.000513382896315, loss after: 0.000512850820087.\n",
      "Epoch:4, weight train batch: 84, step:19, loss before: 0.000441483512986, loss after: 0.000440869189333.\n",
      "Epoch:4, weight train batch: 84, step:20, loss before: 0.000334501441102, loss after: 0.000334143929649.\n",
      "Epoch:4, weight train batch: 84, step:21, loss before: 0.000380694313208, loss after: 0.000380225130357.\n",
      "Epoch:4, weight train batch: 84, step:22, loss before: 0.000404291553423, loss after: 0.000403859652579.\n",
      "Epoch:4, weight train batch: 84, step:23, loss before: 0.0466727055609, loss after: 0.0466169342399.\n",
      "Epoch:4, weight train batch: 84, step:24, loss before: 0.000448286824394, loss after: 0.000448499049526.\n",
      "Epoch:4, weight train batch: 84, step:25, loss before: 0.000495442887768, loss after: 0.000496206106618.\n",
      "Epoch:4, weight train batch: 84, step:26, loss before: 0.000870270247106, loss after: 0.000870355870575.\n",
      "Epoch:4, weight train batch: 84, step:27, loss before: 0.000400081044063, loss after: 0.000400189077482.\n",
      "Epoch:4, weight train batch: 84, step:28, loss before: 0.000432438595453, loss after: 0.000432561442722.\n",
      "Epoch:4, weight train batch: 84, step:29, loss before: 0.000422537792474, loss after: 0.000422671844717.\n",
      "Epoch:4, weight train batch: 84, step:30, loss before: 0.000368712586351, loss after: 0.000368738605175.\n",
      "Epoch:4, weight train batch: 84, step:31, loss before: 0.000408314808737, loss after: 0.000408378080465.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 80, loss before: 0.000472287443699, loss after: 0.000548636133317.\n",
      "Epoch:4, weight train batch: 85, step:0, loss before: 0.000433875480667, loss after: 0.000433704204625.\n",
      "Epoch:4, weight train batch: 85, step:1, loss before: 0.000458012626041, loss after: 0.000457766873296.\n",
      "Epoch:4, weight train batch: 85, step:2, loss before: 0.000416510622017, loss after: 0.000416331895394.\n",
      "Epoch:4, weight train batch: 85, step:3, loss before: 0.000373026821762, loss after: 0.000372687994968.\n",
      "Epoch:4, weight train batch: 85, step:4, loss before: 0.00042774018948, loss after: 0.000427446095273.\n",
      "Epoch:4, weight train batch: 85, step:5, loss before: 0.000468807236757, loss after: 0.000468393962365.\n",
      "Epoch:4, weight train batch: 85, step:6, loss before: 0.000400231452659, loss after: 0.00039983302122.\n",
      "Epoch:4, weight train batch: 85, step:7, loss before: 0.000431803055108, loss after: 0.000431337626651.\n",
      "Epoch:4, weight train batch: 85, step:8, loss before: 0.000422659679316, loss after: 0.000422242650529.\n",
      "Epoch:4, weight train batch: 85, step:9, loss before: 0.000450250052381, loss after: 0.000449769780971.\n",
      "Epoch:4, weight train batch: 85, step:10, loss before: 0.000445957557531, loss after: 0.000445469777333.\n",
      "Epoch:4, weight train batch: 85, step:11, loss before: 0.000460021372419, loss after: 0.000459578353912.\n",
      "Epoch:4, weight train batch: 85, step:12, loss before: 0.00042568083154, loss after: 0.000425196776632.\n",
      "Epoch:4, weight train batch: 85, step:13, loss before: 0.000437616166892, loss after: 0.000437079987023.\n",
      "Epoch:4, weight train batch: 85, step:14, loss before: 0.000577330996748, loss after: 0.00057667249348.\n",
      "Epoch:4, weight train batch: 85, step:15, loss before: 0.00585202081129, loss after: 0.0058398200199.\n",
      "Epoch:4, weight train batch: 85, step:16, loss before: 0.000360707286745, loss after: 0.000360130157787.\n",
      "Epoch:4, weight train batch: 85, step:17, loss before: 0.00057519931579, loss after: 0.000574499659706.\n",
      "Epoch:4, weight train batch: 85, step:18, loss before: 0.000435870548245, loss after: 0.000435356720118.\n",
      "Epoch:4, weight train batch: 85, step:19, loss before: 0.000414627196733, loss after: 0.000414266047301.\n",
      "Epoch:4, weight train batch: 85, step:20, loss before: 0.000416462222347, loss after: 0.000416074995883.\n",
      "Epoch:4, weight train batch: 85, step:21, loss before: 0.000394227565266, loss after: 0.000393870112021.\n",
      "Epoch:4, weight train batch: 85, step:22, loss before: 0.000420151627623, loss after: 0.000419764430262.\n",
      "Epoch:4, weight train batch: 85, step:23, loss before: 0.000436656933744, loss after: 0.00043620634824.\n",
      "Epoch:4, weight train batch: 85, step:24, loss before: 0.000432292348705, loss after: 0.000431860447861.\n",
      "Epoch:4, weight train batch: 85, step:25, loss before: 0.000414459034801, loss after: 0.00041403825162.\n",
      "Epoch:4, weight train batch: 85, step:26, loss before: 0.000380267039873, loss after: 0.000379905890441.\n",
      "Epoch:4, weight train batch: 85, step:27, loss before: 0.000401734752813, loss after: 0.000401351222536.\n",
      "Epoch:4, weight train batch: 85, step:28, loss before: 0.000804881914519, loss after: 0.000803964794613.\n",
      "Epoch:4, weight train batch: 85, step:29, loss before: 0.000410059001297, loss after: 0.000409634492826.\n",
      "Epoch:4, weight train batch: 85, step:30, loss before: 0.000442159187514, loss after: 0.000441690033767.\n",
      "Epoch:4, weight train batch: 85, step:31, loss before: 0.000363584375009, loss after: 0.000363118946552.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 81, loss before: 0.000398842501454, loss after: 0.000398842501454.\n",
      "Epoch:4, weight train batch: 86, step:0, loss before: 0.000448324572062, loss after: 0.000447870290373.\n",
      "Epoch:4, weight train batch: 86, step:1, loss before: 0.000394275877625, loss after: 0.000393870024709.\n",
      "Epoch:4, weight train batch: 86, step:2, loss before: 0.000417461502366, loss after: 0.000417003495386.\n",
      "Epoch:4, weight train batch: 86, step:3, loss before: 0.00040837720735, loss after: 0.00040796014946.\n",
      "Epoch:4, weight train batch: 86, step:4, loss before: 0.00035172313801, loss after: 0.000351302383933.\n",
      "Epoch:4, weight train batch: 86, step:5, loss before: 0.000385278981412, loss after: 0.000384847051464.\n",
      "Epoch:4, weight train batch: 86, step:6, loss before: 0.000402943522204, loss after: 0.000402530218707.\n",
      "Epoch:4, weight train batch: 86, step:7, loss before: 0.000342882529367, loss after: 0.000342458020896.\n",
      "Epoch:4, weight train batch: 86, step:8, loss before: 0.000398941367166, loss after: 0.000398546690121.\n",
      "Epoch:4, weight train batch: 86, step:9, loss before: 0.000438725895947, loss after: 0.000438293965999.\n",
      "Epoch:4, weight train batch: 86, step:10, loss before: 0.000397422089009, loss after: 0.000396978954086.\n",
      "Epoch:4, weight train batch: 86, step:11, loss before: 0.000324642489431, loss after: 0.000324240361806.\n",
      "Epoch:4, weight train batch: 86, step:12, loss before: 0.00041723169852, loss after: 0.000416833267082.\n",
      "Epoch:4, weight train batch: 86, step:13, loss before: 0.00038800315815, loss after: 0.000387604755815.\n",
      "Epoch:4, weight train batch: 86, step:14, loss before: 0.000404430320486, loss after: 0.000403972284403.\n",
      "Epoch:4, weight train batch: 86, step:15, loss before: 0.00036883741268, loss after: 0.000368472508853.\n",
      "Epoch:4, weight train batch: 86, step:16, loss before: 0.000418525392888, loss after: 0.000418123294367.\n",
      "Epoch:4, weight train batch: 86, step:17, loss before: 0.00038032757584, loss after: 0.000379888195312.\n",
      "Epoch:4, weight train batch: 86, step:18, loss before: 0.000431216787547, loss after: 0.000430810905527.\n",
      "Epoch:4, weight train batch: 86, step:19, loss before: 0.000460868905066, loss after: 0.000460410956293.\n",
      "Epoch:4, weight train batch: 86, step:20, loss before: 0.000501491769683, loss after: 0.000500966911204.\n",
      "Epoch:4, weight train batch: 86, step:21, loss before: 0.00041682110168, loss after: 0.000416385417338.\n",
      "Epoch:4, weight train batch: 86, step:22, loss before: 0.000403260841267, loss after: 0.000402821489843.\n",
      "Epoch:4, weight train batch: 86, step:23, loss before: 0.00036759863724, loss after: 0.000367185333744.\n",
      "Epoch:4, weight train batch: 86, step:24, loss before: 0.000423784484155, loss after: 0.000423348799814.\n",
      "Epoch:4, weight train batch: 86, step:25, loss before: 0.000348583271261, loss after: 0.000348195986589.\n",
      "Epoch:4, weight train batch: 86, step:26, loss before: 0.00042153056711, loss after: 0.000421113567427.\n",
      "Epoch:4, weight train batch: 86, step:27, loss before: 0.000364227540558, loss after: 0.000363803002983.\n",
      "Epoch:4, weight train batch: 86, step:28, loss before: 0.000398427888285, loss after: 0.000398029515054.\n",
      "Epoch:4, weight train batch: 86, step:29, loss before: 0.000378037977498, loss after: 0.000377602293156.\n",
      "Epoch:4, weight train batch: 86, step:30, loss before: 0.000422348093707, loss after: 0.000421927368734.\n",
      "Epoch:4, weight train batch: 86, step:31, loss before: 0.000421133416239, loss after: 0.000420679105446.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 82, loss before: 0.000401215802412, loss after: 0.000425684906077.\n",
      "Epoch:4, weight train batch: 87, step:0, loss before: 0.000400769524276, loss after: 0.000400374818128.\n",
      "Epoch:4, weight train batch: 87, step:1, loss before: 0.000425018923124, loss after: 0.000424512516474.\n",
      "Epoch:4, weight train batch: 87, step:2, loss before: 0.000361413927749, loss after: 0.000361045327736.\n",
      "Epoch:4, weight train batch: 87, step:3, loss before: 0.000447683414677, loss after: 0.000447281287052.\n",
      "Epoch:4, weight train batch: 87, step:4, loss before: 0.000433829176472, loss after: 0.000433292996604.\n",
      "Epoch:4, weight train batch: 87, step:5, loss before: 0.000295925769024, loss after: 0.000295612961054.\n",
      "Epoch:4, weight train batch: 87, step:6, loss before: 0.00038026162656, loss after: 0.000379919045372.\n",
      "Epoch:4, weight train batch: 87, step:7, loss before: 0.000347241904819, loss after: 0.000346884451574.\n",
      "Epoch:4, weight train batch: 87, step:8, loss before: 0.000357005366823, loss after: 0.000356670236215.\n",
      "Epoch:4, weight train batch: 87, step:9, loss before: 0.000364825391443, loss after: 0.00036444561556.\n",
      "Epoch:4, weight train batch: 87, step:10, loss before: 0.000414474459831, loss after: 0.000414068577811.\n",
      "Epoch:4, weight train batch: 87, step:11, loss before: 0.000410332926549, loss after: 0.000409953150665.\n",
      "Epoch:4, weight train batch: 87, step:12, loss before: 0.000374224735424, loss after: 0.000373859831598.\n",
      "Epoch:4, weight train batch: 87, step:13, loss before: 0.000345708569512, loss after: 0.000345384614775.\n",
      "Epoch:4, weight train batch: 87, step:14, loss before: 0.000337292731274, loss after: 0.000336916651577.\n",
      "Epoch:4, weight train batch: 87, step:15, loss before: 0.000378506723791, loss after: 0.000378149241442.\n",
      "Epoch:4, weight train batch: 87, step:16, loss before: 0.000382259575417, loss after: 0.000381902151275.\n",
      "Epoch:4, weight train batch: 87, step:17, loss before: 0.000364483392332, loss after: 0.000364174309652.\n",
      "Epoch:4, weight train batch: 87, step:18, loss before: 0.000389884633478, loss after: 0.000389463850297.\n",
      "Epoch:4, weight train batch: 87, step:19, loss before: 0.000430915970355, loss after: 0.00043051756802.\n",
      "Epoch:4, weight train batch: 87, step:20, loss before: 0.000376233947463, loss after: 0.000375857809559.\n",
      "Epoch:4, weight train batch: 87, step:21, loss before: 0.000363435654435, loss after: 0.000363067025319.\n",
      "Epoch:4, weight train batch: 87, step:22, loss before: 0.000392524234485, loss after: 0.00039217050653.\n",
      "Epoch:4, weight train batch: 87, step:23, loss before: 0.00032611907227, loss after: 0.000325821136357.\n",
      "Epoch:4, weight train batch: 87, step:24, loss before: 0.000354123825673, loss after: 0.000353747745976.\n",
      "Epoch:4, weight train batch: 87, step:25, loss before: 0.000412349298131, loss after: 0.000411958288169.\n",
      "Epoch:4, weight train batch: 87, step:26, loss before: 0.000365176907508, loss after: 0.000364797131624.\n",
      "Epoch:4, weight train batch: 87, step:27, loss before: 0.00034308686736, loss after: 0.000342774088494.\n",
      "Epoch:4, weight train batch: 87, step:28, loss before: 0.000338337325957, loss after: 0.000337976089213.\n",
      "Epoch:4, weight train batch: 87, step:29, loss before: 0.000344456871971, loss after: 0.000344151543686.\n",
      "Epoch:4, weight train batch: 87, step:30, loss before: 0.000350020593032, loss after: 0.000349692942109.\n",
      "Epoch:4, weight train batch: 87, step:31, loss before: 0.000336555909598, loss after: 0.000336183526088.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 83, loss before: 0.000370189489331, loss after: 0.00299172382802.\n",
      "Epoch:4, weight train batch: 88, step:0, loss before: 0.0106602022424, loss after: 0.0106491791084.\n",
      "Epoch:4, weight train batch: 88, step:1, loss before: 0.000385983497836, loss after: 0.000385506893508.\n",
      "Epoch:4, weight train batch: 88, step:2, loss before: 0.00041098886868, loss after: 0.000410434091464.\n",
      "Epoch:4, weight train batch: 88, step:3, loss before: 0.00110572122503, loss after: 0.00110418489203.\n",
      "Epoch:4, weight train batch: 88, step:4, loss before: 0.000386138621252, loss after: 0.000385643390473.\n",
      "Epoch:4, weight train batch: 88, step:5, loss before: 0.000418223266024, loss after: 0.000417567964178.\n",
      "Epoch:4, weight train batch: 88, step:6, loss before: 0.000335204356816, loss after: 0.000334869255312.\n",
      "Epoch:4, weight train batch: 88, step:7, loss before: 0.000375410658307, loss after: 0.00037503085332.\n",
      "Epoch:4, weight train batch: 88, step:8, loss before: 0.000413416390074, loss after: 0.000412880268414.\n",
      "Epoch:4, weight train batch: 88, step:9, loss before: 0.000436651520431, loss after: 0.000436197326053.\n",
      "Epoch:4, weight train batch: 88, step:10, loss before: 0.000410342181567, loss after: 0.000409839471104.\n",
      "Epoch:4, weight train batch: 88, step:11, loss before: 0.000375977630029, loss after: 0.000375579227693.\n",
      "Epoch:4, weight train batch: 88, step:12, loss before: 0.00034639131627, loss after: 0.00034601893276.\n",
      "Epoch:4, weight train batch: 88, step:13, loss before: 0.000413792295149, loss after: 0.000413341796957.\n",
      "Epoch:4, weight train batch: 88, step:14, loss before: 0.000356566946721, loss after: 0.000356101460056.\n",
      "Epoch:4, weight train batch: 88, step:15, loss before: 0.000405742495786, loss after: 0.000405318045523.\n",
      "Epoch:4, weight train batch: 88, step:16, loss before: 0.000402815756388, loss after: 0.000402361503802.\n",
      "Epoch:4, weight train batch: 88, step:17, loss before: 0.000418270123191, loss after: 0.000417786010075.\n",
      "Epoch:4, weight train batch: 88, step:18, loss before: 0.000361604354111, loss after: 0.00036122824531.\n",
      "Epoch:4, weight train batch: 88, step:19, loss before: 0.000474082276924, loss after: 0.000473598251119.\n",
      "Epoch:4, weight train batch: 88, step:20, loss before: 0.000363499391824, loss after: 0.000363078666851.\n",
      "Epoch:4, weight train batch: 88, step:21, loss before: 0.000373967981432, loss after: 0.000373599323211.\n",
      "Epoch:4, weight train batch: 88, step:22, loss before: 0.000372549373424, loss after: 0.000372154638171.\n",
      "Epoch:4, weight train batch: 88, step:23, loss before: 0.000843912595883, loss after: 0.000842703389935.\n",
      "Epoch:4, weight train batch: 88, step:24, loss before: 0.000369363377104, loss after: 0.0003689500154.\n",
      "Epoch:4, weight train batch: 88, step:25, loss before: 0.000315840065014, loss after: 0.000315471377689.\n",
      "Epoch:4, weight train batch: 88, step:26, loss before: 0.00037843559403, loss after: 0.0003780334373.\n",
      "Epoch:4, weight train batch: 88, step:27, loss before: 0.000361338374205, loss after: 0.000360910140444.\n",
      "Epoch:4, weight train batch: 88, step:28, loss before: 0.000412396795582, loss after: 0.000411994638853.\n",
      "Epoch:4, weight train batch: 88, step:29, loss before: 0.000374324794393, loss after: 0.000373907765606.\n",
      "Epoch:4, weight train batch: 88, step:30, loss before: 0.000410733744502, loss after: 0.000410324137192.\n",
      "Epoch:4, weight train batch: 88, step:31, loss before: 0.000374025752535, loss after: 0.0003736273502.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 84, loss before: 0.000353175099008, loss after: 0.000353175099008.\n",
      "Epoch:4, weight train batch: 89, step:0, loss before: 0.000397698371671, loss after: 0.000397247844376.\n",
      "Epoch:4, weight train batch: 89, step:1, loss before: 0.000403170415666, loss after: 0.000402738485718.\n",
      "Epoch:4, weight train batch: 89, step:2, loss before: 0.000753682048526, loss after: 0.000753055384848.\n",
      "Epoch:4, weight train batch: 89, step:3, loss before: 0.000412538065575, loss after: 0.000412091234466.\n",
      "Epoch:4, weight train batch: 89, step:4, loss before: 0.000360625534086, loss after: 0.000360208447091.\n",
      "Epoch:4, weight train batch: 89, step:5, loss before: 0.000426899990998, loss after: 0.000426453218097.\n",
      "Epoch:4, weight train batch: 89, step:6, loss before: 0.000306544592604, loss after: 0.000306172209093.\n",
      "Epoch:4, weight train batch: 89, step:7, loss before: 0.000379326287657, loss after: 0.000378983735573.\n",
      "Epoch:4, weight train batch: 89, step:8, loss before: 0.000287846167339, loss after: 0.000287514732918.\n",
      "Epoch:4, weight train batch: 89, step:9, loss before: 0.046056419611, loss after: 0.0459976680577.\n",
      "Epoch:4, weight train batch: 89, step:10, loss before: 0.000366525171557, loss after: 0.000366082007531.\n",
      "Epoch:4, weight train batch: 89, step:11, loss before: 0.00040567968972, loss after: 0.000405318511184.\n",
      "Epoch:4, weight train batch: 89, step:12, loss before: 0.000382092577638, loss after: 0.000381913792808.\n",
      "Epoch:4, weight train batch: 89, step:13, loss before: 0.000377105810912, loss after: 0.000377217453206.\n",
      "Epoch:4, weight train batch: 89, step:14, loss before: 0.0003366805322, loss after: 0.000336673052516.\n",
      "Epoch:4, weight train batch: 89, step:15, loss before: 0.000364340958185, loss after: 0.000364154780982.\n",
      "Epoch:4, weight train batch: 89, step:16, loss before: 0.000298426282825, loss after: 0.000298228929751.\n",
      "Epoch:4, weight train batch: 89, step:17, loss before: 0.000386457279092, loss after: 0.000386312021874.\n",
      "Epoch:4, weight train batch: 89, step:18, loss before: 0.0003692417813, loss after: 0.000369018351194.\n",
      "Epoch:4, weight train batch: 89, step:19, loss before: 0.000337193021551, loss after: 0.000336991914082.\n",
      "Epoch:4, weight train batch: 89, step:20, loss before: 0.000341154664056, loss after: 0.000340946106007.\n",
      "Epoch:4, weight train batch: 89, step:21, loss before: 0.000369935529307, loss after: 0.000369637622498.\n",
      "Epoch:4, weight train batch: 89, step:22, loss before: 0.000332367490046, loss after: 0.000332121708198.\n",
      "Epoch:4, weight train batch: 89, step:23, loss before: 0.000390167813748, loss after: 0.000389847555198.\n",
      "Epoch:4, weight train batch: 89, step:24, loss before: 0.000395415117964, loss after: 0.000395132083213.\n",
      "Epoch:4, weight train batch: 89, step:25, loss before: 0.000338969606673, loss after: 0.000338660553098.\n",
      "Epoch:4, weight train batch: 89, step:26, loss before: 0.000432074564742, loss after: 0.000431739375927.\n",
      "Epoch:4, weight train batch: 89, step:27, loss before: 0.000360666716006, loss after: 0.000360335310688.\n",
      "Epoch:4, weight train batch: 89, step:28, loss before: 0.000389492604882, loss after: 0.000389138876926.\n",
      "Epoch:4, weight train batch: 89, step:29, loss before: 0.000366307562217, loss after: 0.000366009655409.\n",
      "Epoch:4, weight train batch: 89, step:30, loss before: 0.000413768517319, loss after: 0.00041334782145.\n",
      "Epoch:4, weight train batch: 89, step:31, loss before: 0.000353026262019, loss after: 0.000352698552888.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 85, loss before: 0.000431532418588, loss after: 0.011504817754.\n",
      "Epoch:4, weight train batch: 90, step:0, loss before: 0.000394385075197, loss after: 0.000393982918467.\n",
      "Epoch:4, weight train batch: 90, step:1, loss before: 0.00033710282878, loss after: 0.000336767698172.\n",
      "Epoch:4, weight train batch: 90, step:2, loss before: 0.000346661778167, loss after: 0.000346311717294.\n",
      "Epoch:4, weight train batch: 90, step:3, loss before: 0.000316820747685, loss after: 0.000316507939715.\n",
      "Epoch:4, weight train batch: 90, step:4, loss before: 0.000358293618774, loss after: 0.000357943587005.\n",
      "Epoch:4, weight train batch: 90, step:5, loss before: 0.000377685588319, loss after: 0.000377268559532.\n",
      "Epoch:4, weight train batch: 90, step:6, loss before: 0.000811055186205, loss after: 0.000809992896393.\n",
      "Epoch:4, weight train batch: 90, step:7, loss before: 0.000346525397617, loss after: 0.000346156768501.\n",
      "Epoch:4, weight train batch: 90, step:8, loss before: 0.000370283407392, loss after: 0.000369922199752.\n",
      "Epoch:4, weight train batch: 90, step:9, loss before: 0.000296588113997, loss after: 0.000296267855447.\n",
      "Epoch:4, weight train batch: 90, step:10, loss before: 0.000355509342626, loss after: 0.000355122116162.\n",
      "Epoch:4, weight train batch: 90, step:11, loss before: 0.000272076344118, loss after: 0.000271782104392.\n",
      "Epoch:4, weight train batch: 90, step:12, loss before: 0.000363256229321, loss after: 0.000362932216376.\n",
      "Epoch:4, weight train batch: 90, step:13, loss before: 0.000408365216572, loss after: 0.000407974293921.\n",
      "Epoch:4, weight train batch: 90, step:14, loss before: 0.000394259288441, loss after: 0.00039383105468.\n",
      "Epoch:4, weight train batch: 90, step:15, loss before: 0.000335788994562, loss after: 0.000335465068929.\n",
      "Epoch:4, weight train batch: 90, step:16, loss before: 0.000340371450875, loss after: 0.000340025115293.\n",
      "Epoch:4, weight train batch: 90, step:17, loss before: 0.000359079858754, loss after: 0.00035874848254.\n",
      "Epoch:4, weight train batch: 90, step:18, loss before: 0.000360258098226, loss after: 0.000359911791747.\n",
      "Epoch:4, weight train batch: 90, step:19, loss before: 0.000330677139573, loss after: 0.000330356881022.\n",
      "Epoch:4, weight train batch: 90, step:20, loss before: 0.000342423911206, loss after: 0.000342088780599.\n",
      "Epoch:4, weight train batch: 90, step:21, loss before: 0.000325421191519, loss after: 0.000325104687363.\n",
      "Epoch:4, weight train batch: 90, step:22, loss before: 0.000323826534441, loss after: 0.000323536078213.\n",
      "Epoch:4, weight train batch: 90, step:23, loss before: 0.000327875372022, loss after: 0.000327570014633.\n",
      "Epoch:4, weight train batch: 90, step:24, loss before: 0.000328347203322, loss after: 0.000328064168571.\n",
      "Epoch:4, weight train batch: 90, step:25, loss before: 0.000799770350568, loss after: 0.000798681925517.\n",
      "Epoch:4, weight train batch: 90, step:26, loss before: 0.000341963692335, loss after: 0.000341654609656.\n",
      "Epoch:4, weight train batch: 90, step:27, loss before: 0.000348213157849, loss after: 0.000347885448718.\n",
      "Epoch:4, weight train batch: 90, step:28, loss before: 0.000361982325558, loss after: 0.000361647165846.\n",
      "Epoch:4, weight train batch: 90, step:29, loss before: 0.000376446172595, loss after: 0.000376103620511.\n",
      "Epoch:4, weight train batch: 90, step:30, loss before: 0.000449901679531, loss after: 0.000449469895102.\n",
      "Epoch:4, weight train batch: 90, step:31, loss before: 0.000719237432349, loss after: 0.000718736846466.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 86, loss before: 0.000345397944329, loss after: 0.000355767435394.\n",
      "Epoch:4, weight train batch: 91, step:0, loss before: 0.000353963521775, loss after: 0.000353594892658.\n",
      "Epoch:4, weight train batch: 91, step:1, loss before: 0.000368932232959, loss after: 0.000368597073248.\n",
      "Epoch:4, weight train batch: 91, step:2, loss before: 0.000345983135048, loss after: 0.000345651758835.\n",
      "Epoch:4, weight train batch: 91, step:3, loss before: 0.000487633340526, loss after: 0.000487201556098.\n",
      "Epoch:4, weight train batch: 91, step:4, loss before: 0.000305279623717, loss after: 0.000305015244521.\n",
      "Epoch:4, weight train batch: 91, step:5, loss before: 0.000349563924829, loss after: 0.000349254900357.\n",
      "Epoch:4, weight train batch: 91, step:6, loss before: 0.000348634144757, loss after: 0.000348298985045.\n",
      "Epoch:4, weight train batch: 91, step:7, loss before: 0.00036422352423, loss after: 0.000363839964848.\n",
      "Epoch:4, weight train batch: 91, step:8, loss before: 0.000825653551146, loss after: 0.000824469607323.\n",
      "Epoch:4, weight train batch: 91, step:9, loss before: 0.000337828649208, loss after: 0.000337497243891.\n",
      "Epoch:4, weight train batch: 91, step:10, loss before: 0.000393205613364, loss after: 0.000392822083086.\n",
      "Epoch:4, weight train batch: 91, step:11, loss before: 0.000486185192131, loss after: 0.000485757365823.\n",
      "Epoch:4, weight train batch: 91, step:12, loss before: 0.000336053490173, loss after: 0.000335755583365.\n",
      "Epoch:4, weight train batch: 91, step:13, loss before: 0.000337550853146, loss after: 0.000337215722539.\n",
      "Epoch:4, weight train batch: 91, step:14, loss before: 0.000359717232641, loss after: 0.00035931885941.\n",
      "Epoch:4, weight train batch: 91, step:15, loss before: 0.000351604598109, loss after: 0.000351295515429.\n",
      "Epoch:4, weight train batch: 91, step:16, loss before: 0.00042519159615, loss after: 0.000424793339334.\n",
      "Epoch:4, weight train batch: 91, step:17, loss before: 0.000449406827101, loss after: 0.000448982522357.\n",
      "Epoch:4, weight train batch: 91, step:18, loss before: 0.000354497635271, loss after: 0.000354151328793.\n",
      "Epoch:4, weight train batch: 91, step:19, loss before: 0.000395068898797, loss after: 0.000394704169594.\n",
      "Epoch:4, weight train batch: 91, step:20, loss before: 0.0103584313765, loss after: 0.010348604992.\n",
      "Epoch:4, weight train batch: 91, step:21, loss before: 0.000309215771267, loss after: 0.000308780116029.\n",
      "Epoch:4, weight train batch: 91, step:22, loss before: 0.00034039845923, loss after: 0.000339955382515.\n",
      "Epoch:4, weight train batch: 91, step:23, loss before: 0.000350308662746, loss after: 0.000349832058419.\n",
      "Epoch:4, weight train batch: 91, step:24, loss before: 0.000346408458427, loss after: 0.000345983920852.\n",
      "Epoch:4, weight train batch: 91, step:25, loss before: 0.000370014226064, loss after: 0.000369530171156.\n",
      "Epoch:4, weight train batch: 91, step:26, loss before: 0.000302393280435, loss after: 0.000302110274788.\n",
      "Epoch:4, weight train batch: 91, step:27, loss before: 0.000310705043375, loss after: 0.000310332688969.\n",
      "Epoch:4, weight train batch: 91, step:28, loss before: 0.000373323739041, loss after: 0.00037291040644.\n",
      "Epoch:4, weight train batch: 91, step:29, loss before: 0.0002816504566, loss after: 0.000281360000372.\n",
      "Epoch:4, weight train batch: 91, step:30, loss before: 0.000336170196533, loss after: 0.000335771765094.\n",
      "Epoch:4, weight train batch: 91, step:31, loss before: 0.000342287181411, loss after: 0.000341963226674.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 87, loss before: 0.000333198695444, loss after: 0.0015566830989.\n",
      "Epoch:4, weight train batch: 92, step:0, loss before: 0.000366204418242, loss after: 0.000365791085642.\n",
      "Epoch:4, weight train batch: 92, step:1, loss before: 0.000395673996536, loss after: 0.000395234586904.\n",
      "Epoch:4, weight train batch: 92, step:2, loss before: 0.000355012249202, loss after: 0.000354662246536.\n",
      "Epoch:4, weight train batch: 92, step:3, loss before: 0.000391515844967, loss after: 0.00039113603998.\n",
      "Epoch:4, weight train batch: 92, step:4, loss before: 0.000330156675773, loss after: 0.000329765665811.\n",
      "Epoch:4, weight train batch: 92, step:5, loss before: 0.000397367286496, loss after: 0.000396991265006.\n",
      "Epoch:4, weight train batch: 92, step:6, loss before: 0.000338766316418, loss after: 0.000338438607287.\n",
      "Epoch:4, weight train batch: 92, step:7, loss before: 0.000339018821251, loss after: 0.000338709738571.\n",
      "Epoch:4, weight train batch: 92, step:8, loss before: 0.000316587917041, loss after: 0.000316237856168.\n",
      "Epoch:4, weight train batch: 92, step:9, loss before: 0.0003803097934, loss after: 0.000379911391065.\n",
      "Epoch:4, weight train batch: 92, step:10, loss before: 0.000337926787324, loss after: 0.000337584177032.\n",
      "Epoch:4, weight train batch: 92, step:11, loss before: 0.000333768286509, loss after: 0.000333455507644.\n",
      "Epoch:4, weight train batch: 92, step:12, loss before: 0.000334641576046, loss after: 0.000334317621309.\n",
      "Epoch:4, weight train batch: 92, step:13, loss before: 0.000367902073776, loss after: 0.000367496220861.\n",
      "Epoch:4, weight train batch: 92, step:14, loss before: 0.000321507774061, loss after: 0.000321232248098.\n",
      "Epoch:4, weight train batch: 92, step:15, loss before: 0.000321074854583, loss after: 0.000320780673064.\n",
      "Epoch:4, weight train batch: 92, step:16, loss before: 0.000308720977046, loss after: 0.000308400776703.\n",
      "Epoch:4, weight train batch: 92, step:17, loss before: 0.000310646020807, loss after: 0.00031036301516.\n",
      "Epoch:4, weight train batch: 92, step:18, loss before: 0.000318617268931, loss after: 0.000318334263284.\n",
      "Epoch:4, weight train batch: 92, step:19, loss before: 0.000320392340655, loss after: 0.000320101884427.\n",
      "Epoch:4, weight train batch: 92, step:20, loss before: 0.000407010287745, loss after: 0.000406671635574.\n",
      "Epoch:4, weight train batch: 92, step:21, loss before: 0.000324073131196, loss after: 0.000323737971485.\n",
      "Epoch:4, weight train batch: 92, step:22, loss before: 0.00031418146682, loss after: 0.000313924567308.\n",
      "Epoch:4, weight train batch: 92, step:23, loss before: 0.000361902348232, loss after: 0.000361556012649.\n",
      "Epoch:4, weight train batch: 92, step:24, loss before: 0.000359295867383, loss after: 0.000358968158253.\n",
      "Epoch:4, weight train batch: 92, step:25, loss before: 0.000330327718984, loss after: 0.000330029812176.\n",
      "Epoch:4, weight train batch: 92, step:26, loss before: 0.00032254261896, loss after: 0.000322244712152.\n",
      "Epoch:4, weight train batch: 92, step:27, loss before: 0.00028550325078, loss after: 0.000285220216028.\n",
      "Epoch:4, weight train batch: 92, step:28, loss before: 0.000973660266027, loss after: 0.000972802750766.\n",
      "Epoch:4, weight train batch: 92, step:29, loss before: 0.000366694381228, loss after: 0.000366385327652.\n",
      "Epoch:4, weight train batch: 92, step:30, loss before: 0.000364091654774, loss after: 0.000363763945643.\n",
      "Epoch:4, weight train batch: 92, step:31, loss before: 0.000322661595419, loss after: 0.000322374893585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 88, loss before: 0.000313229160383, loss after: 0.00276876566932.\n",
      "Epoch:4, weight train batch: 93, step:0, loss before: 0.000305200082948, loss after: 0.000304939399939.\n",
      "Epoch:4, weight train batch: 93, step:1, loss before: 0.000298789876979, loss after: 0.000298514321912.\n",
      "Epoch:4, weight train batch: 93, step:2, loss before: 0.001071797451, loss after: 0.00107047823258.\n",
      "Epoch:4, weight train batch: 93, step:3, loss before: 0.000293850520393, loss after: 0.000293601042358.\n",
      "Epoch:4, weight train batch: 93, step:4, loss before: 0.000316274701618, loss after: 0.000315999117447.\n",
      "Epoch:4, weight train batch: 93, step:5, loss before: 0.00024541647872, loss after: 0.000245137140155.\n",
      "Epoch:4, weight train batch: 93, step:6, loss before: 0.000278609979432, loss after: 0.000278323248494.\n",
      "Epoch:4, weight train batch: 93, step:7, loss before: 0.000337873963872, loss after: 0.000337605830282.\n",
      "Epoch:4, weight train batch: 93, step:8, loss before: 0.000317514466587, loss after: 0.000317227793857.\n",
      "Epoch:4, weight train batch: 93, step:9, loss before: 0.000350615009665, loss after: 0.000350291025825.\n",
      "Epoch:4, weight train batch: 93, step:10, loss before: 0.000312087358907, loss after: 0.000311837880872.\n",
      "Epoch:4, weight train batch: 93, step:11, loss before: 0.000252365280176, loss after: 0.000252123223618.\n",
      "Epoch:4, weight train batch: 93, step:12, loss before: 0.000312100368319, loss after: 0.00031179128564.\n",
      "Epoch:4, weight train batch: 93, step:13, loss before: 0.000314083124977, loss after: 0.000313826196361.\n",
      "Epoch:4, weight train batch: 93, step:14, loss before: 0.000291105010547, loss after: 0.000290825701086.\n",
      "Epoch:4, weight train batch: 93, step:15, loss before: 0.000723268836737, loss after: 0.000722558761481.\n",
      "Epoch:4, weight train batch: 93, step:16, loss before: 0.000333475356456, loss after: 0.000333169940859.\n",
      "Epoch:4, weight train batch: 93, step:17, loss before: 0.000270468066446, loss after: 0.000270229735179.\n",
      "Epoch:4, weight train batch: 93, step:18, loss before: 0.000402284989832, loss after: 0.000401949917432.\n",
      "Epoch:4, weight train batch: 93, step:19, loss before: 0.000331211311277, loss after: 0.000330905953888.\n",
      "Epoch:4, weight train batch: 93, step:20, loss before: 0.000317806407111, loss after: 0.000317519705277.\n",
      "Epoch:4, weight train batch: 93, step:21, loss before: 0.000314962526318, loss after: 0.000314668344799.\n",
      "Epoch:4, weight train batch: 93, step:22, loss before: 0.000420955824666, loss after: 0.000420620839577.\n",
      "Epoch:4, weight train batch: 93, step:23, loss before: 0.00030711144791, loss after: 0.000306824716972.\n",
      "Epoch:4, weight train batch: 93, step:24, loss before: 0.000361052691005, loss after: 0.000360721256584.\n",
      "Epoch:4, weight train batch: 93, step:25, loss before: 0.000445212295745, loss after: 0.000444803008577.\n",
      "Epoch:4, weight train batch: 93, step:26, loss before: 0.000319917569868, loss after: 0.000319645740092.\n",
      "Epoch:4, weight train batch: 93, step:27, loss before: 0.000369638815755, loss after: 0.000369266635971.\n",
      "Epoch:4, weight train batch: 93, step:28, loss before: 0.000334590265993, loss after: 0.000334273732733.\n",
      "Epoch:4, weight train batch: 93, step:29, loss before: 0.000357715383871, loss after: 0.000357417477062.\n",
      "Epoch:4, weight train batch: 93, step:30, loss before: 0.000450600520708, loss after: 0.00045010948088.\n",
      "Epoch:4, weight train batch: 93, step:31, loss before: 0.000285580637865, loss after: 0.000285338581307.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 89, loss before: 0.000333083793521, loss after: 0.000318325910484.\n",
      "Epoch:4, weight train batch: 94, step:0, loss before: 0.000317357422318, loss after: 0.0003170632408.\n",
      "Epoch:4, weight train batch: 94, step:1, loss before: 0.000330527720507, loss after: 0.000330166512867.\n",
      "Epoch:4, weight train batch: 94, step:2, loss before: 0.000307796231937, loss after: 0.000307539303321.\n",
      "Epoch:4, weight train batch: 94, step:3, loss before: 0.000301669118926, loss after: 0.000301371212117.\n",
      "Epoch:4, weight train batch: 94, step:4, loss before: 0.000300785759464, loss after: 0.000300521351164.\n",
      "Epoch:4, weight train batch: 94, step:5, loss before: 0.000338982034009, loss after: 0.000338635698427.\n",
      "Epoch:4, weight train batch: 94, step:6, loss before: 0.000288898212602, loss after: 0.000288685958367.\n",
      "Epoch:4, weight train batch: 94, step:7, loss before: 0.000293088145554, loss after: 0.000292801414616.\n",
      "Epoch:4, weight train batch: 94, step:8, loss before: 0.000298697617836, loss after: 0.00029847791302.\n",
      "Epoch:4, weight train batch: 94, step:9, loss before: 0.000302661326714, loss after: 0.000302367145196.\n",
      "Epoch:4, weight train batch: 94, step:10, loss before: 0.000291498959996, loss after: 0.000291249452857.\n",
      "Epoch:4, weight train batch: 94, step:11, loss before: 0.000273534504231, loss after: 0.000273281300906.\n",
      "Epoch:4, weight train batch: 94, step:12, loss before: 0.000398089410737, loss after: 0.000397765659727.\n",
      "Epoch:4, weight train batch: 94, step:13, loss before: 0.000359063094947, loss after: 0.000358724209946.\n",
      "Epoch:4, weight train batch: 94, step:14, loss before: 0.000320752209518, loss after: 0.000320498977089.\n",
      "Epoch:4, weight train batch: 94, step:15, loss before: 0.00029658904532, loss after: 0.000296332058497.\n",
      "Epoch:4, weight train batch: 94, step:16, loss before: 0.000277720595477, loss after: 0.00027749344008.\n",
      "Epoch:4, weight train batch: 94, step:17, loss before: 0.000311100506224, loss after: 0.000310839852318.\n",
      "Epoch:4, weight train batch: 94, step:18, loss before: 0.000298742088489, loss after: 0.000298507482512.\n",
      "Epoch:4, weight train batch: 94, step:19, loss before: 0.000298007682431, loss after: 0.000297724676784.\n",
      "Epoch:4, weight train batch: 94, step:20, loss before: 0.000339771184372, loss after: 0.00033948442433.\n",
      "Epoch:4, weight train batch: 94, step:21, loss before: 0.000294454424875, loss after: 0.000294223544188.\n",
      "Epoch:4, weight train batch: 94, step:22, loss before: 0.000293068063911, loss after: 0.000292785058264.\n",
      "Epoch:4, weight train batch: 94, step:23, loss before: 0.000326479814248, loss after: 0.000326252687955.\n",
      "Epoch:4, weight train batch: 94, step:24, loss before: 0.000359080702765, loss after: 0.00035873815068.\n",
      "Epoch:4, weight train batch: 94, step:25, loss before: 0.000306734611513, loss after: 0.000306470203213.\n",
      "Epoch:4, weight train batch: 94, step:26, loss before: 0.000336993281962, loss after: 0.000336676748702.\n",
      "Epoch:4, weight train batch: 94, step:27, loss before: 0.000292120443191, loss after: 0.000291863514576.\n",
      "Epoch:4, weight train batch: 94, step:28, loss before: 0.000705991056748, loss after: 0.000705399434082.\n",
      "Epoch:4, weight train batch: 94, step:29, loss before: 0.000296355923638, loss after: 0.000296102662105.\n",
      "Epoch:4, weight train batch: 94, step:30, loss before: 0.000318505743053, loss after: 0.000318200385664.\n",
      "Epoch:4, weight train batch: 94, step:31, loss before: 0.000292847340461, loss after: 0.000292590382742.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 90, loss before: 0.00030928128399, loss after: 0.000313144060783.\n",
      "Epoch:4, weight train batch: 95, step:0, loss before: 0.000315411365591, loss after: 0.000315124634653.\n",
      "Epoch:4, weight train batch: 95, step:1, loss before: 0.000311811454594, loss after: 0.000311580544803.\n",
      "Epoch:4, weight train batch: 95, step:2, loss before: 0.000342874467606, loss after: 0.000342543062288.\n",
      "Epoch:4, weight train batch: 95, step:3, loss before: 0.000291804608423, loss after: 0.000291581178317.\n",
      "Epoch:4, weight train batch: 95, step:4, loss before: 0.000342763582012, loss after: 0.000342465704307.\n",
      "Epoch:4, weight train batch: 95, step:5, loss before: 0.000301055784803, loss after: 0.000300754152704.\n",
      "Epoch:4, weight train batch: 95, step:6, loss before: 0.000330666662194, loss after: 0.000330372480676.\n",
      "Epoch:4, weight train batch: 95, step:7, loss before: 0.000295007717796, loss after: 0.000294806668535.\n",
      "Epoch:4, weight train batch: 95, step:8, loss before: 0.000308243237669, loss after: 0.000307934125885.\n",
      "Epoch:4, weight train batch: 95, step:9, loss before: 0.000285047339275, loss after: 0.000284782901872.\n",
      "Epoch:4, weight train batch: 95, step:10, loss before: 0.000303942360915, loss after: 0.000303633278236.\n",
      "Epoch:4, weight train batch: 95, step:11, loss before: 0.000307368114591, loss after: 0.000307159556542.\n",
      "Epoch:4, weight train batch: 95, step:12, loss before: 0.00031064284849, loss after: 0.00031033376581.\n",
      "Epoch:4, weight train batch: 95, step:13, loss before: 0.000294006778859, loss after: 0.000293757300824.\n",
      "Epoch:4, weight train batch: 95, step:14, loss before: 0.000289207382593, loss after: 0.000288998824544.\n",
      "Epoch:4, weight train batch: 95, step:15, loss before: 0.000272250676062, loss after: 0.000272027216852.\n",
      "Epoch:4, weight train batch: 95, step:16, loss before: 0.00101814232767, loss after: 0.00101727992296.\n",
      "Epoch:4, weight train batch: 95, step:17, loss before: 0.000314836506732, loss after: 0.000314553530188.\n",
      "Epoch:4, weight train batch: 95, step:18, loss before: 0.000347509805579, loss after: 0.00034721562406.\n",
      "Epoch:4, weight train batch: 95, step:19, loss before: 0.000384320388548, loss after: 0.00038403365761.\n",
      "Epoch:4, weight train batch: 95, step:20, loss before: 0.000298413448036, loss after: 0.000298052211292.\n",
      "Epoch:4, weight train batch: 95, step:21, loss before: 0.000315712648444, loss after: 0.000315392418997.\n",
      "Epoch:4, weight train batch: 95, step:22, loss before: 0.000297815917293, loss after: 0.000297611084534.\n",
      "Epoch:4, weight train batch: 95, step:23, loss before: 0.000286654394586, loss after: 0.000286378810415.\n",
      "Epoch:4, weight train batch: 95, step:24, loss before: 0.000421763310442, loss after: 0.000421365053626.\n",
      "Epoch:4, weight train batch: 95, step:25, loss before: 0.000339297344908, loss after: 0.000338962185197.\n",
      "Epoch:4, weight train batch: 95, step:26, loss before: 0.000268405914539, loss after: 0.000268171279458.\n",
      "Epoch:4, weight train batch: 95, step:27, loss before: 0.000253907986917, loss after: 0.000253651058301.\n",
      "Epoch:4, weight train batch: 95, step:28, loss before: 0.000282947497908, loss after: 0.000282709137537.\n",
      "Epoch:4, weight train batch: 95, step:29, loss before: 0.00028879911406, loss after: 0.00028853843105.\n",
      "Epoch:4, weight train batch: 95, step:30, loss before: 0.000301848485833, loss after: 0.000301576626953.\n",
      "Epoch:4, weight train batch: 95, step:31, loss before: 0.000298686296446, loss after: 0.000298459111946.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 91, loss before: 0.000295931298751, loss after: 0.000286740105366.\n",
      "Epoch:4, weight train batch: 96, step:0, loss before: 0.000316947465762, loss after: 0.000316642108373.\n",
      "Epoch:4, weight train batch: 96, step:1, loss before: 0.000328731548507, loss after: 0.000328437366989.\n",
      "Epoch:4, weight train batch: 96, step:2, loss before: 0.00030740123475, loss after: 0.000307129404973.\n",
      "Epoch:4, weight train batch: 96, step:3, loss before: 0.00029761751648, loss after: 0.000297360558761.\n",
      "Epoch:4, weight train batch: 96, step:4, loss before: 0.000271669181529, loss after: 0.000271430850262.\n",
      "Epoch:4, weight train batch: 96, step:5, loss before: 0.000286706257612, loss after: 0.000286412076093.\n",
      "Epoch:4, weight train batch: 96, step:6, loss before: 0.000276688748272, loss after: 0.000276495120488.\n",
      "Epoch:4, weight train batch: 96, step:7, loss before: 0.000309480587021, loss after: 0.00030920127756.\n",
      "Epoch:4, weight train batch: 96, step:8, loss before: 0.000312630785629, loss after: 0.000312340329401.\n",
      "Epoch:4, weight train batch: 96, step:9, loss before: 0.000256182072917, loss after: 0.000255928840488.\n",
      "Epoch:4, weight train batch: 96, step:10, loss before: 0.000312598014716, loss after: 0.00031233736081.\n",
      "Epoch:4, weight train batch: 96, step:11, loss before: 0.000318097183481, loss after: 0.000317829078995.\n",
      "Epoch:4, weight train batch: 96, step:12, loss before: 0.00033979237196, loss after: 0.000339490768965.\n",
      "Epoch:4, weight train batch: 96, step:13, loss before: 0.000304088549456, loss after: 0.000303839042317.\n",
      "Epoch:4, weight train batch: 96, step:14, loss before: 0.000287865754217, loss after: 0.000287634844426.\n",
      "Epoch:4, weight train batch: 96, step:15, loss before: 0.000349547481164, loss after: 0.000349234702298.\n",
      "Epoch:4, weight train batch: 96, step:16, loss before: 0.000306717440253, loss after: 0.000306471658405.\n",
      "Epoch:4, weight train batch: 96, step:17, loss before: 0.000334627518896, loss after: 0.000334288633894.\n",
      "Epoch:4, weight train batch: 96, step:18, loss before: 0.0453190095723, loss after: 0.0452522784472.\n",
      "Epoch:4, weight train batch: 96, step:19, loss before: 0.000329244416207, loss after: 0.000329709902871.\n",
      "Epoch:4, weight train batch: 96, step:20, loss before: 0.000314992212225, loss after: 0.000315129960654.\n",
      "Epoch:4, weight train batch: 96, step:21, loss before: 0.000344435742591, loss after: 0.000344800646417.\n",
      "Epoch:4, weight train batch: 96, step:22, loss before: 0.000331212038873, loss after: 0.00033164024353.\n",
      "Epoch:4, weight train batch: 96, step:23, loss before: 0.000286636088276, loss after: 0.000286621216219.\n",
      "Epoch:4, weight train batch: 96, step:24, loss before: 0.000281987333437, loss after: 0.000282121385681.\n",
      "Epoch:4, weight train batch: 96, step:25, loss before: 0.000265948561719, loss after: 0.000265948532615.\n",
      "Epoch:4, weight train batch: 96, step:26, loss before: 0.000262694025878, loss after: 0.000262504123384.\n",
      "Epoch:4, weight train batch: 96, step:27, loss before: 0.000271477445494, loss after: 0.000271514669294.\n",
      "Epoch:4, weight train batch: 96, step:28, loss before: 0.000317167548928, loss after: 0.000317134021316.\n",
      "Epoch:4, weight train batch: 96, step:29, loss before: 0.000302336673485, loss after: 0.000302288273815.\n",
      "Epoch:4, weight train batch: 96, step:30, loss before: 0.000273194047622, loss after: 0.000273153069429.\n",
      "Epoch:4, weight train batch: 96, step:31, loss before: 0.000329031288857, loss after: 0.000328912108671.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 92, loss before: 0.000270898803137, loss after: 0.00276557402685.\n",
      "Epoch:4, weight train batch: 97, step:0, loss before: 0.000308567163302, loss after: 0.000308392103761.\n",
      "Epoch:4, weight train batch: 97, step:1, loss before: 0.000307372625684, loss after: 0.000307167822029.\n",
      "Epoch:4, weight train batch: 97, step:2, loss before: 0.000299681618344, loss after: 0.000299480569083.\n",
      "Epoch:4, weight train batch: 97, step:3, loss before: 0.000296374957543, loss after: 0.000296110520139.\n",
      "Epoch:4, weight train batch: 97, step:4, loss before: 0.000289608200546, loss after: 0.000289425719529.\n",
      "Epoch:4, weight train batch: 97, step:5, loss before: 0.00030549877556, loss after: 0.000305212044623.\n",
      "Epoch:4, weight train batch: 97, step:6, loss before: 0.00032323790947, loss after: 0.000322958629113.\n",
      "Epoch:4, weight train batch: 97, step:7, loss before: 0.000333475967636, loss after: 0.000333110976499.\n",
      "Epoch:4, weight train batch: 97, step:8, loss before: 0.000257114937995, loss after: 0.000256887753494.\n",
      "Epoch:4, weight train batch: 97, step:9, loss before: 0.00028271030169, loss after: 0.000282483175397.\n",
      "Epoch:4, weight train batch: 97, step:10, loss before: 0.000313907657983, loss after: 0.000313576223562.\n",
      "Epoch:4, weight train batch: 97, step:11, loss before: 0.000297629740089, loss after: 0.000297350459732.\n",
      "Epoch:4, weight train batch: 97, step:12, loss before: 0.00031144625973, loss after: 0.000311055278871.\n",
      "Epoch:4, weight train batch: 97, step:13, loss before: 0.000264010392129, loss after: 0.000263768364675.\n",
      "Epoch:4, weight train batch: 97, step:14, loss before: 0.000249908654951, loss after: 0.000249670294579.\n",
      "Epoch:4, weight train batch: 97, step:15, loss before: 0.0448386855423, loss after: 0.0447717867792.\n",
      "Epoch:4, weight train batch: 97, step:16, loss before: 0.000282165769022, loss after: 0.000282638648059.\n",
      "Epoch:4, weight train batch: 97, step:17, loss before: 0.000277738959994, loss after: 0.000277805957012.\n",
      "Epoch:4, weight train batch: 97, step:18, loss before: 0.000313246942824, loss after: 0.000313202210236.\n",
      "Epoch:4, weight train batch: 97, step:19, loss before: 0.000278547697235, loss after: 0.000278473191429.\n",
      "Epoch:4, weight train batch: 97, step:20, loss before: 0.000291727483273, loss after: 0.000291548727546.\n",
      "Epoch:4, weight train batch: 97, step:21, loss before: 0.000371920934413, loss after: 0.000372129143216.\n",
      "Epoch:4, weight train batch: 97, step:22, loss before: 0.000284300069325, loss after: 0.00028424046468.\n",
      "Epoch:4, weight train batch: 97, step:23, loss before: 0.00028371240478, loss after: 0.000283563393168.\n",
      "Epoch:4, weight train batch: 97, step:24, loss before: 0.000285872083623, loss after: 0.000285760383122.\n",
      "Epoch:4, weight train batch: 97, step:25, loss before: 0.000279897038126, loss after: 0.000279759202385.\n",
      "Epoch:4, weight train batch: 97, step:26, loss before: 0.000279966217931, loss after: 0.000279832107481.\n",
      "Epoch:4, weight train batch: 97, step:27, loss before: 0.000294509576634, loss after: 0.000294274970656.\n",
      "Epoch:4, weight train batch: 97, step:28, loss before: 0.000291555945296, loss after: 0.000291287782602.\n",
      "Epoch:4, weight train batch: 97, step:29, loss before: 0.000378388154786, loss after: 0.000378094235202.\n",
      "Epoch:4, weight train batch: 97, step:30, loss before: 0.000270217307843, loss after: 0.000270019925665.\n",
      "Epoch:4, weight train batch: 97, step:31, loss before: 0.000255304476013, loss after: 0.000255047518294.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 93, loss before: 0.0002817279601, loss after: 0.0002817279601.\n",
      "Epoch:4, weight train batch: 98, step:0, loss before: 0.000298405211652, loss after: 0.000298122176901.\n",
      "Epoch:4, weight train batch: 98, step:1, loss before: 0.000930166861508, loss after: 0.000929097528569.\n",
      "Epoch:4, weight train batch: 98, step:2, loss before: 0.000301489868434, loss after: 0.000300998537568.\n",
      "Epoch:4, weight train batch: 98, step:3, loss before: 0.000306122179609, loss after: 0.00030582054751.\n",
      "Epoch:4, weight train batch: 98, step:4, loss before: 0.00027449359186, loss after: 0.000274162186543.\n",
      "Epoch:4, weight train batch: 98, step:5, loss before: 0.000260444561718, loss after: 0.000260176428128.\n",
      "Epoch:4, weight train batch: 98, step:6, loss before: 0.000274488294963, loss after: 0.000274201564025.\n",
      "Epoch:4, weight train batch: 98, step:7, loss before: 0.00987352989614, loss after: 0.00986361596733.\n",
      "Epoch:4, weight train batch: 98, step:8, loss before: 0.000297643244267, loss after: 0.000297047488857.\n",
      "Epoch:4, weight train batch: 98, step:9, loss before: 0.000307124370011, loss after: 0.000306621659547.\n",
      "Epoch:4, weight train batch: 98, step:10, loss before: 0.000272160832537, loss after: 0.00027178102755.\n",
      "Epoch:4, weight train batch: 98, step:11, loss before: 0.000258328742348, loss after: 0.000257956329733.\n",
      "Epoch:4, weight train batch: 98, step:12, loss before: 0.000254718353972, loss after: 0.00025438319426.\n",
      "Epoch:4, weight train batch: 98, step:13, loss before: 0.000296606915072, loss after: 0.000296234560665.\n",
      "Epoch:4, weight train batch: 98, step:14, loss before: 0.000275343772955, loss after: 0.000275094236713.\n",
      "Epoch:4, weight train batch: 98, step:15, loss before: 0.000281661108602, loss after: 0.000281366927084.\n",
      "Epoch:4, weight train batch: 98, step:16, loss before: 0.000279375090031, loss after: 0.000278984080069.\n",
      "Epoch:4, weight train batch: 98, step:17, loss before: 0.000321805826388, loss after: 0.000321429775795.\n",
      "Epoch:4, weight train batch: 98, step:18, loss before: 0.000296531390632, loss after: 0.000296121812426.\n",
      "Epoch:4, weight train batch: 98, step:19, loss before: 0.000247208110522, loss after: 0.000246910203714.\n",
      "Epoch:4, weight train batch: 98, step:20, loss before: 0.000277420826023, loss after: 0.000277067068964.\n",
      "Epoch:4, weight train batch: 98, step:21, loss before: 0.00029039895162, loss after: 0.000290037714876.\n",
      "Epoch:4, weight train batch: 98, step:22, loss before: 0.000283116882201, loss after: 0.000282729597529.\n",
      "Epoch:4, weight train batch: 98, step:23, loss before: 0.000330781418597, loss after: 0.000330394163029.\n",
      "Epoch:4, weight train batch: 98, step:24, loss before: 0.000273562298389, loss after: 0.000273212237516.\n",
      "Epoch:4, weight train batch: 98, step:25, loss before: 0.000243942893576, loss after: 0.000243633796345.\n",
      "Epoch:4, weight train batch: 98, step:26, loss before: 0.000279538304312, loss after: 0.000279225496342.\n",
      "Epoch:4, weight train batch: 98, step:27, loss before: 0.00040360231651, loss after: 0.000403070065659.\n",
      "Epoch:4, weight train batch: 98, step:28, loss before: 0.000308702728944, loss after: 0.000308285700157.\n",
      "Epoch:4, weight train batch: 98, step:29, loss before: 0.000566400703974, loss after: 0.00056598498486.\n",
      "Epoch:4, weight train batch: 98, step:30, loss before: 0.000276931008557, loss after: 0.000276607024716.\n",
      "Epoch:4, weight train batch: 98, step:31, loss before: 0.000281687593088, loss after: 0.000281356158666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 94, loss before: 0.000296943006106, loss after: 0.000269814801868.\n",
      "Epoch:4, weight train batch: 99, step:0, loss before: 0.000234209815972, loss after: 0.000233997503528.\n",
      "Epoch:4, weight train batch: 99, step:1, loss before: 0.00025476430892, loss after: 0.000254466373008.\n",
      "Epoch:4, weight train batch: 99, step:2, loss before: 0.000241434623604, loss after: 0.000241136673139.\n",
      "Epoch:4, weight train batch: 99, step:3, loss before: 0.000318948819768, loss after: 0.00031866208883.\n",
      "Epoch:4, weight train batch: 99, step:4, loss before: 0.000318979786243, loss after: 0.000318599923048.\n",
      "Epoch:4, weight train batch: 99, step:5, loss before: 0.000274105113931, loss after: 0.000273807207122.\n",
      "Epoch:4, weight train batch: 99, step:6, loss before: 0.000324940483551, loss after: 0.000324620166793.\n",
      "Epoch:4, weight train batch: 99, step:7, loss before: 0.000281210785033, loss after: 0.000280927750282.\n",
      "Epoch:4, weight train batch: 99, step:8, loss before: 0.000305645982735, loss after: 0.00030527357012.\n",
      "Epoch:4, weight train batch: 99, step:9, loss before: 0.00508408481255, loss after: 0.00508235674351.\n",
      "Epoch:4, weight train batch: 99, step:10, loss before: 0.000617143232375, loss after: 0.000616797595285.\n",
      "Epoch:4, weight train batch: 99, step:11, loss before: 0.000303406559397, loss after: 0.000303019274725.\n",
      "Epoch:4, weight train batch: 99, step:12, loss before: 0.000293882389087, loss after: 0.000293577031698.\n",
      "Epoch:4, weight train batch: 99, step:13, loss before: 0.000291284930427, loss after: 0.000291001924779.\n",
      "Epoch:4, weight train batch: 99, step:14, loss before: 0.000422485405579, loss after: 0.00042194998241.\n",
      "Epoch:4, weight train batch: 99, step:15, loss before: 0.000261411623796, loss after: 0.000261121138465.\n",
      "Epoch:4, weight train batch: 99, step:16, loss before: 0.000275288533885, loss after: 0.000274994352367.\n",
      "Epoch:4, weight train batch: 99, step:17, loss before: 0.0002891815966, loss after: 0.000288928364171.\n",
      "Epoch:4, weight train batch: 99, step:18, loss before: 0.000265680253506, loss after: 0.000265337672317.\n",
      "Epoch:4, weight train batch: 99, step:19, loss before: 0.000248553173151, loss after: 0.00024832598865.\n",
      "Epoch:4, weight train batch: 99, step:20, loss before: 0.000263297086349, loss after: 0.000263051304501.\n",
      "Epoch:4, weight train batch: 99, step:21, loss before: 0.000263908412308, loss after: 0.000263684982201.\n",
      "Epoch:4, weight train batch: 99, step:22, loss before: 0.000288570183329, loss after: 0.000288302078843.\n",
      "Epoch:4, weight train batch: 99, step:23, loss before: 0.000605257344432, loss after: 0.000604481319897.\n",
      "Epoch:4, weight train batch: 99, step:24, loss before: 0.000263998284936, loss after: 0.000263737572823.\n",
      "Epoch:4, weight train batch: 99, step:25, loss before: 0.00037213176256, loss after: 0.000371819187421.\n",
      "Epoch:4, weight train batch: 99, step:26, loss before: 0.00512266997248, loss after: 0.00512019777671.\n",
      "Epoch:4, weight train batch: 99, step:27, loss before: 0.00026654911926, loss after: 0.000266269809799.\n",
      "Epoch:4, weight train batch: 99, step:28, loss before: 0.000281982676825, loss after: 0.000281688466202.\n",
      "Epoch:4, weight train batch: 99, step:29, loss before: 0.000661461264826, loss after: 0.000660266377963.\n",
      "Epoch:4, weight train batch: 99, step:30, loss before: 0.000258770596702, loss after: 0.000258539686911.\n",
      "Epoch:4, weight train batch: 99, step:31, loss before: 0.000286485301331, loss after: 0.000286094262265.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:4, struct parameters train batch: 95, loss before: 0.000263586931396, loss after: 0.000260241184151.\n",
      "Epoch:5, weight train batch: 100, step:0, loss before: 0.000276224425761, loss after: 0.00027594884159.\n",
      "Epoch:5, weight train batch: 100, step:1, loss before: 0.000290098047117, loss after: 0.000289811287075.\n",
      "Epoch:5, weight train batch: 100, step:2, loss before: 0.000291870674118, loss after: 0.000291591393761.\n",
      "Epoch:5, weight train batch: 100, step:3, loss before: 0.000270910823019, loss after: 0.000270575692412.\n",
      "Epoch:5, weight train batch: 100, step:4, loss before: 0.000283813424176, loss after: 0.000283534114715.\n",
      "Epoch:5, weight train batch: 100, step:5, loss before: 0.000271091528703, loss after: 0.000270804739557.\n",
      "Epoch:5, weight train batch: 100, step:6, loss before: 0.000332782656187, loss after: 0.000332436378812.\n",
      "Epoch:5, weight train batch: 100, step:7, loss before: 0.000247748976108, loss after: 0.000247532996582.\n",
      "Epoch:5, weight train batch: 100, step:8, loss before: 0.000255498365732, loss after: 0.000255233957432.\n",
      "Epoch:5, weight train batch: 100, step:9, loss before: 0.000299665902276, loss after: 0.000299397768686.\n",
      "Epoch:5, weight train batch: 100, step:10, loss before: 0.000288202572847, loss after: 0.000287982868031.\n",
      "Epoch:5, weight train batch: 100, step:11, loss before: 0.000900610932149, loss after: 0.000899633741938.\n",
      "Epoch:5, weight train batch: 100, step:12, loss before: 0.000279021944152, loss after: 0.000278776162304.\n",
      "Epoch:5, weight train batch: 100, step:13, loss before: 0.000251037068665, loss after: 0.000250813609455.\n",
      "Epoch:5, weight train batch: 100, step:14, loss before: 0.000283975939965, loss after: 0.000283756176941.\n",
      "Epoch:5, weight train batch: 100, step:15, loss before: 0.000273644633126, loss after: 0.000273369019851.\n",
      "Epoch:5, weight train batch: 100, step:16, loss before: 0.000280179432593, loss after: 0.000279952248093.\n",
      "Epoch:5, weight train batch: 100, step:17, loss before: 0.000291416770779, loss after: 0.000291156087769.\n",
      "Epoch:5, weight train batch: 100, step:18, loss before: 0.000257327774307, loss after: 0.000257074512774.\n",
      "Epoch:5, weight train batch: 100, step:19, loss before: 0.000277312588878, loss after: 0.000277092854958.\n",
      "Epoch:5, weight train batch: 100, step:20, loss before: 0.000277733954135, loss after: 0.000277476996416.\n",
      "Epoch:5, weight train batch: 100, step:21, loss before: 0.000274336605798, loss after: 0.000274083344266.\n",
      "Epoch:5, weight train batch: 100, step:22, loss before: 0.000281215208815, loss after: 0.000280961976387.\n",
      "Epoch:5, weight train batch: 100, step:23, loss before: 0.00023384684755, loss after: 0.000233638289501.\n",
      "Epoch:5, weight train batch: 100, step:24, loss before: 0.000262963818386, loss after: 0.000262703106273.\n",
      "Epoch:5, weight train batch: 100, step:25, loss before: 0.00026081505348, loss after: 0.000260602799244.\n",
      "Epoch:5, weight train batch: 100, step:26, loss before: 0.000282928143861, loss after: 0.000282667460851.\n",
      "Epoch:5, weight train batch: 100, step:27, loss before: 0.000269837444648, loss after: 0.00026958793751.\n",
      "Epoch:5, weight train batch: 100, step:28, loss before: 0.000365260988474, loss after: 0.000364948355127.\n",
      "Epoch:5, weight train batch: 100, step:29, loss before: 0.000268341595074, loss after: 0.000268062314717.\n",
      "Epoch:5, weight train batch: 100, step:30, loss before: 0.000225145340664, loss after: 0.000225000083447.\n",
      "Epoch:5, weight train batch: 100, step:31, loss before: 0.000240251247305, loss after: 0.000239997985773.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 96, loss before: 0.000267824507318, loss after: 0.000274677295238.\n",
      "Epoch:5, weight train batch: 101, step:0, loss before: 0.000238219246967, loss after: 0.000237995787757.\n",
      "Epoch:5, weight train batch: 101, step:1, loss before: 0.000253999081906, loss after: 0.000253794249147.\n",
      "Epoch:5, weight train batch: 101, step:2, loss before: 0.000302053347696, loss after: 0.000301755440887.\n",
      "Epoch:5, weight train batch: 101, step:3, loss before: 0.000241903195274, loss after: 0.000241709538386.\n",
      "Epoch:5, weight train batch: 101, step:4, loss before: 0.000284164998448, loss after: 0.000283904315438.\n",
      "Epoch:5, weight train batch: 101, step:5, loss before: 0.000238418972003, loss after: 0.000238169450313.\n",
      "Epoch:5, weight train batch: 101, step:6, loss before: 0.000297760154353, loss after: 0.000297533028061.\n",
      "Epoch:5, weight train batch: 101, step:7, loss before: 0.000247745396337, loss after: 0.000247514486546.\n",
      "Epoch:5, weight train batch: 101, step:8, loss before: 0.000284251203993, loss after: 0.000284012872726.\n",
      "Epoch:5, weight train batch: 101, step:9, loss before: 0.000234413208091, loss after: 0.000234189734329.\n",
      "Epoch:5, weight train batch: 101, step:10, loss before: 0.000236111824051, loss after: 0.000235903251451.\n",
      "Epoch:5, weight train batch: 101, step:11, loss before: 0.000270836462732, loss after: 0.000270613032626.\n",
      "Epoch:5, weight train batch: 101, step:12, loss before: 0.000231895246543, loss after: 0.000231716490816.\n",
      "Epoch:5, weight train batch: 101, step:13, loss before: 0.000283759087324, loss after: 0.000283520726953.\n",
      "Epoch:5, weight train batch: 101, step:14, loss before: 0.000238196036662, loss after: 0.000237998669036.\n",
      "Epoch:5, weight train batch: 101, step:15, loss before: 0.000270029559033, loss after: 0.000269861979177.\n",
      "Epoch:5, weight train batch: 101, step:16, loss before: 0.000281256536255, loss after: 0.000280973530607.\n",
      "Epoch:5, weight train batch: 101, step:17, loss before: 0.000248620985076, loss after: 0.000248423602898.\n",
      "Epoch:5, weight train batch: 101, step:18, loss before: 0.000308929884341, loss after: 0.00030869897455.\n",
      "Epoch:5, weight train batch: 101, step:19, loss before: 0.000241000656388, loss after: 0.000240777197178.\n",
      "Epoch:5, weight train batch: 101, step:20, loss before: 0.000217223714571, loss after: 0.000217011431232.\n",
      "Epoch:5, weight train batch: 101, step:21, loss before: 0.00023471415625, loss after: 0.000234524224652.\n",
      "Epoch:5, weight train batch: 101, step:22, loss before: 0.000267358875135, loss after: 0.000267150317086.\n",
      "Epoch:5, weight train batch: 101, step:23, loss before: 0.000261564331595, loss after: 0.000261314795353.\n",
      "Epoch:5, weight train batch: 101, step:24, loss before: 0.000241465488216, loss after: 0.00024129045778.\n",
      "Epoch:5, weight train batch: 101, step:25, loss before: 0.000261226407019, loss after: 0.000260999251623.\n",
      "Epoch:5, weight train batch: 101, step:26, loss before: 0.000252919446211, loss after: 0.00025268108584.\n",
      "Epoch:5, weight train batch: 101, step:27, loss before: 0.000264803005848, loss after: 0.00026460562367.\n",
      "Epoch:5, weight train batch: 101, step:28, loss before: 0.000239153465373, loss after: 0.000238930020714.\n",
      "Epoch:5, weight train batch: 101, step:29, loss before: 0.000230981531786, loss after: 0.000230806472246.\n",
      "Epoch:5, weight train batch: 101, step:30, loss before: 0.00024542567553, loss after: 0.000245254370384.\n",
      "Epoch:5, weight train batch: 101, step:31, loss before: 0.000259314459981, loss after: 0.000259105872829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 97, loss before: 0.0110475365072, loss after: 0.0002405213163.\n",
      "Epoch:5, weight train batch: 102, step:0, loss before: 0.000253398611676, loss after: 0.000253160251305.\n",
      "Epoch:5, weight train batch: 102, step:1, loss before: 0.000247783493251, loss after: 0.000247586111072.\n",
      "Epoch:5, weight train batch: 102, step:2, loss before: 0.000259406981058, loss after: 0.00025916119921.\n",
      "Epoch:5, weight train batch: 102, step:3, loss before: 0.000258062063949, loss after: 0.000257846084423.\n",
      "Epoch:5, weight train batch: 102, step:4, loss before: 0.000279827625491, loss after: 0.00027960416628.\n",
      "Epoch:5, weight train batch: 102, step:5, loss before: 0.000245865056058, loss after: 0.000245663977694.\n",
      "Epoch:5, weight train batch: 102, step:6, loss before: 0.000274572521448, loss after: 0.000274311809335.\n",
      "Epoch:5, weight train batch: 102, step:7, loss before: 0.000278487656033, loss after: 0.000278279097984.\n",
      "Epoch:5, weight train batch: 102, step:8, loss before: 0.000264733302174, loss after: 0.000264480069745.\n",
      "Epoch:5, weight train batch: 102, step:9, loss before: 0.000220402158448, loss after: 0.000220242029172.\n",
      "Epoch:5, weight train batch: 102, step:10, loss before: 0.000234221719438, loss after: 0.000234013161389.\n",
      "Epoch:5, weight train batch: 102, step:11, loss before: 0.000278374674963, loss after: 0.000278143765172.\n",
      "Epoch:5, weight train batch: 102, step:12, loss before: 0.000254240207141, loss after: 0.000254068901995.\n",
      "Epoch:5, weight train batch: 102, step:13, loss before: 0.000547991076019, loss after: 0.000547646195628.\n",
      "Epoch:5, weight train batch: 102, step:14, loss before: 0.000281679385807, loss after: 0.000281452201307.\n",
      "Epoch:5, weight train batch: 102, step:15, loss before: 0.000249839475146, loss after: 0.000249593664194.\n",
      "Epoch:5, weight train batch: 102, step:16, loss before: 0.000234103004914, loss after: 0.000233916798607.\n",
      "Epoch:5, weight train batch: 102, step:17, loss before: 0.000265722192125, loss after: 0.0002655062126.\n",
      "Epoch:5, weight train batch: 102, step:18, loss before: 0.000244468916208, loss after: 0.000244260358158.\n",
      "Epoch:5, weight train batch: 102, step:19, loss before: 0.000276297680102, loss after: 0.000276074220892.\n",
      "Epoch:5, weight train batch: 102, step:20, loss before: 0.000235119645367, loss after: 0.000234955790802.\n",
      "Epoch:5, weight train batch: 102, step:21, loss before: 0.000242610636633, loss after: 0.000242387177423.\n",
      "Epoch:5, weight train batch: 102, step:22, loss before: 0.000246361742029, loss after: 0.000246164388955.\n",
      "Epoch:5, weight train batch: 102, step:23, loss before: 0.000315984565532, loss after: 0.000315750046866.\n",
      "Epoch:5, weight train batch: 102, step:24, loss before: 0.000243432557909, loss after: 0.000243194212089.\n",
      "Epoch:5, weight train batch: 102, step:25, loss before: 0.000244278431637, loss after: 0.000244069844484.\n",
      "Epoch:5, weight train batch: 102, step:26, loss before: 0.000270868069492, loss after: 0.000270633492619.\n",
      "Epoch:5, weight train batch: 102, step:27, loss before: 0.000334044103511, loss after: 0.000333798525389.\n",
      "Epoch:5, weight train batch: 102, step:28, loss before: 0.000264261703705, loss after: 0.000264060625341.\n",
      "Epoch:5, weight train batch: 102, step:29, loss before: 0.000290559808491, loss after: 0.000290258176392.\n",
      "Epoch:5, weight train batch: 102, step:30, loss before: 0.000245753035415, loss after: 0.000245570554398.\n",
      "Epoch:5, weight train batch: 102, step:31, loss before: 0.000248986500083, loss after: 0.000248774245847.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 98, loss before: 0.00252760807052, loss after: 0.000261649256572.\n",
      "Epoch:5, weight train batch: 103, step:0, loss before: 0.000281005748548, loss after: 0.000280748790829.\n",
      "Epoch:5, weight train batch: 103, step:1, loss before: 0.000243347312789, loss after: 0.000243097776547.\n",
      "Epoch:5, weight train batch: 103, step:2, loss before: 0.00024130816746, loss after: 0.000241118250415.\n",
      "Epoch:5, weight train batch: 103, step:3, loss before: 0.000259970052866, loss after: 0.000259776425082.\n",
      "Epoch:5, weight train batch: 103, step:4, loss before: 0.000250065379078, loss after: 0.000249819568126.\n",
      "Epoch:5, weight train batch: 103, step:5, loss before: 0.000257549982052, loss after: 0.000257315346971.\n",
      "Epoch:5, weight train batch: 103, step:6, loss before: 0.000223109076614, loss after: 0.000222911694436.\n",
      "Epoch:5, weight train batch: 103, step:7, loss before: 0.000239045592025, loss after: 0.000238874272327.\n",
      "Epoch:5, weight train batch: 103, step:8, loss before: 0.000283511384623, loss after: 0.000283314031549.\n",
      "Epoch:5, weight train batch: 103, step:9, loss before: 0.000265737005975, loss after: 0.000265457696514.\n",
      "Epoch:5, weight train batch: 103, step:10, loss before: 0.000255845952779, loss after: 0.00025564112002.\n",
      "Epoch:5, weight train batch: 103, step:11, loss before: 0.000217555556446, loss after: 0.000217328371946.\n",
      "Epoch:5, weight train batch: 103, step:12, loss before: 0.000290172960376, loss after: 0.000289930932922.\n",
      "Epoch:5, weight train batch: 103, step:13, loss before: 0.00027845101431, loss after: 0.000278238760075.\n",
      "Epoch:5, weight train batch: 103, step:14, loss before: 0.000265488924924, loss after: 0.000265254318947.\n",
      "Epoch:5, weight train batch: 103, step:15, loss before: 0.000235485873418, loss after: 0.000235284765949.\n",
      "Epoch:5, weight train batch: 103, step:16, loss before: 0.000192307968973, loss after: 0.000192185078049.\n",
      "Epoch:5, weight train batch: 103, step:17, loss before: 0.000329449365381, loss after: 0.000329174043145.\n",
      "Epoch:5, weight train batch: 103, step:18, loss before: 0.000266874732915, loss after: 0.000266640097834.\n",
      "Epoch:5, weight train batch: 103, step:19, loss before: 0.000273987418041, loss after: 0.000273756566457.\n",
      "Epoch:5, weight train batch: 103, step:20, loss before: 0.000356726261089, loss after: 0.000356421049219.\n",
      "Epoch:5, weight train batch: 103, step:21, loss before: 0.000256774248555, loss after: 0.000256524741417.\n",
      "Epoch:5, weight train batch: 103, step:22, loss before: 0.000257515755948, loss after: 0.000257307197899.\n",
      "Epoch:5, weight train batch: 103, step:23, loss before: 0.000338508747518, loss after: 0.000338222307619.\n",
      "Epoch:5, weight train batch: 103, step:24, loss before: 0.000278931343928, loss after: 0.000278700492345.\n",
      "Epoch:5, weight train batch: 103, step:25, loss before: 0.000191488608834, loss after: 0.000191343366168.\n",
      "Epoch:5, weight train batch: 103, step:26, loss before: 0.000229147000937, loss after: 0.000228945893468.\n",
      "Epoch:5, weight train batch: 103, step:27, loss before: 0.00025421261671, loss after: 0.000254004058661.\n",
      "Epoch:5, weight train batch: 103, step:28, loss before: 0.000237548811128, loss after: 0.000237362604821.\n",
      "Epoch:5, weight train batch: 103, step:29, loss before: 0.000257758278167, loss after: 0.000257505045738.\n",
      "Epoch:5, weight train batch: 103, step:30, loss before: 0.000221452180995, loss after: 0.000221258509555.\n",
      "Epoch:5, weight train batch: 103, step:31, loss before: 0.000234591949265, loss after: 0.000234413164435.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 99, loss before: 0.00371235469356, loss after: 0.000244502676651.\n",
      "Epoch:5, weight train batch: 104, step:0, loss before: 0.000295286532491, loss after: 0.000295033300063.\n",
      "Epoch:5, weight train batch: 104, step:1, loss before: 0.000224375457037, loss after: 0.00022420786263.\n",
      "Epoch:5, weight train batch: 104, step:2, loss before: 0.00027248452534, loss after: 0.000272253644653.\n",
      "Epoch:5, weight train batch: 104, step:3, loss before: 0.000222793780267, loss after: 0.000222570306505.\n",
      "Epoch:5, weight train batch: 104, step:4, loss before: 0.00025049544638, loss after: 0.000250335288001.\n",
      "Epoch:5, weight train batch: 104, step:5, loss before: 0.000251914723776, loss after: 0.000251668971032.\n",
      "Epoch:5, weight train batch: 104, step:6, loss before: 0.000240664012381, loss after: 0.000240503883106.\n",
      "Epoch:5, weight train batch: 104, step:7, loss before: 0.0434193499386, loss after: 0.0433499105275.\n",
      "Epoch:5, weight train batch: 104, step:8, loss before: 0.000252038182225, loss after: 0.000252190890023.\n",
      "Epoch:5, weight train batch: 104, step:9, loss before: 0.000290812226012, loss after: 0.000291277188808.\n",
      "Epoch:5, weight train batch: 104, step:10, loss before: 0.000237482294324, loss after: 0.000237955289776.\n",
      "Epoch:5, weight train batch: 104, step:11, loss before: 0.00022011580586, loss after: 0.000220413756324.\n",
      "Epoch:5, weight train batch: 104, step:12, loss before: 0.000242018708377, loss after: 0.000242417198024.\n",
      "Epoch:5, weight train batch: 104, step:13, loss before: 0.000225076248171, loss after: 0.000225474737817.\n",
      "Epoch:5, weight train batch: 104, step:14, loss before: 0.000222640228458, loss after: 0.000222807822865.\n",
      "Epoch:5, weight train batch: 104, step:15, loss before: 0.000263438560069, loss after: 0.000263598689344.\n",
      "Epoch:5, weight train batch: 104, step:16, loss before: 0.000390405941289, loss after: 0.000390669913031.\n",
      "Epoch:5, weight train batch: 104, step:17, loss before: 0.000242550231633, loss after: 0.000242594920564.\n",
      "Epoch:5, weight train batch: 104, step:18, loss before: 0.000236084320932, loss after: 0.000236054518609.\n",
      "Epoch:5, weight train batch: 104, step:19, loss before: 0.000231302794418, loss after: 0.000231354933931.\n",
      "Epoch:5, weight train batch: 104, step:20, loss before: 0.000245977949817, loss after: 0.000245922099566.\n",
      "Epoch:5, weight train batch: 104, step:21, loss before: 0.000261831912212, loss after: 0.000261749955826.\n",
      "Epoch:5, weight train batch: 104, step:22, loss before: 0.0002394439216, loss after: 0.000239347107708.\n",
      "Epoch:5, weight train batch: 104, step:23, loss before: 0.000249430566328, loss after: 0.000249307660852.\n",
      "Epoch:5, weight train batch: 104, step:24, loss before: 0.000246834388236, loss after: 0.000246677955147.\n",
      "Epoch:5, weight train batch: 104, step:25, loss before: 0.000240227527684, loss after: 0.000240100926021.\n",
      "Epoch:5, weight train batch: 104, step:26, loss before: 0.000263557187282, loss after: 0.000263404508587.\n",
      "Epoch:5, weight train batch: 104, step:27, loss before: 0.000253567995969, loss after: 0.00025335571263.\n",
      "Epoch:5, weight train batch: 104, step:28, loss before: 0.000215723310248, loss after: 0.000215563180973.\n",
      "Epoch:5, weight train batch: 104, step:29, loss before: 0.000215839783777, loss after: 0.000215657288209.\n",
      "Epoch:5, weight train batch: 104, step:30, loss before: 0.000247471150942, loss after: 0.000247284944635.\n",
      "Epoch:5, weight train batch: 104, step:31, loss before: 0.000226591495448, loss after: 0.000226341973757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 100, loss before: 0.000251386954915, loss after: 0.000251386954915.\n",
      "Epoch:5, weight train batch: 105, step:0, loss before: 0.000214993808186, loss after: 0.00021482250304.\n",
      "Epoch:5, weight train batch: 105, step:1, loss before: 0.000285676447675, loss after: 0.000285404617898.\n",
      "Epoch:5, weight train batch: 105, step:2, loss before: 0.000266767776338, loss after: 0.0002665182692.\n",
      "Epoch:5, weight train batch: 105, step:3, loss before: 0.000221415655687, loss after: 0.000221169844735.\n",
      "Epoch:5, weight train batch: 105, step:4, loss before: 0.000243937131017, loss after: 0.00024372113694.\n",
      "Epoch:5, weight train batch: 105, step:5, loss before: 0.000208963145269, loss after: 0.000208687561098.\n",
      "Epoch:5, weight train batch: 105, step:6, loss before: 0.000207147095352, loss after: 0.000206908734981.\n",
      "Epoch:5, weight train batch: 105, step:7, loss before: 0.000236573643633, loss after: 0.000236346473685.\n",
      "Epoch:5, weight train batch: 105, step:8, loss before: 0.000250041717663, loss after: 0.000249792239629.\n",
      "Epoch:5, weight train batch: 105, step:9, loss before: 0.000239740707912, loss after: 0.000239513552515.\n",
      "Epoch:5, weight train batch: 105, step:10, loss before: 0.000209497724427, loss after: 0.000209237026866.\n",
      "Epoch:5, weight train batch: 105, step:11, loss before: 0.00025084608933, loss after: 0.000250615208643.\n",
      "Epoch:5, weight train batch: 105, step:12, loss before: 0.000257140753092, loss after: 0.00025684281718.\n",
      "Epoch:5, weight train batch: 105, step:13, loss before: 0.00023153834627, loss after: 0.000231259036809.\n",
      "Epoch:5, weight train batch: 105, step:14, loss before: 0.000268924457487, loss after: 0.000268596748356.\n",
      "Epoch:5, weight train batch: 105, step:15, loss before: 0.000235516505199, loss after: 0.000235315383179.\n",
      "Epoch:5, weight train batch: 105, step:16, loss before: 0.00023009016877, loss after: 0.000229851837503.\n",
      "Epoch:5, weight train batch: 105, step:17, loss before: 0.000229851822951, loss after: 0.000229732657317.\n",
      "Epoch:5, weight train batch: 105, step:18, loss before: 0.000213755221921, loss after: 0.000213535473449.\n",
      "Epoch:5, weight train batch: 105, step:19, loss before: 0.000245317991357, loss after: 0.000245116883889.\n",
      "Epoch:5, weight train batch: 105, step:20, loss before: 0.000238757405896, loss after: 0.000238578679273.\n",
      "Epoch:5, weight train batch: 105, step:21, loss before: 0.000192942810827, loss after: 0.000192767736735.\n",
      "Epoch:5, weight train batch: 105, step:22, loss before: 0.000213925814023, loss after: 0.000213724706555.\n",
      "Epoch:5, weight train batch: 105, step:23, loss before: 0.000270455348073, loss after: 0.0002702542115.\n",
      "Epoch:5, weight train batch: 105, step:24, loss before: 0.000213553386857, loss after: 0.000213370920392.\n",
      "Epoch:5, weight train batch: 105, step:25, loss before: 0.000208774552448, loss after: 0.00020861068333.\n",
      "Epoch:5, weight train batch: 105, step:26, loss before: 0.000238202410401, loss after: 0.000238008753513.\n",
      "Epoch:5, weight train batch: 105, step:27, loss before: 0.00021678203484, loss after: 0.000216551154153.\n",
      "Epoch:5, weight train batch: 105, step:28, loss before: 0.000229237237363, loss after: 0.000229088269407.\n",
      "Epoch:5, weight train batch: 105, step:29, loss before: 0.000228808377869, loss after: 0.00022857748263.\n",
      "Epoch:5, weight train batch: 105, step:30, loss before: 0.000221829570364, loss after: 0.00022168434225.\n",
      "Epoch:5, weight train batch: 105, step:31, loss before: 0.00023305513605, loss after: 0.000232850259636.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 101, loss before: 0.000238804786932, loss after: 0.000238804786932.\n",
      "Epoch:5, weight train batch: 106, step:0, loss before: 0.00022130391153, loss after: 0.000221125141252.\n",
      "Epoch:5, weight train batch: 106, step:1, loss before: 0.000260663859081, loss after: 0.000260429223999.\n",
      "Epoch:5, weight train batch: 106, step:2, loss before: 0.000225673182285, loss after: 0.000225494412007.\n",
      "Epoch:5, weight train batch: 106, step:3, loss before: 0.000220078713028, loss after: 0.00021988505614.\n",
      "Epoch:5, weight train batch: 106, step:4, loss before: 0.000297508464428, loss after: 0.000297218153719.\n",
      "Epoch:5, weight train batch: 106, step:5, loss before: 0.000250031822361, loss after: 0.000249778560828.\n",
      "Epoch:5, weight train batch: 106, step:6, loss before: 0.000313232420012, loss after: 0.0003130127443.\n",
      "Epoch:5, weight train batch: 106, step:7, loss before: 0.000604648783337, loss after: 0.000603898311965.\n",
      "Epoch:5, weight train batch: 106, step:8, loss before: 0.000249716395047, loss after: 0.00024949296494.\n",
      "Epoch:5, weight train batch: 106, step:9, loss before: 0.000214621424675, loss after: 0.000214416591916.\n",
      "Epoch:5, weight train batch: 106, step:10, loss before: 0.000223303650273, loss after: 0.000223095077672.\n",
      "Epoch:5, weight train batch: 106, step:11, loss before: 0.00022474952857, loss after: 0.000224540985073.\n",
      "Epoch:5, weight train batch: 106, step:12, loss before: 0.000223017850658, loss after: 0.000222820439376.\n",
      "Epoch:5, weight train batch: 106, step:13, loss before: 0.000204402691452, loss after: 0.000204216470593.\n",
      "Epoch:5, weight train batch: 106, step:14, loss before: 0.000274489226285, loss after: 0.000274232239462.\n",
      "Epoch:5, weight train batch: 106, step:15, loss before: 0.000202447074116, loss after: 0.00020232044335.\n",
      "Epoch:5, weight train batch: 106, step:16, loss before: 0.000218354340177, loss after: 0.000218115979806.\n",
      "Epoch:5, weight train batch: 106, step:17, loss before: 0.000208033030503, loss after: 0.000207831937587.\n",
      "Epoch:5, weight train batch: 106, step:18, loss before: 0.000245267001446, loss after: 0.00024508824572.\n",
      "Epoch:5, weight train batch: 106, step:19, loss before: 0.000326319539454, loss after: 0.000326021778164.\n",
      "Epoch:5, weight train batch: 106, step:20, loss before: 0.000212052225834, loss after: 0.000211851118365.\n",
      "Epoch:5, weight train batch: 106, step:21, loss before: 0.000237885498791, loss after: 0.00023769926338.\n",
      "Epoch:5, weight train batch: 106, step:22, loss before: 0.000232305930695, loss after: 0.000232063830481.\n",
      "Epoch:5, weight train batch: 106, step:23, loss before: 0.000232417456573, loss after: 0.000232186590438.\n",
      "Epoch:5, weight train batch: 106, step:24, loss before: 0.00024690508144, loss after: 0.000246666779276.\n",
      "Epoch:5, weight train batch: 106, step:25, loss before: 0.000231635553064, loss after: 0.000231426965911.\n",
      "Epoch:5, weight train batch: 106, step:26, loss before: 0.000215988882701, loss after: 0.000215843640035.\n",
      "Epoch:5, weight train batch: 106, step:27, loss before: 0.00025712151546, loss after: 0.000256864586845.\n",
      "Epoch:5, weight train batch: 106, step:28, loss before: 0.000288450275548, loss after: 0.000288174691377.\n",
      "Epoch:5, weight train batch: 106, step:29, loss before: 0.000218086410314, loss after: 0.000217896478716.\n",
      "Epoch:5, weight train batch: 106, step:30, loss before: 0.000207281496841, loss after: 0.000207091550692.\n",
      "Epoch:5, weight train batch: 106, step:31, loss before: 0.00916538666934, loss after: 0.009153412655.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 102, loss before: 0.000245350296609, loss after: 0.000245294417255.\n",
      "Epoch:5, weight train batch: 107, step:0, loss before: 0.000589126488194, loss after: 0.000588629802223.\n",
      "Epoch:5, weight train batch: 107, step:1, loss before: 0.000243686998147, loss after: 0.000243463553488.\n",
      "Epoch:5, weight train batch: 107, step:2, loss before: 0.000258798740106, loss after: 0.000258552958257.\n",
      "Epoch:5, weight train batch: 107, step:3, loss before: 0.00020784480148, loss after: 0.000207639939617.\n",
      "Epoch:5, weight train batch: 107, step:4, loss before: 0.00025536416797, loss after: 0.000255051301792.\n",
      "Epoch:5, weight train batch: 107, step:5, loss before: 0.000228738106671, loss after: 0.000228518387303.\n",
      "Epoch:5, weight train batch: 107, step:6, loss before: 0.000224924675422, loss after: 0.000224716131925.\n",
      "Epoch:5, weight train batch: 107, step:7, loss before: 0.000205444011954, loss after: 0.000205201940844.\n",
      "Epoch:5, weight train batch: 107, step:8, loss before: 0.000241688510869, loss after: 0.00024146506621.\n",
      "Epoch:5, weight train batch: 107, step:9, loss before: 0.000233698970987, loss after: 0.000233438273426.\n",
      "Epoch:5, weight train batch: 107, step:10, loss before: 0.000193229148863, loss after: 0.000193016850972.\n",
      "Epoch:5, weight train batch: 107, step:11, loss before: 0.00497785210609, loss after: 0.00497526908293.\n",
      "Epoch:5, weight train batch: 107, step:12, loss before: 0.000229897108511, loss after: 0.000229714612942.\n",
      "Epoch:5, weight train batch: 107, step:13, loss before: 0.000218798028072, loss after: 0.000218533648876.\n",
      "Epoch:5, weight train batch: 107, step:14, loss before: 0.000224633651669, loss after: 0.000224391580559.\n",
      "Epoch:5, weight train batch: 107, step:15, loss before: 0.000213736071601, loss after: 0.000213467923459.\n",
      "Epoch:5, weight train batch: 107, step:16, loss before: 0.000210999336559, loss after: 0.000210831756704.\n",
      "Epoch:5, weight train batch: 107, step:17, loss before: 0.00023068243172, loss after: 0.000230440346058.\n",
      "Epoch:5, weight train batch: 107, step:18, loss before: 0.000249721691944, loss after: 0.000249420001637.\n",
      "Epoch:5, weight train batch: 107, step:19, loss before: 0.000221836773562, loss after: 0.000221661743126.\n",
      "Epoch:5, weight train batch: 107, step:20, loss before: 0.000199322064873, loss after: 0.000199046451598.\n",
      "Epoch:5, weight train batch: 107, step:21, loss before: 0.000223581533646, loss after: 0.000223417649977.\n",
      "Epoch:5, weight train batch: 107, step:22, loss before: 0.000260903732851, loss after: 0.000260646804236.\n",
      "Epoch:5, weight train batch: 107, step:23, loss before: 0.000187001831364, loss after: 0.000186796984053.\n",
      "Epoch:5, weight train batch: 107, step:24, loss before: 0.000234298815485, loss after: 0.000234108869336.\n",
      "Epoch:5, weight train batch: 107, step:25, loss before: 0.000225233554374, loss after: 0.000225043622777.\n",
      "Epoch:5, weight train batch: 107, step:26, loss before: 0.000205524818739, loss after: 0.000205275282497.\n",
      "Epoch:5, weight train batch: 107, step:27, loss before: 0.000173757551238, loss after: 0.000173578780959.\n",
      "Epoch:5, weight train batch: 107, step:28, loss before: 0.000227900862228, loss after: 0.000227710916079.\n",
      "Epoch:5, weight train batch: 107, step:29, loss before: 0.000244657305302, loss after: 0.000244437542278.\n",
      "Epoch:5, weight train batch: 107, step:30, loss before: 0.000222999005928, loss after: 0.000222812814172.\n",
      "Epoch:5, weight train batch: 107, step:31, loss before: 0.000218306231545, loss after: 0.000218064145884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 103, loss before: 0.000224815565161, loss after: 0.000307656184305.\n",
      "Epoch:5, weight train batch: 108, step:0, loss before: 0.000243618022068, loss after: 0.000243424379732.\n",
      "Epoch:5, weight train batch: 108, step:1, loss before: 0.000225874013267, loss after: 0.000225669180509.\n",
      "Epoch:5, weight train batch: 108, step:2, loss before: 0.000222239294089, loss after: 0.000221986047109.\n",
      "Epoch:5, weight train batch: 108, step:3, loss before: 0.0002106489992, loss after: 0.000210477679502.\n",
      "Epoch:5, weight train batch: 108, step:4, loss before: 0.000220744957915, loss after: 0.000220551315579.\n",
      "Epoch:5, weight train batch: 108, step:5, loss before: 0.000230637495406, loss after: 0.000230477351579.\n",
      "Epoch:5, weight train batch: 108, step:6, loss before: 0.000209043428185, loss after: 0.000208842335269.\n",
      "Epoch:5, weight train batch: 108, step:7, loss before: 0.000243548303843, loss after: 0.000243332295213.\n",
      "Epoch:5, weight train batch: 108, step:8, loss before: 0.000222049740842, loss after: 0.000221863505431.\n",
      "Epoch:5, weight train batch: 108, step:9, loss before: 0.00022080540657, loss after: 0.000220589412493.\n",
      "Epoch:5, weight train batch: 108, step:10, loss before: 0.000177981710294, loss after: 0.000177821566467.\n",
      "Epoch:5, weight train batch: 108, step:11, loss before: 0.000223777649808, loss after: 0.000223598879529.\n",
      "Epoch:5, weight train batch: 108, step:12, loss before: 0.000217927081394, loss after: 0.000217725973926.\n",
      "Epoch:5, weight train batch: 108, step:13, loss before: 0.000224503848585, loss after: 0.000224325078307.\n",
      "Epoch:5, weight train batch: 108, step:14, loss before: 0.000282115419395, loss after: 0.000281880900729.\n",
      "Epoch:5, weight train batch: 108, step:15, loss before: 0.00021714498871, loss after: 0.000216999731492.\n",
      "Epoch:5, weight train batch: 108, step:16, loss before: 0.000220667934627, loss after: 0.000220444475417.\n",
      "Epoch:5, weight train batch: 108, step:17, loss before: 0.000200528244022, loss after: 0.000200386712095.\n",
      "Epoch:5, weight train batch: 108, step:18, loss before: 0.000220165209612, loss after: 0.000219952926273.\n",
      "Epoch:5, weight train batch: 108, step:19, loss before: 0.000223430804908, loss after: 0.000223304174142.\n",
      "Epoch:5, weight train batch: 108, step:20, loss before: 0.000238590961089, loss after: 0.00023833027808.\n",
      "Epoch:5, weight train batch: 108, step:21, loss before: 0.000207181612495, loss after: 0.000207036355278.\n",
      "Epoch:5, weight train batch: 108, step:22, loss before: 0.000201672810363, loss after: 0.000201501490665.\n",
      "Epoch:5, weight train batch: 108, step:23, loss before: 0.000240560111706, loss after: 0.000240347828367.\n",
      "Epoch:5, weight train batch: 108, step:24, loss before: 0.000193296815269, loss after: 0.000193129191757.\n",
      "Epoch:5, weight train batch: 108, step:25, loss before: 0.000223163908231, loss after: 0.000223000068218.\n",
      "Epoch:5, weight train batch: 108, step:26, loss before: 0.000177598354639, loss after: 0.000177393521881.\n",
      "Epoch:5, weight train batch: 108, step:27, loss before: 0.000224157774937, loss after: 0.00022399763111.\n",
      "Epoch:5, weight train batch: 108, step:28, loss before: 0.000814594095573, loss after: 0.000813475809991.\n",
      "Epoch:5, weight train batch: 108, step:29, loss before: 0.000226928968914, loss after: 0.000226668256801.\n",
      "Epoch:5, weight train batch: 108, step:30, loss before: 0.000200413531275, loss after: 0.000200260838028.\n",
      "Epoch:5, weight train batch: 108, step:31, loss before: 0.00026012051967, loss after: 0.000259878521319.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 104, loss before: 0.000306963047478, loss after: 0.00139837153256.\n",
      "Epoch:5, weight train batch: 109, step:0, loss before: 0.00017716124421, loss after: 0.000177034613444.\n",
      "Epoch:5, weight train batch: 109, step:1, loss before: 0.000826991803478, loss after: 0.000825442024507.\n",
      "Epoch:5, weight train batch: 109, step:2, loss before: 0.000216171960346, loss after: 0.000215955937165.\n",
      "Epoch:5, weight train batch: 109, step:3, loss before: 0.000231286132475, loss after: 0.000231051482842.\n",
      "Epoch:5, weight train batch: 109, step:4, loss before: 0.000225558382226, loss after: 0.000225342373597.\n",
      "Epoch:5, weight train batch: 109, step:5, loss before: 0.000214795581996, loss after: 0.000214542320464.\n",
      "Epoch:5, weight train batch: 109, step:6, loss before: 0.000218131608563, loss after: 0.000217908149352.\n",
      "Epoch:5, weight train batch: 109, step:7, loss before: 0.000284314068267, loss after: 0.00028404983459.\n",
      "Epoch:5, weight train batch: 109, step:8, loss before: 0.000306031550281, loss after: 0.000305711524561.\n",
      "Epoch:5, weight train batch: 109, step:9, loss before: 0.000491062703077, loss after: 0.000490751117468.\n",
      "Epoch:5, weight train batch: 109, step:10, loss before: 0.000834194535855, loss after: 0.000832563149743.\n",
      "Epoch:5, weight train batch: 109, step:11, loss before: 0.000183713069418, loss after: 0.000183508222108.\n",
      "Epoch:5, weight train batch: 109, step:12, loss before: 0.000216406857362, loss after: 0.000216216925764.\n",
      "Epoch:5, weight train batch: 109, step:13, loss before: 0.000199106929358, loss after: 0.000198876005015.\n",
      "Epoch:5, weight train batch: 109, step:14, loss before: 0.000237712229136, loss after: 0.000237503700191.\n",
      "Epoch:5, weight train batch: 109, step:15, loss before: 0.000215573003516, loss after: 0.000215323467273.\n",
      "Epoch:5, weight train batch: 109, step:16, loss before: 0.000207427452551, loss after: 0.000207248667721.\n",
      "Epoch:5, weight train batch: 109, step:17, loss before: 0.000203851843253, loss after: 0.000203606032301.\n",
      "Epoch:5, weight train batch: 109, step:18, loss before: 0.00021237389592, loss after: 0.000212124359678.\n",
      "Epoch:5, weight train batch: 109, step:19, loss before: 0.000196406093892, loss after: 0.000196271997993.\n",
      "Epoch:5, weight train batch: 109, step:20, loss before: 0.000274432357401, loss after: 0.000274142075796.\n",
      "Epoch:5, weight train batch: 109, step:21, loss before: 0.000222352042329, loss after: 0.000222132293857.\n",
      "Epoch:5, weight train batch: 109, step:22, loss before: 0.000197214918444, loss after: 0.000197036133613.\n",
      "Epoch:5, weight train batch: 109, step:23, loss before: 0.000214798637899, loss after: 0.000214590050746.\n",
      "Epoch:5, weight train batch: 109, step:24, loss before: 0.000198916502995, loss after: 0.000198745197849.\n",
      "Epoch:5, weight train batch: 109, step:25, loss before: 0.000213099614484, loss after: 0.000212887331145.\n",
      "Epoch:5, weight train batch: 109, step:26, loss before: 0.000201762843062, loss after: 0.000201613875106.\n",
      "Epoch:5, weight train batch: 109, step:27, loss before: 0.000196663706447, loss after: 0.000196533364942.\n",
      "Epoch:5, weight train batch: 109, step:28, loss before: 0.000203500632779, loss after: 0.00020331813721.\n",
      "Epoch:5, weight train batch: 109, step:29, loss before: 0.000207151722861, loss after: 0.000206972938031.\n",
      "Epoch:5, weight train batch: 109, step:30, loss before: 0.000197486675461, loss after: 0.000197311630473.\n",
      "Epoch:5, weight train batch: 109, step:31, loss before: 0.000187426951015, loss after: 0.000187292898772.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 105, loss before: 0.000320388004184, loss after: 0.000204113777727.\n",
      "Epoch:5, weight train batch: 110, step:0, loss before: 0.00486287102103, loss after: 0.00486084772274.\n",
      "Epoch:5, weight train batch: 110, step:1, loss before: 0.000271933211479, loss after: 0.000271650293143.\n",
      "Epoch:5, weight train batch: 110, step:2, loss before: 0.000195091997739, loss after: 0.000194943029783.\n",
      "Epoch:5, weight train batch: 110, step:3, loss before: 0.000212407234358, loss after: 0.000212202401599.\n",
      "Epoch:5, weight train batch: 110, step:4, loss before: 0.00017413077876, loss after: 0.000173989246832.\n",
      "Epoch:5, weight train batch: 110, step:5, loss before: 0.000207151693758, loss after: 0.000206969212741.\n",
      "Epoch:5, weight train batch: 110, step:6, loss before: 0.000179794908036, loss after: 0.000179616137757.\n",
      "Epoch:5, weight train batch: 110, step:7, loss before: 0.000219890353037, loss after: 0.0002197525464.\n",
      "Epoch:5, weight train batch: 110, step:8, loss before: 0.0001856504241, loss after: 0.000185486540431.\n",
      "Epoch:5, weight train batch: 110, step:9, loss before: 0.000226039206609, loss after: 0.000225804571528.\n",
      "Epoch:5, weight train batch: 110, step:10, loss before: 0.000193543033674, loss after: 0.000193405227037.\n",
      "Epoch:5, weight train batch: 110, step:11, loss before: 0.000180022703717, loss after: 0.000179877431947.\n",
      "Epoch:5, weight train batch: 110, step:12, loss before: 0.000186011602636, loss after: 0.000185851458809.\n",
      "Epoch:5, weight train batch: 110, step:13, loss before: 0.000200559763471, loss after: 0.000200407070224.\n",
      "Epoch:5, weight train batch: 110, step:14, loss before: 0.000192741630599, loss after: 0.000192540494027.\n",
      "Epoch:5, weight train batch: 110, step:15, loss before: 0.00020453419711, loss after: 0.000204385229154.\n",
      "Epoch:5, weight train batch: 110, step:16, loss before: 0.000243111688178, loss after: 0.000242906884523.\n",
      "Epoch:5, weight train batch: 110, step:17, loss before: 0.000222498580115, loss after: 0.000222327274969.\n",
      "Epoch:5, weight train batch: 110, step:18, loss before: 0.000213022023672, loss after: 0.000212869315874.\n",
      "Epoch:5, weight train batch: 110, step:19, loss before: 0.000174133980181, loss after: 0.000173973821802.\n",
      "Epoch:5, weight train batch: 110, step:20, loss before: 0.000226504344027, loss after: 0.000226336764172.\n",
      "Epoch:5, weight train batch: 110, step:21, loss before: 0.000531442288775, loss after: 0.000531141529791.\n",
      "Epoch:5, weight train batch: 110, step:22, loss before: 0.000212049664697, loss after: 0.000211859733099.\n",
      "Epoch:5, weight train batch: 110, step:23, loss before: 0.00022062449716, loss after: 0.000220449423068.\n",
      "Epoch:5, weight train batch: 110, step:24, loss before: 0.000192193736439, loss after: 0.000191959086806.\n",
      "Epoch:5, weight train batch: 110, step:25, loss before: 0.00077135139145, loss after: 0.000770514772739.\n",
      "Epoch:5, weight train batch: 110, step:26, loss before: 0.000199889327632, loss after: 0.000199740345124.\n",
      "Epoch:5, weight train batch: 110, step:27, loss before: 0.00020442607638, loss after: 0.000204210082302.\n",
      "Epoch:5, weight train batch: 110, step:28, loss before: 0.000226389587624, loss after: 0.000226207092055.\n",
      "Epoch:5, weight train batch: 110, step:29, loss before: 0.000271294877166, loss after: 0.000271060445812.\n",
      "Epoch:5, weight train batch: 110, step:30, loss before: 0.000510583922733, loss after: 0.000509892473929.\n",
      "Epoch:5, weight train batch: 110, step:31, loss before: 0.000197967921849, loss after: 0.000197796587599.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 106, loss before: 0.000205929158255, loss after: 0.000193181156646.\n",
      "Epoch:5, weight train batch: 111, step:0, loss before: 0.000208713638131, loss after: 0.000208508805372.\n",
      "Epoch:5, weight train batch: 111, step:1, loss before: 0.000196958266315, loss after: 0.000196768291062.\n",
      "Epoch:5, weight train batch: 111, step:2, loss before: 0.000194701060536, loss after: 0.00019452230481.\n",
      "Epoch:5, weight train batch: 111, step:3, loss before: 0.000178365560714, loss after: 0.000178197951755.\n",
      "Epoch:5, weight train batch: 111, step:4, loss before: 0.0425684936345, loss after: 0.0424464531243.\n",
      "Epoch:5, weight train batch: 111, step:5, loss before: 0.00481300195679, loss after: 0.00481676217169.\n",
      "Epoch:5, weight train batch: 111, step:6, loss before: 0.000202951225219, loss after: 0.000203234289074.\n",
      "Epoch:5, weight train batch: 111, step:7, loss before: 0.000191930259462, loss after: 0.000192187260836.\n",
      "Epoch:5, weight train batch: 111, step:8, loss before: 0.00026440032525, loss after: 0.000264608679572.\n",
      "Epoch:5, weight train batch: 111, step:9, loss before: 0.000201662740437, loss after: 0.000201845250558.\n",
      "Epoch:5, weight train batch: 111, step:10, loss before: 0.000176265253685, loss after: 0.000176287634531.\n",
      "Epoch:5, weight train batch: 111, step:11, loss before: 0.000231435871683, loss after: 0.000231607191381.\n",
      "Epoch:5, weight train batch: 111, step:12, loss before: 0.000189385638805, loss after: 0.000189463869901.\n",
      "Epoch:5, weight train batch: 111, step:13, loss before: 0.000200779453735, loss after: 0.00020088745805.\n",
      "Epoch:5, weight train batch: 111, step:14, loss before: 0.000180066999746, loss after: 0.000180137780262.\n",
      "Epoch:5, weight train batch: 111, step:15, loss before: 0.000201696384465, loss after: 0.000201767164981.\n",
      "Epoch:5, weight train batch: 111, step:16, loss before: 0.00016538183263, loss after: 0.000165441437275.\n",
      "Epoch:5, weight train batch: 111, step:17, loss before: 0.000212546088733, loss after: 0.000212523736991.\n",
      "Epoch:5, weight train batch: 111, step:18, loss before: 0.000213773921132, loss after: 0.000213714331039.\n",
      "Epoch:5, weight train batch: 111, step:19, loss before: 0.000214489744394, loss after: 0.000214422703721.\n",
      "Epoch:5, weight train batch: 111, step:20, loss before: 0.000242528738454, loss after: 0.000242394686211.\n",
      "Epoch:5, weight train batch: 111, step:21, loss before: 0.000191547267605, loss after: 0.000191506289411.\n",
      "Epoch:5, weight train batch: 111, step:22, loss before: 0.00020751694683, loss after: 0.000207431265153.\n",
      "Epoch:5, weight train batch: 111, step:23, loss before: 0.000213600447751, loss after: 0.000213429142605.\n",
      "Epoch:5, weight train batch: 111, step:24, loss before: 0.000193323328858, loss after: 0.000193219049834.\n",
      "Epoch:5, weight train batch: 111, step:25, loss before: 0.000217767403228, loss after: 0.000217625871301.\n",
      "Epoch:5, weight train batch: 111, step:26, loss before: 0.000201505317818, loss after: 0.000201367525733.\n",
      "Epoch:5, weight train batch: 111, step:27, loss before: 0.000173254346009, loss after: 0.000173138891114.\n",
      "Epoch:5, weight train batch: 111, step:28, loss before: 0.000519940687809, loss after: 0.000519201392308.\n",
      "Epoch:5, weight train batch: 111, step:29, loss before: 0.00483515905216, loss after: 0.0048268744722.\n",
      "Epoch:5, weight train batch: 111, step:30, loss before: 0.000206462325878, loss after: 0.000206048949622.\n",
      "Epoch:5, weight train batch: 111, step:31, loss before: 0.000228877761401, loss after: 0.000228378703468.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 107, loss before: 0.000208319877856, loss after: 0.000195014858036.\n",
      "Epoch:5, weight train batch: 112, step:0, loss before: 0.000269783369731, loss after: 0.000269492913503.\n",
      "Epoch:5, weight train batch: 112, step:1, loss before: 0.000200403708732, loss after: 0.000200176553335.\n",
      "Epoch:5, weight train batch: 112, step:2, loss before: 0.000206511685974, loss after: 0.00020624352328.\n",
      "Epoch:5, weight train batch: 112, step:3, loss before: 0.000190696533537, loss after: 0.000190428370843.\n",
      "Epoch:5, weight train batch: 112, step:4, loss before: 0.00017816721811, loss after: 0.000177928857738.\n",
      "Epoch:5, weight train batch: 112, step:5, loss before: 0.000215920488699, loss after: 0.00021573426784.\n",
      "Epoch:5, weight train batch: 112, step:6, loss before: 0.000224270508625, loss after: 0.000223994924454.\n",
      "Epoch:5, weight train batch: 112, step:7, loss before: 0.000241005167481, loss after: 0.000240699766437.\n",
      "Epoch:5, weight train batch: 112, step:8, loss before: 0.000209245699807, loss after: 0.000208932848182.\n",
      "Epoch:5, weight train batch: 112, step:9, loss before: 0.000226867079618, loss after: 0.000226613832638.\n",
      "Epoch:5, weight train batch: 112, step:10, loss before: 0.000160781492013, loss after: 0.000160591560416.\n",
      "Epoch:5, weight train batch: 112, step:11, loss before: 0.000205823074793, loss after: 0.000205636868486.\n",
      "Epoch:5, weight train batch: 112, step:12, loss before: 0.000185062614037, loss after: 0.000184880103916.\n",
      "Epoch:5, weight train batch: 112, step:13, loss before: 0.000194742868189, loss after: 0.000194523119717.\n",
      "Epoch:5, weight train batch: 112, step:14, loss before: 0.000174234752194, loss after: 0.000174044820596.\n",
      "Epoch:5, weight train batch: 112, step:15, loss before: 0.000188309611985, loss after: 0.000188145728316.\n",
      "Epoch:5, weight train batch: 112, step:16, loss before: 0.000199956673896, loss after: 0.000199699687073.\n",
      "Epoch:5, weight train batch: 112, step:17, loss before: 0.000174979984877, loss after: 0.000174790038727.\n",
      "Epoch:5, weight train batch: 112, step:18, loss before: 0.000175616412889, loss after: 0.0001754785917.\n",
      "Epoch:5, weight train batch: 112, step:19, loss before: 0.000202099108719, loss after: 0.000201942690182.\n",
      "Epoch:5, weight train batch: 112, step:20, loss before: 0.000185125711141, loss after: 0.000184898526641.\n",
      "Epoch:5, weight train batch: 112, step:21, loss before: 0.000201949820621, loss after: 0.000201785936952.\n",
      "Epoch:5, weight train batch: 112, step:22, loss before: 0.00475845066831, loss after: 0.00475629232824.\n",
      "Epoch:5, weight train batch: 112, step:23, loss before: 0.000208352401387, loss after: 0.000208117751754.\n",
      "Epoch:5, weight train batch: 112, step:24, loss before: 0.000178562913788, loss after: 0.000178387883352.\n",
      "Epoch:5, weight train batch: 112, step:25, loss before: 0.000209890160477, loss after: 0.000209614547202.\n",
      "Epoch:5, weight train batch: 112, step:26, loss before: 0.000191370898392, loss after: 0.00019112881273.\n",
      "Epoch:5, weight train batch: 112, step:27, loss before: 0.00018784875283, loss after: 0.000187640165677.\n",
      "Epoch:5, weight train batch: 112, step:28, loss before: 0.000200176262297, loss after: 0.000200008667889.\n",
      "Epoch:5, weight train batch: 112, step:29, loss before: 0.000187412719242, loss after: 0.000187140816706.\n",
      "Epoch:5, weight train batch: 112, step:30, loss before: 0.0412739254534, loss after: 0.0412010215223.\n",
      "Epoch:5, weight train batch: 112, step:31, loss before: 0.000216426778934, loss after: 0.000216542219277.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 108, loss before: 0.000185084878467, loss after: 0.000256674276898.\n",
      "Epoch:5, weight train batch: 113, step:0, loss before: 0.000196984969079, loss after: 0.000197059416678.\n",
      "Epoch:5, weight train batch: 113, step:1, loss before: 0.000167359627085, loss after: 0.000167326099472.\n",
      "Epoch:5, weight train batch: 113, step:2, loss before: 0.000195531436475, loss after: 0.000195728818653.\n",
      "Epoch:5, weight train batch: 113, step:3, loss before: 0.000201152943191, loss after: 0.00020099277026.\n",
      "Epoch:5, weight train batch: 113, step:4, loss before: 0.000184581091162, loss after: 0.000184599703061.\n",
      "Epoch:5, weight train batch: 113, step:5, loss before: 0.000201786097023, loss after: 0.000201760019991.\n",
      "Epoch:5, weight train batch: 113, step:6, loss before: 0.000174037413672, loss after: 0.000173918233486.\n",
      "Epoch:5, weight train batch: 113, step:7, loss before: 0.000168681290234, loss after: 0.000168644037331.\n",
      "Epoch:5, weight train batch: 113, step:8, loss before: 0.000474718748592, loss after: 0.000474127940834.\n",
      "Epoch:5, weight train batch: 113, step:9, loss before: 0.000241228335653, loss after: 0.000241064510192.\n",
      "Epoch:5, weight train batch: 113, step:10, loss before: 0.000176026049303, loss after: 0.000175918015884.\n",
      "Epoch:5, weight train batch: 113, step:11, loss before: 0.000181263385457, loss after: 0.000181110663107.\n",
      "Epoch:5, weight train batch: 113, step:12, loss before: 0.00023716504802, loss after: 0.000236993771978.\n",
      "Epoch:5, weight train batch: 113, step:13, loss before: 0.000185464945389, loss after: 0.000185275013791.\n",
      "Epoch:5, weight train batch: 113, step:14, loss before: 0.00868957862258, loss after: 0.00867853779346.\n",
      "Epoch:5, weight train batch: 113, step:15, loss before: 0.000208914483665, loss after: 0.000208504818147.\n",
      "Epoch:5, weight train batch: 113, step:16, loss before: 0.000208539015148, loss after: 0.000208270852454.\n",
      "Epoch:5, weight train batch: 113, step:17, loss before: 0.000188306177733, loss after: 0.000187985890079.\n",
      "Epoch:5, weight train batch: 113, step:18, loss before: 0.000188633886864, loss after: 0.000188402977074.\n",
      "Epoch:5, weight train batch: 113, step:19, loss before: 0.000184611737495, loss after: 0.000184343574801.\n",
      "Epoch:5, weight train batch: 113, step:20, loss before: 0.000154468303663, loss after: 0.00015423365403.\n",
      "Epoch:5, weight train batch: 113, step:21, loss before: 0.000162435506354, loss after: 0.000162264186656.\n",
      "Epoch:5, weight train batch: 113, step:22, loss before: 0.000166931771673, loss after: 0.000166767902556.\n",
      "Epoch:5, weight train batch: 113, step:23, loss before: 0.000171221967321, loss after: 0.000171028281329.\n",
      "Epoch:5, weight train batch: 113, step:24, loss before: 0.000199475820409, loss after: 0.000199196481844.\n",
      "Epoch:5, weight train batch: 113, step:25, loss before: 0.000193848463823, loss after: 0.000193662242964.\n",
      "Epoch:5, weight train batch: 113, step:26, loss before: 0.000222432645387, loss after: 0.000222190588829.\n",
      "Epoch:5, weight train batch: 113, step:27, loss before: 0.000182734627742, loss after: 0.000182492527529.\n",
      "Epoch:5, weight train batch: 113, step:28, loss before: 0.000481057679281, loss after: 0.000480753078591.\n",
      "Epoch:5, weight train batch: 113, step:29, loss before: 0.00019460884505, loss after: 0.000194396532606.\n",
      "Epoch:5, weight train batch: 113, step:30, loss before: 0.000170576910023, loss after: 0.000170346014784.\n",
      "Epoch:5, weight train batch: 113, step:31, loss before: 0.00016951552243, loss after: 0.000169355364051.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 109, loss before: 0.00018542453472, loss after: 0.00018542453472.\n",
      "Epoch:5, weight train batch: 114, step:0, loss before: 0.000185476645129, loss after: 0.00018527553766.\n",
      "Epoch:5, weight train batch: 114, step:1, loss before: 0.000189938611584, loss after: 0.000189785918337.\n",
      "Epoch:5, weight train batch: 114, step:2, loss before: 0.000197915083845, loss after: 0.000197613393539.\n",
      "Epoch:5, weight train batch: 114, step:3, loss before: 0.000168297949131, loss after: 0.000168141516042.\n",
      "Epoch:5, weight train batch: 114, step:4, loss before: 0.000196136417799, loss after: 0.000195898042875.\n",
      "Epoch:5, weight train batch: 114, step:5, loss before: 0.000155422167154, loss after: 0.000155288085807.\n",
      "Epoch:5, weight train batch: 114, step:6, loss before: 0.000195119020646, loss after: 0.000194884371012.\n",
      "Epoch:5, weight train batch: 114, step:7, loss before: 0.000207835590118, loss after: 0.00020766427042.\n",
      "Epoch:5, weight train batch: 114, step:8, loss before: 0.000173556923983, loss after: 0.000173422857188.\n",
      "Epoch:5, weight train batch: 114, step:9, loss before: 0.000285127258394, loss after: 0.000284825830022.\n",
      "Epoch:5, weight train batch: 114, step:10, loss before: 0.000206810451346, loss after: 0.000206639117096.\n",
      "Epoch:5, weight train batch: 114, step:11, loss before: 0.000194970329176, loss after: 0.000194739419385.\n",
      "Epoch:5, weight train batch: 114, step:12, loss before: 0.000185289638466, loss after: 0.000185103417607.\n",
      "Epoch:5, weight train batch: 114, step:13, loss before: 0.000159157527378, loss after: 0.000159001079737.\n",
      "Epoch:5, weight train batch: 114, step:14, loss before: 0.000256072322372, loss after: 0.000255823018961.\n",
      "Epoch:5, weight train batch: 114, step:15, loss before: 0.000191409533727, loss after: 0.000191215862287.\n",
      "Epoch:5, weight train batch: 114, step:16, loss before: 0.000208553363336, loss after: 0.000208348530577.\n",
      "Epoch:5, weight train batch: 114, step:17, loss before: 0.000170972198248, loss after: 0.000170771076228.\n",
      "Epoch:5, weight train batch: 114, step:18, loss before: 0.000200311202207, loss after: 0.000200132431928.\n",
      "Epoch:5, weight train batch: 114, step:19, loss before: 0.000190623366507, loss after: 0.000190414808458.\n",
      "Epoch:5, weight train batch: 114, step:20, loss before: 0.000163642442203, loss after: 0.000163493459695.\n",
      "Epoch:5, weight train batch: 114, step:21, loss before: 0.000202427181648, loss after: 0.00020224841137.\n",
      "Epoch:5, weight train batch: 114, step:22, loss before: 0.000178700662218, loss after: 0.000178585207323.\n",
      "Epoch:5, weight train batch: 114, step:23, loss before: 0.000259489694145, loss after: 0.000259236607235.\n",
      "Epoch:5, weight train batch: 114, step:24, loss before: 0.000179359849426, loss after: 0.00017921833205.\n",
      "Epoch:5, weight train batch: 114, step:25, loss before: 0.00019420676108, loss after: 0.000194050313439.\n",
      "Epoch:5, weight train batch: 114, step:26, loss before: 0.000176119705429, loss after: 0.000175948371179.\n",
      "Epoch:5, weight train batch: 114, step:27, loss before: 0.000174119428266, loss after: 0.000173966720467.\n",
      "Epoch:5, weight train batch: 114, step:28, loss before: 0.000176834728336, loss after: 0.000176723027835.\n",
      "Epoch:5, weight train batch: 114, step:29, loss before: 0.000198166264454, loss after: 0.000197980029043.\n",
      "Epoch:5, weight train batch: 114, step:30, loss before: 0.000185670302017, loss after: 0.00018553994596.\n",
      "Epoch:5, weight train batch: 114, step:31, loss before: 0.000732235028408, loss after: 0.000731079140678.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 110, loss before: 0.00223212433048, loss after: 0.00017350903363.\n",
      "Epoch:5, weight train batch: 115, step:0, loss before: 0.000186470715562, loss after: 0.000186258403119.\n",
      "Epoch:5, weight train batch: 115, step:1, loss before: 0.000207779550692, loss after: 0.000207626857446.\n",
      "Epoch:5, weight train batch: 115, step:2, loss before: 0.000189953221707, loss after: 0.000189740938367.\n",
      "Epoch:5, weight train batch: 115, step:3, loss before: 0.000175323250005, loss after: 0.000175151901203.\n",
      "Epoch:5, weight train batch: 115, step:4, loss before: 0.00018193788128, loss after: 0.000181785202585.\n",
      "Epoch:5, weight train batch: 115, step:5, loss before: 0.000738567614462, loss after: 0.000737178022973.\n",
      "Epoch:5, weight train batch: 115, step:6, loss before: 0.000157191781909, loss after: 0.000156945956405.\n",
      "Epoch:5, weight train batch: 115, step:7, loss before: 0.000174846180016, loss after: 0.000174693472218.\n",
      "Epoch:5, weight train batch: 115, step:8, loss before: 0.000173475913471, loss after: 0.000173237523995.\n",
      "Epoch:5, weight train batch: 115, step:9, loss before: 0.000187837460544, loss after: 0.000187658675713.\n",
      "Epoch:5, weight train batch: 115, step:10, loss before: 0.000189551225048, loss after: 0.000189387341379.\n",
      "Epoch:5, weight train batch: 115, step:11, loss before: 0.000189893544302, loss after: 0.000189714759472.\n",
      "Epoch:5, weight train batch: 115, step:12, loss before: 0.000181561947102, loss after: 0.000181405514013.\n",
      "Epoch:5, weight train batch: 115, step:13, loss before: 0.000174834654899, loss after: 0.000174644694198.\n",
      "Epoch:5, weight train batch: 115, step:14, loss before: 0.00027204270009, loss after: 0.000271856668405.\n",
      "Epoch:5, weight train batch: 115, step:15, loss before: 0.0399865284562, loss after: 0.0398943945765.\n",
      "Epoch:5, weight train batch: 115, step:16, loss before: 0.000181218696525, loss after: 0.00018147942319.\n",
      "Epoch:5, weight train batch: 115, step:17, loss before: 0.000204591138754, loss after: 0.000204877898796.\n",
      "Epoch:5, weight train batch: 115, step:18, loss before: 0.000174761284143, loss after: 0.000174839486135.\n",
      "Epoch:5, weight train batch: 115, step:19, loss before: 0.000204290030524, loss after: 0.000204427808058.\n",
      "Epoch:5, weight train batch: 115, step:20, loss before: 0.000162349824677, loss after: 0.000162580734468.\n",
      "Epoch:5, weight train batch: 115, step:21, loss before: 0.000169407430803, loss after: 0.000169515435118.\n",
      "Epoch:5, weight train batch: 115, step:22, loss before: 0.00018085713964, loss after: 0.000180965143954.\n",
      "Epoch:5, weight train batch: 115, step:23, loss before: 0.000181166833499, loss after: 0.000181256211363.\n",
      "Epoch:5, weight train batch: 115, step:24, loss before: 0.000178552654688, loss after: 0.000178493064595.\n",
      "Epoch:5, weight train batch: 115, step:25, loss before: 0.000223540118895, loss after: 0.000223595969146.\n",
      "Epoch:5, weight train batch: 115, step:26, loss before: 0.000176905319677, loss after: 0.000176931411261.\n",
      "Epoch:5, weight train batch: 115, step:27, loss before: 0.000194456646568, loss after: 0.000194434280274.\n",
      "Epoch:5, weight train batch: 115, step:28, loss before: 0.000190563863725, loss after: 0.000190485647181.\n",
      "Epoch:5, weight train batch: 115, step:29, loss before: 0.000163873366546, loss after: 0.000163791424711.\n",
      "Epoch:5, weight train batch: 115, step:30, loss before: 0.000206368160434, loss after: 0.000206278782571.\n",
      "Epoch:5, weight train batch: 115, step:31, loss before: 0.000172980478965, loss after: 0.000172879925231.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 111, loss before: 0.000177640249603, loss after: 0.000184442935279.\n",
      "Epoch:5, weight train batch: 116, step:0, loss before: 0.000190322636627, loss after: 0.000190229533473.\n",
      "Epoch:5, weight train batch: 116, step:1, loss before: 0.000194266976905, loss after: 0.000194117994397.\n",
      "Epoch:5, weight train batch: 116, step:2, loss before: 0.000186898818356, loss after: 0.000186824327102.\n",
      "Epoch:5, weight train batch: 116, step:3, loss before: 0.000483344309032, loss after: 0.000482885312522.\n",
      "Epoch:5, weight train batch: 116, step:4, loss before: 0.000168703787494, loss after: 0.000168551079696.\n",
      "Epoch:5, weight train batch: 116, step:5, loss before: 0.000190153863514, loss after: 0.000189975093235.\n",
      "Epoch:5, weight train batch: 116, step:6, loss before: 0.000179442140507, loss after: 0.000179296883289.\n",
      "Epoch:5, weight train batch: 116, step:7, loss before: 0.000171684077941, loss after: 0.000171482970472.\n",
      "Epoch:5, weight train batch: 116, step:8, loss before: 0.000198848429136, loss after: 0.000198747875402.\n",
      "Epoch:5, weight train batch: 116, step:9, loss before: 0.000176763191121, loss after: 0.000176535992068.\n",
      "Epoch:5, weight train batch: 116, step:10, loss before: 0.000157247442985, loss after: 0.000157105911057.\n",
      "Epoch:5, weight train batch: 116, step:11, loss before: 0.000172768137418, loss after: 0.000172634056071.\n",
      "Epoch:5, weight train batch: 116, step:12, loss before: 0.000181524577783, loss after: 0.000181312294444.\n",
      "Epoch:5, weight train batch: 116, step:13, loss before: 0.000150684587425, loss after: 0.000150565407239.\n",
      "Epoch:5, weight train batch: 116, step:14, loss before: 0.000171334249899, loss after: 0.000171136838617.\n",
      "Epoch:5, weight train batch: 116, step:15, loss before: 0.000200944632525, loss after: 0.000200765833142.\n",
      "Epoch:5, weight train batch: 116, step:16, loss before: 0.000160283554578, loss after: 0.0001601047843.\n",
      "Epoch:5, weight train batch: 116, step:17, loss before: 0.000155802335939, loss after: 0.00015563845227.\n",
      "Epoch:5, weight train batch: 116, step:18, loss before: 0.00019379677542, loss after: 0.000193573330762.\n",
      "Epoch:5, weight train batch: 116, step:19, loss before: 0.000178995163878, loss after: 0.000178764239536.\n",
      "Epoch:5, weight train batch: 116, step:20, loss before: 0.000192616149434, loss after: 0.000192429928575.\n",
      "Epoch:5, weight train batch: 116, step:21, loss before: 0.000162357144291, loss after: 0.000162148557138.\n",
      "Epoch:5, weight train batch: 116, step:22, loss before: 0.000181527953828, loss after: 0.000181356648682.\n",
      "Epoch:5, weight train batch: 116, step:23, loss before: 0.000203995950869, loss after: 0.000203765011975.\n",
      "Epoch:5, weight train batch: 116, step:24, loss before: 0.000178332469659, loss after: 0.0001781276369.\n",
      "Epoch:5, weight train batch: 116, step:25, loss before: 0.000207816832699, loss after: 0.000207515171496.\n",
      "Epoch:5, weight train batch: 116, step:26, loss before: 0.000176157191163, loss after: 0.000175956054591.\n",
      "Epoch:5, weight train batch: 116, step:27, loss before: 0.000152792723384, loss after: 0.000152550637722.\n",
      "Epoch:5, weight train batch: 116, step:28, loss before: 0.000169192091562, loss after: 0.000169039383763.\n",
      "Epoch:5, weight train batch: 116, step:29, loss before: 0.000231876212638, loss after: 0.000231641737628.\n",
      "Epoch:5, weight train batch: 116, step:30, loss before: 0.000162375989021, loss after: 0.000162137614097.\n",
      "Epoch:5, weight train batch: 116, step:31, loss before: 0.000160394352861, loss after: 0.000160263996804.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 112, loss before: 0.000175264169229, loss after: 0.000365674379282.\n",
      "Epoch:5, weight train batch: 117, step:0, loss before: 0.000134932808578, loss after: 0.000134802423418.\n",
      "Epoch:5, weight train batch: 117, step:1, loss before: 0.00019455733127, loss after: 0.000194408348761.\n",
      "Epoch:5, weight train batch: 117, step:2, loss before: 0.000168760030647, loss after: 0.000168581260368.\n",
      "Epoch:5, weight train batch: 117, step:3, loss before: 0.000169527775142, loss after: 0.000169378807186.\n",
      "Epoch:5, weight train batch: 117, step:4, loss before: 0.000187592231669, loss after: 0.000187398560229.\n",
      "Epoch:5, weight train batch: 117, step:5, loss before: 0.000172861065948, loss after: 0.000172738160472.\n",
      "Epoch:5, weight train batch: 117, step:6, loss before: 0.000161109637702, loss after: 0.000160975585459.\n",
      "Epoch:5, weight train batch: 117, step:7, loss before: 0.000178555681487, loss after: 0.000178391783265.\n",
      "Epoch:5, weight train batch: 117, step:8, loss before: 0.000148006278323, loss after: 0.000147909449879.\n",
      "Epoch:5, weight train batch: 117, step:9, loss before: 0.000155236324645, loss after: 0.000155079862452.\n",
      "Epoch:5, weight train batch: 117, step:10, loss before: 0.000208368262975, loss after: 0.000208215555176.\n",
      "Epoch:5, weight train batch: 117, step:11, loss before: 0.000176239293069, loss after: 0.000176053057658.\n",
      "Epoch:5, weight train batch: 117, step:12, loss before: 0.00018157705199, loss after: 0.000181439259904.\n",
      "Epoch:5, weight train batch: 117, step:13, loss before: 0.000172939209733, loss after: 0.000172812608071.\n",
      "Epoch:5, weight train batch: 117, step:14, loss before: 0.000181062598131, loss after: 0.000180880073458.\n",
      "Epoch:5, weight train batch: 117, step:15, loss before: 0.000153712986503, loss after: 0.000153582630446.\n",
      "Epoch:5, weight train batch: 117, step:16, loss before: 0.000145320955198, loss after: 0.000145190599142.\n",
      "Epoch:5, weight train batch: 117, step:17, loss before: 0.000174425731529, loss after: 0.000174295375473.\n",
      "Epoch:5, weight train batch: 117, step:18, loss before: 0.000182534204214, loss after: 0.000182377771125.\n",
      "Epoch:5, weight train batch: 117, step:19, loss before: 0.000190620310605, loss after: 0.0001904713572.\n",
      "Epoch:5, weight train batch: 117, step:20, loss before: 0.000173374908627, loss after: 0.000173255728441.\n",
      "Epoch:5, weight train batch: 117, step:21, loss before: 0.000472851912491, loss after: 0.000472422718303.\n",
      "Epoch:5, weight train batch: 117, step:22, loss before: 0.000168082595337, loss after: 0.000167903810507.\n",
      "Epoch:5, weight train batch: 117, step:23, loss before: 0.000163210585015, loss after: 0.000163095130119.\n",
      "Epoch:5, weight train batch: 117, step:24, loss before: 0.00015253626043, loss after: 0.000152435706696.\n",
      "Epoch:5, weight train batch: 117, step:25, loss before: 0.000179401715286, loss after: 0.000179241556907.\n",
      "Epoch:5, weight train batch: 117, step:26, loss before: 0.000178310525371, loss after: 0.00017815407773.\n",
      "Epoch:5, weight train batch: 117, step:27, loss before: 0.000142806369695, loss after: 0.00014269464009.\n",
      "Epoch:5, weight train batch: 117, step:28, loss before: 0.000207104923902, loss after: 0.000206929893466.\n",
      "Epoch:5, weight train batch: 117, step:29, loss before: 0.000150751235196, loss after: 0.000150632055011.\n",
      "Epoch:5, weight train batch: 117, step:30, loss before: 0.000187060039025, loss after: 0.000186884979485.\n",
      "Epoch:5, weight train batch: 117, step:31, loss before: 0.000179918861249, loss after: 0.000179754992132.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 113, loss before: 0.000178388581844, loss after: 0.000178194924956.\n",
      "Epoch:5, weight train batch: 118, step:0, loss before: 0.000166927726241, loss after: 0.00016674521612.\n",
      "Epoch:5, weight train batch: 118, step:1, loss before: 0.000171617459273, loss after: 0.000171498279087.\n",
      "Epoch:5, weight train batch: 118, step:2, loss before: 0.000178243877599, loss after: 0.000178124682861.\n",
      "Epoch:5, weight train batch: 118, step:3, loss before: 0.000178556714673, loss after: 0.000178389105713.\n",
      "Epoch:5, weight train batch: 118, step:4, loss before: 0.000162603682838, loss after: 0.000162458411069.\n",
      "Epoch:5, weight train batch: 118, step:5, loss before: 0.000151068234118, loss after: 0.000150937878061.\n",
      "Epoch:5, weight train batch: 118, step:6, loss before: 0.0001899873605, loss after: 0.000189868180314.\n",
      "Epoch:5, weight train batch: 118, step:7, loss before: 0.000165929290233, loss after: 0.000165787743754.\n",
      "Epoch:5, weight train batch: 118, step:8, loss before: 0.000160439551109, loss after: 0.000160294264788.\n",
      "Epoch:5, weight train batch: 118, step:9, loss before: 0.00018166177324, loss after: 0.000181557508768.\n",
      "Epoch:5, weight train batch: 118, step:10, loss before: 0.000169725681189, loss after: 0.00016956179752.\n",
      "Epoch:5, weight train batch: 118, step:11, loss before: 0.000141286785947, loss after: 0.000141182506923.\n",
      "Epoch:5, weight train batch: 118, step:12, loss before: 0.000168392289197, loss after: 0.000168239581399.\n",
      "Epoch:5, weight train batch: 118, step:13, loss before: 0.000152371707372, loss after: 0.000152241365868.\n",
      "Epoch:5, weight train batch: 118, step:14, loss before: 0.000190172664588, loss after: 0.000190053484403.\n",
      "Epoch:5, weight train batch: 118, step:15, loss before: 0.00467663165182, loss after: 0.00467449286953.\n",
      "Epoch:5, weight train batch: 118, step:16, loss before: 0.00069081253605, loss after: 0.000689677661285.\n",
      "Epoch:5, weight train batch: 118, step:17, loss before: 0.000180820657988, loss after: 0.000180641887709.\n",
      "Epoch:5, weight train batch: 118, step:18, loss before: 0.000154818670126, loss after: 0.000154654786456.\n",
      "Epoch:5, weight train batch: 118, step:19, loss before: 0.000156354042701, loss after: 0.000156201334903.\n",
      "Epoch:5, weight train batch: 118, step:20, loss before: 0.000144244550029, loss after: 0.00014411417942.\n",
      "Epoch:5, weight train batch: 118, step:21, loss before: 0.000175189517904, loss after: 0.000174995831912.\n",
      "Epoch:5, weight train batch: 118, step:22, loss before: 0.0001777891448, loss after: 0.000177629000973.\n",
      "Epoch:5, weight train batch: 118, step:23, loss before: 0.000163761855219, loss after: 0.000163635209901.\n",
      "Epoch:5, weight train batch: 118, step:24, loss before: 0.000160297888215, loss after: 0.000160145194968.\n",
      "Epoch:5, weight train batch: 118, step:25, loss before: 0.000154513661982, loss after: 0.000154401932377.\n",
      "Epoch:5, weight train batch: 118, step:26, loss before: 0.000181625553523, loss after: 0.000181435592822.\n",
      "Epoch:5, weight train batch: 118, step:27, loss before: 0.000160793060786, loss after: 0.000160670140758.\n",
      "Epoch:5, weight train batch: 118, step:28, loss before: 0.00018348445883, loss after: 0.000183331751032.\n",
      "Epoch:5, weight train batch: 118, step:29, loss before: 0.00014371497673, loss after: 0.000143584620673.\n",
      "Epoch:5, weight train batch: 118, step:30, loss before: 0.000164447817951, loss after: 0.000164306286024.\n",
      "Epoch:5, weight train batch: 118, step:31, loss before: 0.000170679180883, loss after: 0.000170519022504.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 114, loss before: 0.000158298804308, loss after: 0.00217723660171.\n",
      "Epoch:5, weight train batch: 119, step:0, loss before: 0.00017424300313, loss after: 0.000174056767719.\n",
      "Epoch:5, weight train batch: 119, step:1, loss before: 0.000246631621849, loss after: 0.000246412004344.\n",
      "Epoch:5, weight train batch: 119, step:2, loss before: 0.000157851376571, loss after: 0.000157683767611.\n",
      "Epoch:5, weight train batch: 119, step:3, loss before: 0.00024332459725, loss after: 0.000243112488533.\n",
      "Epoch:5, weight train batch: 119, step:4, loss before: 0.000156953086844, loss after: 0.000156837617396.\n",
      "Epoch:5, weight train batch: 119, step:5, loss before: 0.000176988105522, loss after: 0.000176779532922.\n",
      "Epoch:5, weight train batch: 119, step:6, loss before: 0.000149139028508, loss after: 0.000149038460222.\n",
      "Epoch:5, weight train batch: 119, step:7, loss before: 0.00021378044039, loss after: 0.000213568157051.\n",
      "Epoch:5, weight train batch: 119, step:8, loss before: 0.00017094683426, loss after: 0.000170809042174.\n",
      "Epoch:5, weight train batch: 119, step:9, loss before: 0.000253725622315, loss after: 0.000253491132753.\n",
      "Epoch:5, weight train batch: 119, step:10, loss before: 0.000172712680069, loss after: 0.00017255997227.\n",
      "Epoch:5, weight train batch: 119, step:11, loss before: 0.000150423875311, loss after: 0.000150289793964.\n",
      "Epoch:5, weight train batch: 119, step:12, loss before: 0.000150856154505, loss after: 0.000150714622578.\n",
      "Epoch:5, weight train batch: 119, step:13, loss before: 0.000158245675266, loss after: 0.00015814510698.\n",
      "Epoch:5, weight train batch: 119, step:14, loss before: 0.000165140460012, loss after: 0.000164995202795.\n",
      "Epoch:5, weight train batch: 119, step:15, loss before: 0.000145976897329, loss after: 0.000145842815982.\n",
      "Epoch:5, weight train batch: 119, step:16, loss before: 0.00489941984415, loss after: 0.00489732716233.\n",
      "Epoch:5, weight train batch: 119, step:17, loss before: 0.000140646356158, loss after: 0.000140530886711.\n",
      "Epoch:5, weight train batch: 119, step:18, loss before: 0.000178347720066, loss after: 0.000178139147465.\n",
      "Epoch:5, weight train batch: 119, step:19, loss before: 0.000170712388353, loss after: 0.000170544808498.\n",
      "Epoch:5, weight train batch: 119, step:20, loss before: 0.000189075435628, loss after: 0.000188881749636.\n",
      "Epoch:5, weight train batch: 119, step:21, loss before: 0.000144944744534, loss after: 0.000144747347804.\n",
      "Epoch:5, weight train batch: 119, step:22, loss before: 0.000156245776452, loss after: 0.000156096793944.\n",
      "Epoch:5, weight train batch: 119, step:23, loss before: 0.000135387614137, loss after: 0.00013525353279.\n",
      "Epoch:5, weight train batch: 119, step:24, loss before: 0.000152830441948, loss after: 0.000152666558279.\n",
      "Epoch:5, weight train batch: 119, step:25, loss before: 0.000147492683027, loss after: 0.000147351151099.\n",
      "Epoch:5, weight train batch: 119, step:26, loss before: 0.000193052896066, loss after: 0.000192900173715.\n",
      "Epoch:5, weight train batch: 119, step:27, loss before: 0.000171047809999, loss after: 0.000170891391463.\n",
      "Epoch:5, weight train batch: 119, step:28, loss before: 0.000139149065944, loss after: 0.000139055948239.\n",
      "Epoch:5, weight train batch: 119, step:29, loss before: 0.000154372362886, loss after: 0.000154227105668.\n",
      "Epoch:5, weight train batch: 119, step:30, loss before: 0.000172675820068, loss after: 0.000172482148628.\n",
      "Epoch:5, weight train batch: 119, step:31, loss before: 0.000148238206748, loss after: 0.000148100371007.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:5, struct parameters train batch: 115, loss before: 0.000162376541994, loss after: 0.000162376541994.\n",
      "Epoch:6, weight train batch: 120, step:0, loss before: 0.000152606793563, loss after: 0.000152480177348.\n",
      "Epoch:6, weight train batch: 120, step:1, loss before: 0.000150516920257, loss after: 0.00015037538833.\n",
      "Epoch:6, weight train batch: 120, step:2, loss before: 0.000186684308574, loss after: 0.000186542776646.\n",
      "Epoch:6, weight train batch: 120, step:3, loss before: 0.000158737195306, loss after: 0.000158554670634.\n",
      "Epoch:6, weight train batch: 120, step:4, loss before: 0.00017872051103, loss after: 0.000178593894816.\n",
      "Epoch:6, weight train batch: 120, step:5, loss before: 0.000182464485988, loss after: 0.00018231550348.\n",
      "Epoch:6, weight train batch: 120, step:6, loss before: 0.000157746660989, loss after: 0.000157623755513.\n",
      "Epoch:6, weight train batch: 120, step:7, loss before: 0.000163799762959, loss after: 0.000163680582773.\n",
      "Epoch:6, weight train batch: 120, step:8, loss before: 0.000137760187499, loss after: 0.000137633556733.\n",
      "Epoch:6, weight train batch: 120, step:9, loss before: 0.000152275213622, loss after: 0.000152122491272.\n",
      "Epoch:6, weight train batch: 120, step:10, loss before: 0.000166317709954, loss after: 0.000166205994901.\n",
      "Epoch:6, weight train batch: 120, step:11, loss before: 0.000160607669386, loss after: 0.000160514551681.\n",
      "Epoch:6, weight train batch: 120, step:12, loss before: 0.000135736932862, loss after: 0.000135610287543.\n",
      "Epoch:6, weight train batch: 120, step:13, loss before: 0.000177461872227, loss after: 0.000177320354851.\n",
      "Epoch:6, weight train batch: 120, step:14, loss before: 0.00823894701898, loss after: 0.00822640862316.\n",
      "Epoch:6, weight train batch: 120, step:15, loss before: 0.000151537533384, loss after: 0.000151250773342.\n",
      "Epoch:6, weight train batch: 120, step:16, loss before: 0.000142099539516, loss after: 0.000141890981467.\n",
      "Epoch:6, weight train batch: 120, step:17, loss before: 0.000160086026881, loss after: 0.00015985511709.\n",
      "Epoch:6, weight train batch: 120, step:18, loss before: 0.000141995085869, loss after: 0.000141868455103.\n",
      "Epoch:6, weight train batch: 120, step:19, loss before: 0.00807890854776, loss after: 0.00805683061481.\n",
      "Epoch:6, weight train batch: 120, step:20, loss before: 0.000170623141457, loss after: 0.000170138984686.\n",
      "Epoch:6, weight train batch: 120, step:21, loss before: 0.00017643746105, loss after: 0.000175912311533.\n",
      "Epoch:6, weight train batch: 120, step:22, loss before: 0.000131558685098, loss after: 0.000131301698275.\n",
      "Epoch:6, weight train batch: 120, step:23, loss before: 0.000146199992741, loss after: 0.000145902042277.\n",
      "Epoch:6, weight train batch: 120, step:24, loss before: 0.000146721838973, loss after: 0.00014660267334.\n",
      "Epoch:6, weight train batch: 120, step:25, loss before: 0.000173230917426, loss after: 0.000172981381183.\n",
      "Epoch:6, weight train batch: 120, step:26, loss before: 0.000142088450957, loss after: 0.000141857526614.\n",
      "Epoch:6, weight train batch: 120, step:27, loss before: 0.000160168594448, loss after: 0.00015999727475.\n",
      "Epoch:6, weight train batch: 120, step:28, loss before: 0.000149801984662, loss after: 0.000149649291416.\n",
      "Epoch:6, weight train batch: 120, step:29, loss before: 0.000149559884449, loss after: 0.000149328960106.\n",
      "Epoch:6, weight train batch: 120, step:30, loss before: 0.000137462178827, loss after: 0.000137279683258.\n",
      "Epoch:6, weight train batch: 120, step:31, loss before: 0.000163788761711, loss after: 0.000163602555403.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 116, loss before: 0.000151381740579, loss after: 0.000151381740579.\n",
      "Epoch:6, weight train batch: 121, step:0, loss before: 0.00784759689122, loss after: 0.00782973039895.\n",
      "Epoch:6, weight train batch: 121, step:1, loss before: 0.000137309456477, loss after: 0.000137041293783.\n",
      "Epoch:6, weight train batch: 121, step:2, loss before: 0.000178758433321, loss after: 0.000178434420377.\n",
      "Epoch:6, weight train batch: 121, step:3, loss before: 0.000143161218148, loss after: 0.000142919103382.\n",
      "Epoch:6, weight train batch: 121, step:4, loss before: 0.000143701443449, loss after: 0.000143477984238.\n",
      "Epoch:6, weight train batch: 121, step:5, loss before: 0.000157799600856, loss after: 0.000157576141646.\n",
      "Epoch:6, weight train batch: 121, step:6, loss before: 0.000145012323628, loss after: 0.000144792575156.\n",
      "Epoch:6, weight train batch: 121, step:7, loss before: 0.000146591832163, loss after: 0.000146446574945.\n",
      "Epoch:6, weight train batch: 121, step:8, loss before: 0.000137652095873, loss after: 0.000137436072691.\n",
      "Epoch:6, weight train batch: 121, step:9, loss before: 0.000146197242429, loss after: 0.000146011007018.\n",
      "Epoch:6, weight train batch: 121, step:10, loss before: 0.000161178089911, loss after: 0.000161021656822.\n",
      "Epoch:6, weight train batch: 121, step:11, loss before: 0.000157888964168, loss after: 0.000157702743309.\n",
      "Epoch:6, weight train batch: 121, step:12, loss before: 0.000145313912071, loss after: 0.000145194731886.\n",
      "Epoch:6, weight train batch: 121, step:13, loss before: 0.000156164533109, loss after: 0.000155978297698.\n",
      "Epoch:6, weight train batch: 121, step:14, loss before: 0.000151415209984, loss after: 0.000151269952767.\n",
      "Epoch:6, weight train batch: 121, step:15, loss before: 0.000154674926307, loss after: 0.000154511042638.\n",
      "Epoch:6, weight train batch: 121, step:16, loss before: 0.00016736111138, loss after: 0.000167200953001.\n",
      "Epoch:6, weight train batch: 121, step:17, loss before: 0.000143116660183, loss after: 0.000143016077345.\n",
      "Epoch:6, weight train batch: 121, step:18, loss before: 0.000142904144013, loss after: 0.000142725359183.\n",
      "Epoch:6, weight train batch: 121, step:19, loss before: 0.000119419870316, loss after: 0.00011932302732.\n",
      "Epoch:6, weight train batch: 121, step:20, loss before: 0.000154056251631, loss after: 0.00015389235341.\n",
      "Epoch:6, weight train batch: 121, step:21, loss before: 0.000151966582052, loss after: 0.000151843691128.\n",
      "Epoch:6, weight train batch: 121, step:22, loss before: 0.000162444164744, loss after: 0.000162287731655.\n",
      "Epoch:6, weight train batch: 121, step:23, loss before: 0.000192869774764, loss after: 0.000192739462364.\n",
      "Epoch:6, weight train batch: 121, step:24, loss before: 0.00759127549827, loss after: 0.00757933733985.\n",
      "Epoch:6, weight train batch: 121, step:25, loss before: 0.000144141042256, loss after: 0.000143951081554.\n",
      "Epoch:6, weight train batch: 121, step:26, loss before: 0.00013554430916, loss after: 0.000135328285978.\n",
      "Epoch:6, weight train batch: 121, step:27, loss before: 0.000146394537296, loss after: 0.000146193400724.\n",
      "Epoch:6, weight train batch: 121, step:28, loss before: 0.000172367173946, loss after: 0.000172143700183.\n",
      "Epoch:6, weight train batch: 121, step:29, loss before: 0.000153862521984, loss after: 0.000153642773512.\n",
      "Epoch:6, weight train batch: 121, step:30, loss before: 0.000148040940985, loss after: 0.000147877057316.\n",
      "Epoch:6, weight train batch: 121, step:31, loss before: 0.000145027443068, loss after: 0.000144852383528.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 117, loss before: 0.000149095954839, loss after: 0.000149095954839.\n",
      "Epoch:6, weight train batch: 122, step:0, loss before: 0.00016654538922, loss after: 0.000166359168361.\n",
      "Epoch:6, weight train batch: 122, step:1, loss before: 0.000131357563077, loss after: 0.000131253269501.\n",
      "Epoch:6, weight train batch: 122, step:2, loss before: 0.000138173782034, loss after: 0.000137972645462.\n",
      "Epoch:6, weight train batch: 122, step:3, loss before: 0.000166858633747, loss after: 0.000166705925949.\n",
      "Epoch:6, weight train batch: 122, step:4, loss before: 0.000153203087393, loss after: 0.000153042914462.\n",
      "Epoch:6, weight train batch: 122, step:5, loss before: 0.000174840795808, loss after: 0.000174654574948.\n",
      "Epoch:6, weight train batch: 122, step:6, loss before: 0.000138364091981, loss after: 0.000138192757731.\n",
      "Epoch:6, weight train batch: 122, step:7, loss before: 0.000161803895026, loss after: 0.000161632560776.\n",
      "Epoch:6, weight train batch: 122, step:8, loss before: 0.000139582174597, loss after: 0.000139503958053.\n",
      "Epoch:6, weight train batch: 122, step:9, loss before: 0.000158667477081, loss after: 0.000158511043992.\n",
      "Epoch:6, weight train batch: 122, step:10, loss before: 0.000141306605656, loss after: 0.000141161348438.\n",
      "Epoch:6, weight train batch: 122, step:11, loss before: 0.000169514911249, loss after: 0.000169347316842.\n",
      "Epoch:6, weight train batch: 122, step:12, loss before: 0.000164649594808, loss after: 0.00016454528668.\n",
      "Epoch:6, weight train batch: 122, step:13, loss before: 0.000149184488691, loss after: 0.000149028055603.\n",
      "Epoch:6, weight train batch: 122, step:14, loss before: 0.000167539983522, loss after: 0.000167376099853.\n",
      "Epoch:6, weight train batch: 122, step:15, loss before: 0.000134602480102, loss after: 0.000134475834784.\n",
      "Epoch:6, weight train batch: 122, step:16, loss before: 0.000138300354593, loss after: 0.000138166273246.\n",
      "Epoch:6, weight train batch: 122, step:17, loss before: 0.000140282339999, loss after: 0.000140155709232.\n",
      "Epoch:6, weight train batch: 122, step:18, loss before: 0.000136524118716, loss after: 0.000136356509756.\n",
      "Epoch:6, weight train batch: 122, step:19, loss before: 0.000146271893755, loss after: 0.000146137812408.\n",
      "Epoch:6, weight train batch: 122, step:20, loss before: 0.000126794941025, loss after: 0.00012671299919.\n",
      "Epoch:6, weight train batch: 122, step:21, loss before: 0.000409036583733, loss after: 0.000408503954532.\n",
      "Epoch:6, weight train batch: 122, step:22, loss before: 0.000143396202475, loss after: 0.000143254641443.\n",
      "Epoch:6, weight train batch: 122, step:23, loss before: 0.000208489276702, loss after: 0.000208344077691.\n",
      "Epoch:6, weight train batch: 122, step:24, loss before: 0.000129227395519, loss after: 0.000129138003103.\n",
      "Epoch:6, weight train batch: 122, step:25, loss before: 0.000154533219757, loss after: 0.000154406574438.\n",
      "Epoch:6, weight train batch: 122, step:26, loss before: 0.000137741983053, loss after: 0.000137622788316.\n",
      "Epoch:6, weight train batch: 122, step:27, loss before: 0.000137801573146, loss after: 0.000137652590638.\n",
      "Epoch:6, weight train batch: 122, step:28, loss before: 0.000143302851939, loss after: 0.000143239536555.\n",
      "Epoch:6, weight train batch: 122, step:29, loss before: 0.00015679434, loss after: 0.000156637921464.\n",
      "Epoch:6, weight train batch: 122, step:30, loss before: 0.000155032466864, loss after: 0.000154935623868.\n",
      "Epoch:6, weight train batch: 122, step:31, loss before: 0.000139388212119, loss after: 0.000139231764479.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 118, loss before: 0.000146013844642, loss after: 0.000145581812831.\n",
      "Epoch:6, weight train batch: 123, step:0, loss before: 0.000131160195451, loss after: 0.000131081964355.\n",
      "Epoch:6, weight train batch: 123, step:1, loss before: 0.000157274596859, loss after: 0.000157133064931.\n",
      "Epoch:6, weight train batch: 123, step:2, loss before: 0.000155919071403, loss after: 0.000155818503117.\n",
      "Epoch:6, weight train batch: 123, step:3, loss before: 0.000134874062496, loss after: 0.000134732516017.\n",
      "Epoch:6, weight train batch: 123, step:4, loss before: 0.000152734399308, loss after: 0.000152607768541.\n",
      "Epoch:6, weight train batch: 123, step:5, loss before: 0.000141559925396, loss after: 0.000141470547533.\n",
      "Epoch:6, weight train batch: 123, step:6, loss before: 0.000122492638184, loss after: 0.000122343655676.\n",
      "Epoch:6, weight train batch: 123, step:7, loss before: 0.000133901572553, loss after: 0.000133823356009.\n",
      "Epoch:6, weight train batch: 123, step:8, loss before: 0.000159330695169, loss after: 0.000159200339112.\n",
      "Epoch:6, weight train batch: 123, step:9, loss before: 0.000196230103029, loss after: 0.00019610353047.\n",
      "Epoch:6, weight train batch: 123, step:10, loss before: 0.000153226195835, loss after: 0.000153088389197.\n",
      "Epoch:6, weight train batch: 123, step:11, loss before: 0.00014526261657, loss after: 0.000145121099195.\n",
      "Epoch:6, weight train batch: 123, step:12, loss before: 0.000134054629598, loss after: 0.000133935420308.\n",
      "Epoch:6, weight train batch: 123, step:13, loss before: 0.000126370199723, loss after: 0.000126265906147.\n",
      "Epoch:6, weight train batch: 123, step:14, loss before: 0.000146435835632, loss after: 0.000146338992636.\n",
      "Epoch:6, weight train batch: 123, step:15, loss before: 0.000131327891722, loss after: 0.000131238499307.\n",
      "Epoch:6, weight train batch: 123, step:16, loss before: 0.000125372200273, loss after: 0.000125282793306.\n",
      "Epoch:6, weight train batch: 123, step:17, loss before: 0.000152149063069, loss after: 0.000152037362568.\n",
      "Epoch:6, weight train batch: 123, step:18, loss before: 0.000132360117277, loss after: 0.000132240907988.\n",
      "Epoch:6, weight train batch: 123, step:19, loss before: 0.000166381752933, loss after: 0.000166296085808.\n",
      "Epoch:6, weight train batch: 123, step:20, loss before: 0.000143221011967, loss after: 0.00014310554252.\n",
      "Epoch:6, weight train batch: 123, step:21, loss before: 0.000147899321746, loss after: 0.00014777641627.\n",
      "Epoch:6, weight train batch: 123, step:22, loss before: 0.000140923133586, loss after: 0.0001408039534.\n",
      "Epoch:6, weight train batch: 123, step:23, loss before: 0.000619713799097, loss after: 0.000618934747763.\n",
      "Epoch:6, weight train batch: 123, step:24, loss before: 0.000140710850246, loss after: 0.000140591640957.\n",
      "Epoch:6, weight train batch: 123, step:25, loss before: 0.000123986799736, loss after: 0.000123893667478.\n",
      "Epoch:6, weight train batch: 123, step:26, loss before: 0.000127782084746, loss after: 0.000127633087686.\n",
      "Epoch:6, weight train batch: 123, step:27, loss before: 0.000133730674861, loss after: 0.000133637571707.\n",
      "Epoch:6, weight train batch: 123, step:28, loss before: 0.000118916810607, loss after: 0.000118797615869.\n",
      "Epoch:6, weight train batch: 123, step:29, loss before: 0.000147001890582, loss after: 0.000146908772876.\n",
      "Epoch:6, weight train batch: 123, step:30, loss before: 0.000136088128784, loss after: 0.000136006201501.\n",
      "Epoch:6, weight train batch: 123, step:31, loss before: 0.000144674064359, loss after: 0.000144577206811.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 119, loss before: 0.000212022903725, loss after: 0.000137037161039.\n",
      "Epoch:6, weight train batch: 124, step:0, loss before: 0.000113158479508, loss after: 0.00011303928477.\n",
      "Epoch:6, weight train batch: 124, step:1, loss before: 0.00012304019765, loss after: 0.000122943369206.\n",
      "Epoch:6, weight train batch: 124, step:2, loss before: 0.000136874179589, loss after: 0.000136781047331.\n",
      "Epoch:6, weight train batch: 124, step:3, loss before: 0.000129990861751, loss after: 0.000129834428662.\n",
      "Epoch:6, weight train batch: 124, step:4, loss before: 0.000125789723825, loss after: 0.000125689140987.\n",
      "Epoch:6, weight train batch: 124, step:5, loss before: 0.000123595469631, loss after: 0.000123509787954.\n",
      "Epoch:6, weight train batch: 124, step:6, loss before: 0.00013406551443, loss after: 0.000134005909786.\n",
      "Epoch:6, weight train batch: 124, step:7, loss before: 0.000413113244576, loss after: 0.000412746681832.\n",
      "Epoch:6, weight train batch: 124, step:8, loss before: 0.000413308909629, loss after: 0.000412562047131.\n",
      "Epoch:6, weight train batch: 124, step:9, loss before: 0.00015959556913, loss after: 0.000159543415066.\n",
      "Epoch:6, weight train batch: 124, step:10, loss before: 0.000150376625243, loss after: 0.000150257445057.\n",
      "Epoch:6, weight train batch: 124, step:11, loss before: 0.000144230623846, loss after: 0.00014413378085.\n",
      "Epoch:6, weight train batch: 124, step:12, loss before: 0.000130158747197, loss after: 0.000130061918753.\n",
      "Epoch:6, weight train batch: 124, step:13, loss before: 0.000145541824168, loss after: 0.000145404002978.\n",
      "Epoch:6, weight train batch: 124, step:14, loss before: 0.00014007401478, loss after: 0.000139954805491.\n",
      "Epoch:6, weight train batch: 124, step:15, loss before: 0.000604220374953, loss after: 0.000603668740951.\n",
      "Epoch:6, weight train batch: 124, step:16, loss before: 0.00013334324467, loss after: 0.000133209134219.\n",
      "Epoch:6, weight train batch: 124, step:17, loss before: 0.000127580831759, loss after: 0.000127498904476.\n",
      "Epoch:6, weight train batch: 124, step:18, loss before: 0.000142211720231, loss after: 0.000142051561852.\n",
      "Epoch:6, weight train batch: 124, step:19, loss before: 0.000139366311487, loss after: 0.000139269468491.\n",
      "Epoch:6, weight train batch: 124, step:20, loss before: 0.000136408692924, loss after: 0.000136293223477.\n",
      "Epoch:6, weight train batch: 124, step:21, loss before: 0.000139135387144, loss after: 0.000138993840665.\n",
      "Epoch:6, weight train batch: 124, step:22, loss before: 0.000398767180741, loss after: 0.000398522475734.\n",
      "Epoch:6, weight train batch: 124, step:23, loss before: 0.000140185395139, loss after: 0.000140066200402.\n",
      "Epoch:6, weight train batch: 124, step:24, loss before: 0.000134669142426, loss after: 0.000134520145366.\n",
      "Epoch:6, weight train batch: 124, step:25, loss before: 0.000149795712787, loss after: 0.000149695144501.\n",
      "Epoch:6, weight train batch: 124, step:26, loss before: 0.000155025161803, loss after: 0.000154902241775.\n",
      "Epoch:6, weight train batch: 124, step:27, loss before: 0.00010869208927, loss after: 0.000108550550067.\n",
      "Epoch:6, weight train batch: 124, step:28, loss before: 0.00039403673145, loss after: 0.000393769762013.\n",
      "Epoch:6, weight train batch: 124, step:29, loss before: 0.00019641011022, loss after: 0.000196257475181.\n",
      "Epoch:6, weight train batch: 124, step:30, loss before: 0.000129569874844, loss after: 0.000129432068206.\n",
      "Epoch:6, weight train batch: 124, step:31, loss before: 0.000126575003378, loss after: 0.000126500497572.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 120, loss before: 0.000145252502989, loss after: 0.000139183655847.\n",
      "Epoch:6, weight train batch: 125, step:0, loss before: 0.000130389424157, loss after: 0.000130281405291.\n",
      "Epoch:6, weight train batch: 125, step:1, loss before: 0.000128214276629, loss after: 0.000128117433633.\n",
      "Epoch:6, weight train batch: 125, step:2, loss before: 0.000139459370985, loss after: 0.000139366253279.\n",
      "Epoch:6, weight train batch: 125, step:3, loss before: 0.00451156171039, loss after: 0.00450923619792.\n",
      "Epoch:6, weight train batch: 125, step:4, loss before: 0.000130121246912, loss after: 0.000130002052174.\n",
      "Epoch:6, weight train batch: 125, step:5, loss before: 0.000138355884701, loss after: 0.000138195740874.\n",
      "Epoch:6, weight train batch: 125, step:6, loss before: 0.000118704789202, loss after: 0.000118641481095.\n",
      "Epoch:6, weight train batch: 125, step:7, loss before: 0.000148503109813, loss after: 0.000148339226143.\n",
      "Epoch:6, weight train batch: 125, step:8, loss before: 0.000145229045302, loss after: 0.000145124751725.\n",
      "Epoch:6, weight train batch: 125, step:9, loss before: 0.00012612460705, loss after: 0.000126009137603.\n",
      "Epoch:6, weight train batch: 125, step:10, loss before: 0.00012393083307, loss after: 0.000123819088913.\n",
      "Epoch:6, weight train batch: 125, step:11, loss before: 0.000180625997018, loss after: 0.000180469665793.\n",
      "Epoch:6, weight train batch: 125, step:12, loss before: 0.000152954584337, loss after: 0.000152835389599.\n",
      "Epoch:6, weight train batch: 125, step:13, loss before: 0.000141347874887, loss after: 0.000141221244121.\n",
      "Epoch:6, weight train batch: 125, step:14, loss before: 0.000145623998833, loss after: 0.000145504804095.\n",
      "Epoch:6, weight train batch: 125, step:15, loss before: 0.000138070085086, loss after: 0.000137984417961.\n",
      "Epoch:6, weight train batch: 125, step:16, loss before: 0.000132967106765, loss after: 0.000132836750709.\n",
      "Epoch:6, weight train batch: 125, step:17, loss before: 0.000142249366036, loss after: 0.000142130156746.\n",
      "Epoch:6, weight train batch: 125, step:18, loss before: 0.000125167818624, loss after: 0.00012510077795.\n",
      "Epoch:6, weight train batch: 125, step:19, loss before: 0.000208677345654, loss after: 0.000208543322515.\n",
      "Epoch:6, weight train batch: 125, step:20, loss before: 0.000136989940074, loss after: 0.000136826041853.\n",
      "Epoch:6, weight train batch: 125, step:21, loss before: 0.000135123918881, loss after: 0.000135019625304.\n",
      "Epoch:6, weight train batch: 125, step:22, loss before: 0.000133421635837, loss after: 0.000133362045744.\n",
      "Epoch:6, weight train batch: 125, step:23, loss before: 0.000131138163852, loss after: 0.000130985441501.\n",
      "Epoch:6, weight train batch: 125, step:24, loss before: 0.000136926595587, loss after: 0.000136833492434.\n",
      "Epoch:6, weight train batch: 125, step:25, loss before: 0.000128888495965, loss after: 0.000128799118102.\n",
      "Epoch:6, weight train batch: 125, step:26, loss before: 0.000141834971146, loss after: 0.000141730706673.\n",
      "Epoch:6, weight train batch: 125, step:27, loss before: 0.000367322936654, loss after: 0.000366878783097.\n",
      "Epoch:6, weight train batch: 125, step:28, loss before: 0.00015473147505, loss after: 0.000154597393703.\n",
      "Epoch:6, weight train batch: 125, step:29, loss before: 0.000143750483403, loss after: 0.000143653654959.\n",
      "Epoch:6, weight train batch: 125, step:30, loss before: 0.000605771900155, loss after: 0.00060518598184.\n",
      "Epoch:6, weight train batch: 125, step:31, loss before: 0.000126467493828, loss after: 0.000126374361571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 121, loss before: 0.000134629415697, loss after: 0.000134629415697.\n",
      "Epoch:6, weight train batch: 126, step:0, loss before: 0.000135179594508, loss after: 0.000135105103254.\n",
      "Epoch:6, weight train batch: 126, step:1, loss before: 0.00014191797527, loss after: 0.000141817406984.\n",
      "Epoch:6, weight train batch: 126, step:2, loss before: 0.000582629349083, loss after: 0.000581882020924.\n",
      "Epoch:6, weight train batch: 126, step:3, loss before: 0.0391261167824, loss after: 0.0389951318502.\n",
      "Epoch:6, weight train batch: 126, step:4, loss before: 0.000124951446196, loss after: 0.000125495280372.\n",
      "Epoch:6, weight train batch: 126, step:5, loss before: 0.000143851095345, loss after: 0.00014443587861.\n",
      "Epoch:6, weight train batch: 126, step:6, loss before: 0.000123498641187, loss after: 0.000124191486975.\n",
      "Epoch:6, weight train batch: 126, step:7, loss before: 0.000127018778585, loss after: 0.000127666920889.\n",
      "Epoch:6, weight train batch: 126, step:8, loss before: 0.000121744553326, loss after: 0.000122597557493.\n",
      "Epoch:6, weight train batch: 126, step:9, loss before: 0.000376962270821, loss after: 0.000377966323867.\n",
      "Epoch:6, weight train batch: 126, step:10, loss before: 0.000157495465828, loss after: 0.000158102629939.\n",
      "Epoch:6, weight train batch: 126, step:11, loss before: 0.000135812966619, loss after: 0.00013632698392.\n",
      "Epoch:6, weight train batch: 126, step:12, loss before: 0.000104908031062, loss after: 0.00010532894521.\n",
      "Epoch:6, weight train batch: 126, step:13, loss before: 0.000147818063851, loss after: 0.000148089980939.\n",
      "Epoch:6, weight train batch: 126, step:14, loss before: 0.000143754557939, loss after: 0.000144000397995.\n",
      "Epoch:6, weight train batch: 126, step:15, loss before: 0.000118578318506, loss after: 0.000118812975415.\n",
      "Epoch:6, weight train batch: 126, step:16, loss before: 0.000140562304296, loss after: 0.000140718737384.\n",
      "Epoch:6, weight train batch: 126, step:17, loss before: 0.000153926637722, loss after: 0.000153937828145.\n",
      "Epoch:6, weight train batch: 126, step:18, loss before: 0.000140892690979, loss after: 0.0001410752011.\n",
      "Epoch:6, weight train batch: 126, step:19, loss before: 0.000140528136399, loss after: 0.000140490898048.\n",
      "Epoch:6, weight train batch: 126, step:20, loss before: 0.000194333784748, loss after: 0.00019437847368.\n",
      "Epoch:6, weight train batch: 126, step:21, loss before: 0.000158310795086, loss after: 0.000158321985509.\n",
      "Epoch:6, weight train batch: 126, step:22, loss before: 0.000177553214598, loss after: 0.000177497393452.\n",
      "Epoch:6, weight train batch: 126, step:23, loss before: 0.000132476212457, loss after: 0.000132561894134.\n",
      "Epoch:6, weight train batch: 126, step:24, loss before: 0.000142014760058, loss after: 0.000141970071127.\n",
      "Epoch:6, weight train batch: 126, step:25, loss before: 0.00014010394807, loss after: 0.00014005927369.\n",
      "Epoch:6, weight train batch: 126, step:26, loss before: 0.000137064605951, loss after: 0.000137001290568.\n",
      "Epoch:6, weight train batch: 126, step:27, loss before: 0.000153137283633, loss after: 0.000153055341798.\n",
      "Epoch:6, weight train batch: 126, step:28, loss before: 0.000147434242535, loss after: 0.000147374637891.\n",
      "Epoch:6, weight train batch: 126, step:29, loss before: 0.000131827662699, loss after: 0.000131723354571.\n",
      "Epoch:6, weight train batch: 126, step:30, loss before: 0.000144379868289, loss after: 0.000144335179357.\n",
      "Epoch:6, weight train batch: 126, step:31, loss before: 0.000135969370604, loss after: 0.000135850190418.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 122, loss before: 0.000140053947689, loss after: 0.000134369664011.\n",
      "Epoch:6, weight train batch: 127, step:0, loss before: 0.000130218017148, loss after: 0.000130117448862.\n",
      "Epoch:6, weight train batch: 127, step:1, loss before: 0.0381263196468, loss after: 0.0380809679627.\n",
      "Epoch:6, weight train batch: 127, step:2, loss before: 0.000177026042365, loss after: 0.000177026129677.\n",
      "Epoch:6, weight train batch: 127, step:3, loss before: 0.000161230986123, loss after: 0.000161584815942.\n",
      "Epoch:6, weight train batch: 127, step:4, loss before: 0.000135298963869, loss after: 0.000135392067023.\n",
      "Epoch:6, weight train batch: 127, step:5, loss before: 0.000145508631249, loss after: 0.000145683676237.\n",
      "Epoch:6, weight train batch: 127, step:6, loss before: 0.000127044666442, loss after: 0.000127096805954.\n",
      "Epoch:6, weight train batch: 127, step:7, loss before: 0.000125182268675, loss after: 0.000125130114611.\n",
      "Epoch:6, weight train batch: 127, step:8, loss before: 0.000145788158989, loss after: 0.000145803045598.\n",
      "Epoch:6, weight train batch: 127, step:9, loss before: 0.000142636752571, loss after: 0.000142584598507.\n",
      "Epoch:6, weight train batch: 127, step:10, loss before: 0.000134427362354, loss after: 0.000134393849294.\n",
      "Epoch:6, weight train batch: 127, step:11, loss before: 0.000155669942615, loss after: 0.000155718371389.\n",
      "Epoch:6, weight train batch: 127, step:12, loss before: 0.000140900985571, loss after: 0.000140860007377.\n",
      "Epoch:6, weight train batch: 127, step:13, loss before: 0.00014166503388, loss after: 0.000141594253364.\n",
      "Epoch:6, weight train batch: 127, step:14, loss before: 0.000147322760313, loss after: 0.000147207290865.\n",
      "Epoch:6, weight train batch: 127, step:15, loss before: 0.000139545227285, loss after: 0.00013948562264.\n",
      "Epoch:6, weight train batch: 127, step:16, loss before: 0.000156671536388, loss after: 0.000156600770424.\n",
      "Epoch:6, weight train batch: 127, step:17, loss before: 0.000152980879648, loss after: 0.000152854248881.\n",
      "Epoch:6, weight train batch: 127, step:18, loss before: 0.00012217235053, loss after: 0.000122120196465.\n",
      "Epoch:6, weight train batch: 127, step:19, loss before: 0.000138293835334, loss after: 0.000138133662404.\n",
      "Epoch:6, weight train batch: 127, step:20, loss before: 0.000139061012305, loss after: 0.000138971634442.\n",
      "Epoch:6, weight train batch: 127, step:21, loss before: 0.000123789621284, loss after: 0.000123666686704.\n",
      "Epoch:6, weight train batch: 127, step:22, loss before: 0.000127037346829, loss after: 0.000126925617224.\n",
      "Epoch:6, weight train batch: 127, step:23, loss before: 0.00465384684503, loss after: 0.00463846325874.\n",
      "Epoch:6, weight train batch: 127, step:24, loss before: 0.000218775472604, loss after: 0.000218362140004.\n",
      "Epoch:6, weight train batch: 127, step:25, loss before: 0.000142283271998, loss after: 0.000142022545333.\n",
      "Epoch:6, weight train batch: 127, step:26, loss before: 0.00014638392895, loss after: 0.000145914644236.\n",
      "Epoch:6, weight train batch: 127, step:27, loss before: 0.000134173940751, loss after: 0.000133808935061.\n",
      "Epoch:6, weight train batch: 127, step:28, loss before: 0.000153621396748, loss after: 0.000153263841639.\n",
      "Epoch:6, weight train batch: 127, step:29, loss before: 0.00014630248188, loss after: 0.000146049220348.\n",
      "Epoch:6, weight train batch: 127, step:30, loss before: 0.00013732946536, loss after: 0.000137165567139.\n",
      "Epoch:6, weight train batch: 127, step:31, loss before: 0.000156273701577, loss after: 0.000156076304847.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 123, loss before: 0.000138591145515, loss after: 0.00013864794164.\n",
      "Epoch:6, weight train batch: 128, step:0, loss before: 0.000145743513713, loss after: 0.000145564728882.\n",
      "Epoch:6, weight train batch: 128, step:1, loss before: 0.000135023627081, loss after: 0.000134885805892.\n",
      "Epoch:6, weight train batch: 128, step:2, loss before: 0.000134904374136, loss after: 0.000134814967168.\n",
      "Epoch:6, weight train batch: 128, step:3, loss before: 0.000142972305184, loss after: 0.000142782344483.\n",
      "Epoch:6, weight train batch: 128, step:4, loss before: 0.000140900665428, loss after: 0.000140803836985.\n",
      "Epoch:6, weight train batch: 128, step:5, loss before: 0.000132788496558, loss after: 0.000132646950078.\n",
      "Epoch:6, weight train batch: 128, step:6, loss before: 0.000147833270603, loss after: 0.000147732716869.\n",
      "Epoch:6, weight train batch: 128, step:7, loss before: 0.00014089877368, loss after: 0.000140712538268.\n",
      "Epoch:6, weight train batch: 128, step:8, loss before: 0.000127808321849, loss after: 0.000127700317535.\n",
      "Epoch:6, weight train batch: 128, step:9, loss before: 0.000124948448502, loss after: 0.000124769663671.\n",
      "Epoch:6, weight train batch: 128, step:10, loss before: 0.000125719059724, loss after: 0.000125629681861.\n",
      "Epoch:6, weight train batch: 128, step:11, loss before: 0.0374830588698, loss after: 0.0374424643815.\n",
      "Epoch:6, weight train batch: 128, step:12, loss before: 0.000126992614241, loss after: 0.000126985163661.\n",
      "Epoch:6, weight train batch: 128, step:13, loss before: 0.000201320741326, loss after: 0.00020161048451.\n",
      "Epoch:6, weight train batch: 128, step:14, loss before: 0.00720465555787, loss after: 0.00719753745943.\n",
      "Epoch:6, weight train batch: 128, step:15, loss before: 0.000124772719573, loss after: 0.000124590209452.\n",
      "Epoch:6, weight train batch: 128, step:16, loss before: 0.00013481498172, loss after: 0.000134628746309.\n",
      "Epoch:6, weight train batch: 128, step:17, loss before: 0.000130714019178, loss after: 0.00013058364857.\n",
      "Epoch:6, weight train batch: 128, step:18, loss before: 0.000133615656523, loss after: 0.000133436857141.\n",
      "Epoch:6, weight train batch: 128, step:19, loss before: 0.000198107911274, loss after: 0.000197895788006.\n",
      "Epoch:6, weight train batch: 128, step:20, loss before: 0.000145713886013, loss after: 0.00014550529886.\n",
      "Epoch:6, weight train batch: 128, step:21, loss before: 0.000129764026497, loss after: 0.000129622494569.\n",
      "Epoch:6, weight train batch: 128, step:22, loss before: 0.000134870919283, loss after: 0.000134714471642.\n",
      "Epoch:6, weight train batch: 128, step:23, loss before: 0.000138934643473, loss after: 0.000138796836836.\n",
      "Epoch:6, weight train batch: 128, step:24, loss before: 0.000143556913827, loss after: 0.000143415367347.\n",
      "Epoch:6, weight train batch: 128, step:25, loss before: 0.00014094990911, loss after: 0.000140830728924.\n",
      "Epoch:6, weight train batch: 128, step:26, loss before: 0.000114403053885, loss after: 0.000114280133857.\n",
      "Epoch:6, weight train batch: 128, step:27, loss before: 0.000139485957334, loss after: 0.00013938912889.\n",
      "Epoch:6, weight train batch: 128, step:28, loss before: 0.000126091443235, loss after: 0.000125886581372.\n",
      "Epoch:6, weight train batch: 128, step:29, loss before: 0.000137649651151, loss after: 0.000137556518894.\n",
      "Epoch:6, weight train batch: 128, step:30, loss before: 0.00013837980805, loss after: 0.000138242001412.\n",
      "Epoch:6, weight train batch: 128, step:31, loss before: 0.000137049952173, loss after: 0.000136930757435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 124, loss before: 0.000139591924381, loss after: 0.000267811235972.\n",
      "Epoch:6, weight train batch: 129, step:0, loss before: 0.000104830221971, loss after: 0.000104703576653.\n",
      "Epoch:6, weight train batch: 129, step:1, loss before: 0.0001456020982, loss after: 0.000145468016854.\n",
      "Epoch:6, weight train batch: 129, step:2, loss before: 0.000141493655974, loss after: 0.000141340962728.\n",
      "Epoch:6, weight train batch: 129, step:3, loss before: 0.000129134918097, loss after: 0.000129019463202.\n",
      "Epoch:6, weight train batch: 129, step:4, loss before: 0.000381306512281, loss after: 0.000380773650249.\n",
      "Epoch:6, weight train batch: 129, step:5, loss before: 0.000138547315146, loss after: 0.000138409493957.\n",
      "Epoch:6, weight train batch: 129, step:6, loss before: 0.000128616869915, loss after: 0.000128475337988.\n",
      "Epoch:6, weight train batch: 129, step:7, loss before: 0.00012184894149, loss after: 0.000121729746752.\n",
      "Epoch:6, weight train batch: 129, step:8, loss before: 0.000139609153848, loss after: 0.000139452720759.\n",
      "Epoch:6, weight train batch: 129, step:9, loss before: 0.00014224628103, loss after: 0.000142141987453.\n",
      "Epoch:6, weight train batch: 129, step:10, loss before: 0.000144209072459, loss after: 0.000144089892274.\n",
      "Epoch:6, weight train batch: 129, step:11, loss before: 0.000140167350764, loss after: 0.000140014628414.\n",
      "Epoch:6, weight train batch: 129, step:12, loss before: 0.00012908608187, loss after: 0.000128966887132.\n",
      "Epoch:6, weight train batch: 129, step:13, loss before: 0.000142074859468, loss after: 0.000141974291182.\n",
      "Epoch:6, weight train batch: 129, step:14, loss before: 0.000123476726003, loss after: 0.000123320292914.\n",
      "Epoch:6, weight train batch: 129, step:15, loss before: 0.000122888217447, loss after: 0.00012274668552.\n",
      "Epoch:6, weight train batch: 129, step:16, loss before: 0.000130978572997, loss after: 0.00013085937826.\n",
      "Epoch:6, weight train batch: 129, step:17, loss before: 0.000143924960867, loss after: 0.00014379460481.\n",
      "Epoch:6, weight train batch: 129, step:18, loss before: 0.000140771124279, loss after: 0.00014065191499.\n",
      "Epoch:6, weight train batch: 129, step:19, loss before: 0.000115647169878, loss after: 0.000115520531836.\n",
      "Epoch:6, weight train batch: 129, step:20, loss before: 0.000154721899889, loss after: 0.000154610170284.\n",
      "Epoch:6, weight train batch: 129, step:21, loss before: 0.000134442481794, loss after: 0.000134293484734.\n",
      "Epoch:6, weight train batch: 129, step:22, loss before: 0.000119755452033, loss after: 0.000119643707876.\n",
      "Epoch:6, weight train batch: 129, step:23, loss before: 0.000125000369735, loss after: 0.000124881189549.\n",
      "Epoch:6, weight train batch: 129, step:24, loss before: 0.000125394886709, loss after: 0.000125309219584.\n",
      "Epoch:6, weight train batch: 129, step:25, loss before: 0.000121815253806, loss after: 0.000121669982036.\n",
      "Epoch:6, weight train batch: 129, step:26, loss before: 0.000127801249619, loss after: 0.000127711857203.\n",
      "Epoch:6, weight train batch: 129, step:27, loss before: 0.000138804476592, loss after: 0.000138670395245.\n",
      "Epoch:6, weight train batch: 129, step:28, loss before: 0.00447052158415, loss after: 0.00446847919375.\n",
      "Epoch:6, weight train batch: 129, step:29, loss before: 0.000116399532999, loss after: 0.00011633621034.\n",
      "Epoch:6, weight train batch: 129, step:30, loss before: 0.000119490949146, loss after: 0.000119330783491.\n",
      "Epoch:6, weight train batch: 129, step:31, loss before: 0.000122612400446, loss after: 0.000122478304547.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 125, loss before: 0.000203238610993, loss after: 0.00928557384759.\n",
      "Epoch:6, weight train batch: 130, step:0, loss before: 0.000109515800432, loss after: 0.000109430140583.\n",
      "Epoch:6, weight train batch: 130, step:1, loss before: 0.000141475262353, loss after: 0.000141326294397.\n",
      "Epoch:6, weight train batch: 130, step:2, loss before: 0.000121696342831, loss after: 0.000121633012895.\n",
      "Epoch:6, weight train batch: 130, step:3, loss before: 0.000129492342239, loss after: 0.000129343359731.\n",
      "Epoch:6, weight train batch: 130, step:4, loss before: 0.000131000764668, loss after: 0.000130874133902.\n",
      "Epoch:6, weight train batch: 130, step:5, loss before: 0.000139199139085, loss after: 0.000139106006827.\n",
      "Epoch:6, weight train batch: 130, step:6, loss before: 0.000126728569739, loss after: 0.000126579572679.\n",
      "Epoch:6, weight train batch: 130, step:7, loss before: 0.00012672090088, loss after: 0.00012657562911.\n",
      "Epoch:6, weight train batch: 130, step:8, loss before: 0.000132509172545, loss after: 0.000132412329549.\n",
      "Epoch:6, weight train batch: 130, step:9, loss before: 0.000111460401968, loss after: 0.000111356101115.\n",
      "Epoch:6, weight train batch: 130, step:10, loss before: 0.000126359591377, loss after: 0.000126273924252.\n",
      "Epoch:6, weight train batch: 130, step:11, loss before: 0.000122392753838, loss after: 0.00012225122191.\n",
      "Epoch:6, weight train batch: 130, step:12, loss before: 0.000131362394313, loss after: 0.000131232023705.\n",
      "Epoch:6, weight train batch: 130, step:13, loss before: 0.000138044531923, loss after: 0.000137902985443.\n",
      "Epoch:6, weight train batch: 130, step:14, loss before: 0.000128103012685, loss after: 0.000127980107209.\n",
      "Epoch:6, weight train batch: 130, step:15, loss before: 0.000123160221847, loss after: 0.000123093166621.\n",
      "Epoch:6, weight train batch: 130, step:16, loss before: 0.00012419167615, loss after: 0.000124035243061.\n",
      "Epoch:6, weight train batch: 130, step:17, loss before: 0.000133492969326, loss after: 0.00013339240104.\n",
      "Epoch:6, weight train batch: 130, step:18, loss before: 0.000122601137264, loss after: 0.000122515455587.\n",
      "Epoch:6, weight train batch: 130, step:19, loss before: 0.000130349071696, loss after: 0.000130170272314.\n",
      "Epoch:6, weight train batch: 130, step:20, loss before: 0.000132554137963, loss after: 0.000132461020257.\n",
      "Epoch:6, weight train batch: 130, step:21, loss before: 0.000125466001919, loss after: 0.000125369144371.\n",
      "Epoch:6, weight train batch: 130, step:22, loss before: 0.000122996250866, loss after: 0.000122877056128.\n",
      "Epoch:6, weight train batch: 130, step:23, loss before: 0.000104256461782, loss after: 0.000104181970528.\n",
      "Epoch:6, weight train batch: 130, step:24, loss before: 0.000661301543005, loss after: 0.000659783661831.\n",
      "Epoch:6, weight train batch: 130, step:25, loss before: 0.000131961758598, loss after: 0.000131805325509.\n",
      "Epoch:6, weight train batch: 130, step:26, loss before: 0.000133276800625, loss after: 0.000133146444568.\n",
      "Epoch:6, weight train batch: 130, step:27, loss before: 0.000103384874819, loss after: 0.000103243321064.\n",
      "Epoch:6, weight train batch: 130, step:28, loss before: 0.000118697913422, loss after: 0.000118563832075.\n",
      "Epoch:6, weight train batch: 130, step:29, loss before: 0.000121703764307, loss after: 0.000121524972201.\n",
      "Epoch:6, weight train batch: 130, step:30, loss before: 0.000124664948089, loss after: 0.000124549478642.\n",
      "Epoch:6, weight train batch: 130, step:31, loss before: 0.00012594636064, loss after: 0.000125823455164.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 126, loss before: 0.000182354910066, loss after: 0.000116962037282.\n",
      "Epoch:6, weight train batch: 131, step:0, loss before: 0.000121655131807, loss after: 0.00012155456352.\n",
      "Epoch:6, weight train batch: 131, step:1, loss before: 0.000111691275379, loss after: 0.00011153856758.\n",
      "Epoch:6, weight train batch: 131, step:2, loss before: 0.000121018398204, loss after: 0.000120899203466.\n",
      "Epoch:6, weight train batch: 131, step:3, loss before: 0.000140119474963, loss after: 0.000139989104355.\n",
      "Epoch:6, weight train batch: 131, step:4, loss before: 0.000121863697132, loss after: 0.000121778022731.\n",
      "Epoch:6, weight train batch: 131, step:5, loss before: 0.000117539311759, loss after: 0.000117390321975.\n",
      "Epoch:6, weight train batch: 131, step:6, loss before: 0.000124952028273, loss after: 0.000124851459987.\n",
      "Epoch:6, weight train batch: 131, step:7, loss before: 0.000129265070427, loss after: 0.000129157037009.\n",
      "Epoch:6, weight train batch: 131, step:8, loss before: 0.000128486761241, loss after: 0.000128389918245.\n",
      "Epoch:6, weight train batch: 131, step:9, loss before: 0.000118559968541, loss after: 0.000118373718578.\n",
      "Epoch:6, weight train batch: 131, step:10, loss before: 0.000132688612211, loss after: 0.000132580593345.\n",
      "Epoch:6, weight train batch: 131, step:11, loss before: 0.000127015257021, loss after: 0.000126925850054.\n",
      "Epoch:6, weight train batch: 131, step:12, loss before: 0.000137577037094, loss after: 0.000137491384521.\n",
      "Epoch:6, weight train batch: 131, step:13, loss before: 0.000145542886457, loss after: 0.000145360390889.\n",
      "Epoch:6, weight train batch: 131, step:14, loss before: 0.000131146138301, loss after: 0.000131053006044.\n",
      "Epoch:6, weight train batch: 131, step:15, loss before: 0.000118034775369, loss after: 0.00011794539023.\n",
      "Epoch:6, weight train batch: 131, step:16, loss before: 0.00013421937183, loss after: 0.000134100177092.\n",
      "Epoch:6, weight train batch: 131, step:17, loss before: 0.000109225489723, loss after: 0.000109143540612.\n",
      "Epoch:6, weight train batch: 131, step:18, loss before: 0.000114775422844, loss after: 0.000114663678687.\n",
      "Epoch:6, weight train batch: 131, step:19, loss before: 0.000129034393467, loss after: 0.000128933839733.\n",
      "Epoch:6, weight train batch: 131, step:20, loss before: 0.00012197583419, loss after: 0.000121890159789.\n",
      "Epoch:6, weight train batch: 131, step:21, loss before: 0.000363396306057, loss after: 0.000362929655239.\n",
      "Epoch:6, weight train batch: 131, step:22, loss before: 0.00012060131121, loss after: 0.000120523109217.\n",
      "Epoch:6, weight train batch: 131, step:23, loss before: 0.00011312541028, loss after: 0.000112976420496.\n",
      "Epoch:6, weight train batch: 131, step:24, loss before: 0.000112536741653, loss after: 0.000112458525109.\n",
      "Epoch:6, weight train batch: 131, step:25, loss before: 0.000108078253106, loss after: 0.000107959058369.\n",
      "Epoch:6, weight train batch: 131, step:26, loss before: 0.000103768412373, loss after: 0.000103697646409.\n",
      "Epoch:6, weight train batch: 131, step:27, loss before: 0.000106707586383, loss after: 0.000106588398921.\n",
      "Epoch:6, weight train batch: 131, step:28, loss before: 0.000122091252706, loss after: 0.00012199440971.\n",
      "Epoch:6, weight train batch: 131, step:29, loss before: 0.000115967399324, loss after: 0.000115863105748.\n",
      "Epoch:6, weight train batch: 131, step:30, loss before: 0.000128401152324, loss after: 0.000128304294776.\n",
      "Epoch:6, weight train batch: 131, step:31, loss before: 0.000126464205096, loss after: 0.000126311497297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 127, loss before: 0.000128303858219, loss after: 0.000114642389235.\n",
      "Epoch:6, weight train batch: 132, step:0, loss before: 0.000104263919638, loss after: 0.000104185703094.\n",
      "Epoch:6, weight train batch: 132, step:1, loss before: 0.000129924505018, loss after: 0.00012983137276.\n",
      "Epoch:6, weight train batch: 132, step:2, loss before: 0.000106603110908, loss after: 0.00010648391617.\n",
      "Epoch:6, weight train batch: 132, step:3, loss before: 0.000127581864945, loss after: 0.000127477571368.\n",
      "Epoch:6, weight train batch: 132, step:4, loss before: 0.000166070167325, loss after: 0.000165932375239.\n",
      "Epoch:6, weight train batch: 132, step:5, loss before: 0.000115151968203, loss after: 0.000115055110655.\n",
      "Epoch:6, weight train batch: 132, step:6, loss before: 0.000109650107333, loss after: 0.000109597960545.\n",
      "Epoch:6, weight train batch: 132, step:7, loss before: 0.000129403051687, loss after: 0.00012928385695.\n",
      "Epoch:6, weight train batch: 132, step:8, loss before: 0.000115743998322, loss after: 0.000115658323921.\n",
      "Epoch:6, weight train batch: 132, step:9, loss before: 0.000122880795971, loss after: 0.000122791389003.\n",
      "Epoch:6, weight train batch: 132, step:10, loss before: 0.000125290753203, loss after: 0.000125171558466.\n",
      "Epoch:6, weight train batch: 132, step:11, loss before: 0.00011955096852, loss after: 0.000119428063044.\n",
      "Epoch:6, weight train batch: 132, step:12, loss before: 0.000134603003971, loss after: 0.000134502450237.\n",
      "Epoch:6, weight train batch: 132, step:13, loss before: 0.00011558024562, loss after: 0.000115487127914.\n",
      "Epoch:6, weight train batch: 132, step:14, loss before: 0.000124862708617, loss after: 0.000124743499327.\n",
      "Epoch:6, weight train batch: 132, step:15, loss before: 0.00013475943706, loss after: 0.000134658883326.\n",
      "Epoch:6, weight train batch: 132, step:16, loss before: 0.000117774165119, loss after: 0.000117681047413.\n",
      "Epoch:6, weight train batch: 132, step:17, loss before: 0.000108487955004, loss after: 0.000108368767542.\n",
      "Epoch:6, weight train batch: 132, step:18, loss before: 0.000108216081571, loss after: 0.000108096886834.\n",
      "Epoch:6, weight train batch: 132, step:19, loss before: 0.000110309309093, loss after: 0.000110231085273.\n",
      "Epoch:6, weight train batch: 132, step:20, loss before: 9.62217891356e-05, loss after: 9.61696423474e-05.\n",
      "Epoch:6, weight train batch: 132, step:21, loss before: 0.000115449707664, loss after: 0.000115330498375.\n",
      "Epoch:6, weight train batch: 132, step:22, loss before: 9.44229323068e-05, loss after: 9.43447012105e-05.\n",
      "Epoch:6, weight train batch: 132, step:23, loss before: 0.000124556972878, loss after: 0.000124463855173.\n",
      "Epoch:6, weight train batch: 132, step:24, loss before: 0.000120474483992, loss after: 0.000120355296531.\n",
      "Epoch:6, weight train batch: 132, step:25, loss before: 0.000125007631141, loss after: 0.000124892176245.\n",
      "Epoch:6, weight train batch: 132, step:26, loss before: 0.000119286458357, loss after: 0.000119193333376.\n",
      "Epoch:6, weight train batch: 132, step:27, loss before: 0.000109166088805, loss after: 0.000109117667307.\n",
      "Epoch:6, weight train batch: 132, step:28, loss before: 0.000119439282571, loss after: 0.000119320095109.\n",
      "Epoch:6, weight train batch: 132, step:29, loss before: 0.000127350824187, loss after: 0.0001272502559.\n",
      "Epoch:6, weight train batch: 132, step:30, loss before: 0.000117621406389, loss after: 0.000117546907859.\n",
      "Epoch:6, weight train batch: 132, step:31, loss before: 0.000121964578284, loss after: 0.000121845390822.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 128, loss before: 0.000173597334651, loss after: 0.000114955393656.\n",
      "Epoch:6, weight train batch: 133, step:0, loss before: 9.92650384433e-05, loss after: 9.91644774331e-05.\n",
      "Epoch:6, weight train batch: 133, step:1, loss before: 0.000129559630295, loss after: 0.000129462801851.\n",
      "Epoch:6, weight train batch: 133, step:2, loss before: 0.000122825105791, loss after: 0.000122728262795.\n",
      "Epoch:6, weight train batch: 133, step:3, loss before: 0.000112343157525, loss after: 0.000112246314529.\n",
      "Epoch:6, weight train batch: 133, step:4, loss before: 0.000129831416416, loss after: 0.000129771811771.\n",
      "Epoch:6, weight train batch: 133, step:5, loss before: 0.000101880119473, loss after: 0.000101798170363.\n",
      "Epoch:6, weight train batch: 133, step:6, loss before: 0.000116884017189, loss after: 0.000116787174193.\n",
      "Epoch:6, weight train batch: 133, step:7, loss before: 0.00016981860972, loss after: 0.000169680817635.\n",
      "Epoch:6, weight train batch: 133, step:8, loss before: 0.000584563764278, loss after: 0.00058334111236.\n",
      "Epoch:6, weight train batch: 133, step:9, loss before: 0.000109363689262, loss after: 0.000109210959636.\n",
      "Epoch:6, weight train batch: 133, step:10, loss before: 0.000105083541712, loss after: 0.000104960621684.\n",
      "Epoch:6, weight train batch: 133, step:11, loss before: 0.00010356738494, loss after: 0.00010342211317.\n",
      "Epoch:6, weight train batch: 133, step:12, loss before: 9.46239451878e-05, loss after: 9.45122010307e-05.\n",
      "Epoch:6, weight train batch: 133, step:13, loss before: 0.000117539500934, loss after: 0.00011739051115.\n",
      "Epoch:6, weight train batch: 133, step:14, loss before: 0.000113263362437, loss after: 0.00011318140605.\n",
      "Epoch:6, weight train batch: 133, step:15, loss before: 0.000126002123579, loss after: 0.000125901569845.\n",
      "Epoch:6, weight train batch: 133, step:16, loss before: 0.000341334409313, loss after: 0.000341159960954.\n",
      "Epoch:6, weight train batch: 133, step:17, loss before: 0.000118415038742, loss after: 0.000118266048958.\n",
      "Epoch:6, weight train batch: 133, step:18, loss before: 0.000100572709925, loss after: 0.000100490768091.\n",
      "Epoch:6, weight train batch: 133, step:19, loss before: 0.000120716875244, loss after: 0.000120616299682.\n",
      "Epoch:6, weight train batch: 133, step:20, loss before: 0.000126527593238, loss after: 0.000126408398501.\n",
      "Epoch:6, weight train batch: 133, step:21, loss before: 0.000137679948239, loss after: 0.000137571943924.\n",
      "Epoch:6, weight train batch: 133, step:22, loss before: 0.000106286774098, loss after: 0.000106193656393.\n",
      "Epoch:6, weight train batch: 133, step:23, loss before: 0.00010957577615, loss after: 0.000109467757284.\n",
      "Epoch:6, weight train batch: 133, step:24, loss before: 0.000115930415632, loss after: 0.000115811220894.\n",
      "Epoch:6, weight train batch: 133, step:25, loss before: 0.000103314341686, loss after: 0.000103224956547.\n",
      "Epoch:6, weight train batch: 133, step:26, loss before: 0.000114354639663, loss after: 0.000114268972538.\n",
      "Epoch:6, weight train batch: 133, step:27, loss before: 0.000178375295945, loss after: 0.000178215224878.\n",
      "Epoch:6, weight train batch: 133, step:28, loss before: 0.000114719761768, loss after: 0.000114600567031.\n",
      "Epoch:6, weight train batch: 133, step:29, loss before: 9.72239067778e-05, loss after: 9.71494155237e-05.\n",
      "Epoch:6, weight train batch: 133, step:30, loss before: 0.000367963628378, loss after: 0.000367622968042.\n",
      "Epoch:6, weight train batch: 133, step:31, loss before: 0.000123875695863, loss after: 0.000123790028738.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 129, loss before: 0.000105350707599, loss after: 0.000105377708678.\n",
      "Epoch:6, weight train batch: 134, step:0, loss before: 9.93769863271e-05, loss after: 9.93062130874e-05.\n",
      "Epoch:6, weight train batch: 134, step:1, loss before: 0.000112540808914, loss after: 0.0001124216069.\n",
      "Epoch:6, weight train batch: 134, step:2, loss before: 0.000101138786704, loss after: 0.00010106429545.\n",
      "Epoch:6, weight train batch: 134, step:3, loss before: 0.000111006011139, loss after: 0.000110912886157.\n",
      "Epoch:6, weight train batch: 134, step:4, loss before: 0.000122072728118, loss after: 0.000121975863294.\n",
      "Epoch:6, weight train batch: 134, step:5, loss before: 0.000103183934698, loss after: 0.00010306473996.\n",
      "Epoch:6, weight train batch: 134, step:6, loss before: 0.000559330743272, loss after: 0.000558232073672.\n",
      "Epoch:6, weight train batch: 134, step:7, loss before: 0.000110622349894, loss after: 0.000110477063572.\n",
      "Epoch:6, weight train batch: 134, step:8, loss before: 9.7305921372e-05, loss after: 9.72239722614e-05.\n",
      "Epoch:6, weight train batch: 134, step:9, loss before: 9.68665044638e-05, loss after: 9.67547603068e-05.\n",
      "Epoch:6, weight train batch: 134, step:10, loss before: 0.000134018424433, loss after: 0.000133899244247.\n",
      "Epoch:6, weight train batch: 134, step:11, loss before: 0.000110864653834, loss after: 0.000110760360258.\n",
      "Epoch:6, weight train batch: 134, step:12, loss before: 0.000115688249934, loss after: 0.000115598842967.\n",
      "Epoch:6, weight train batch: 134, step:13, loss before: 9.7502983408e-05, loss after: 9.74433933152e-05.\n",
      "Epoch:6, weight train batch: 134, step:14, loss before: 0.000124773199786, loss after: 0.000124654005049.\n",
      "Epoch:6, weight train batch: 134, step:15, loss before: 0.000110588902317, loss after: 0.000110499502625.\n",
      "Epoch:6, weight train batch: 134, step:16, loss before: 0.000136357470183, loss after: 0.000136223447043.\n",
      "Epoch:6, weight train batch: 134, step:17, loss before: 9.6501345979e-05, loss after: 9.6352348919e-05.\n",
      "Epoch:6, weight train batch: 134, step:18, loss before: 0.000107698549982, loss after: 0.000107601706986.\n",
      "Epoch:6, weight train batch: 134, step:19, loss before: 0.000110179375042, loss after: 0.000110112327093.\n",
      "Epoch:6, weight train batch: 134, step:20, loss before: 0.000131939930725, loss after: 0.000131820735987.\n",
      "Epoch:6, weight train batch: 134, step:21, loss before: 0.000112354580779, loss after: 0.000112294990686.\n",
      "Epoch:6, weight train batch: 134, step:22, loss before: 0.000108711828943, loss after: 0.000108607535367.\n",
      "Epoch:6, weight train batch: 134, step:23, loss before: 0.000121912700706, loss after: 0.000121808414406.\n",
      "Epoch:6, weight train batch: 134, step:24, loss before: 0.00437658140436, loss after: 0.00437439931557.\n",
      "Epoch:6, weight train batch: 134, step:25, loss before: 0.000118437135825, loss after: 0.000118303047202.\n",
      "Epoch:6, weight train batch: 134, step:26, loss before: 0.000115677132271, loss after: 0.000115617534902.\n",
      "Epoch:6, weight train batch: 134, step:27, loss before: 0.000110205233796, loss after: 0.000110100932943.\n",
      "Epoch:6, weight train batch: 134, step:28, loss before: 0.000103206293716, loss after: 0.000103176491393.\n",
      "Epoch:6, weight train batch: 134, step:29, loss before: 0.000341467210092, loss after: 0.000341107690474.\n",
      "Epoch:6, weight train batch: 134, step:30, loss before: 0.000124773461721, loss after: 0.000124706421047.\n",
      "Epoch:6, weight train batch: 134, step:31, loss before: 0.000115006667329, loss after: 0.000114861410111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 130, loss before: 0.000107706771814, loss after: 0.000107706771814.\n",
      "Epoch:6, weight train batch: 135, step:0, loss before: 0.000120373973914, loss after: 0.000120254786452.\n",
      "Epoch:6, weight train batch: 135, step:1, loss before: 0.000117785406474, loss after: 0.000117718358524.\n",
      "Epoch:6, weight train batch: 135, step:2, loss before: 0.000120817523566, loss after: 0.000120672259072.\n",
      "Epoch:6, weight train batch: 135, step:3, loss before: 0.000120586482808, loss after: 0.000120511984278.\n",
      "Epoch:6, weight train batch: 135, step:4, loss before: 0.00010938214109, loss after: 0.000109303924546.\n",
      "Epoch:6, weight train batch: 135, step:5, loss before: 0.000106063118437, loss after: 0.00010597743676.\n",
      "Epoch:6, weight train batch: 135, step:6, loss before: 0.000107571817352, loss after: 0.000107489875518.\n",
      "Epoch:6, weight train batch: 135, step:7, loss before: 0.000106305225927, loss after: 0.000106156228867.\n",
      "Epoch:6, weight train batch: 135, step:8, loss before: 0.000111129127617, loss after: 0.00011106581951.\n",
      "Epoch:6, weight train batch: 135, step:9, loss before: 0.000118850861327, loss after: 0.00011874284246.\n",
      "Epoch:6, weight train batch: 135, step:10, loss before: 0.000109739703475, loss after: 0.000109676388092.\n",
      "Epoch:6, weight train batch: 135, step:11, loss before: 0.000110015425889, loss after: 0.000109918582893.\n",
      "Epoch:6, weight train batch: 135, step:12, loss before: 0.000104312493932, loss after: 0.00010422309424.\n",
      "Epoch:6, weight train batch: 135, step:13, loss before: 0.000103805919935, loss after: 0.000103720260086.\n",
      "Epoch:6, weight train batch: 135, step:14, loss before: 0.000110261062218, loss after: 0.000110197739559.\n",
      "Epoch:6, weight train batch: 135, step:15, loss before: 0.000104685052065, loss after: 0.000104629172711.\n",
      "Epoch:6, weight train batch: 135, step:16, loss before: 0.000113881775178, loss after: 0.000113788657472.\n",
      "Epoch:6, weight train batch: 135, step:17, loss before: 8.92936222954e-05, loss after: 8.92228563316e-05.\n",
      "Epoch:6, weight train batch: 135, step:18, loss before: 0.000122527242638, loss after: 0.000122430399642.\n",
      "Epoch:6, weight train batch: 135, step:19, loss before: 0.00434335786849, loss after: 0.00434105983004.\n",
      "Epoch:6, weight train batch: 135, step:20, loss before: 0.000102327190689, loss after: 0.0001021893695.\n",
      "Epoch:6, weight train batch: 135, step:21, loss before: 0.000108275868115, loss after: 0.00010820881289.\n",
      "Epoch:6, weight train batch: 135, step:22, loss before: 0.00010056157771, loss after: 0.000100420031231.\n",
      "Epoch:6, weight train batch: 135, step:23, loss before: 0.000127030711155, loss after: 0.000126933882711.\n",
      "Epoch:6, weight train batch: 135, step:24, loss before: 0.000105292063381, loss after: 0.000105210121546.\n",
      "Epoch:6, weight train batch: 135, step:25, loss before: 0.000115997696412, loss after: 0.000115930641186.\n",
      "Epoch:6, weight train batch: 135, step:26, loss before: 9.16515418794e-05, loss after: 9.15211712709e-05.\n",
      "Epoch:6, weight train batch: 135, step:27, loss before: 0.000103649552329, loss after: 0.000103593680251.\n",
      "Epoch:6, weight train batch: 135, step:28, loss before: 0.000135403766762, loss after: 0.00013527343981.\n",
      "Epoch:6, weight train batch: 135, step:29, loss before: 0.000108499240014, loss after: 0.000108435924631.\n",
      "Epoch:6, weight train batch: 135, step:30, loss before: 0.000154184934217, loss after: 0.000154039706104.\n",
      "Epoch:6, weight train batch: 135, step:31, loss before: 0.00011388900748, loss after: 0.000113810798211.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 131, loss before: 0.000102728532511, loss after: 0.000282056163996.\n",
      "Epoch:6, weight train batch: 136, step:0, loss before: 0.000100774042949, loss after: 0.0001006883831.\n",
      "Epoch:6, weight train batch: 136, step:1, loss before: 9.85983351711e-05, loss after: 9.85014848993e-05.\n",
      "Epoch:6, weight train batch: 136, step:2, loss before: 0.000106048348243, loss after: 0.000105925442767.\n",
      "Epoch:6, weight train batch: 136, step:3, loss before: 0.000122601908515, loss after: 0.000122568395454.\n",
      "Epoch:6, weight train batch: 136, step:4, loss before: 0.000116757524665, loss after: 0.000116656949103.\n",
      "Epoch:6, weight train batch: 136, step:5, loss before: 0.000113468500786, loss after: 0.000113360467367.\n",
      "Epoch:6, weight train batch: 136, step:6, loss before: 0.000109955886728, loss after: 0.000109896282083.\n",
      "Epoch:6, weight train batch: 136, step:7, loss before: 0.000102085046819, loss after: 0.000101999365143.\n",
      "Epoch:6, weight train batch: 136, step:8, loss before: 0.000105094906758, loss after: 0.000105039034679.\n",
      "Epoch:6, weight train batch: 136, step:9, loss before: 0.000108000196633, loss after: 0.000107910796942.\n",
      "Epoch:6, weight train batch: 136, step:10, loss before: 0.000113855756354, loss after: 0.00011378499039.\n",
      "Epoch:6, weight train batch: 136, step:11, loss before: 9.19719168451e-05, loss after: 9.18937003007e-05.\n",
      "Epoch:6, weight train batch: 136, step:12, loss before: 9.19646481634e-05, loss after: 9.18752484722e-05.\n",
      "Epoch:6, weight train batch: 136, step:13, loss before: 0.000101172561699, loss after: 0.000101071986137.\n",
      "Epoch:6, weight train batch: 136, step:14, loss before: 0.000107236613985, loss after: 0.00010714722157.\n",
      "Epoch:6, weight train batch: 136, step:15, loss before: 0.000101924953924, loss after: 0.000101887708297.\n",
      "Epoch:6, weight train batch: 136, step:16, loss before: 9.85352671705e-05, loss after: 9.84495854937e-05.\n",
      "Epoch:6, weight train batch: 136, step:17, loss before: 9.50561734498e-05, loss after: 9.49369714363e-05.\n",
      "Epoch:6, weight train batch: 136, step:18, loss before: 9.17669458431e-05, loss after: 9.17483266676e-05.\n",
      "Epoch:6, weight train batch: 136, step:19, loss before: 0.000106987055915, loss after: 0.000106897656224.\n",
      "Epoch:6, weight train batch: 136, step:20, loss before: 0.000110224296805, loss after: 0.000110164706712.\n",
      "Epoch:6, weight train batch: 136, step:21, loss before: 9.89672334981e-05, loss after: 9.88480387605e-05.\n",
      "Epoch:6, weight train batch: 136, step:22, loss before: 0.000106588588096, loss after: 0.000106528998003.\n",
      "Epoch:6, weight train batch: 136, step:23, loss before: 0.000125675083837, loss after: 0.000125563325128.\n",
      "Epoch:6, weight train batch: 136, step:24, loss before: 0.000108842141344, loss after: 0.000108808613732.\n",
      "Epoch:6, weight train batch: 136, step:25, loss before: 0.000116496768896, loss after: 0.000116399918625.\n",
      "Epoch:6, weight train batch: 136, step:26, loss before: 9.48253145907e-05, loss after: 9.47396329138e-05.\n",
      "Epoch:6, weight train batch: 136, step:27, loss before: 0.00010696114623, loss after: 0.000106901556137.\n",
      "Epoch:6, weight train batch: 136, step:28, loss before: 0.000103362690425, loss after: 0.000103277008748.\n",
      "Epoch:6, weight train batch: 136, step:29, loss before: 9.47878797888e-05, loss after: 9.47171065491e-05.\n",
      "Epoch:6, weight train batch: 136, step:30, loss before: 0.000110812616185, loss after: 0.000110715773189.\n",
      "Epoch:6, weight train batch: 136, step:31, loss before: 0.000131914581289, loss after: 0.000131802866235.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 132, loss before: 0.000108224725409, loss after: 0.000108564636321.\n",
      "Epoch:6, weight train batch: 137, step:0, loss before: 0.000109445551061, loss after: 0.000109378503112.\n",
      "Epoch:6, weight train batch: 137, step:1, loss before: 0.000101574711152, loss after: 0.000101492769318.\n",
      "Epoch:6, weight train batch: 137, step:2, loss before: 0.000329380447511, loss after: 0.000329213449731.\n",
      "Epoch:6, weight train batch: 137, step:3, loss before: 0.000102092366433, loss after: 0.000102017867903.\n",
      "Epoch:6, weight train batch: 137, step:4, loss before: 0.000107832551294, loss after: 0.000107813924842.\n",
      "Epoch:6, weight train batch: 137, step:5, loss before: 9.64792416198e-05, loss after: 9.63898492046e-05.\n",
      "Epoch:6, weight train batch: 137, step:6, loss before: 8.85562621988e-05, loss after: 8.84892215254e-05.\n",
      "Epoch:6, weight train batch: 137, step:7, loss before: 0.000115099974209, loss after: 0.000115003116662.\n",
      "Epoch:6, weight train batch: 137, step:8, loss before: 0.000107344603748, loss after: 0.000107258936623.\n",
      "Epoch:6, weight train batch: 137, step:9, loss before: 9.42926417338e-05, loss after: 9.42442129599e-05.\n",
      "Epoch:6, weight train batch: 137, step:10, loss before: 0.0042985198088, loss after: 0.00429609231651.\n",
      "Epoch:6, weight train batch: 137, step:11, loss before: 0.000107370593469, loss after: 0.000107262574602.\n",
      "Epoch:6, weight train batch: 137, step:12, loss before: 0.000106908977614, loss after: 0.000106819577923.\n",
      "Epoch:6, weight train batch: 137, step:13, loss before: 0.000104063001345, loss after: 0.000104033213574.\n",
      "Epoch:6, weight train batch: 137, step:14, loss before: 0.000105933002487, loss after: 0.000105810089735.\n",
      "Epoch:6, weight train batch: 137, step:15, loss before: 0.000114262518764, loss after: 0.000114232723718.\n",
      "Epoch:6, weight train batch: 137, step:16, loss before: 9.13090188988e-05, loss after: 9.1238252935e-05.\n",
      "Epoch:6, weight train batch: 137, step:17, loss before: 0.000112540888949, loss after: 0.000112451489258.\n",
      "Epoch:6, weight train batch: 137, step:18, loss before: 0.000103634651168, loss after: 0.000103545258753.\n",
      "Epoch:6, weight train batch: 137, step:19, loss before: 0.000118128285976, loss after: 0.000118046336866.\n",
      "Epoch:6, weight train batch: 137, step:20, loss before: 0.00012953885016, loss after: 0.000129393592943.\n",
      "Epoch:6, weight train batch: 137, step:21, loss before: 0.000103545251477, loss after: 0.000103444690467.\n",
      "Epoch:6, weight train batch: 137, step:22, loss before: 0.000102774327388, loss after: 0.000102684920421.\n",
      "Epoch:6, weight train batch: 137, step:23, loss before: 7.61486517149e-05, loss after: 7.60890470701e-05.\n",
      "Epoch:6, weight train batch: 137, step:24, loss before: 0.000140741074574, loss after: 0.000140640564496.\n",
      "Epoch:6, weight train batch: 137, step:25, loss before: 0.000104182268842, loss after: 0.000104063074104.\n",
      "Epoch:6, weight train batch: 137, step:26, loss before: 9.88258980215e-05, loss after: 9.880727157e-05.\n",
      "Epoch:6, weight train batch: 137, step:27, loss before: 0.0371092297137, loss after: 0.0370612703264.\n",
      "Epoch:6, weight train batch: 137, step:28, loss before: 0.000101403515146, loss after: 0.000101537596493.\n",
      "Epoch:6, weight train batch: 137, step:29, loss before: 9.03815307538e-05, loss after: 9.05156266526e-05.\n",
      "Epoch:6, weight train batch: 137, step:30, loss before: 0.000104417100374, loss after: 0.000104476690467.\n",
      "Epoch:6, weight train batch: 137, step:31, loss before: 0.000159559422173, loss after: 0.000159938761499.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 133, loss before: 0.000118645410112, loss after: 0.00174338382203.\n",
      "Epoch:6, weight train batch: 138, step:0, loss before: 0.000110015578684, loss after: 0.000110168286483.\n",
      "Epoch:6, weight train batch: 138, step:1, loss before: 0.000138817384141, loss after: 0.00013890300761.\n",
      "Epoch:6, weight train batch: 138, step:2, loss before: 9.63077109191e-05, loss after: 9.6307718195e-05.\n",
      "Epoch:6, weight train batch: 138, step:3, loss before: 0.00010819779709, loss after: 0.000108257394459.\n",
      "Epoch:6, weight train batch: 138, step:4, loss before: 9.11263196031e-05, loss after: 9.11821844056e-05.\n",
      "Epoch:6, weight train batch: 138, step:5, loss before: 0.000100911754998, loss after: 0.00010090431897.\n",
      "Epoch:6, weight train batch: 138, step:6, loss before: 9.36966462177e-05, loss after: 9.37152726692e-05.\n",
      "Epoch:6, weight train batch: 138, step:7, loss before: 0.0001172081611, loss after: 0.000117211871839.\n",
      "Epoch:6, weight train batch: 138, step:8, loss before: 8.92266107257e-05, loss after: 8.91893578228e-05.\n",
      "Epoch:6, weight train batch: 138, step:9, loss before: 0.000140724761877, loss after: 0.00014071361511.\n",
      "Epoch:6, weight train batch: 138, step:10, loss before: 9.99097028398e-05, loss after: 9.98612740659e-05.\n",
      "Epoch:6, weight train batch: 138, step:11, loss before: 0.000102278689155, loss after: 0.000102274956589.\n",
      "Epoch:6, weight train batch: 138, step:12, loss before: 9.86172235571e-05, loss after: 9.85688093351e-05.\n",
      "Epoch:6, weight train batch: 138, step:13, loss before: 9.54771530814e-05, loss after: 9.54138376983e-05.\n",
      "Epoch:6, weight train batch: 138, step:14, loss before: 0.000101939862361, loss after: 0.000101876546978.\n",
      "Epoch:6, weight train batch: 138, step:15, loss before: 0.000105586572317, loss after: 0.000105519517092.\n",
      "Epoch:6, weight train batch: 138, step:16, loss before: 0.000175766006578, loss after: 0.000175669192686.\n",
      "Epoch:6, weight train batch: 138, step:17, loss before: 0.000104495127744, loss after: 0.000104461607407.\n",
      "Epoch:6, weight train batch: 138, step:18, loss before: 0.000155197354616, loss after: 0.000155100555276.\n",
      "Epoch:6, weight train batch: 138, step:19, loss before: 0.000107594372821, loss after: 0.000107478903374.\n",
      "Epoch:6, weight train batch: 138, step:20, loss before: 0.000104230661236, loss after: 0.000104144986835.\n",
      "Epoch:6, weight train batch: 138, step:21, loss before: 0.000107568899693, loss after: 0.000107509309601.\n",
      "Epoch:6, weight train batch: 138, step:22, loss before: 0.000111758912681, loss after: 0.000111654619104.\n",
      "Epoch:6, weight train batch: 138, step:23, loss before: 0.000102483660157, loss after: 0.000102394260466.\n",
      "Epoch:6, weight train batch: 138, step:24, loss before: 0.000100282413769, loss after: 0.000100163211755.\n",
      "Epoch:6, weight train batch: 138, step:25, loss before: 9.39833334996e-05, loss after: 9.39051242312e-05.\n",
      "Epoch:6, weight train batch: 138, step:26, loss before: 0.000144301258842, loss after: 0.000144178397022.\n",
      "Epoch:6, weight train batch: 138, step:27, loss before: 9.80175100267e-05, loss after: 9.79243777692e-05.\n",
      "Epoch:6, weight train batch: 138, step:28, loss before: 0.000102386969957, loss after: 0.000102249141491.\n",
      "Epoch:6, weight train batch: 138, step:29, loss before: 9.66467923718e-05, loss after: 9.65909202932e-05.\n",
      "Epoch:6, weight train batch: 138, step:30, loss before: 9.25081621972e-05, loss after: 9.24001360545e-05.\n",
      "Epoch:6, weight train batch: 138, step:31, loss before: 0.000107966916403, loss after: 0.000107847728941.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 134, loss before: 9.7326526884e-05, loss after: 9.73237329163e-05.\n",
      "Epoch:6, weight train batch: 139, step:0, loss before: 8.84853216121e-05, loss after: 8.84108230821e-05.\n",
      "Epoch:6, weight train batch: 139, step:1, loss before: 0.000103072088677, loss after: 0.000102960359072.\n",
      "Epoch:6, weight train batch: 139, step:2, loss before: 0.000116593721032, loss after: 0.000116429830086.\n",
      "Epoch:6, weight train batch: 139, step:3, loss before: 0.000106644525658, loss after: 0.000106603554741.\n",
      "Epoch:6, weight train batch: 139, step:4, loss before: 0.000102412966953, loss after: 0.000102297497506.\n",
      "Epoch:6, weight train batch: 139, step:5, loss before: 0.000108275839011, loss after: 0.000108167812868.\n",
      "Epoch:6, weight train batch: 139, step:6, loss before: 0.000116664567031, loss after: 0.000116504401376.\n",
      "Epoch:6, weight train batch: 139, step:7, loss before: 9.5555340522e-05, loss after: 9.55031864578e-05.\n",
      "Epoch:6, weight train batch: 139, step:8, loss before: 0.000157281552674, loss after: 0.000157110363944.\n",
      "Epoch:6, weight train batch: 139, step:9, loss before: 9.95485243038e-05, loss after: 9.94628644548e-05.\n",
      "Epoch:6, weight train batch: 139, step:10, loss before: 0.000102953119494, loss after: 0.000102792939288.\n",
      "Epoch:6, weight train batch: 139, step:11, loss before: 0.00429745437577, loss after: 0.00427917949855.\n",
      "Epoch:6, weight train batch: 139, step:12, loss before: 0.000108653024654, loss after: 0.000108280553832.\n",
      "Epoch:6, weight train batch: 139, step:13, loss before: 9.35066345846e-05, loss after: 9.3387439847e-05.\n",
      "Epoch:6, weight train batch: 139, step:14, loss before: 0.000102357000287, loss after: 0.000102282516309.\n",
      "Epoch:6, weight train batch: 139, step:15, loss before: 0.000105296014226, loss after: 0.000105180537503.\n",
      "Epoch:6, weight train batch: 139, step:16, loss before: 0.000107873784145, loss after: 0.000107803018182.\n",
      "Epoch:6, weight train batch: 139, step:17, loss before: 9.7473814094e-05, loss after: 9.73695132416e-05.\n",
      "Epoch:6, weight train batch: 139, step:18, loss before: 0.000107803163701, loss after: 0.000107762192783.\n",
      "Epoch:6, weight train batch: 139, step:19, loss before: 9.74290451268e-05, loss after: 9.73508213065e-05.\n",
      "Epoch:6, weight train batch: 139, step:20, loss before: 9.79989272309e-05, loss after: 9.79393225862e-05.\n",
      "Epoch:6, weight train batch: 139, step:21, loss before: 9.65762083069e-05, loss after: 9.64607388596e-05.\n",
      "Epoch:6, weight train batch: 139, step:22, loss before: 0.000110764216515, loss after: 0.000110693443276.\n",
      "Epoch:6, weight train batch: 139, step:23, loss before: 7.93481158325e-05, loss after: 7.92847858975e-05.\n",
      "Epoch:6, weight train batch: 139, step:24, loss before: 0.000106283143396, loss after: 0.000106234721898.\n",
      "Epoch:6, weight train batch: 139, step:25, loss before: 0.000106923886051, loss after: 0.000106759980554.\n",
      "Epoch:6, weight train batch: 139, step:26, loss before: 8.85153276613e-05, loss after: 8.84967012098e-05.\n",
      "Epoch:6, weight train batch: 139, step:27, loss before: 0.00011609475041, loss after: 0.000115990456834.\n",
      "Epoch:6, weight train batch: 139, step:28, loss before: 0.000103351703729, loss after: 0.000103314458102.\n",
      "Epoch:6, weight train batch: 139, step:29, loss before: 0.000109214917757, loss after: 0.000109039843665.\n",
      "Epoch:6, weight train batch: 139, step:30, loss before: 8.51926524774e-05, loss after: 8.51479562698e-05.\n",
      "Epoch:6, weight train batch: 139, step:31, loss before: 9.80287150014e-05, loss after: 9.80026379693e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:6, struct parameters train batch: 135, loss before: 0.00010380425374, loss after: 0.000102208185126.\n",
      "Epoch:7, weight train batch: 140, step:0, loss before: 9.63451166172e-05, loss after: 9.62594494922e-05.\n",
      "Epoch:7, weight train batch: 140, step:1, loss before: 0.000139338255394, loss after: 0.000139215379022.\n",
      "Epoch:7, weight train batch: 140, step:2, loss before: 0.00011226170318, loss after: 0.000112183493911.\n",
      "Epoch:7, weight train batch: 140, step:3, loss before: 0.000114116890472, loss after: 0.000114008871606.\n",
      "Epoch:7, weight train batch: 140, step:4, loss before: 9.92729401332e-05, loss after: 9.92505883914e-05.\n",
      "Epoch:7, weight train batch: 140, step:5, loss before: 9.70640685409e-05, loss after: 9.69448665273e-05.\n",
      "Epoch:7, weight train batch: 140, step:6, loss before: 0.000112440575322, loss after: 0.000112362366053.\n",
      "Epoch:7, weight train batch: 140, step:7, loss before: 8.43956804601e-05, loss after: 8.43062880449e-05.\n",
      "Epoch:7, weight train batch: 140, step:8, loss before: 9.89785985439e-05, loss after: 9.89376276266e-05.\n",
      "Epoch:7, weight train batch: 140, step:9, loss before: 0.000337211822625, loss after: 0.000336815399351.\n",
      "Epoch:7, weight train batch: 140, step:10, loss before: 9.42927363212e-05, loss after: 9.42368642427e-05.\n",
      "Epoch:7, weight train batch: 140, step:11, loss before: 8.8995861006e-05, loss after: 8.88915528776e-05.\n",
      "Epoch:7, weight train batch: 140, step:12, loss before: 9.77159579634e-05, loss after: 9.76563605946e-05.\n",
      "Epoch:7, weight train batch: 140, step:13, loss before: 0.000106264647911, loss after: 0.000106145453174.\n",
      "Epoch:7, weight train batch: 140, step:14, loss before: 0.00050812237896, loss after: 0.000507253920659.\n",
      "Epoch:7, weight train batch: 140, step:15, loss before: 0.000105795406853, loss after: 0.000105694831291.\n",
      "Epoch:7, weight train batch: 140, step:16, loss before: 0.000104122824268, loss after: 0.000104003622255.\n",
      "Epoch:7, weight train batch: 140, step:17, loss before: 9.15102209547e-05, loss after: 9.14208285394e-05.\n",
      "Epoch:7, weight train batch: 140, step:18, loss before: 9.39873643802e-05, loss after: 9.38569864957e-05.\n",
      "Epoch:7, weight train batch: 140, step:19, loss before: 8.15942330519e-05, loss after: 8.15383682493e-05.\n",
      "Epoch:7, weight train batch: 140, step:20, loss before: 9.55852228799e-05, loss after: 9.55069917836e-05.\n",
      "Epoch:7, weight train batch: 140, step:21, loss before: 0.000105132159661, loss after: 0.000105046492536.\n",
      "Epoch:7, weight train batch: 140, step:22, loss before: 9.71310801106e-05, loss after: 9.70677647274e-05.\n",
      "Epoch:7, weight train batch: 140, step:23, loss before: 8.35611353978e-05, loss after: 8.34605598357e-05.\n",
      "Epoch:7, weight train batch: 140, step:24, loss before: 8.78933642525e-05, loss after: 8.78039572854e-05.\n",
      "Epoch:7, weight train batch: 140, step:25, loss before: 0.000104122795165, loss after: 0.000104029677459.\n",
      "Epoch:7, weight train batch: 140, step:26, loss before: 8.63512832439e-05, loss after: 8.62842280185e-05.\n",
      "Epoch:7, weight train batch: 140, step:27, loss before: 0.000496757915244, loss after: 0.000495531712659.\n",
      "Epoch:7, weight train batch: 140, step:28, loss before: 0.000107207073597, loss after: 0.000107158644823.\n",
      "Epoch:7, weight train batch: 140, step:29, loss before: 9.53988928813e-05, loss after: 9.53057678998e-05.\n",
      "Epoch:7, weight train batch: 140, step:30, loss before: 0.000100774268503, loss after: 0.000100669960375.\n",
      "Epoch:7, weight train batch: 140, step:31, loss before: 9.2854781542e-05, loss after: 9.27989167394e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 136, loss before: 9.85204387689e-05, loss after: 9.12400719244e-05.\n",
      "Epoch:7, weight train batch: 141, step:0, loss before: 0.000103050057078, loss after: 0.000102930855064.\n",
      "Epoch:7, weight train batch: 141, step:1, loss before: 9.98169125523e-05, loss after: 9.97163297143e-05.\n",
      "Epoch:7, weight train batch: 141, step:2, loss before: 8.1843973021e-05, loss after: 8.17657492007e-05.\n",
      "Epoch:7, weight train batch: 141, step:3, loss before: 8.94242839422e-05, loss after: 8.93870310392e-05.\n",
      "Epoch:7, weight train batch: 141, step:4, loss before: 8.66229602252e-05, loss after: 8.65037582116e-05.\n",
      "Epoch:7, weight train batch: 141, step:5, loss before: 7.77057503001e-05, loss after: 7.76126325945e-05.\n",
      "Epoch:7, weight train batch: 141, step:6, loss before: 8.31216239021e-05, loss after: 8.30396820675e-05.\n",
      "Epoch:7, weight train batch: 141, step:7, loss before: 0.000479955517221, loss after: 0.000478711241158.\n",
      "Epoch:7, weight train batch: 141, step:8, loss before: 0.0365314520895, loss after: 0.0364822521806.\n",
      "Epoch:7, weight train batch: 141, step:9, loss before: 0.000127012346638, loss after: 0.000126893268316.\n",
      "Epoch:7, weight train batch: 141, step:10, loss before: 0.000319057464367, loss after: 0.000318875740049.\n",
      "Epoch:7, weight train batch: 141, step:11, loss before: 9.35774514801e-05, loss after: 9.34880517889e-05.\n",
      "Epoch:7, weight train batch: 141, step:12, loss before: 9.30002206587e-05, loss after: 9.29592424654e-05.\n",
      "Epoch:7, weight train batch: 141, step:13, loss before: 9.6907679108e-05, loss after: 9.69411921687e-05.\n",
      "Epoch:7, weight train batch: 141, step:14, loss before: 0.000115015536721, loss after: 0.000115030445158.\n",
      "Epoch:7, weight train batch: 141, step:15, loss before: 9.7462652775e-05, loss after: 9.73806963884e-05.\n",
      "Epoch:7, weight train batch: 141, step:16, loss before: 9.73807036644e-05, loss after: 9.7388146969e-05.\n",
      "Epoch:7, weight train batch: 141, step:17, loss before: 0.000103631202364, loss after: 0.000103627477074.\n",
      "Epoch:7, weight train batch: 141, step:18, loss before: 9.12867035368e-05, loss after: 9.12196555873e-05.\n",
      "Epoch:7, weight train batch: 141, step:19, loss before: 0.000103452337498, loss after: 0.000103415084595.\n",
      "Epoch:7, weight train batch: 141, step:20, loss before: 0.000100483666756, loss after: 0.00010040916095.\n",
      "Epoch:7, weight train batch: 141, step:21, loss before: 7.8662771557e-05, loss after: 7.86739474279e-05.\n",
      "Epoch:7, weight train batch: 141, step:22, loss before: 0.000136318703881, loss after: 0.000136207003379.\n",
      "Epoch:7, weight train batch: 141, step:23, loss before: 9.45868960116e-05, loss after: 9.44975035964e-05.\n",
      "Epoch:7, weight train batch: 141, step:24, loss before: 8.83886823431e-05, loss after: 8.8362605311e-05.\n",
      "Epoch:7, weight train batch: 141, step:25, loss before: 8.43470334075e-05, loss after: 8.42986046337e-05.\n",
      "Epoch:7, weight train batch: 141, step:26, loss before: 8.71555675985e-05, loss after: 8.71108786669e-05.\n",
      "Epoch:7, weight train batch: 141, step:27, loss before: 0.000107464031316, loss after: 0.000107430503704.\n",
      "Epoch:7, weight train batch: 141, step:28, loss before: 9.04001863091e-05, loss after: 9.02809842955e-05.\n",
      "Epoch:7, weight train batch: 141, step:29, loss before: 9.37340082601e-05, loss after: 9.37004951993e-05.\n",
      "Epoch:7, weight train batch: 141, step:30, loss before: 8.87796923053e-05, loss after: 8.87312708073e-05.\n",
      "Epoch:7, weight train batch: 141, step:31, loss before: 0.000103739213955, loss after: 0.000103690807009.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 137, loss before: 9.58972013905e-05, loss after: 9.5898132713e-05.\n",
      "Epoch:7, weight train batch: 142, step:0, loss before: 9.17262950679e-05, loss after: 9.16071003303e-05.\n",
      "Epoch:7, weight train batch: 142, step:1, loss before: 7.93406798039e-05, loss after: 7.93183280621e-05.\n",
      "Epoch:7, weight train batch: 142, step:2, loss before: 8.67908020155e-05, loss after: 8.67423805175e-05.\n",
      "Epoch:7, weight train batch: 142, step:3, loss before: 9.22701146919e-05, loss after: 9.22030594666e-05.\n",
      "Epoch:7, weight train batch: 142, step:4, loss before: 9.06013738131e-05, loss after: 9.05454944586e-05.\n",
      "Epoch:7, weight train batch: 142, step:5, loss before: 9.40357058425e-05, loss after: 9.39500314416e-05.\n",
      "Epoch:7, weight train batch: 142, step:6, loss before: 9.08918300411e-05, loss after: 9.08359652385e-05.\n",
      "Epoch:7, weight train batch: 142, step:7, loss before: 9.42294645938e-05, loss after: 9.41922116908e-05.\n",
      "Epoch:7, weight train batch: 142, step:8, loss before: 8.75057448866e-05, loss after: 8.74498655321e-05.\n",
      "Epoch:7, weight train batch: 142, step:9, loss before: 0.000103150552604, loss after: 0.000103061167465.\n",
      "Epoch:7, weight train batch: 142, step:10, loss before: 8.59489082359e-05, loss after: 8.5900486738e-05.\n",
      "Epoch:7, weight train batch: 142, step:11, loss before: 0.000446534133516, loss after: 0.000445840938482.\n",
      "Epoch:7, weight train batch: 142, step:12, loss before: 0.000105884770164, loss after: 0.000105787927168.\n",
      "Epoch:7, weight train batch: 142, step:13, loss before: 8.65969850565e-05, loss after: 8.65634574438e-05.\n",
      "Epoch:7, weight train batch: 142, step:14, loss before: 9.94370057015e-05, loss after: 9.9369965028e-05.\n",
      "Epoch:7, weight train batch: 142, step:15, loss before: 8.0860532762e-05, loss after: 8.0786034232e-05.\n",
      "Epoch:7, weight train batch: 142, step:16, loss before: 8.53193196235e-05, loss after: 8.52597222547e-05.\n",
      "Epoch:7, weight train batch: 142, step:17, loss before: 8.62767192302e-05, loss after: 8.61575099407e-05.\n",
      "Epoch:7, weight train batch: 142, step:18, loss before: 9.9533557659e-05, loss after: 9.94516158244e-05.\n",
      "Epoch:7, weight train batch: 142, step:19, loss before: 8.869029989e-05, loss after: 8.86567795533e-05.\n",
      "Epoch:7, weight train batch: 142, step:20, loss before: 9.47919324972e-05, loss after: 9.47137159528e-05.\n",
      "Epoch:7, weight train batch: 142, step:21, loss before: 0.00011205705232, loss after: 0.000111971385195.\n",
      "Epoch:7, weight train batch: 142, step:22, loss before: 8.141190483e-05, loss after: 8.13299557194e-05.\n",
      "Epoch:7, weight train batch: 142, step:23, loss before: 9.42554979702e-05, loss after: 9.42145270528e-05.\n",
      "Epoch:7, weight train batch: 142, step:24, loss before: 0.000101854413515, loss after: 0.000101753837953.\n",
      "Epoch:7, weight train batch: 142, step:25, loss before: 8.94987897482e-05, loss after: 8.94727127161e-05.\n",
      "Epoch:7, weight train batch: 142, step:26, loss before: 8.05662566563e-05, loss after: 8.04917508503e-05.\n",
      "Epoch:7, weight train batch: 142, step:27, loss before: 8.69024224812e-05, loss after: 8.68465431267e-05.\n",
      "Epoch:7, weight train batch: 142, step:28, loss before: 0.00423107855022, loss after: 0.00422884011641.\n",
      "Epoch:7, weight train batch: 142, step:29, loss before: 0.000134345580591, loss after: 0.000134252462885.\n",
      "Epoch:7, weight train batch: 142, step:30, loss before: 8.18589542178e-05, loss after: 8.18142580101e-05.\n",
      "Epoch:7, weight train batch: 142, step:31, loss before: 0.000143204582855, loss after: 0.000143077981193.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 138, loss before: 8.96151832421e-05, loss after: 8.96151832421e-05.\n",
      "Epoch:7, weight train batch: 143, step:0, loss before: 0.000132056025905, loss after: 0.000131940585561.\n",
      "Epoch:7, weight train batch: 143, step:1, loss before: 7.59175163694e-05, loss after: 7.58951646276e-05.\n",
      "Epoch:7, weight train batch: 143, step:2, loss before: 8.9297638624e-05, loss after: 8.92007956281e-05.\n",
      "Epoch:7, weight train batch: 143, step:3, loss before: 8.24884191388e-05, loss after: 8.24399976409e-05.\n",
      "Epoch:7, weight train batch: 143, step:4, loss before: 8.85041372385e-05, loss after: 8.8399843662e-05.\n",
      "Epoch:7, weight train batch: 143, step:5, loss before: 8.91075615073e-05, loss after: 8.90516821528e-05.\n",
      "Epoch:7, weight train batch: 143, step:6, loss before: 8.89139046194e-05, loss after: 8.88393988134e-05.\n",
      "Epoch:7, weight train batch: 143, step:7, loss before: 0.000150296924403, loss after: 0.000150159190525.\n",
      "Epoch:7, weight train batch: 143, step:8, loss before: 8.70962248882e-05, loss after: 8.70775984367e-05.\n",
      "Epoch:7, weight train batch: 143, step:9, loss before: 8.47755291034e-05, loss after: 8.46898474265e-05.\n",
      "Epoch:7, weight train batch: 143, step:10, loss before: 9.43150516832e-05, loss after: 9.42517290241e-05.\n",
      "Epoch:7, weight train batch: 143, step:11, loss before: 0.000127003906528, loss after: 0.000126914543216.\n",
      "Epoch:7, weight train batch: 143, step:12, loss before: 0.000106421211967, loss after: 0.000106339262857.\n",
      "Epoch:7, weight train batch: 143, step:13, loss before: 8.65039182827e-05, loss after: 8.64145185915e-05.\n",
      "Epoch:7, weight train batch: 143, step:14, loss before: 9.79692558758e-05, loss after: 9.78686948656e-05.\n",
      "Epoch:7, weight train batch: 143, step:15, loss before: 9.72467241809e-05, loss after: 9.71796835074e-05.\n",
      "Epoch:7, weight train batch: 143, step:16, loss before: 9.4225833891e-05, loss after: 9.41960315686e-05.\n",
      "Epoch:7, weight train batch: 143, step:17, loss before: 7.67222081777e-05, loss after: 7.66365265008e-05.\n",
      "Epoch:7, weight train batch: 143, step:18, loss before: 9.99919648166e-05, loss after: 9.99398180284e-05.\n",
      "Epoch:7, weight train batch: 143, step:19, loss before: 0.000103888334706, loss after: 0.000103813843452.\n",
      "Epoch:7, weight train batch: 143, step:20, loss before: 8.967013855e-05, loss after: 8.96105339052e-05.\n",
      "Epoch:7, weight train batch: 143, step:21, loss before: 0.000115003909741, loss after: 0.000114881011541.\n",
      "Epoch:7, weight train batch: 143, step:22, loss before: 9.41251637414e-05, loss after: 9.4058123068e-05.\n",
      "Epoch:7, weight train batch: 143, step:23, loss before: 8.78785285749e-05, loss after: 8.77816710272e-05.\n",
      "Epoch:7, weight train batch: 143, step:24, loss before: 9.16704375413e-05, loss after: 9.16406352189e-05.\n",
      "Epoch:7, weight train batch: 143, step:25, loss before: 0.000120452074043, loss after: 0.000120373864775.\n",
      "Epoch:7, weight train batch: 143, step:26, loss before: 0.000102007194073, loss after: 0.000101887999335.\n",
      "Epoch:7, weight train batch: 143, step:27, loss before: 0.000101221201476, loss after: 0.000101172772702.\n",
      "Epoch:7, weight train batch: 143, step:28, loss before: 0.000104439575807, loss after: 0.000104361359263.\n",
      "Epoch:7, weight train batch: 143, step:29, loss before: 0.000126868253574, loss after: 0.000126749073388.\n",
      "Epoch:7, weight train batch: 143, step:30, loss before: 7.03449622961e-05, loss after: 7.02555626049e-05.\n",
      "Epoch:7, weight train batch: 143, step:31, loss before: 9.80997574516e-05, loss after: 9.80587865342e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 139, loss before: 9.07021167222e-05, loss after: 0.000138710835017.\n",
      "Epoch:7, weight train batch: 144, step:0, loss before: 9.49856330408e-05, loss after: 9.49185923673e-05.\n",
      "Epoch:7, weight train batch: 144, step:1, loss before: 8.78710416146e-05, loss after: 8.78300634213e-05.\n",
      "Epoch:7, weight train batch: 144, step:2, loss before: 9.16928256629e-05, loss after: 9.1607158538e-05.\n",
      "Epoch:7, weight train batch: 144, step:3, loss before: 9.44976854953e-05, loss after: 9.44306448218e-05.\n",
      "Epoch:7, weight train batch: 144, step:4, loss before: 8.80536026671e-05, loss after: 8.79940125742e-05.\n",
      "Epoch:7, weight train batch: 144, step:5, loss before: 9.94779547909e-05, loss after: 9.939228039e-05.\n",
      "Epoch:7, weight train batch: 144, step:6, loss before: 9.29704110604e-05, loss after: 9.28698282223e-05.\n",
      "Epoch:7, weight train batch: 144, step:7, loss before: 8.25703973533e-05, loss after: 8.25182432891e-05.\n",
      "Epoch:7, weight train batch: 144, step:8, loss before: 9.15661730687e-05, loss after: 9.15028504096e-05.\n",
      "Epoch:7, weight train batch: 144, step:9, loss before: 8.9245615527e-05, loss after: 8.91599484021e-05.\n",
      "Epoch:7, weight train batch: 144, step:10, loss before: 9.9880315247e-05, loss after: 9.98244431685e-05.\n",
      "Epoch:7, weight train batch: 144, step:11, loss before: 9.56301082624e-05, loss after: 9.55593422987e-05.\n",
      "Epoch:7, weight train batch: 144, step:12, loss before: 9.96157396003e-05, loss after: 9.95449663606e-05.\n",
      "Epoch:7, weight train batch: 144, step:13, loss before: 9.03034087969e-05, loss after: 9.02400788618e-05.\n",
      "Epoch:7, weight train batch: 144, step:14, loss before: 9.03109103092e-05, loss after: 9.02475876501e-05.\n",
      "Epoch:7, weight train batch: 144, step:15, loss before: 8.38183623273e-05, loss after: 8.37326879264e-05.\n",
      "Epoch:7, weight train batch: 144, step:16, loss before: 6.74805269227e-05, loss after: 6.74469993101e-05.\n",
      "Epoch:7, weight train batch: 144, step:17, loss before: 7.90689082351e-05, loss after: 7.90204940131e-05.\n",
      "Epoch:7, weight train batch: 144, step:18, loss before: 8.89362781891e-05, loss after: 8.89176590135e-05.\n",
      "Epoch:7, weight train batch: 144, step:19, loss before: 9.03254622244e-05, loss after: 9.02658648556e-05.\n",
      "Epoch:7, weight train batch: 144, step:20, loss before: 8.8425949798e-05, loss after: 8.83253669599e-05.\n",
      "Epoch:7, weight train batch: 144, step:21, loss before: 8.13337101135e-05, loss after: 8.12554935692e-05.\n",
      "Epoch:7, weight train batch: 144, step:22, loss before: 9.72394482233e-05, loss after: 9.71686677076e-05.\n",
      "Epoch:7, weight train batch: 144, step:23, loss before: 9.25720378291e-05, loss after: 9.25422355067e-05.\n",
      "Epoch:7, weight train batch: 144, step:24, loss before: 9.60287143243e-05, loss after: 9.59653843893e-05.\n",
      "Epoch:7, weight train batch: 144, step:25, loss before: 9.9828132079e-05, loss after: 9.97238385025e-05.\n",
      "Epoch:7, weight train batch: 144, step:26, loss before: 0.000101608704426, loss after: 0.000101530487882.\n",
      "Epoch:7, weight train batch: 144, step:27, loss before: 9.42892511375e-05, loss after: 9.42222031881e-05.\n",
      "Epoch:7, weight train batch: 144, step:28, loss before: 9.1517707915e-05, loss after: 9.14618358365e-05.\n",
      "Epoch:7, weight train batch: 144, step:29, loss before: 0.000124975049403, loss after: 0.000124885671539.\n",
      "Epoch:7, weight train batch: 144, step:30, loss before: 9.13947951631e-05, loss after: 9.13649928407e-05.\n",
      "Epoch:7, weight train batch: 144, step:31, loss before: 0.000110164881335, loss after: 0.00011008666479.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 140, loss before: 0.00898401532322, loss after: 8.61957087182e-05.\n",
      "Epoch:7, weight train batch: 145, step:0, loss before: 8.56432379805e-05, loss after: 8.5587365902e-05.\n",
      "Epoch:7, weight train batch: 145, step:1, loss before: 9.83903519227e-05, loss after: 9.83121426543e-05.\n",
      "Epoch:7, weight train batch: 145, step:2, loss before: 9.13129551918e-05, loss after: 9.12459072424e-05.\n",
      "Epoch:7, weight train batch: 145, step:3, loss before: 8.73383251019e-05, loss after: 8.72936288943e-05.\n",
      "Epoch:7, weight train batch: 145, step:4, loss before: 8.17844265839e-05, loss after: 8.1698752183e-05.\n",
      "Epoch:7, weight train batch: 145, step:5, loss before: 9.250115545e-05, loss after: 9.24341220525e-05.\n",
      "Epoch:7, weight train batch: 145, step:6, loss before: 7.91359852883e-05, loss after: 7.90801132098e-05.\n",
      "Epoch:7, weight train batch: 145, step:7, loss before: 9.18157893466e-05, loss after: 9.17822762858e-05.\n",
      "Epoch:7, weight train batch: 145, step:8, loss before: 8.8723943918e-05, loss after: 8.86606285349e-05.\n",
      "Epoch:7, weight train batch: 145, step:9, loss before: 8.82808089955e-05, loss after: 8.8187676738e-05.\n",
      "Epoch:7, weight train batch: 145, step:10, loss before: 0.00011746569362, loss after: 0.000117387498904.\n",
      "Epoch:7, weight train batch: 145, step:11, loss before: 0.00011140514107, loss after: 0.000111312023364.\n",
      "Epoch:7, weight train batch: 145, step:12, loss before: 8.11251811683e-05, loss after: 8.10730271041e-05.\n",
      "Epoch:7, weight train batch: 145, step:13, loss before: 9.28215813474e-05, loss after: 9.27992296056e-05.\n",
      "Epoch:7, weight train batch: 145, step:14, loss before: 9.08510628506e-05, loss after: 9.0757945145e-05.\n",
      "Epoch:7, weight train batch: 145, step:15, loss before: 6.69851287967e-05, loss after: 6.69516084599e-05.\n",
      "Epoch:7, weight train batch: 145, step:16, loss before: 8.80089137354e-05, loss after: 8.79306826391e-05.\n",
      "Epoch:7, weight train batch: 145, step:17, loss before: 9.4691538834e-05, loss after: 9.46543004829e-05.\n",
      "Epoch:7, weight train batch: 145, step:18, loss before: 8.88395152288e-05, loss after: 8.87761998456e-05.\n",
      "Epoch:7, weight train batch: 145, step:19, loss before: 9.1726447863e-05, loss after: 9.16631252039e-05.\n",
      "Epoch:7, weight train batch: 145, step:20, loss before: 0.000639669131488, loss after: 0.000638988916762.\n",
      "Epoch:7, weight train batch: 145, step:21, loss before: 7.43679847801e-05, loss after: 7.43344644434e-05.\n",
      "Epoch:7, weight train batch: 145, step:22, loss before: 9.77609161055e-05, loss after: 9.7705044027e-05.\n",
      "Epoch:7, weight train batch: 145, step:23, loss before: 9.6267205663e-05, loss after: 9.6267205663e-05.\n",
      "Epoch:7, weight train batch: 145, step:24, loss before: 9.0661138529e-05, loss after: 9.05419437913e-05.\n",
      "Epoch:7, weight train batch: 145, step:25, loss before: 8.45707472763e-05, loss after: 8.4529776359e-05.\n",
      "Epoch:7, weight train batch: 145, step:26, loss before: 0.000100666409708, loss after: 0.000100558390841.\n",
      "Epoch:7, weight train batch: 145, step:27, loss before: 0.000295080448268, loss after: 0.000294528610539.\n",
      "Epoch:7, weight train batch: 145, step:28, loss before: 9.27209912334e-05, loss after: 9.26502179937e-05.\n",
      "Epoch:7, weight train batch: 145, step:29, loss before: 7.92701321188e-05, loss after: 7.92179780547e-05.\n",
      "Epoch:7, weight train batch: 145, step:30, loss before: 9.23225088627e-05, loss after: 9.2251728347e-05.\n",
      "Epoch:7, weight train batch: 145, step:31, loss before: 8.47569244797e-05, loss after: 8.46936018206e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 141, loss before: 0.00211941893212, loss after: 8.30155477161e-05.\n",
      "Epoch:7, weight train batch: 146, step:0, loss before: 9.14135307539e-05, loss after: 9.13464828045e-05.\n",
      "Epoch:7, weight train batch: 146, step:1, loss before: 7.73443025537e-05, loss after: 7.72847051849e-05.\n",
      "Epoch:7, weight train batch: 146, step:2, loss before: 0.00638749310747, loss after: 0.00637526297942.\n",
      "Epoch:7, weight train batch: 146, step:3, loss before: 8.01082787802e-05, loss after: 7.99034241936e-05.\n",
      "Epoch:7, weight train batch: 146, step:4, loss before: 7.44201825e-05, loss after: 7.43009877624e-05.\n",
      "Epoch:7, weight train batch: 146, step:5, loss before: 7.44948119973e-05, loss after: 7.43681666791e-05.\n",
      "Epoch:7, weight train batch: 146, step:6, loss before: 7.17456714483e-05, loss after: 7.16413778719e-05.\n",
      "Epoch:7, weight train batch: 146, step:7, loss before: 8.40977882035e-05, loss after: 8.39972199174e-05.\n",
      "Epoch:7, weight train batch: 146, step:8, loss before: 7.66291341279e-05, loss after: 7.65509175835e-05.\n",
      "Epoch:7, weight train batch: 146, step:9, loss before: 8.10358469607e-05, loss after: 8.09166522231e-05.\n",
      "Epoch:7, weight train batch: 146, step:10, loss before: 7.69009857322e-05, loss after: 7.68451136537e-05.\n",
      "Epoch:7, weight train batch: 146, step:11, loss before: 8.95623816177e-05, loss after: 8.94394615898e-05.\n",
      "Epoch:7, weight train batch: 146, step:12, loss before: 8.46006150823e-05, loss after: 8.45037648105e-05.\n",
      "Epoch:7, weight train batch: 146, step:13, loss before: 7.99816625658e-05, loss after: 7.99146218924e-05.\n",
      "Epoch:7, weight train batch: 146, step:14, loss before: 9.36782889767e-05, loss after: 9.36186988838e-05.\n",
      "Epoch:7, weight train batch: 146, step:15, loss before: 8.80908773979e-05, loss after: 8.79642320797e-05.\n",
      "Epoch:7, weight train batch: 146, step:16, loss before: 0.000128761850647, loss after: 0.000128657571622.\n",
      "Epoch:7, weight train batch: 146, step:17, loss before: 8.11178906588e-05, loss after: 8.10508499853e-05.\n",
      "Epoch:7, weight train batch: 146, step:18, loss before: 9.04451007955e-05, loss after: 9.03855107026e-05.\n",
      "Epoch:7, weight train batch: 146, step:19, loss before: 7.74374493631e-05, loss after: 7.73555002525e-05.\n",
      "Epoch:7, weight train batch: 146, step:20, loss before: 7.76349115768e-05, loss after: 7.760139124e-05.\n",
      "Epoch:7, weight train batch: 146, step:21, loss before: 7.45878642192e-05, loss after: 7.45394499972e-05.\n",
      "Epoch:7, weight train batch: 146, step:22, loss before: 8.53901728988e-05, loss after: 8.52709781611e-05.\n",
      "Epoch:7, weight train batch: 146, step:23, loss before: 8.04026785772e-05, loss after: 8.03728762548e-05.\n",
      "Epoch:7, weight train batch: 146, step:24, loss before: 7.70947517594e-05, loss after: 7.70426122472e-05.\n",
      "Epoch:7, weight train batch: 146, step:25, loss before: 9.07505891519e-05, loss after: 9.06760978978e-05.\n",
      "Epoch:7, weight train batch: 146, step:26, loss before: 8.0566474935e-05, loss after: 8.04770825198e-05.\n",
      "Epoch:7, weight train batch: 146, step:27, loss before: 7.08480220055e-05, loss after: 7.08256702637e-05.\n",
      "Epoch:7, weight train batch: 146, step:28, loss before: 0.000304090877762, loss after: 0.000303920067381.\n",
      "Epoch:7, weight train batch: 146, step:29, loss before: 9.12534087547e-05, loss after: 9.11640163395e-05.\n",
      "Epoch:7, weight train batch: 146, step:30, loss before: 7.91440834291e-05, loss after: 7.90993872215e-05.\n",
      "Epoch:7, weight train batch: 146, step:31, loss before: 7.72401472204e-05, loss after: 7.71917257225e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 142, loss before: 9.3171482149e-05, loss after: 9.6084215329e-05.\n",
      "Epoch:7, weight train batch: 147, step:0, loss before: 8.50737342262e-05, loss after: 8.49806092447e-05.\n",
      "Epoch:7, weight train batch: 147, step:1, loss before: 8.24736634968e-05, loss after: 8.24289600132e-05.\n",
      "Epoch:7, weight train batch: 147, step:2, loss before: 8.53455785546e-05, loss after: 8.52785306051e-05.\n",
      "Epoch:7, weight train batch: 147, step:3, loss before: 0.000135793874506, loss after: 0.000135715672513.\n",
      "Epoch:7, weight train batch: 147, step:4, loss before: 9.21064929571e-05, loss after: 9.2032001703e-05.\n",
      "Epoch:7, weight train batch: 147, step:5, loss before: 7.45469296817e-05, loss after: 7.44985009078e-05.\n",
      "Epoch:7, weight train batch: 147, step:6, loss before: 8.25109600555e-05, loss after: 8.2455087977e-05.\n",
      "Epoch:7, weight train batch: 147, step:7, loss before: 0.0357906967402, loss after: 0.035732679069.\n",
      "Epoch:7, weight train batch: 147, step:8, loss before: 0.00012996228179, loss after: 0.00013041269267.\n",
      "Epoch:7, weight train batch: 147, step:9, loss before: 9.38683806453e-05, loss after: 9.39540477702e-05.\n",
      "Epoch:7, weight train batch: 147, step:10, loss before: 8.20415953058e-05, loss after: 8.22501897346e-05.\n",
      "Epoch:7, weight train batch: 147, step:11, loss before: 0.00415672082454, loss after: 0.00415658717975.\n",
      "Epoch:7, weight train batch: 147, step:12, loss before: 7.78397006798e-05, loss after: 7.79030233389e-05.\n",
      "Epoch:7, weight train batch: 147, step:13, loss before: 8.48764248076e-05, loss after: 8.49323041621e-05.\n",
      "Epoch:7, weight train batch: 147, step:14, loss before: 8.48874915391e-05, loss after: 8.49731586641e-05.\n",
      "Epoch:7, weight train batch: 147, step:15, loss before: 7.69383332226e-05, loss after: 7.70724436734e-05.\n",
      "Epoch:7, weight train batch: 147, step:16, loss before: 7.94862062321e-05, loss after: 7.95383602963e-05.\n",
      "Epoch:7, weight train batch: 147, step:17, loss before: 7.80669943197e-05, loss after: 7.81005146564e-05.\n",
      "Epoch:7, weight train batch: 147, step:18, loss before: 9.78318566922e-05, loss after: 9.7805794212e-05.\n",
      "Epoch:7, weight train batch: 147, step:19, loss before: 7.31910331524e-05, loss after: 7.32506305212e-05.\n",
      "Epoch:7, weight train batch: 147, step:20, loss before: 9.19013546081e-05, loss after: 9.19199810596e-05.\n",
      "Epoch:7, weight train batch: 147, step:21, loss before: 8.29318814795e-05, loss after: 8.29691271065e-05.\n",
      "Epoch:7, weight train batch: 147, step:22, loss before: 9.64573555393e-05, loss after: 9.6416377346e-05.\n",
      "Epoch:7, weight train batch: 147, step:23, loss before: 8.78861101228e-05, loss after: 8.79196304595e-05.\n",
      "Epoch:7, weight train batch: 147, step:24, loss before: 9.11567040021e-05, loss after: 9.11492534215e-05.\n",
      "Epoch:7, weight train batch: 147, step:25, loss before: 8.76215926837e-05, loss after: 8.76439444255e-05.\n",
      "Epoch:7, weight train batch: 147, step:26, loss before: 8.33416270325e-05, loss after: 8.32782970974e-05.\n",
      "Epoch:7, weight train batch: 147, step:27, loss before: 0.000126672617625, loss after: 0.000126646496938.\n",
      "Epoch:7, weight train batch: 147, step:28, loss before: 8.29281634651e-05, loss after: 8.29318887554e-05.\n",
      "Epoch:7, weight train batch: 147, step:29, loss before: 9.05197011889e-05, loss after: 9.04824482859e-05.\n",
      "Epoch:7, weight train batch: 147, step:30, loss before: 7.78547982918e-05, loss after: 7.78175453888e-05.\n",
      "Epoch:7, weight train batch: 147, step:31, loss before: 9.19535086723e-05, loss after: 9.18827427085e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 143, loss before: 8.50729848025e-05, loss after: 8.11392674223e-05.\n",
      "Epoch:7, weight train batch: 148, step:0, loss before: 8.42766166897e-05, loss after: 8.42319132062e-05.\n",
      "Epoch:7, weight train batch: 148, step:1, loss before: 8.34943493828e-05, loss after: 8.34570964798e-05.\n",
      "Epoch:7, weight train batch: 148, step:2, loss before: 9.00727100088e-05, loss after: 9.00056620594e-05.\n",
      "Epoch:7, weight train batch: 148, step:3, loss before: 0.000131040302222, loss after: 0.000130947199068.\n",
      "Epoch:7, weight train batch: 148, step:4, loss before: 6.85572085786e-05, loss after: 6.85199629515e-05.\n",
      "Epoch:7, weight train batch: 148, step:5, loss before: 8.4060629888e-05, loss after: 8.39637796162e-05.\n",
      "Epoch:7, weight train batch: 148, step:6, loss before: 7.6912343502e-05, loss after: 7.68937170506e-05.\n",
      "Epoch:7, weight train batch: 148, step:7, loss before: 8.31740617286e-05, loss after: 8.31479846966e-05.\n",
      "Epoch:7, weight train batch: 148, step:8, loss before: 7.21405303921e-05, loss after: 7.20697571523e-05.\n",
      "Epoch:7, weight train batch: 148, step:9, loss before: 9.17452125577e-05, loss after: 9.16818826227e-05.\n",
      "Epoch:7, weight train batch: 148, step:10, loss before: 9.22519175219e-05, loss after: 9.21439059312e-05.\n",
      "Epoch:7, weight train batch: 148, step:11, loss before: 8.14680097392e-05, loss after: 8.14456579974e-05.\n",
      "Epoch:7, weight train batch: 148, step:12, loss before: 6.62104284856e-05, loss after: 6.61359299556e-05.\n",
      "Epoch:7, weight train batch: 148, step:13, loss before: 6.69329456287e-05, loss after: 6.68919674354e-05.\n",
      "Epoch:7, weight train batch: 148, step:14, loss before: 8.09166158433e-05, loss after: 8.08570184745e-05.\n",
      "Epoch:7, weight train batch: 148, step:15, loss before: 7.92142964201e-05, loss after: 7.91547063272e-05.\n",
      "Epoch:7, weight train batch: 148, step:16, loss before: 8.16244501038e-05, loss after: 8.1564852735e-05.\n",
      "Epoch:7, weight train batch: 148, step:17, loss before: 8.43214074848e-05, loss after: 8.42767185532e-05.\n",
      "Epoch:7, weight train batch: 148, step:18, loss before: 8.22651345516e-05, loss after: 8.22018046165e-05.\n",
      "Epoch:7, weight train batch: 148, step:19, loss before: 8.22204819997e-05, loss after: 8.21310823085e-05.\n",
      "Epoch:7, weight train batch: 148, step:20, loss before: 8.67202761583e-05, loss after: 8.66830232553e-05.\n",
      "Epoch:7, weight train batch: 148, step:21, loss before: 8.60869331518e-05, loss after: 8.59975407366e-05.\n",
      "Epoch:7, weight train batch: 148, step:22, loss before: 8.21495923446e-05, loss after: 8.21123467176e-05.\n",
      "Epoch:7, weight train batch: 148, step:23, loss before: 8.07155302027e-05, loss after: 8.06633761385e-05.\n",
      "Epoch:7, weight train batch: 148, step:24, loss before: 8.42095032567e-05, loss after: 8.41312721604e-05.\n",
      "Epoch:7, weight train batch: 148, step:25, loss before: 6.83410835336e-05, loss after: 6.82665850036e-05.\n",
      "Epoch:7, weight train batch: 148, step:26, loss before: 7.43160344427e-05, loss after: 7.4293682701e-05.\n",
      "Epoch:7, weight train batch: 148, step:27, loss before: 8.89552902663e-05, loss after: 8.88956928975e-05.\n",
      "Epoch:7, weight train batch: 148, step:28, loss before: 8.08645127108e-05, loss after: 8.08049080661e-05.\n",
      "Epoch:7, weight train batch: 148, step:29, loss before: 8.76998747117e-05, loss after: 8.76104750205e-05.\n",
      "Epoch:7, weight train batch: 148, step:30, loss before: 7.93037834228e-05, loss after: 7.92851569713e-05.\n",
      "Epoch:7, weight train batch: 148, step:31, loss before: 9.05458146008e-05, loss after: 9.04824846657e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 144, loss before: 0.000135912530823, loss after: 8.07155884104e-05.\n",
      "Epoch:7, weight train batch: 149, step:0, loss before: 9.118658636e-05, loss after: 9.11158131203e-05.\n",
      "Epoch:7, weight train batch: 149, step:1, loss before: 8.15872408566e-05, loss after: 8.15201856312e-05.\n",
      "Epoch:7, weight train batch: 149, step:2, loss before: 7.50796243665e-05, loss after: 7.49902246753e-05.\n",
      "Epoch:7, weight train batch: 149, step:3, loss before: 0.00410897005349, loss after: 0.00410663848743.\n",
      "Epoch:7, weight train batch: 149, step:4, loss before: 7.59177200962e-05, loss after: 7.58730238886e-05.\n",
      "Epoch:7, weight train batch: 149, step:5, loss before: 8.26786272228e-05, loss after: 8.25445313239e-05.\n",
      "Epoch:7, weight train batch: 149, step:6, loss before: 9.53101407504e-05, loss after: 9.52729023993e-05.\n",
      "Epoch:7, weight train batch: 149, step:7, loss before: 8.95140256034e-05, loss after: 8.94246186363e-05.\n",
      "Epoch:7, weight train batch: 149, step:8, loss before: 9.33284900384e-05, loss after: 9.32875191211e-05.\n",
      "Epoch:7, weight train batch: 149, step:9, loss before: 0.000133420398924, loss after: 0.000133256558911.\n",
      "Epoch:7, weight train batch: 149, step:10, loss before: 8.65264591994e-05, loss after: 8.64892135723e-05.\n",
      "Epoch:7, weight train batch: 149, step:11, loss before: 0.00012589560356, loss after: 0.000125765262055.\n",
      "Epoch:7, weight train batch: 149, step:12, loss before: 7.77505410952e-05, loss after: 7.76909437263e-05.\n",
      "Epoch:7, weight train batch: 149, step:13, loss before: 9.7329102573e-05, loss after: 9.71801127889e-05.\n",
      "Epoch:7, weight train batch: 149, step:14, loss before: 0.000272256700555, loss after: 0.000272148958175.\n",
      "Epoch:7, weight train batch: 149, step:15, loss before: 8.02835129434e-05, loss after: 8.02239082986e-05.\n",
      "Epoch:7, weight train batch: 149, step:16, loss before: 8.00600173534e-05, loss after: 7.99408226158e-05.\n",
      "Epoch:7, weight train batch: 149, step:17, loss before: 7.29676394258e-05, loss after: 7.29527382646e-05.\n",
      "Epoch:7, weight train batch: 149, step:18, loss before: 8.85622721398e-05, loss after: 8.84840483195e-05.\n",
      "Epoch:7, weight train batch: 149, step:19, loss before: 8.26451796456e-05, loss after: 8.25483293738e-05.\n",
      "Epoch:7, weight train batch: 149, step:20, loss before: 8.06262396509e-05, loss after: 8.05442978162e-05.\n",
      "Epoch:7, weight train batch: 149, step:21, loss before: 7.84620351624e-05, loss after: 7.8394987213e-05.\n",
      "Epoch:7, weight train batch: 149, step:22, loss before: 7.59252798161e-05, loss after: 7.58321548346e-05.\n",
      "Epoch:7, weight train batch: 149, step:23, loss before: 8.57294653542e-05, loss after: 8.56624174048e-05.\n",
      "Epoch:7, weight train batch: 149, step:24, loss before: 6.66945852572e-05, loss after: 6.66722335154e-05.\n",
      "Epoch:7, weight train batch: 149, step:25, loss before: 7.13956324034e-05, loss after: 7.13472109055e-05.\n",
      "Epoch:7, weight train batch: 149, step:26, loss before: 8.05814925116e-05, loss after: 8.04995434009e-05.\n",
      "Epoch:7, weight train batch: 149, step:27, loss before: 7.51801562728e-05, loss after: 7.51019397285e-05.\n",
      "Epoch:7, weight train batch: 149, step:28, loss before: 8.9420878794e-05, loss after: 8.93426622497e-05.\n",
      "Epoch:7, weight train batch: 149, step:29, loss before: 0.0001073199237, loss after: 0.000107271516754.\n",
      "Epoch:7, weight train batch: 149, step:30, loss before: 8.04771843832e-05, loss after: 8.03840666777e-05.\n",
      "Epoch:7, weight train batch: 149, step:31, loss before: 8.2317419583e-05, loss after: 8.22168512968e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 145, loss before: 9.64541177382e-05, loss after: 7.94454535935e-05.\n",
      "Epoch:7, weight train batch: 150, step:0, loss before: 8.20565910544e-05, loss after: 8.20305140223e-05.\n",
      "Epoch:7, weight train batch: 150, step:1, loss before: 7.80410628067e-05, loss after: 7.79740148573e-05.\n",
      "Epoch:7, weight train batch: 150, step:2, loss before: 8.48802374094e-05, loss after: 8.4850435087e-05.\n",
      "Epoch:7, weight train batch: 150, step:3, loss before: 8.0868252553e-05, loss after: 8.07490578154e-05.\n",
      "Epoch:7, weight train batch: 150, step:4, loss before: 8.21273570182e-05, loss after: 8.20938294055e-05.\n",
      "Epoch:7, weight train batch: 150, step:5, loss before: 7.65063450672e-05, loss after: 7.64355791034e-05.\n",
      "Epoch:7, weight train batch: 150, step:6, loss before: 6.63370301481e-05, loss after: 6.62923339405e-05.\n",
      "Epoch:7, weight train batch: 150, step:7, loss before: 7.81416310929e-05, loss after: 7.80857517384e-05.\n",
      "Epoch:7, weight train batch: 150, step:8, loss before: 7.5176518294e-05, loss after: 7.51169209252e-05.\n",
      "Epoch:7, weight train batch: 150, step:9, loss before: 7.19056188245e-05, loss after: 7.18348383089e-05.\n",
      "Epoch:7, weight train batch: 150, step:10, loss before: 7.9449142504e-05, loss after: 7.9449142504e-05.\n",
      "Epoch:7, weight train batch: 150, step:11, loss before: 8.74354154803e-05, loss after: 8.73497483553e-05.\n",
      "Epoch:7, weight train batch: 150, step:12, loss before: 7.18277005944e-05, loss after: 7.17755465303e-05.\n",
      "Epoch:7, weight train batch: 150, step:13, loss before: 0.00425920356065, loss after: 0.0042560226284.\n",
      "Epoch:7, weight train batch: 150, step:14, loss before: 9.20898746699e-05, loss after: 9.20191014302e-05.\n",
      "Epoch:7, weight train batch: 150, step:15, loss before: 0.00407635746524, loss after: 0.00407064845785.\n",
      "Epoch:7, weight train batch: 150, step:16, loss before: 7.03228870407e-05, loss after: 7.02632969478e-05.\n",
      "Epoch:7, weight train batch: 150, step:17, loss before: 0.000290056632366, loss after: 0.000289734249236.\n",
      "Epoch:7, weight train batch: 150, step:18, loss before: 8.02499635029e-05, loss after: 8.02052600193e-05.\n",
      "Epoch:7, weight train batch: 150, step:19, loss before: 7.39658717066e-05, loss after: 7.38615708542e-05.\n",
      "Epoch:7, weight train batch: 150, step:20, loss before: 8.29133423395e-05, loss after: 8.2846301666e-05.\n",
      "Epoch:7, weight train batch: 150, step:21, loss before: 7.07363869878e-05, loss after: 7.06097416696e-05.\n",
      "Epoch:7, weight train batch: 150, step:22, loss before: 0.000289697491098, loss after: 0.000289045914542.\n",
      "Epoch:7, weight train batch: 150, step:23, loss before: 8.41535947984e-05, loss after: 8.40716529638e-05.\n",
      "Epoch:7, weight train batch: 150, step:24, loss before: 7.07699073246e-05, loss after: 7.07214785507e-05.\n",
      "Epoch:7, weight train batch: 150, step:25, loss before: 7.31650216039e-05, loss after: 7.30644387659e-05.\n",
      "Epoch:7, weight train batch: 150, step:26, loss before: 0.0350505821407, loss after: 0.0350001901388.\n",
      "Epoch:7, weight train batch: 150, step:27, loss before: 6.92984758643e-05, loss after: 6.94661066518e-05.\n",
      "Epoch:7, weight train batch: 150, step:28, loss before: 7.21704709576e-05, loss after: 7.24088749848e-05.\n",
      "Epoch:7, weight train batch: 150, step:29, loss before: 5.98928090767e-05, loss after: 6.00790590397e-05.\n",
      "Epoch:7, weight train batch: 150, step:30, loss before: 7.9355930211e-05, loss after: 7.94900261099e-05.\n",
      "Epoch:7, weight train batch: 150, step:31, loss before: 9.27212677198e-05, loss after: 9.28739900701e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 146, loss before: 7.71070262999e-05, loss after: 7.71070262999e-05.\n",
      "Epoch:7, weight train batch: 151, step:0, loss before: 6.6970307671e-05, loss after: 6.7082051828e-05.\n",
      "Epoch:7, weight train batch: 151, step:1, loss before: 0.000108159329102, loss after: 0.000108338026621.\n",
      "Epoch:7, weight train batch: 151, step:2, loss before: 8.0305893789e-05, loss after: 8.03692237241e-05.\n",
      "Epoch:7, weight train batch: 151, step:3, loss before: 9.33582850848e-05, loss after: 9.34774798225e-05.\n",
      "Epoch:7, weight train batch: 151, step:4, loss before: 0.000257338047959, loss after: 0.000256979226833.\n",
      "Epoch:7, weight train batch: 151, step:5, loss before: 7.16340873623e-05, loss after: 7.16340800864e-05.\n",
      "Epoch:7, weight train batch: 151, step:6, loss before: 7.76685847086e-05, loss after: 7.7735632658e-05.\n",
      "Epoch:7, weight train batch: 151, step:7, loss before: 7.22152908565e-05, loss after: 7.22376425983e-05.\n",
      "Epoch:7, weight train batch: 151, step:8, loss before: 8.76777703525e-05, loss after: 8.76666017575e-05.\n",
      "Epoch:7, weight train batch: 151, step:9, loss before: 8.71301599545e-05, loss after: 8.7197200628e-05.\n",
      "Epoch:7, weight train batch: 151, step:10, loss before: 7.20922471373e-05, loss after: 7.20736134099e-05.\n",
      "Epoch:7, weight train batch: 151, step:11, loss before: 8.90521114343e-05, loss after: 8.90893570613e-05.\n",
      "Epoch:7, weight train batch: 151, step:12, loss before: 8.07902033557e-05, loss after: 8.07455071481e-05.\n",
      "Epoch:7, weight train batch: 151, step:13, loss before: 8.32076329971e-05, loss after: 8.32039077068e-05.\n",
      "Epoch:7, weight train batch: 151, step:14, loss before: 7.13881745469e-05, loss after: 7.13471963536e-05.\n",
      "Epoch:7, weight train batch: 151, step:15, loss before: 0.000133024936076, loss after: 0.000132969056722.\n",
      "Epoch:7, weight train batch: 151, step:16, loss before: 8.8854751084e-05, loss after: 8.88249633135e-05.\n",
      "Epoch:7, weight train batch: 151, step:17, loss before: 8.48019990372e-05, loss after: 8.47349583637e-05.\n",
      "Epoch:7, weight train batch: 151, step:18, loss before: 8.21534340503e-05, loss after: 8.20863788249e-05.\n",
      "Epoch:7, weight train batch: 151, step:19, loss before: 7.66776502132e-05, loss after: 7.66180528444e-05.\n",
      "Epoch:7, weight train batch: 151, step:20, loss before: 8.66755144671e-05, loss after: 8.6601023213e-05.\n",
      "Epoch:7, weight train batch: 151, step:21, loss before: 8.10022320366e-05, loss after: 8.09351840871e-05.\n",
      "Epoch:7, weight train batch: 151, step:22, loss before: 7.99631525297e-05, loss after: 7.98998298706e-05.\n",
      "Epoch:7, weight train batch: 151, step:23, loss before: 6.11219802522e-05, loss after: 6.10996285104e-05.\n",
      "Epoch:7, weight train batch: 151, step:24, loss before: 7.09822270437e-05, loss after: 7.08816514816e-05.\n",
      "Epoch:7, weight train batch: 151, step:25, loss before: 8.52788289194e-05, loss after: 8.5249033873e-05.\n",
      "Epoch:7, weight train batch: 151, step:26, loss before: 7.14143752703e-05, loss after: 7.1324975579e-05.\n",
      "Epoch:7, weight train batch: 151, step:27, loss before: 6.60613150103e-05, loss after: 6.60166115267e-05.\n",
      "Epoch:7, weight train batch: 151, step:28, loss before: 8.04065493867e-05, loss after: 8.03394941613e-05.\n",
      "Epoch:7, weight train batch: 151, step:29, loss before: 8.65452893777e-05, loss after: 8.64260800881e-05.\n",
      "Epoch:7, weight train batch: 151, step:30, loss before: 7.42006086512e-05, loss after: 7.41782569094e-05.\n",
      "Epoch:7, weight train batch: 151, step:31, loss before: 8.07193573564e-05, loss after: 8.06262323749e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 147, loss before: 8.42134395498e-05, loss after: 8.42050576466e-05.\n",
      "Epoch:7, weight train batch: 152, step:0, loss before: 5.92894102738e-05, loss after: 5.92596079514e-05.\n",
      "Epoch:7, weight train batch: 152, step:1, loss before: 8.21385692689e-05, loss after: 8.20491768536e-05.\n",
      "Epoch:7, weight train batch: 152, step:2, loss before: 7.45804791222e-05, loss after: 7.45395082049e-05.\n",
      "Epoch:7, weight train batch: 152, step:3, loss before: 6.72049500281e-05, loss after: 6.70857552905e-05.\n",
      "Epoch:7, weight train batch: 152, step:4, loss before: 6.99727825122e-05, loss after: 6.9920628448e-05.\n",
      "Epoch:7, weight train batch: 152, step:5, loss before: 7.04494887032e-05, loss after: 7.03675468685e-05.\n",
      "Epoch:7, weight train batch: 152, step:6, loss before: 6.77822972648e-05, loss after: 6.7759945523e-05.\n",
      "Epoch:7, weight train batch: 152, step:7, loss before: 8.5524370661e-05, loss after: 8.54237950989e-05.\n",
      "Epoch:7, weight train batch: 152, step:8, loss before: 6.71938978485e-05, loss after: 6.71789966873e-05.\n",
      "Epoch:7, weight train batch: 152, step:9, loss before: 7.27068108972e-05, loss after: 7.25503632566e-05.\n",
      "Epoch:7, weight train batch: 152, step:10, loss before: 8.23397713248e-05, loss after: 8.22689908091e-05.\n",
      "Epoch:7, weight train batch: 152, step:11, loss before: 8.19597771624e-05, loss after: 8.19038978079e-05.\n",
      "Epoch:7, weight train batch: 152, step:12, loss before: 0.00012470537331, loss after: 0.000124541518744.\n",
      "Epoch:7, weight train batch: 152, step:13, loss before: 7.40180767025e-05, loss after: 7.39845563658e-05.\n",
      "Epoch:7, weight train batch: 152, step:14, loss before: 8.23994923849e-05, loss after: 8.22802903713e-05.\n",
      "Epoch:7, weight train batch: 152, step:15, loss before: 7.68677637097e-05, loss after: 7.68044410506e-05.\n",
      "Epoch:7, weight train batch: 152, step:16, loss before: 7.24610144971e-05, loss after: 7.24051351426e-05.\n",
      "Epoch:7, weight train batch: 152, step:17, loss before: 7.87413664511e-05, loss after: 7.86221644375e-05.\n",
      "Epoch:7, weight train batch: 152, step:18, loss before: 7.53776839701e-05, loss after: 7.53553322284e-05.\n",
      "Epoch:7, weight train batch: 152, step:19, loss before: 0.000488045479869, loss after: 0.000486761098728.\n",
      "Epoch:7, weight train batch: 152, step:20, loss before: 7.70613842178e-05, loss after: 7.69794423832e-05.\n",
      "Epoch:7, weight train batch: 152, step:21, loss before: 0.000255024322541, loss after: 0.000254756945651.\n",
      "Epoch:7, weight train batch: 152, step:22, loss before: 6.55027251923e-05, loss after: 6.5361171437e-05.\n",
      "Epoch:7, weight train batch: 152, step:23, loss before: 8.51095392136e-05, loss after: 8.50126816658e-05.\n",
      "Epoch:7, weight train batch: 152, step:24, loss before: 7.41932308301e-05, loss after: 7.40740360925e-05.\n",
      "Epoch:7, weight train batch: 152, step:25, loss before: 7.35784997232e-05, loss after: 7.34742061468e-05.\n",
      "Epoch:7, weight train batch: 152, step:26, loss before: 7.77841050876e-05, loss after: 7.76909873821e-05.\n",
      "Epoch:7, weight train batch: 152, step:27, loss before: 8.87543064891e-05, loss after: 8.86798079591e-05.\n",
      "Epoch:7, weight train batch: 152, step:28, loss before: 8.13377992017e-05, loss after: 8.12409562059e-05.\n",
      "Epoch:7, weight train batch: 152, step:29, loss before: 7.40776158636e-05, loss after: 7.40031246096e-05.\n",
      "Epoch:7, weight train batch: 152, step:30, loss before: 6.86390849296e-05, loss after: 6.85794948367e-05.\n",
      "Epoch:7, weight train batch: 152, step:31, loss before: 8.24142844067e-05, loss after: 8.23137161206e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 148, loss before: 7.16313079465e-05, loss after: 7.15847418178e-05.\n",
      "Epoch:7, weight train batch: 153, step:0, loss before: 6.85942941345e-05, loss after: 6.85235136189e-05.\n",
      "Epoch:7, weight train batch: 153, step:1, loss before: 6.92315079505e-05, loss after: 6.91458262736e-05.\n",
      "Epoch:7, weight train batch: 153, step:2, loss before: 5.87418071518e-05, loss after: 5.87082868151e-05.\n",
      "Epoch:7, weight train batch: 153, step:3, loss before: 7.94082006905e-05, loss after: 7.9389574239e-05.\n",
      "Epoch:7, weight train batch: 153, step:4, loss before: 6.96971110301e-05, loss after: 6.95779090165e-05.\n",
      "Epoch:7, weight train batch: 153, step:5, loss before: 8.28053889563e-05, loss after: 8.27569601825e-05.\n",
      "Epoch:7, weight train batch: 153, step:6, loss before: 7.23866323824e-05, loss after: 7.22935074009e-05.\n",
      "Epoch:7, weight train batch: 153, step:7, loss before: 8.22951406008e-05, loss after: 8.22392612463e-05.\n",
      "Epoch:7, weight train batch: 153, step:8, loss before: 6.8639179517e-05, loss after: 6.85795748723e-05.\n",
      "Epoch:7, weight train batch: 153, step:9, loss before: 7.31540058041e-05, loss after: 7.30571628083e-05.\n",
      "Epoch:7, weight train batch: 153, step:10, loss before: 0.00596920726821, loss after: 0.00595751684159.\n",
      "Epoch:7, weight train batch: 153, step:11, loss before: 6.77080679452e-05, loss after: 6.76484705764e-05.\n",
      "Epoch:7, weight train batch: 153, step:12, loss before: 7.49904211261e-05, loss after: 7.49121973058e-05.\n",
      "Epoch:7, weight train batch: 153, step:13, loss before: 7.40628165659e-05, loss after: 7.38989256206e-05.\n",
      "Epoch:7, weight train batch: 153, step:14, loss before: 6.64935359964e-05, loss after: 6.64041363052e-05.\n",
      "Epoch:7, weight train batch: 153, step:15, loss before: 8.49920033943e-05, loss after: 8.48355557537e-05.\n",
      "Epoch:7, weight train batch: 153, step:16, loss before: 7.65883887652e-05, loss after: 7.649899635e-05.\n",
      "Epoch:7, weight train batch: 153, step:17, loss before: 6.76707059029e-05, loss after: 6.76409108564e-05.\n",
      "Epoch:7, weight train batch: 153, step:18, loss before: 6.43108141958e-05, loss after: 6.42474915367e-05.\n",
      "Epoch:7, weight train batch: 153, step:19, loss before: 7.24834681023e-05, loss after: 7.2394075687e-05.\n",
      "Epoch:7, weight train batch: 153, step:20, loss before: 7.1637921792e-05, loss after: 7.1563423262e-05.\n",
      "Epoch:7, weight train batch: 153, step:21, loss before: 8.28390693641e-05, loss after: 8.27124167699e-05.\n",
      "Epoch:7, weight train batch: 153, step:22, loss before: 6.65719126118e-05, loss after: 6.65197658236e-05.\n",
      "Epoch:7, weight train batch: 153, step:23, loss before: 7.4748408224e-05, loss after: 7.46664591134e-05.\n",
      "Epoch:7, weight train batch: 153, step:24, loss before: 0.000484199874336, loss after: 0.00048320897622.\n",
      "Epoch:7, weight train batch: 153, step:25, loss before: 7.56795197958e-05, loss after: 7.56348163122e-05.\n",
      "Epoch:7, weight train batch: 153, step:26, loss before: 7.55156725063e-05, loss after: 7.54560751375e-05.\n",
      "Epoch:7, weight train batch: 153, step:27, loss before: 8.0857265857e-05, loss after: 8.07678588899e-05.\n",
      "Epoch:7, weight train batch: 153, step:28, loss before: 6.16882607574e-05, loss after: 6.16025936324e-05.\n",
      "Epoch:7, weight train batch: 153, step:29, loss before: 7.4286297604e-05, loss after: 7.42304255255e-05.\n",
      "Epoch:7, weight train batch: 153, step:30, loss before: 6.75590417814e-05, loss after: 6.74659167998e-05.\n",
      "Epoch:7, weight train batch: 153, step:31, loss before: 7.71472114138e-05, loss after: 7.71025224822e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 149, loss before: 0.00149800989311, loss after: 6.9715155405e-05.\n",
      "Epoch:7, weight train batch: 154, step:0, loss before: 6.7015105742e-05, loss after: 6.69331566314e-05.\n",
      "Epoch:7, weight train batch: 154, step:1, loss before: 8.17737309262e-05, loss after: 8.16917818156e-05.\n",
      "Epoch:7, weight train batch: 154, step:2, loss before: 0.000274401711067, loss after: 0.000274187070318.\n",
      "Epoch:7, weight train batch: 154, step:3, loss before: 6.94550108165e-05, loss after: 6.93693291396e-05.\n",
      "Epoch:7, weight train batch: 154, step:4, loss before: 7.78027897468e-05, loss after: 7.77320165071e-05.\n",
      "Epoch:7, weight train batch: 154, step:5, loss before: 8.56962433318e-05, loss after: 8.55807593325e-05.\n",
      "Epoch:7, weight train batch: 154, step:6, loss before: 7.74266154622e-05, loss after: 7.73782012402e-05.\n",
      "Epoch:7, weight train batch: 154, step:7, loss before: 7.13771441951e-05, loss after: 7.12579349056e-05.\n",
      "Epoch:7, weight train batch: 154, step:8, loss before: 7.22971890355e-05, loss after: 7.22971890355e-05.\n",
      "Epoch:7, weight train batch: 154, step:9, loss before: 7.73781430325e-05, loss after: 7.7285025327e-05.\n",
      "Epoch:7, weight train batch: 154, step:10, loss before: 6.87473075232e-05, loss after: 6.87063293299e-05.\n",
      "Epoch:7, weight train batch: 154, step:11, loss before: 7.78363610152e-05, loss after: 7.77171517257e-05.\n",
      "Epoch:7, weight train batch: 154, step:12, loss before: 8.27310577733e-05, loss after: 8.27310577733e-05.\n",
      "Epoch:7, weight train batch: 154, step:13, loss before: 6.6195600084e-05, loss after: 6.61434532958e-05.\n",
      "Epoch:7, weight train batch: 154, step:14, loss before: 7.28634186089e-05, loss after: 7.28038139641e-05.\n",
      "Epoch:7, weight train batch: 154, step:15, loss before: 7.69981998019e-05, loss after: 7.69013495301e-05.\n",
      "Epoch:7, weight train batch: 154, step:16, loss before: 7.32694752514e-05, loss after: 7.31949767214e-05.\n",
      "Epoch:7, weight train batch: 154, step:17, loss before: 7.36493675504e-05, loss after: 7.36158399377e-05.\n",
      "Epoch:7, weight train batch: 154, step:18, loss before: 7.8439778008e-05, loss after: 7.83652940299e-05.\n",
      "Epoch:7, weight train batch: 154, step:19, loss before: 7.67374585848e-05, loss after: 7.6715106843e-05.\n",
      "Epoch:7, weight train batch: 154, step:20, loss before: 6.55549592921e-05, loss after: 6.55065377941e-05.\n",
      "Epoch:7, weight train batch: 154, step:21, loss before: 7.15634305379e-05, loss after: 7.15038331691e-05.\n",
      "Epoch:7, weight train batch: 154, step:22, loss before: 0.000127424413222, loss after: 0.000127349951072.\n",
      "Epoch:7, weight train batch: 154, step:23, loss before: 7.03192927176e-05, loss after: 7.02634279151e-05.\n",
      "Epoch:7, weight train batch: 154, step:24, loss before: 6.39904028503e-05, loss after: 6.39382487861e-05.\n",
      "Epoch:7, weight train batch: 154, step:25, loss before: 7.779297448e-05, loss after: 7.7744552982e-05.\n",
      "Epoch:7, weight train batch: 154, step:26, loss before: 0.000106563667941, loss after: 0.000106444502308.\n",
      "Epoch:7, weight train batch: 154, step:27, loss before: 7.97100074124e-05, loss after: 7.96951062512e-05.\n",
      "Epoch:7, weight train batch: 154, step:28, loss before: 7.38654489396e-05, loss after: 7.37984082662e-05.\n",
      "Epoch:7, weight train batch: 154, step:29, loss before: 6.12860167166e-05, loss after: 6.1241313233e-05.\n",
      "Epoch:7, weight train batch: 154, step:30, loss before: 8.81597661646e-05, loss after: 8.81374289747e-05.\n",
      "Epoch:7, weight train batch: 154, step:31, loss before: 6.49924841127e-05, loss after: 6.49440626148e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 150, loss before: 8.6849409854e-05, loss after: 0.00864378921688.\n",
      "Epoch:7, weight train batch: 155, step:0, loss before: 7.95628584456e-05, loss after: 7.94548395788e-05.\n",
      "Epoch:7, weight train batch: 155, step:1, loss before: 7.45322977309e-05, loss after: 7.44876015233e-05.\n",
      "Epoch:7, weight train batch: 155, step:2, loss before: 6.75552655593e-05, loss after: 6.75291958032e-05.\n",
      "Epoch:7, weight train batch: 155, step:3, loss before: 6.33497111266e-05, loss after: 6.32863811916e-05.\n",
      "Epoch:7, weight train batch: 155, step:4, loss before: 7.30609099264e-05, loss after: 7.29975872673e-05.\n",
      "Epoch:7, weight train batch: 155, step:5, loss before: 7.64283249737e-05, loss after: 7.64059732319e-05.\n",
      "Epoch:7, weight train batch: 155, step:6, loss before: 7.57391608204e-05, loss after: 7.56460358389e-05.\n",
      "Epoch:7, weight train batch: 155, step:7, loss before: 6.49775320198e-05, loss after: 6.49589055683e-05.\n",
      "Epoch:7, weight train batch: 155, step:8, loss before: 7.78773464845e-05, loss after: 7.7847551438e-05.\n",
      "Epoch:7, weight train batch: 155, step:9, loss before: 6.99988449924e-05, loss after: 6.99168958818e-05.\n",
      "Epoch:7, weight train batch: 155, step:10, loss before: 7.12318724254e-05, loss after: 7.12281471351e-05.\n",
      "Epoch:7, weight train batch: 155, step:11, loss before: 6.48024579277e-05, loss after: 6.47130509606e-05.\n",
      "Epoch:7, weight train batch: 155, step:12, loss before: 6.54171089991e-05, loss after: 6.53835813864e-05.\n",
      "Epoch:7, weight train batch: 155, step:13, loss before: 7.41672411095e-05, loss after: 7.41002004361e-05.\n",
      "Epoch:7, weight train batch: 155, step:14, loss before: 7.41411713534e-05, loss after: 7.4074123404e-05.\n",
      "Epoch:7, weight train batch: 155, step:15, loss before: 6.4619933255e-05, loss after: 6.45901309326e-05.\n",
      "Epoch:7, weight train batch: 155, step:16, loss before: 7.16155773262e-05, loss after: 7.1552254667e-05.\n",
      "Epoch:7, weight train batch: 155, step:17, loss before: 7.81642156653e-05, loss after: 7.81455892138e-05.\n",
      "Epoch:7, weight train batch: 155, step:18, loss before: 7.363090117e-05, loss after: 7.35266075935e-05.\n",
      "Epoch:7, weight train batch: 155, step:19, loss before: 6.67581189191e-05, loss after: 6.6732041887e-05.\n",
      "Epoch:7, weight train batch: 155, step:20, loss before: 6.44448591629e-05, loss after: 6.44076062599e-05.\n",
      "Epoch:7, weight train batch: 155, step:21, loss before: 6.89968801453e-05, loss after: 6.89074804541e-05.\n",
      "Epoch:7, weight train batch: 155, step:22, loss before: 7.22190670785e-05, loss after: 7.22190670785e-05.\n",
      "Epoch:7, weight train batch: 155, step:23, loss before: 6.7708097049e-05, loss after: 6.76559575368e-05.\n",
      "Epoch:7, weight train batch: 155, step:24, loss before: 7.30161991669e-05, loss after: 7.29565945221e-05.\n",
      "Epoch:7, weight train batch: 155, step:25, loss before: 6.21166473138e-05, loss after: 6.20346982032e-05.\n",
      "Epoch:7, weight train batch: 155, step:26, loss before: 0.00397153478116, loss after: 0.00396920274943.\n",
      "Epoch:7, weight train batch: 155, step:27, loss before: 0.000282772583887, loss after: 0.000282686844002.\n",
      "Epoch:7, weight train batch: 155, step:28, loss before: 6.09769049333e-05, loss after: 6.09657290624e-05.\n",
      "Epoch:7, weight train batch: 155, step:29, loss before: 7.78810644988e-05, loss after: 7.77357927291e-05.\n",
      "Epoch:7, weight train batch: 155, step:30, loss before: 6.57971249893e-05, loss after: 6.57449709252e-05.\n",
      "Epoch:7, weight train batch: 155, step:31, loss before: 7.53183630877e-05, loss after: 7.52773921704e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 151, loss before: 7.01646640664e-05, loss after: 0.000111261411803.\n",
      "Epoch:7, weight train batch: 156, step:0, loss before: 6.71381785651e-05, loss after: 6.7037603003e-05.\n",
      "Epoch:7, weight train batch: 156, step:1, loss before: 6.86392304488e-05, loss after: 6.86094281264e-05.\n",
      "Epoch:7, weight train batch: 156, step:2, loss before: 0.000118561001727, loss after: 0.000118378542538.\n",
      "Epoch:7, weight train batch: 156, step:3, loss before: 7.12580222171e-05, loss after: 7.12095934432e-05.\n",
      "Epoch:7, weight train batch: 156, step:4, loss before: 7.07848739694e-05, loss after: 7.07587969373e-05.\n",
      "Epoch:7, weight train batch: 156, step:5, loss before: 6.878458953e-05, loss after: 6.86914718244e-05.\n",
      "Epoch:7, weight train batch: 156, step:6, loss before: 7.00511518517e-05, loss after: 7.00213495293e-05.\n",
      "Epoch:7, weight train batch: 156, step:7, loss before: 7.0703055826e-05, loss after: 7.06434511812e-05.\n",
      "Epoch:7, weight train batch: 156, step:8, loss before: 5.9181391407e-05, loss after: 5.9106896515e-05.\n",
      "Epoch:7, weight train batch: 156, step:9, loss before: 7.760173321e-05, loss after: 7.75235093897e-05.\n",
      "Epoch:7, weight train batch: 156, step:10, loss before: 7.62479394325e-05, loss after: 7.62218696764e-05.\n",
      "Epoch:7, weight train batch: 156, step:11, loss before: 7.14741036063e-05, loss after: 7.13735353202e-05.\n",
      "Epoch:7, weight train batch: 156, step:12, loss before: 6.29846617812e-05, loss after: 6.29623100394e-05.\n",
      "Epoch:7, weight train batch: 156, step:13, loss before: 7.46776204323e-05, loss after: 7.464781811e-05.\n",
      "Epoch:7, weight train batch: 156, step:14, loss before: 7.53295316827e-05, loss after: 7.52438500058e-05.\n",
      "Epoch:7, weight train batch: 156, step:15, loss before: 7.38804519642e-05, loss after: 7.38096714485e-05.\n",
      "Epoch:7, weight train batch: 156, step:16, loss before: 6.63745013298e-05, loss after: 6.63521495881e-05.\n",
      "Epoch:7, weight train batch: 156, step:17, loss before: 7.37686932553e-05, loss after: 7.37128211767e-05.\n",
      "Epoch:7, weight train batch: 156, step:18, loss before: 8.11352656456e-05, loss after: 8.1079400843e-05.\n",
      "Epoch:7, weight train batch: 156, step:19, loss before: 5.73262841499e-05, loss after: 5.72555145482e-05.\n",
      "Epoch:7, weight train batch: 156, step:20, loss before: 5.95948476985e-05, loss after: 5.95948476985e-05.\n",
      "Epoch:7, weight train batch: 156, step:21, loss before: 6.72610476613e-05, loss after: 6.71716406941e-05.\n",
      "Epoch:7, weight train batch: 156, step:22, loss before: 6.81512974552e-05, loss after: 6.80954181007e-05.\n",
      "Epoch:7, weight train batch: 156, step:23, loss before: 6.87659485266e-05, loss after: 6.87361462042e-05.\n",
      "Epoch:7, weight train batch: 156, step:24, loss before: 6.91161840223e-05, loss after: 6.90938322805e-05.\n",
      "Epoch:7, weight train batch: 156, step:25, loss before: 9.85635851976e-05, loss after: 9.8507720395e-05.\n",
      "Epoch:7, weight train batch: 156, step:26, loss before: 6.23476953479e-05, loss after: 6.22843654128e-05.\n",
      "Epoch:7, weight train batch: 156, step:27, loss before: 7.15523201507e-05, loss after: 7.14852722012e-05.\n",
      "Epoch:7, weight train batch: 156, step:28, loss before: 6.68885477353e-05, loss after: 6.68587454129e-05.\n",
      "Epoch:7, weight train batch: 156, step:29, loss before: 7.89338009781e-05, loss after: 7.88406759966e-05.\n",
      "Epoch:7, weight train batch: 156, step:30, loss before: 6.8117849878e-05, loss after: 6.80880475556e-05.\n",
      "Epoch:7, weight train batch: 156, step:31, loss before: 7.66966477386e-05, loss after: 7.66593948356e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 152, loss before: 7.83496361692e-05, loss after: 6.52178423479e-05.\n",
      "Epoch:7, weight train batch: 157, step:0, loss before: 7.39474780858e-05, loss after: 7.38804374123e-05.\n",
      "Epoch:7, weight train batch: 157, step:1, loss before: 0.0343747697771, loss after: 0.0343219153583.\n",
      "Epoch:7, weight train batch: 157, step:2, loss before: 5.64584042877e-05, loss after: 5.65068294236e-05.\n",
      "Epoch:7, weight train batch: 157, step:3, loss before: 7.10866152076e-05, loss after: 7.12169930921e-05.\n",
      "Epoch:7, weight train batch: 157, step:4, loss before: 7.96058520791e-05, loss after: 7.98293549451e-05.\n",
      "Epoch:7, weight train batch: 157, step:5, loss before: 6.23700470896e-05, loss after: 6.24780659564e-05.\n",
      "Epoch:7, weight train batch: 157, step:6, loss before: 7.41784751881e-05, loss after: 7.43423734093e-05.\n",
      "Epoch:7, weight train batch: 157, step:7, loss before: 7.16056383681e-05, loss after: 7.16056383681e-05.\n",
      "Epoch:7, weight train batch: 157, step:8, loss before: 7.44317367207e-05, loss after: 7.44950593798e-05.\n",
      "Epoch:7, weight train batch: 157, step:9, loss before: 6.05856839684e-05, loss after: 6.06005851296e-05.\n",
      "Epoch:7, weight train batch: 157, step:10, loss before: 8.69052382768e-05, loss after: 8.69685682119e-05.\n",
      "Epoch:7, weight train batch: 157, step:11, loss before: 7.31540349079e-05, loss after: 7.31838372303e-05.\n",
      "Epoch:7, weight train batch: 157, step:12, loss before: 6.49961584713e-05, loss after: 6.50147849228e-05.\n",
      "Epoch:7, weight train batch: 157, step:13, loss before: 7.23642733647e-05, loss after: 7.2442497185e-05.\n",
      "Epoch:7, weight train batch: 157, step:14, loss before: 6.88292857376e-05, loss after: 6.88106520101e-05.\n",
      "Epoch:7, weight train batch: 157, step:15, loss before: 6.98983785696e-05, loss after: 6.98946532793e-05.\n",
      "Epoch:7, weight train batch: 157, step:16, loss before: 0.000445384444902, loss after: 0.000444920355221.\n",
      "Epoch:7, weight train batch: 157, step:17, loss before: 6.73578470014e-05, loss after: 6.73429458402e-05.\n",
      "Epoch:7, weight train batch: 157, step:18, loss before: 0.000109198714199, loss after: 0.000109042346594.\n",
      "Epoch:7, weight train batch: 157, step:19, loss before: 7.17869916116e-05, loss after: 7.1742295404e-05.\n",
      "Epoch:7, weight train batch: 157, step:20, loss before: 6.9976587838e-05, loss after: 6.99281663401e-05.\n",
      "Epoch:7, weight train batch: 157, step:21, loss before: 6.36180193396e-05, loss after: 6.35695905657e-05.\n",
      "Epoch:7, weight train batch: 157, step:22, loss before: 6.02430591243e-05, loss after: 6.01573847234e-05.\n",
      "Epoch:7, weight train batch: 157, step:23, loss before: 7.76166561991e-05, loss after: 7.75943044573e-05.\n",
      "Epoch:7, weight train batch: 157, step:24, loss before: 8.49363932502e-05, loss after: 8.49140415085e-05.\n",
      "Epoch:7, weight train batch: 157, step:25, loss before: 0.000232214006246, loss after: 0.000231980069657.\n",
      "Epoch:7, weight train batch: 157, step:26, loss before: 6.98090007063e-05, loss after: 6.97270588716e-05.\n",
      "Epoch:7, weight train batch: 157, step:27, loss before: 7.12990149623e-05, loss after: 7.1258036769e-05.\n",
      "Epoch:7, weight train batch: 157, step:28, loss before: 7.14927082299e-05, loss after: 7.13958579581e-05.\n",
      "Epoch:7, weight train batch: 157, step:29, loss before: 5.6003962527e-05, loss after: 5.59629843337e-05.\n",
      "Epoch:7, weight train batch: 157, step:30, loss before: 6.82667960064e-05, loss after: 6.81773963151e-05.\n",
      "Epoch:7, weight train batch: 157, step:31, loss before: 7.09189771442e-05, loss after: 7.08742882125e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 153, loss before: 7.01386525179e-05, loss after: 7.13129338692e-05.\n",
      "Epoch:7, weight train batch: 158, step:0, loss before: 5.97066136834e-05, loss after: 5.96246682107e-05.\n",
      "Epoch:7, weight train batch: 158, step:1, loss before: 6.24818057986e-05, loss after: 6.24594613328e-05.\n",
      "Epoch:7, weight train batch: 158, step:2, loss before: 7.29528692318e-05, loss after: 7.28336744942e-05.\n",
      "Epoch:7, weight train batch: 158, step:3, loss before: 7.25543432054e-05, loss after: 7.25096397218e-05.\n",
      "Epoch:7, weight train batch: 158, step:4, loss before: 7.89242185419e-05, loss after: 7.88124743849e-05.\n",
      "Epoch:7, weight train batch: 158, step:5, loss before: 0.000233167011174, loss after: 0.000233074286371.\n",
      "Epoch:7, weight train batch: 158, step:6, loss before: 5.80117230129e-05, loss after: 5.79335028306e-05.\n",
      "Epoch:7, weight train batch: 158, step:7, loss before: 6.38377532596e-05, loss after: 6.37856064714e-05.\n",
      "Epoch:7, weight train batch: 158, step:8, loss before: 6.73541726428e-05, loss after: 6.72908499837e-05.\n",
      "Epoch:7, weight train batch: 158, step:9, loss before: 7.35489011277e-05, loss after: 7.34557761461e-05.\n",
      "Epoch:7, weight train batch: 158, step:10, loss before: 6.78347278154e-05, loss after: 6.77974749124e-05.\n",
      "Epoch:7, weight train batch: 158, step:11, loss before: 7.11388274794e-05, loss after: 7.10419699317e-05.\n",
      "Epoch:7, weight train batch: 158, step:12, loss before: 6.18224876234e-05, loss after: 6.17777841398e-05.\n",
      "Epoch:7, weight train batch: 158, step:13, loss before: 5.17760927323e-05, loss after: 5.16904183314e-05.\n",
      "Epoch:7, weight train batch: 158, step:14, loss before: 6.15915705566e-05, loss after: 6.15655008005e-05.\n",
      "Epoch:7, weight train batch: 158, step:15, loss before: 6.36365657556e-05, loss after: 6.3517363742e-05.\n",
      "Epoch:7, weight train batch: 158, step:16, loss before: 6.72759488225e-05, loss after: 6.72461465001e-05.\n",
      "Epoch:7, weight train batch: 158, step:17, loss before: 6.46572370897e-05, loss after: 6.45976397209e-05.\n",
      "Epoch:7, weight train batch: 158, step:18, loss before: 6.3629115175e-05, loss after: 6.35657925159e-05.\n",
      "Epoch:7, weight train batch: 158, step:19, loss before: 6.39455902274e-05, loss after: 6.38934434392e-05.\n",
      "Epoch:7, weight train batch: 158, step:20, loss before: 6.03100779699e-05, loss after: 6.02579239057e-05.\n",
      "Epoch:7, weight train batch: 158, step:21, loss before: 6.08054942859e-05, loss after: 6.07496222074e-05.\n",
      "Epoch:7, weight train batch: 158, step:22, loss before: 0.000107904292236, loss after: 0.000107792584458.\n",
      "Epoch:7, weight train batch: 158, step:23, loss before: 5.96694590058e-05, loss after: 5.96210375079e-05.\n",
      "Epoch:7, weight train batch: 158, step:24, loss before: 6.50483852951e-05, loss after: 6.49925059406e-05.\n",
      "Epoch:7, weight train batch: 158, step:25, loss before: 6.44114188617e-05, loss after: 6.43890671199e-05.\n",
      "Epoch:7, weight train batch: 158, step:26, loss before: 6.73840404488e-05, loss after: 6.73654139973e-05.\n",
      "Epoch:7, weight train batch: 158, step:27, loss before: 5.30536526639e-05, loss after: 5.29866083525e-05.\n",
      "Epoch:7, weight train batch: 158, step:28, loss before: 6.73839967931e-05, loss after: 6.73504691804e-05.\n",
      "Epoch:7, weight train batch: 158, step:29, loss before: 6.96786082699e-05, loss after: 6.95594062563e-05.\n",
      "Epoch:7, weight train batch: 158, step:30, loss before: 6.79464646964e-05, loss after: 6.78980359226e-05.\n",
      "Epoch:7, weight train batch: 158, step:31, loss before: 6.53949100524e-05, loss after: 6.52906092e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 154, loss before: 6.83841863065e-05, loss after: 9.17444995139e-05.\n",
      "Epoch:7, weight train batch: 159, step:0, loss before: 6.90899178153e-05, loss after: 6.90675660735e-05.\n",
      "Epoch:7, weight train batch: 159, step:1, loss before: 6.31672446616e-05, loss after: 6.31113725831e-05.\n",
      "Epoch:7, weight train batch: 159, step:2, loss before: 6.17852492724e-05, loss after: 6.17517216597e-05.\n",
      "Epoch:7, weight train batch: 159, step:3, loss before: 5.82278153161e-05, loss after: 5.81793938181e-05.\n",
      "Epoch:7, weight train batch: 159, step:4, loss before: 5.87866306887e-05, loss after: 5.86860514886e-05.\n",
      "Epoch:7, weight train batch: 159, step:5, loss before: 6.57784621581e-05, loss after: 6.57523924019e-05.\n",
      "Epoch:7, weight train batch: 159, step:6, loss before: 5.93216609559e-05, loss after: 5.92993164901e-05.\n",
      "Epoch:7, weight train batch: 159, step:7, loss before: 6.40947837383e-05, loss after: 6.4005391323e-05.\n",
      "Epoch:7, weight train batch: 159, step:8, loss before: 7.3150426033e-05, loss after: 7.3150426033e-05.\n",
      "Epoch:7, weight train batch: 159, step:9, loss before: 6.97829309502e-05, loss after: 6.97121577105e-05.\n",
      "Epoch:7, weight train batch: 159, step:10, loss before: 7.63502321206e-05, loss after: 7.62906274758e-05.\n",
      "Epoch:7, weight train batch: 159, step:11, loss before: 6.41358274152e-05, loss after: 6.40836806269e-05.\n",
      "Epoch:7, weight train batch: 159, step:12, loss before: 6.30443464615e-05, loss after: 6.29810238024e-05.\n",
      "Epoch:7, weight train batch: 159, step:13, loss before: 6.84605474817e-05, loss after: 6.8427019869e-05.\n",
      "Epoch:7, weight train batch: 159, step:14, loss before: 6.19193451712e-05, loss after: 6.18895428488e-05.\n",
      "Epoch:7, weight train batch: 159, step:15, loss before: 5.85629859415e-05, loss after: 5.8507113863e-05.\n",
      "Epoch:7, weight train batch: 159, step:16, loss before: 0.000120095624879, loss after: 0.000119995114801.\n",
      "Epoch:7, weight train batch: 159, step:17, loss before: 6.94998307154e-05, loss after: 6.94663031027e-05.\n",
      "Epoch:7, weight train batch: 159, step:18, loss before: 9.83525533229e-05, loss after: 9.82929850579e-05.\n",
      "Epoch:7, weight train batch: 159, step:19, loss before: 6.54917384963e-05, loss after: 6.53911702102e-05.\n",
      "Epoch:7, weight train batch: 159, step:20, loss before: 7.6280819485e-05, loss after: 7.62249401305e-05.\n",
      "Epoch:7, weight train batch: 159, step:21, loss before: 6.78794312989e-05, loss after: 6.78533615428e-05.\n",
      "Epoch:7, weight train batch: 159, step:22, loss before: 6.57077180222e-05, loss after: 6.5644402639e-05.\n",
      "Epoch:7, weight train batch: 159, step:23, loss before: 6.06491666986e-05, loss after: 6.06305402471e-05.\n",
      "Epoch:7, weight train batch: 159, step:24, loss before: 6.24855965725e-05, loss after: 6.24185486231e-05.\n",
      "Epoch:7, weight train batch: 159, step:25, loss before: 0.00010552884487, loss after: 0.00010546555859.\n",
      "Epoch:7, weight train batch: 159, step:26, loss before: 6.29176647635e-05, loss after: 6.28878624411e-05.\n",
      "Epoch:7, weight train batch: 159, step:27, loss before: 7.03491896274e-05, loss after: 7.02597899362e-05.\n",
      "Epoch:7, weight train batch: 159, step:28, loss before: 6.29511778243e-05, loss after: 6.29251007922e-05.\n",
      "Epoch:7, weight train batch: 159, step:29, loss before: 7.53370040911e-05, loss after: 7.52848500269e-05.\n",
      "Epoch:7, weight train batch: 159, step:30, loss before: 6.49627545499e-05, loss after: 6.49068824714e-05.\n",
      "Epoch:7, weight train batch: 159, step:31, loss before: 6.71417219564e-05, loss after: 6.7111919634e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:7, struct parameters train batch: 155, loss before: 0.000101431265648, loss after: 6.76245181239e-05.\n",
      "Epoch:8, weight train batch: 160, step:0, loss before: 6.67879940011e-05, loss after: 6.67209387757e-05.\n",
      "Epoch:8, weight train batch: 160, step:1, loss before: 5.6305580074e-05, loss after: 5.62944078411e-05.\n",
      "Epoch:8, weight train batch: 160, step:2, loss before: 6.61772282911e-05, loss after: 6.61101803416e-05.\n",
      "Epoch:8, weight train batch: 160, step:3, loss before: 6.53423558106e-05, loss after: 6.53200040688e-05.\n",
      "Epoch:8, weight train batch: 160, step:4, loss before: 6.48808345431e-05, loss after: 6.48398636258e-05.\n",
      "Epoch:8, weight train batch: 160, step:5, loss before: 6.37148914393e-05, loss after: 6.36552940705e-05.\n",
      "Epoch:8, weight train batch: 160, step:6, loss before: 5.83135333727e-05, loss after: 5.83135333727e-05.\n",
      "Epoch:8, weight train batch: 160, step:7, loss before: 7.29902385501e-05, loss after: 7.2889670264e-05.\n",
      "Epoch:8, weight train batch: 160, step:8, loss before: 5.71997370571e-05, loss after: 5.71997370571e-05.\n",
      "Epoch:8, weight train batch: 160, step:9, loss before: 0.00413462426513, loss after: 0.00413159793243.\n",
      "Epoch:8, weight train batch: 160, step:10, loss before: 6.74473994877e-05, loss after: 6.73803515383e-05.\n",
      "Epoch:8, weight train batch: 160, step:11, loss before: 7.07403378328e-05, loss after: 7.06732826075e-05.\n",
      "Epoch:8, weight train batch: 160, step:12, loss before: 6.55848198221e-05, loss after: 6.5558750066e-05.\n",
      "Epoch:8, weight train batch: 160, step:13, loss before: 6.59747020109e-05, loss after: 6.58741191728e-05.\n",
      "Epoch:8, weight train batch: 160, step:14, loss before: 4.36143636762e-05, loss after: 4.35957372247e-05.\n",
      "Epoch:8, weight train batch: 160, step:15, loss before: 6.00009698246e-05, loss after: 5.99450941081e-05.\n",
      "Epoch:8, weight train batch: 160, step:16, loss before: 6.4430074417e-05, loss after: 6.44040046609e-05.\n",
      "Epoch:8, weight train batch: 160, step:17, loss before: 5.83880246268e-05, loss after: 5.83694018133e-05.\n",
      "Epoch:8, weight train batch: 160, step:18, loss before: 7.4033261626e-05, loss after: 7.39624883863e-05.\n",
      "Epoch:8, weight train batch: 160, step:19, loss before: 6.83227626723e-05, loss after: 6.82259124005e-05.\n",
      "Epoch:8, weight train batch: 160, step:20, loss before: 0.00554992910475, loss after: 0.00553685985506.\n",
      "Epoch:8, weight train batch: 160, step:21, loss before: 5.74157456867e-05, loss after: 5.72816461499e-05.\n",
      "Epoch:8, weight train batch: 160, step:22, loss before: 6.67172425892e-05, loss after: 6.65831466904e-05.\n",
      "Epoch:8, weight train batch: 160, step:23, loss before: 5.72817152715e-05, loss after: 5.71923119423e-05.\n",
      "Epoch:8, weight train batch: 160, step:24, loss before: 6.34652824374e-05, loss after: 6.33162853774e-05.\n",
      "Epoch:8, weight train batch: 160, step:25, loss before: 6.2154031184e-05, loss after: 6.2079532654e-05.\n",
      "Epoch:8, weight train batch: 160, step:26, loss before: 6.89821172273e-05, loss after: 6.88591971993e-05.\n",
      "Epoch:8, weight train batch: 160, step:27, loss before: 5.94161465415e-05, loss after: 5.93155709794e-05.\n",
      "Epoch:8, weight train batch: 160, step:28, loss before: 5.29084354639e-05, loss after: 5.28302116436e-05.\n",
      "Epoch:8, weight train batch: 160, step:29, loss before: 5.80452979193e-05, loss after: 5.79857005505e-05.\n",
      "Epoch:8, weight train batch: 160, step:30, loss before: 6.82222598698e-05, loss after: 6.81403034832e-05.\n",
      "Epoch:8, weight train batch: 160, step:31, loss before: 6.00493985985e-05, loss after: 5.99972445343e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 156, loss before: 6.21131403022e-05, loss after: 6.21131403022e-05.\n",
      "Epoch:8, weight train batch: 161, step:0, loss before: 6.38192141196e-05, loss after: 6.37149205431e-05.\n",
      "Epoch:8, weight train batch: 161, step:1, loss before: 7.44598000892e-05, loss after: 7.44225544622e-05.\n",
      "Epoch:8, weight train batch: 161, step:2, loss before: 6.43444727757e-05, loss after: 6.42997692921e-05.\n",
      "Epoch:8, weight train batch: 161, step:3, loss before: 6.21019717073e-05, loss after: 6.20311984676e-05.\n",
      "Epoch:8, weight train batch: 161, step:4, loss before: 6.23701416771e-05, loss after: 6.2306819018e-05.\n",
      "Epoch:8, weight train batch: 161, step:5, loss before: 5.78591098019e-05, loss after: 5.77920582145e-05.\n",
      "Epoch:8, weight train batch: 161, step:6, loss before: 5.71401542402e-05, loss after: 5.71140844841e-05.\n",
      "Epoch:8, weight train batch: 161, step:7, loss before: 6.46276021143e-05, loss after: 6.4523293986e-05.\n",
      "Epoch:8, weight train batch: 161, step:8, loss before: 6.00717685302e-05, loss after: 6.00419698458e-05.\n",
      "Epoch:8, weight train batch: 161, step:9, loss before: 5.49311844225e-05, loss after: 5.49051073904e-05.\n",
      "Epoch:8, weight train batch: 161, step:10, loss before: 6.00531420787e-05, loss after: 6.00009952905e-05.\n",
      "Epoch:8, weight train batch: 161, step:11, loss before: 5.73972101847e-05, loss after: 5.736368621e-05.\n",
      "Epoch:8, weight train batch: 161, step:12, loss before: 6.04964443482e-05, loss after: 6.0407044657e-05.\n",
      "Epoch:8, weight train batch: 161, step:13, loss before: 6.25675893389e-05, loss after: 6.25117172603e-05.\n",
      "Epoch:8, weight train batch: 161, step:14, loss before: 6.4933046815e-05, loss after: 6.49106950732e-05.\n",
      "Epoch:8, weight train batch: 161, step:15, loss before: 5.91293173784e-05, loss after: 5.90957934037e-05.\n",
      "Epoch:8, weight train batch: 161, step:16, loss before: 5.74008990952e-05, loss after: 5.73562065256e-05.\n",
      "Epoch:8, weight train batch: 161, step:17, loss before: 6.66949854349e-05, loss after: 6.66167616146e-05.\n",
      "Epoch:8, weight train batch: 161, step:18, loss before: 5.91740790696e-05, loss after: 5.91144744249e-05.\n",
      "Epoch:8, weight train batch: 161, step:19, loss before: 5.94533557887e-05, loss after: 5.93900331296e-05.\n",
      "Epoch:8, weight train batch: 161, step:20, loss before: 5.08634184371e-05, loss after: 5.08261655341e-05.\n",
      "Epoch:8, weight train batch: 161, step:21, loss before: 6.62590973661e-05, loss after: 6.623302761e-05.\n",
      "Epoch:8, weight train batch: 161, step:22, loss before: 6.04666674917e-05, loss after: 6.04443193879e-05.\n",
      "Epoch:8, weight train batch: 161, step:23, loss before: 0.000137658367748, loss after: 0.000137576484121.\n",
      "Epoch:8, weight train batch: 161, step:24, loss before: 6.53092283756e-05, loss after: 6.52161033941e-05.\n",
      "Epoch:8, weight train batch: 161, step:25, loss before: 0.000108714164526, loss after: 0.000108650885522.\n",
      "Epoch:8, weight train batch: 161, step:26, loss before: 5.98408441874e-05, loss after: 5.97812468186e-05.\n",
      "Epoch:8, weight train batch: 161, step:27, loss before: 5.60934277019e-05, loss after: 5.60263761145e-05.\n",
      "Epoch:8, weight train batch: 161, step:28, loss before: 6.18188641965e-05, loss after: 6.17853438598e-05.\n",
      "Epoch:8, weight train batch: 161, step:29, loss before: 6.37596385786e-05, loss after: 6.37223856756e-05.\n",
      "Epoch:8, weight train batch: 161, step:30, loss before: 5.8257697674e-05, loss after: 5.82241700613e-05.\n",
      "Epoch:8, weight train batch: 161, step:31, loss before: 5.41713379789e-05, loss after: 5.4122909205e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 157, loss before: 0.000100135192042, loss after: 6.4419778937e-05.\n",
      "Epoch:8, weight train batch: 162, step:0, loss before: 6.62107631797e-05, loss after: 6.61548838252e-05.\n",
      "Epoch:8, weight train batch: 162, step:1, loss before: 0.000243333022809, loss after: 0.000242958805757.\n",
      "Epoch:8, weight train batch: 162, step:2, loss before: 5.62014756724e-05, loss after: 5.61604974791e-05.\n",
      "Epoch:8, weight train batch: 162, step:3, loss before: 5.75350204599e-05, loss after: 5.74642399442e-05.\n",
      "Epoch:8, weight train batch: 162, step:4, loss before: 4.90120874019e-05, loss after: 4.89785634272e-05.\n",
      "Epoch:8, weight train batch: 162, step:5, loss before: 6.28171837889e-05, loss after: 6.27911140327e-05.\n",
      "Epoch:8, weight train batch: 162, step:6, loss before: 5.83992732572e-05, loss after: 5.83173168707e-05.\n",
      "Epoch:8, weight train batch: 162, step:7, loss before: 5.94161574554e-05, loss after: 5.94161574554e-05.\n",
      "Epoch:8, weight train batch: 162, step:8, loss before: 6.09695634921e-05, loss after: 6.08913396718e-05.\n",
      "Epoch:8, weight train batch: 162, step:9, loss before: 6.64715335006e-05, loss after: 6.64342878736e-05.\n",
      "Epoch:8, weight train batch: 162, step:10, loss before: 0.000219710695092, loss after: 0.000219217297854.\n",
      "Epoch:8, weight train batch: 162, step:11, loss before: 6.01910360274e-05, loss after: 6.01314422966e-05.\n",
      "Epoch:8, weight train batch: 162, step:12, loss before: 6.14202581346e-05, loss after: 6.13681040704e-05.\n",
      "Epoch:8, weight train batch: 162, step:13, loss before: 5.58736064704e-05, loss after: 5.58177307539e-05.\n",
      "Epoch:8, weight train batch: 162, step:14, loss before: 6.21913204668e-05, loss after: 6.21540675638e-05.\n",
      "Epoch:8, weight train batch: 162, step:15, loss before: 7.04759731889e-05, loss after: 7.0427544415e-05.\n",
      "Epoch:8, weight train batch: 162, step:16, loss before: 6.90268643666e-05, loss after: 6.89635417075e-05.\n",
      "Epoch:8, weight train batch: 162, step:17, loss before: 6.30108988844e-05, loss after: 6.29624701105e-05.\n",
      "Epoch:8, weight train batch: 162, step:18, loss before: 6.00643797952e-05, loss after: 6.00234125159e-05.\n",
      "Epoch:8, weight train batch: 162, step:19, loss before: 5.83620385441e-05, loss after: 5.83359615121e-05.\n",
      "Epoch:8, weight train batch: 162, step:20, loss before: 6.08093796473e-05, loss after: 6.07423280599e-05.\n",
      "Epoch:8, weight train batch: 162, step:21, loss before: 5.74903606321e-05, loss after: 5.7427034335e-05.\n",
      "Epoch:8, weight train batch: 162, step:22, loss before: 6.51305017527e-05, loss after: 6.51007067063e-05.\n",
      "Epoch:8, weight train batch: 162, step:23, loss before: 5.90660529269e-05, loss after: 5.90027339058e-05.\n",
      "Epoch:8, weight train batch: 162, step:24, loss before: 5.81980420975e-05, loss after: 5.81682397751e-05.\n",
      "Epoch:8, weight train batch: 162, step:25, loss before: 5.84885638091e-05, loss after: 5.84513109061e-05.\n",
      "Epoch:8, weight train batch: 162, step:26, loss before: 7.27507431293e-05, loss after: 7.26836879039e-05.\n",
      "Epoch:8, weight train batch: 162, step:27, loss before: 5.38099266123e-05, loss after: 5.37652231287e-05.\n",
      "Epoch:8, weight train batch: 162, step:28, loss before: 5.28116288478e-05, loss after: 5.27818301634e-05.\n",
      "Epoch:8, weight train batch: 162, step:29, loss before: 6.32604715065e-05, loss after: 6.32604715065e-05.\n",
      "Epoch:8, weight train batch: 162, step:30, loss before: 5.97440011916e-05, loss after: 5.96806748945e-05.\n",
      "Epoch:8, weight train batch: 162, step:31, loss before: 6.01724022999e-05, loss after: 6.01425999776e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 158, loss before: 6.02664440521e-05, loss after: 6.47270644549e-05.\n",
      "Epoch:8, weight train batch: 163, step:0, loss before: 5.58177998755e-05, loss after: 5.57395760552e-05.\n",
      "Epoch:8, weight train batch: 163, step:1, loss before: 6.36329932604e-05, loss after: 6.36329932604e-05.\n",
      "Epoch:8, weight train batch: 163, step:2, loss before: 5.69985932088e-05, loss after: 5.693899584e-05.\n",
      "Epoch:8, weight train batch: 163, step:3, loss before: 6.3491446781e-05, loss after: 6.34653697489e-05.\n",
      "Epoch:8, weight train batch: 163, step:4, loss before: 6.31896909908e-05, loss after: 6.31412694929e-05.\n",
      "Epoch:8, weight train batch: 163, step:5, loss before: 5.09304809384e-05, loss after: 5.09081291966e-05.\n",
      "Epoch:8, weight train batch: 163, step:6, loss before: 6.25192187726e-05, loss after: 6.24856984359e-05.\n",
      "Epoch:8, weight train batch: 163, step:7, loss before: 6.84644764988e-05, loss after: 6.83862454025e-05.\n",
      "Epoch:8, weight train batch: 163, step:8, loss before: 5.96620775468e-05, loss after: 5.96136487729e-05.\n",
      "Epoch:8, weight train batch: 163, step:9, loss before: 5.47076633666e-05, loss after: 5.46815863345e-05.\n",
      "Epoch:8, weight train batch: 163, step:10, loss before: 5.83209839533e-05, loss after: 5.82762877457e-05.\n",
      "Epoch:8, weight train batch: 163, step:11, loss before: 7.62753479648e-05, loss after: 7.61933988542e-05.\n",
      "Epoch:8, weight train batch: 163, step:12, loss before: 6.35398973827e-05, loss after: 6.35026444797e-05.\n",
      "Epoch:8, weight train batch: 163, step:13, loss before: 7.46125879232e-05, loss after: 7.46051373426e-05.\n",
      "Epoch:8, weight train batch: 163, step:14, loss before: 6.57302443869e-05, loss after: 6.56557531329e-05.\n",
      "Epoch:8, weight train batch: 163, step:15, loss before: 5.92224678257e-05, loss after: 5.92075666646e-05.\n",
      "Epoch:8, weight train batch: 163, step:16, loss before: 7.05679267412e-05, loss after: 7.04710764694e-05.\n",
      "Epoch:8, weight train batch: 163, step:17, loss before: 8.43942252686e-05, loss after: 8.4375620645e-05.\n",
      "Epoch:8, weight train batch: 163, step:18, loss before: 9.90923144855e-05, loss after: 9.90066619124e-05.\n",
      "Epoch:8, weight train batch: 163, step:19, loss before: 5.74755031266e-05, loss after: 5.7430806919e-05.\n",
      "Epoch:8, weight train batch: 163, step:20, loss before: 5.73376237298e-05, loss after: 5.72780190851e-05.\n",
      "Epoch:8, weight train batch: 163, step:21, loss before: 5.18393972015e-05, loss after: 5.18393972015e-05.\n",
      "Epoch:8, weight train batch: 163, step:22, loss before: 5.89320043218e-05, loss after: 5.88314214838e-05.\n",
      "Epoch:8, weight train batch: 163, step:23, loss before: 6.15245880908e-05, loss after: 6.15245880908e-05.\n",
      "Epoch:8, weight train batch: 163, step:24, loss before: 9.86297382042e-05, loss after: 9.85254737316e-05.\n",
      "Epoch:8, weight train batch: 163, step:25, loss before: 7.69083708292e-05, loss after: 7.68785830587e-05.\n",
      "Epoch:8, weight train batch: 163, step:26, loss before: 5.25397699676e-05, loss after: 5.25062496308e-05.\n",
      "Epoch:8, weight train batch: 163, step:27, loss before: 7.82049683039e-05, loss after: 7.81379203545e-05.\n",
      "Epoch:8, weight train batch: 163, step:28, loss before: 5.60338667128e-05, loss after: 5.60338667128e-05.\n",
      "Epoch:8, weight train batch: 163, step:29, loss before: 0.00522762117907, loss after: 0.00521486718208.\n",
      "Epoch:8, weight train batch: 163, step:30, loss before: 5.49796386622e-05, loss after: 5.49125907128e-05.\n",
      "Epoch:8, weight train batch: 163, step:31, loss before: 0.000528957461938, loss after: 0.000528193369973.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 159, loss before: 0.00108423724305, loss after: 5.6618686358e-05.\n",
      "Epoch:8, weight train batch: 164, step:0, loss before: 5.3951596783e-05, loss after: 5.38212188985e-05.\n",
      "Epoch:8, weight train batch: 164, step:1, loss before: 6.18115227553e-05, loss after: 6.16662437096e-05.\n",
      "Epoch:8, weight train batch: 164, step:2, loss before: 5.51174598513e-05, loss after: 5.50429649593e-05.\n",
      "Epoch:8, weight train batch: 164, step:3, loss before: 5.78590843361e-05, loss after: 5.7795761677e-05.\n",
      "Epoch:8, weight train batch: 164, step:4, loss before: 5.04537165398e-05, loss after: 5.04015661136e-05.\n",
      "Epoch:8, weight train batch: 164, step:5, loss before: 6.73427493894e-05, loss after: 6.7264532845e-05.\n",
      "Epoch:8, weight train batch: 164, step:6, loss before: 4.99768611917e-05, loss after: 4.99694106111e-05.\n",
      "Epoch:8, weight train batch: 164, step:7, loss before: 4.99135639984e-05, loss after: 4.98278895975e-05.\n",
      "Epoch:8, weight train batch: 164, step:8, loss before: 5.57619714527e-05, loss after: 5.57358944206e-05.\n",
      "Epoch:8, weight train batch: 164, step:9, loss before: 5.28935852344e-05, loss after: 5.27669326402e-05.\n",
      "Epoch:8, weight train batch: 164, step:10, loss before: 5.65479931538e-05, loss after: 5.64697693335e-05.\n",
      "Epoch:8, weight train batch: 164, step:11, loss before: 5.04834315507e-05, loss after: 5.04610834469e-05.\n",
      "Epoch:8, weight train batch: 164, step:12, loss before: 5.63244393561e-05, loss after: 5.62648383493e-05.\n",
      "Epoch:8, weight train batch: 164, step:13, loss before: 5.55496153538e-05, loss after: 5.54862854187e-05.\n",
      "Epoch:8, weight train batch: 164, step:14, loss before: 5.5661330407e-05, loss after: 5.56427075935e-05.\n",
      "Epoch:8, weight train batch: 164, step:15, loss before: 5.99377635808e-05, loss after: 5.98669939791e-05.\n",
      "Epoch:8, weight train batch: 164, step:16, loss before: 4.36591581092e-05, loss after: 4.36554328189e-05.\n",
      "Epoch:8, weight train batch: 164, step:17, loss before: 6.2426115619e-05, loss after: 6.23478845228e-05.\n",
      "Epoch:8, weight train batch: 164, step:18, loss before: 5.73488068767e-05, loss after: 5.72854805796e-05.\n",
      "Epoch:8, weight train batch: 164, step:19, loss before: 6.65332481731e-05, loss after: 6.64922699798e-05.\n",
      "Epoch:8, weight train batch: 164, step:20, loss before: 6.75369738019e-05, loss after: 6.74550174153e-05.\n",
      "Epoch:8, weight train batch: 164, step:21, loss before: 5.96471545578e-05, loss after: 5.9624802816e-05.\n",
      "Epoch:8, weight train batch: 164, step:22, loss before: 5.43501555512e-05, loss after: 5.43240821571e-05.\n",
      "Epoch:8, weight train batch: 164, step:23, loss before: 5.2144878282e-05, loss after: 5.21225265402e-05.\n",
      "Epoch:8, weight train batch: 164, step:24, loss before: 5.57508101338e-05, loss after: 5.56725863134e-05.\n",
      "Epoch:8, weight train batch: 164, step:25, loss before: 4.91461760248e-05, loss after: 4.9086575018e-05.\n",
      "Epoch:8, weight train batch: 164, step:26, loss before: 5.19177046954e-05, loss after: 5.18916276633e-05.\n",
      "Epoch:8, weight train batch: 164, step:27, loss before: 6.393106014e-05, loss after: 6.38640049146e-05.\n",
      "Epoch:8, weight train batch: 164, step:28, loss before: 5.30649449502e-05, loss after: 5.30463184987e-05.\n",
      "Epoch:8, weight train batch: 164, step:29, loss before: 5.79411316721e-05, loss after: 5.7915058278e-05.\n",
      "Epoch:8, weight train batch: 164, step:30, loss before: 5.72296012251e-05, loss after: 5.71923519601e-05.\n",
      "Epoch:8, weight train batch: 164, step:31, loss before: 6.28396082902e-05, loss after: 6.27613844699e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 160, loss before: 5.93883305555e-05, loss after: 5.93883305555e-05.\n",
      "Epoch:8, weight train batch: 165, step:0, loss before: 5.56017766939e-05, loss after: 5.56017766939e-05.\n",
      "Epoch:8, weight train batch: 165, step:1, loss before: 5.30761535629e-05, loss after: 5.29867465957e-05.\n",
      "Epoch:8, weight train batch: 165, step:2, loss before: 8.88540889719e-05, loss after: 8.88131326064e-05.\n",
      "Epoch:8, weight train batch: 165, step:3, loss before: 5.49610485905e-05, loss after: 5.49349715584e-05.\n",
      "Epoch:8, weight train batch: 165, step:4, loss before: 5.70322517888e-05, loss after: 5.70136253373e-05.\n",
      "Epoch:8, weight train batch: 165, step:5, loss before: 5.82801512792e-05, loss after: 5.82503562327e-05.\n",
      "Epoch:8, weight train batch: 165, step:6, loss before: 5.24018687429e-05, loss after: 5.23385424458e-05.\n",
      "Epoch:8, weight train batch: 165, step:7, loss before: 5.68235409446e-05, loss after: 5.68235409446e-05.\n",
      "Epoch:8, weight train batch: 165, step:8, loss before: 5.23273993167e-05, loss after: 5.22677983099e-05.\n",
      "Epoch:8, weight train batch: 165, step:9, loss before: 5.27595184394e-05, loss after: 5.2729716117e-05.\n",
      "Epoch:8, weight train batch: 165, step:10, loss before: 4.8851914471e-05, loss after: 4.87736870127e-05.\n",
      "Epoch:8, weight train batch: 165, step:11, loss before: 5.72892749915e-05, loss after: 5.72892749915e-05.\n",
      "Epoch:8, weight train batch: 165, step:12, loss before: 5.49832548131e-05, loss after: 5.49497308384e-05.\n",
      "Epoch:8, weight train batch: 165, step:13, loss before: 6.06083049206e-05, loss after: 6.05412496952e-05.\n",
      "Epoch:8, weight train batch: 165, step:14, loss before: 6.0213424149e-05, loss after: 6.0213424149e-05.\n",
      "Epoch:8, weight train batch: 165, step:15, loss before: 6.34170282865e-05, loss after: 6.33388044662e-05.\n",
      "Epoch:8, weight train batch: 165, step:16, loss before: 5.69837939111e-05, loss after: 5.69502662984e-05.\n",
      "Epoch:8, weight train batch: 165, step:17, loss before: 5.76766142331e-05, loss after: 5.76430902584e-05.\n",
      "Epoch:8, weight train batch: 165, step:18, loss before: 5.62201457797e-05, loss after: 5.61642700632e-05.\n",
      "Epoch:8, weight train batch: 165, step:19, loss before: 4.71942112199e-05, loss after: 4.71755847684e-05.\n",
      "Epoch:8, weight train batch: 165, step:20, loss before: 4.99694651808e-05, loss after: 4.98912413605e-05.\n",
      "Epoch:8, weight train batch: 165, step:21, loss before: 5.74159494136e-05, loss after: 5.73861507291e-05.\n",
      "Epoch:8, weight train batch: 165, step:22, loss before: 5.54900470888e-05, loss after: 5.54490725335e-05.\n",
      "Epoch:8, weight train batch: 165, step:23, loss before: 4.82819596073e-05, loss after: 4.82819596073e-05.\n",
      "Epoch:8, weight train batch: 165, step:24, loss before: 5.71402997593e-05, loss after: 5.70508927922e-05.\n",
      "Epoch:8, weight train batch: 165, step:25, loss before: 5.71886994294e-05, loss after: 5.71439959458e-05.\n",
      "Epoch:8, weight train batch: 165, step:26, loss before: 5.34859645995e-05, loss after: 5.34598912054e-05.\n",
      "Epoch:8, weight train batch: 165, step:27, loss before: 9.6390969702e-05, loss after: 9.62978738244e-05.\n",
      "Epoch:8, weight train batch: 165, step:28, loss before: 5.99117483944e-05, loss after: 5.9844696807e-05.\n",
      "Epoch:8, weight train batch: 165, step:29, loss before: 0.000219404741074, loss after: 0.000219345456571.\n",
      "Epoch:8, weight train batch: 165, step:30, loss before: 5.7266865042e-05, loss after: 5.71998170926e-05.\n",
      "Epoch:8, weight train batch: 165, step:31, loss before: 5.72185163037e-05, loss after: 5.71775417484e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 161, loss before: 5.71437121835e-05, loss after: 0.00128749303985.\n",
      "Epoch:8, weight train batch: 166, step:0, loss before: 4.98577028338e-05, loss after: 4.98092776979e-05.\n",
      "Epoch:8, weight train batch: 166, step:1, loss before: 5.28675809619e-05, loss after: 5.28675809619e-05.\n",
      "Epoch:8, weight train batch: 166, step:2, loss before: 5.54229918635e-05, loss after: 5.53633872187e-05.\n",
      "Epoch:8, weight train batch: 166, step:3, loss before: 8.52769589983e-05, loss after: 8.52211087476e-05.\n",
      "Epoch:8, weight train batch: 166, step:4, loss before: 4.65312004962e-05, loss after: 4.64827717224e-05.\n",
      "Epoch:8, weight train batch: 166, step:5, loss before: 4.90716738568e-05, loss after: 4.90157981403e-05.\n",
      "Epoch:8, weight train batch: 166, step:6, loss before: 4.71420935355e-05, loss after: 4.71160201414e-05.\n",
      "Epoch:8, weight train batch: 166, step:7, loss before: 5.45811344637e-05, loss after: 5.45811344637e-05.\n",
      "Epoch:8, weight train batch: 166, step:8, loss before: 6.09063208685e-05, loss after: 6.08057380305e-05.\n",
      "Epoch:8, weight train batch: 166, step:9, loss before: 8.834664186e-05, loss after: 8.83168686414e-05.\n",
      "Epoch:8, weight train batch: 166, step:10, loss before: 0.000191075116163, loss after: 0.000190785722225.\n",
      "Epoch:8, weight train batch: 166, step:11, loss before: 5.81423664698e-05, loss after: 5.80492378504e-05.\n",
      "Epoch:8, weight train batch: 166, step:12, loss before: 8.87725909706e-05, loss after: 8.87279165909e-05.\n",
      "Epoch:8, weight train batch: 166, step:13, loss before: 4.82000650663e-05, loss after: 4.81777169625e-05.\n",
      "Epoch:8, weight train batch: 166, step:14, loss before: 4.58383146906e-05, loss after: 4.57489113614e-05.\n",
      "Epoch:8, weight train batch: 166, step:15, loss before: 5.43203568668e-05, loss after: 5.42868328921e-05.\n",
      "Epoch:8, weight train batch: 166, step:16, loss before: 5.64511574339e-05, loss after: 5.64511574339e-05.\n",
      "Epoch:8, weight train batch: 166, step:17, loss before: 5.59221371077e-05, loss after: 5.58625324629e-05.\n",
      "Epoch:8, weight train batch: 166, step:18, loss before: 4.78126639791e-05, loss after: 4.7760509915e-05.\n",
      "Epoch:8, weight train batch: 166, step:19, loss before: 5.51622542844e-05, loss after: 5.5132451962e-05.\n",
      "Epoch:8, weight train batch: 166, step:20, loss before: 5.07106960868e-05, loss after: 5.06622709509e-05.\n",
      "Epoch:8, weight train batch: 166, step:21, loss before: 5.70321790292e-05, loss after: 5.70321790292e-05.\n",
      "Epoch:8, weight train batch: 166, step:22, loss before: 5.08634693688e-05, loss after: 5.08373959747e-05.\n",
      "Epoch:8, weight train batch: 166, step:23, loss before: 5.59929321753e-05, loss after: 5.59594045626e-05.\n",
      "Epoch:8, weight train batch: 166, step:24, loss before: 5.6983801187e-05, loss after: 5.68869545532e-05.\n",
      "Epoch:8, weight train batch: 166, step:25, loss before: 5.31506957486e-05, loss after: 5.31208934262e-05.\n",
      "Epoch:8, weight train batch: 166, step:26, loss before: 5.40110413567e-05, loss after: 5.39849679626e-05.\n",
      "Epoch:8, weight train batch: 166, step:27, loss before: 4.93920597364e-05, loss after: 4.93920597364e-05.\n",
      "Epoch:8, weight train batch: 166, step:28, loss before: 5.61531705898e-05, loss after: 5.60712214792e-05.\n",
      "Epoch:8, weight train batch: 166, step:29, loss before: 9.34170529945e-05, loss after: 9.33537521632e-05.\n",
      "Epoch:8, weight train batch: 166, step:30, loss before: 5.25099712831e-05, loss after: 5.24503702763e-05.\n",
      "Epoch:8, weight train batch: 166, step:31, loss before: 5.11539910804e-05, loss after: 5.11018442921e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 162, loss before: 5.48186108063e-05, loss after: 5.48186108063e-05.\n",
      "Epoch:8, weight train batch: 167, step:0, loss before: 4.47133425041e-05, loss after: 4.47133425041e-05.\n",
      "Epoch:8, weight train batch: 167, step:1, loss before: 0.00496305245906, loss after: 0.00495246052742.\n",
      "Epoch:8, weight train batch: 167, step:2, loss before: 5.18431661476e-05, loss after: 5.17537628184e-05.\n",
      "Epoch:8, weight train batch: 167, step:3, loss before: 5.11838370585e-05, loss after: 5.10832614964e-05.\n",
      "Epoch:8, weight train batch: 167, step:4, loss before: 5.10832614964e-05, loss after: 5.09864112246e-05.\n",
      "Epoch:8, weight train batch: 167, step:5, loss before: 4.99694506289e-05, loss after: 4.99024026794e-05.\n",
      "Epoch:8, weight train batch: 167, step:6, loss before: 4.82857503812e-05, loss after: 4.8233596317e-05.\n",
      "Epoch:8, weight train batch: 167, step:7, loss before: 5.43055139133e-05, loss after: 5.41974877706e-05.\n",
      "Epoch:8, weight train batch: 167, step:8, loss before: 4.69335209345e-05, loss after: 4.68739199277e-05.\n",
      "Epoch:8, weight train batch: 167, step:9, loss before: 5.12248516316e-05, loss after: 5.11950529472e-05.\n",
      "Epoch:8, weight train batch: 167, step:10, loss before: 8.32676960272e-05, loss after: 8.31634097267e-05.\n",
      "Epoch:8, weight train batch: 167, step:11, loss before: 5.46854207641e-05, loss after: 5.45997427253e-05.\n",
      "Epoch:8, weight train batch: 167, step:12, loss before: 5.22082336829e-05, loss after: 5.21747133462e-05.\n",
      "Epoch:8, weight train batch: 167, step:13, loss before: 5.6525641412e-05, loss after: 5.64585934626e-05.\n",
      "Epoch:8, weight train batch: 167, step:14, loss before: 3.69539411622e-05, loss after: 3.68980654457e-05.\n",
      "Epoch:8, weight train batch: 167, step:15, loss before: 4.53801367257e-05, loss after: 4.53354332421e-05.\n",
      "Epoch:8, weight train batch: 167, step:16, loss before: 6.30296854069e-05, loss after: 6.29887072137e-05.\n",
      "Epoch:8, weight train batch: 167, step:17, loss before: 0.0337716601789, loss after: 0.0337000153959.\n",
      "Epoch:8, weight train batch: 167, step:18, loss before: 4.7712092055e-05, loss after: 4.77903158753e-05.\n",
      "Epoch:8, weight train batch: 167, step:19, loss before: 5.25286341144e-05, loss after: 5.26180338056e-05.\n",
      "Epoch:8, weight train batch: 167, step:20, loss before: 4.64120239485e-05, loss after: 4.65014272777e-05.\n",
      "Epoch:8, weight train batch: 167, step:21, loss before: 4.94517735206e-05, loss after: 4.95486237924e-05.\n",
      "Epoch:8, weight train batch: 167, step:22, loss before: 5.05020325363e-05, loss after: 5.05765274283e-05.\n",
      "Epoch:8, weight train batch: 167, step:23, loss before: 0.0332503020763, loss after: 0.0331299826503.\n",
      "Epoch:8, weight train batch: 167, step:24, loss before: 4.31375956396e-05, loss after: 4.32269953308e-05.\n",
      "Epoch:8, weight train batch: 167, step:25, loss before: 4.7436406021e-05, loss after: 4.75742344861e-05.\n",
      "Epoch:8, weight train batch: 167, step:26, loss before: 4.44748802693e-05, loss after: 4.46611338702e-05.\n",
      "Epoch:8, weight train batch: 167, step:27, loss before: 5.58625833946e-05, loss after: 5.60562803003e-05.\n",
      "Epoch:8, weight train batch: 167, step:28, loss before: 5.60115804547e-05, loss after: 5.62052773603e-05.\n",
      "Epoch:8, weight train batch: 167, step:29, loss before: 4.56444977317e-05, loss after: 4.57413480035e-05.\n",
      "Epoch:8, weight train batch: 167, step:30, loss before: 5.13626473548e-05, loss after: 5.15116480528e-05.\n",
      "Epoch:8, weight train batch: 167, step:31, loss before: 6.02581858402e-05, loss after: 6.04071901762e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 163, loss before: 9.45277279243e-05, loss after: 6.27193803666e-05.\n",
      "Epoch:8, weight train batch: 168, step:0, loss before: 5.28675736859e-05, loss after: 5.28973760083e-05.\n",
      "Epoch:8, weight train batch: 168, step:1, loss before: 5.56651502848e-05, loss after: 5.5743381381e-05.\n",
      "Epoch:8, weight train batch: 168, step:2, loss before: 5.24130991835e-05, loss after: 5.24577990291e-05.\n",
      "Epoch:8, weight train batch: 168, step:3, loss before: 5.55272781639e-05, loss after: 5.55272781639e-05.\n",
      "Epoch:8, weight train batch: 168, step:4, loss before: 4.99955640407e-05, loss after: 5.00253663631e-05.\n",
      "Epoch:8, weight train batch: 168, step:5, loss before: 5.79597872274e-05, loss after: 5.7967237808e-05.\n",
      "Epoch:8, weight train batch: 168, step:6, loss before: 5.21933434356e-05, loss after: 5.22156915395e-05.\n",
      "Epoch:8, weight train batch: 168, step:7, loss before: 7.74518048274e-05, loss after: 7.75337102823e-05.\n",
      "Epoch:8, weight train batch: 168, step:8, loss before: 6.07796609984e-05, loss after: 6.08094633208e-05.\n",
      "Epoch:8, weight train batch: 168, step:9, loss before: 5.17388689332e-05, loss after: 5.17351436429e-05.\n",
      "Epoch:8, weight train batch: 168, step:10, loss before: 4.92765648232e-05, loss after: 4.92765648232e-05.\n",
      "Epoch:8, weight train batch: 168, step:11, loss before: 5.72296048631e-05, loss after: 5.72333301534e-05.\n",
      "Epoch:8, weight train batch: 168, step:12, loss before: 4.90828824695e-05, loss after: 4.90828824695e-05.\n",
      "Epoch:8, weight train batch: 168, step:13, loss before: 4.43259013991e-05, loss after: 4.43072785856e-05.\n",
      "Epoch:8, weight train batch: 168, step:14, loss before: 5.93380354985e-05, loss after: 5.93529293837e-05.\n",
      "Epoch:8, weight train batch: 168, step:15, loss before: 6.9393980084e-05, loss after: 6.93455585861e-05.\n",
      "Epoch:8, weight train batch: 168, step:16, loss before: 6.22734660283e-05, loss after: 6.22436637059e-05.\n",
      "Epoch:8, weight train batch: 168, step:17, loss before: 5.42198176845e-05, loss after: 5.41825684195e-05.\n",
      "Epoch:8, weight train batch: 168, step:18, loss before: 0.00020941713592, loss after: 0.00020924997807.\n",
      "Epoch:8, weight train batch: 168, step:19, loss before: 5.5244199757e-05, loss after: 5.5244199757e-05.\n",
      "Epoch:8, weight train batch: 168, step:20, loss before: 5.29867684236e-05, loss after: 5.29569661012e-05.\n",
      "Epoch:8, weight train batch: 168, step:21, loss before: 5.13067643624e-05, loss after: 5.12732367497e-05.\n",
      "Epoch:8, weight train batch: 168, step:22, loss before: 5.56986233278e-05, loss after: 5.56315717404e-05.\n",
      "Epoch:8, weight train batch: 168, step:23, loss before: 5.48269235878e-05, loss after: 5.47971212654e-05.\n",
      "Epoch:8, weight train batch: 168, step:24, loss before: 5.4309166444e-05, loss after: 5.42756461073e-05.\n",
      "Epoch:8, weight train batch: 168, step:25, loss before: 4.54620458186e-05, loss after: 4.5443426643e-05.\n",
      "Epoch:8, weight train batch: 168, step:26, loss before: 5.64511028642e-05, loss after: 5.63766006962e-05.\n",
      "Epoch:8, weight train batch: 168, step:27, loss before: 6.02469954174e-05, loss after: 6.01985666435e-05.\n",
      "Epoch:8, weight train batch: 168, step:28, loss before: 5.37094892934e-05, loss after: 5.36871411896e-05.\n",
      "Epoch:8, weight train batch: 168, step:29, loss before: 9.89761174424e-05, loss after: 9.88830579445e-05.\n",
      "Epoch:8, weight train batch: 168, step:30, loss before: 5.684595817e-05, loss after: 5.68236064282e-05.\n",
      "Epoch:8, weight train batch: 168, step:31, loss before: 5.27931006218e-05, loss after: 5.27223237441e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 164, loss before: 5.09547353431e-05, loss after: 5.09547353431e-05.\n",
      "Epoch:8, weight train batch: 169, step:0, loss before: 5.24279894307e-05, loss after: 5.24056376889e-05.\n",
      "Epoch:8, weight train batch: 169, step:1, loss before: 5.37690139026e-05, loss after: 5.37056948815e-05.\n",
      "Epoch:8, weight train batch: 169, step:2, loss before: 4.62034076918e-05, loss after: 4.61922318209e-05.\n",
      "Epoch:8, weight train batch: 169, step:3, loss before: 5.02525581396e-05, loss after: 5.02190341649e-05.\n",
      "Epoch:8, weight train batch: 169, step:4, loss before: 5.64250949537e-05, loss after: 5.63654975849e-05.\n",
      "Epoch:8, weight train batch: 169, step:5, loss before: 5.6760298321e-05, loss after: 5.66634480492e-05.\n",
      "Epoch:8, weight train batch: 169, step:6, loss before: 0.000360885489499, loss after: 0.000360221194569.\n",
      "Epoch:8, weight train batch: 169, step:7, loss before: 5.68124269194e-05, loss after: 5.67938004679e-05.\n",
      "Epoch:8, weight train batch: 169, step:8, loss before: 0.000100898876553, loss after: 0.000100768564153.\n",
      "Epoch:8, weight train batch: 169, step:9, loss before: 4.32382003055e-05, loss after: 4.32121305494e-05.\n",
      "Epoch:8, weight train batch: 169, step:10, loss before: 0.000203841162147, loss after: 0.000203729621717.\n",
      "Epoch:8, weight train batch: 169, step:11, loss before: 5.38584863534e-05, loss after: 5.37951600563e-05.\n",
      "Epoch:8, weight train batch: 169, step:12, loss before: 5.25248615304e-05, loss after: 5.24764327565e-05.\n",
      "Epoch:8, weight train batch: 169, step:13, loss before: 5.42309644516e-05, loss after: 5.41639165021e-05.\n",
      "Epoch:8, weight train batch: 169, step:14, loss before: 4.76337954751e-05, loss after: 4.75816414109e-05.\n",
      "Epoch:8, weight train batch: 169, step:15, loss before: 5.29979806743e-05, loss after: 5.29532771907e-05.\n",
      "Epoch:8, weight train batch: 169, step:16, loss before: 5.61344895686e-05, loss after: 5.60786174901e-05.\n",
      "Epoch:8, weight train batch: 169, step:17, loss before: 6.16327815806e-05, loss after: 6.15508324699e-05.\n",
      "Epoch:8, weight train batch: 169, step:18, loss before: 0.000226202595513, loss after: 0.000225898518693.\n",
      "Epoch:8, weight train batch: 169, step:19, loss before: 4.89822959935e-05, loss after: 4.89226949867e-05.\n",
      "Epoch:8, weight train batch: 169, step:20, loss before: 5.37653941137e-05, loss after: 5.37355954293e-05.\n",
      "Epoch:8, weight train batch: 169, step:21, loss before: 0.00021337500948, loss after: 0.000212833983824.\n",
      "Epoch:8, weight train batch: 169, step:22, loss before: 4.53391767223e-05, loss after: 4.52646709164e-05.\n",
      "Epoch:8, weight train batch: 169, step:23, loss before: 5.00104360981e-05, loss after: 4.99545640196e-05.\n",
      "Epoch:8, weight train batch: 169, step:24, loss before: 5.84850640735e-05, loss after: 5.84701629123e-05.\n",
      "Epoch:8, weight train batch: 169, step:25, loss before: 7.42349802749e-05, loss after: 7.41753901821e-05.\n",
      "Epoch:8, weight train batch: 169, step:26, loss before: 5.00402347825e-05, loss after: 4.99508387293e-05.\n",
      "Epoch:8, weight train batch: 169, step:27, loss before: 4.74625194329e-05, loss after: 4.74289918202e-05.\n",
      "Epoch:8, weight train batch: 169, step:28, loss before: 5.11614889547e-05, loss after: 5.11354155606e-05.\n",
      "Epoch:8, weight train batch: 169, step:29, loss before: 4.99061134178e-05, loss after: 4.98800400237e-05.\n",
      "Epoch:8, weight train batch: 169, step:30, loss before: 4.71495732199e-05, loss after: 4.70601662528e-05.\n",
      "Epoch:8, weight train batch: 169, step:31, loss before: 5.11950347573e-05, loss after: 5.1142887969e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 165, loss before: 5.35586004844e-05, loss after: 5.35586004844e-05.\n",
      "Epoch:8, weight train batch: 170, step:0, loss before: 5.14184939675e-05, loss after: 5.14184939675e-05.\n",
      "Epoch:8, weight train batch: 170, step:1, loss before: 4.92095314257e-05, loss after: 4.91536557092e-05.\n",
      "Epoch:8, weight train batch: 170, step:2, loss before: 8.02549911896e-05, loss after: 8.02140275482e-05.\n",
      "Epoch:8, weight train batch: 170, step:3, loss before: 5.27260417584e-05, loss after: 5.26329167769e-05.\n",
      "Epoch:8, weight train batch: 170, step:4, loss before: 4.88370060339e-05, loss after: 4.87960278406e-05.\n",
      "Epoch:8, weight train batch: 170, step:5, loss before: 5.81833301112e-05, loss after: 5.81200038141e-05.\n",
      "Epoch:8, weight train batch: 170, step:6, loss before: 5.02898328705e-05, loss after: 5.02525799675e-05.\n",
      "Epoch:8, weight train batch: 170, step:7, loss before: 5.41601912118e-05, loss after: 5.40856890439e-05.\n",
      "Epoch:8, weight train batch: 170, step:8, loss before: 4.99918460264e-05, loss after: 4.99657689943e-05.\n",
      "Epoch:8, weight train batch: 170, step:9, loss before: 4.973475734e-05, loss after: 4.96751599712e-05.\n",
      "Epoch:8, weight train batch: 170, step:10, loss before: 4.8978599807e-05, loss after: 4.89525227749e-05.\n",
      "Epoch:8, weight train batch: 170, step:11, loss before: 4.88183832204e-05, loss after: 4.87736833747e-05.\n",
      "Epoch:8, weight train batch: 170, step:12, loss before: 5.32699195901e-05, loss after: 5.31767909706e-05.\n",
      "Epoch:8, weight train batch: 170, step:13, loss before: 7.91475031292e-05, loss after: 7.90879130363e-05.\n",
      "Epoch:8, weight train batch: 170, step:14, loss before: 4.90046732011e-05, loss after: 4.89487938466e-05.\n",
      "Epoch:8, weight train batch: 170, step:15, loss before: 0.000345837179339, loss after: 0.000345172244124.\n",
      "Epoch:8, weight train batch: 170, step:16, loss before: 5.40409964742e-05, loss after: 5.40037472092e-05.\n",
      "Epoch:8, weight train batch: 170, step:17, loss before: 4.70452505397e-05, loss after: 4.69670194434e-05.\n",
      "Epoch:8, weight train batch: 170, step:18, loss before: 4.80920207337e-05, loss after: 4.80622184114e-05.\n",
      "Epoch:8, weight train batch: 170, step:19, loss before: 4.80548078485e-05, loss after: 4.80026574223e-05.\n",
      "Epoch:8, weight train batch: 170, step:20, loss before: 4.25043253927e-05, loss after: 4.24484460382e-05.\n",
      "Epoch:8, weight train batch: 170, step:21, loss before: 5.10721147293e-05, loss after: 5.10274221597e-05.\n",
      "Epoch:8, weight train batch: 170, step:22, loss before: 4.71086095786e-05, loss after: 4.70192026114e-05.\n",
      "Epoch:8, weight train batch: 170, step:23, loss before: 4.46276135335e-05, loss after: 4.45903642685e-05.\n",
      "Epoch:8, weight train batch: 170, step:24, loss before: 4.53912871308e-05, loss after: 4.5368935389e-05.\n",
      "Epoch:8, weight train batch: 170, step:25, loss before: 5.53597383259e-05, loss after: 5.5274060287e-05.\n",
      "Epoch:8, weight train batch: 170, step:26, loss before: 4.93138686579e-05, loss after: 4.92915205541e-05.\n",
      "Epoch:8, weight train batch: 170, step:27, loss before: 4.92915205541e-05, loss after: 4.92393664899e-05.\n",
      "Epoch:8, weight train batch: 170, step:28, loss before: 5.14818966622e-05, loss after: 5.14185703651e-05.\n",
      "Epoch:8, weight train batch: 170, step:29, loss before: 3.98073752876e-05, loss after: 3.97701223847e-05.\n",
      "Epoch:8, weight train batch: 170, step:30, loss before: 4.22249650001e-05, loss after: 4.22063421865e-05.\n",
      "Epoch:8, weight train batch: 170, step:31, loss before: 5.32661870238e-05, loss after: 5.31954174221e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 166, loss before: 6.35380274616e-05, loss after: 0.000126057318994.\n",
      "Epoch:8, weight train batch: 171, step:0, loss before: 4.75555716548e-05, loss after: 4.75220440421e-05.\n",
      "Epoch:8, weight train batch: 171, step:1, loss before: 4.2198887968e-05, loss after: 4.21728109359e-05.\n",
      "Epoch:8, weight train batch: 171, step:2, loss before: 5.02414004586e-05, loss after: 5.01780705235e-05.\n",
      "Epoch:8, weight train batch: 171, step:3, loss before: 4.37708949903e-05, loss after: 4.37522685388e-05.\n",
      "Epoch:8, weight train batch: 171, step:4, loss before: 4.28060702689e-05, loss after: 4.272039223e-05.\n",
      "Epoch:8, weight train batch: 171, step:5, loss before: 4.44972720288e-05, loss after: 4.44637480541e-05.\n",
      "Epoch:8, weight train batch: 171, step:6, loss before: 0.00477508548647, loss after: 0.00476453686133.\n",
      "Epoch:8, weight train batch: 171, step:7, loss before: 0.000220993417315, loss after: 0.000220562636969.\n",
      "Epoch:8, weight train batch: 171, step:8, loss before: 4.57750575151e-05, loss after: 4.56968336948e-05.\n",
      "Epoch:8, weight train batch: 171, step:9, loss before: 4.95000276715e-05, loss after: 4.92690669489e-05.\n",
      "Epoch:8, weight train batch: 171, step:10, loss before: 5.23126145708e-05, loss after: 5.22343907505e-05.\n",
      "Epoch:8, weight train batch: 171, step:11, loss before: 4.57861751784e-05, loss after: 4.57303030998e-05.\n",
      "Epoch:8, weight train batch: 171, step:12, loss before: 5.00142123201e-05, loss after: 4.99434354424e-05.\n",
      "Epoch:8, weight train batch: 171, step:13, loss before: 4.39832547272e-05, loss after: 4.39162031398e-05.\n",
      "Epoch:8, weight train batch: 171, step:14, loss before: 4.72687788715e-05, loss after: 4.72240790259e-05.\n",
      "Epoch:8, weight train batch: 171, step:15, loss before: 3.58364195563e-05, loss after: 3.575818846e-05.\n",
      "Epoch:8, weight train batch: 171, step:16, loss before: 4.32084270869e-05, loss after: 4.31339285569e-05.\n",
      "Epoch:8, weight train batch: 171, step:17, loss before: 5.04314157297e-05, loss after: 5.03718110849e-05.\n",
      "Epoch:8, weight train batch: 171, step:18, loss before: 4.23441742896e-05, loss after: 4.23218298238e-05.\n",
      "Epoch:8, weight train batch: 171, step:19, loss before: 5.19177410752e-05, loss after: 5.18357919645e-05.\n",
      "Epoch:8, weight train batch: 171, step:20, loss before: 3.84178893e-05, loss after: 3.83769111068e-05.\n",
      "Epoch:8, weight train batch: 171, step:21, loss before: 5.19214663655e-05, loss after: 5.18693123013e-05.\n",
      "Epoch:8, weight train batch: 171, step:22, loss before: 4.43036406068e-05, loss after: 4.42775635747e-05.\n",
      "Epoch:8, weight train batch: 171, step:23, loss before: 9.26204447751e-05, loss after: 9.25050335354e-05.\n",
      "Epoch:8, weight train batch: 171, step:24, loss before: 4.65759549115e-05, loss after: 4.65200755571e-05.\n",
      "Epoch:8, weight train batch: 171, step:25, loss before: 5.45588518435e-05, loss after: 5.45216062164e-05.\n",
      "Epoch:8, weight train batch: 171, step:26, loss before: 4.6192217269e-05, loss after: 4.61735908175e-05.\n",
      "Epoch:8, weight train batch: 171, step:27, loss before: 4.39050563728e-05, loss after: 4.38678071077e-05.\n",
      "Epoch:8, weight train batch: 171, step:28, loss before: 4.87253200845e-05, loss after: 4.86619937874e-05.\n",
      "Epoch:8, weight train batch: 171, step:29, loss before: 5.28974451299e-05, loss after: 5.28974451299e-05.\n",
      "Epoch:8, weight train batch: 171, step:30, loss before: 4.70303893962e-05, loss after: 4.69745100418e-05.\n",
      "Epoch:8, weight train batch: 171, step:31, loss before: 6.29632704658e-05, loss after: 6.286642747e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 167, loss before: 5.52881174372e-05, loss after: 5.02448092448e-05.\n",
      "Epoch:8, weight train batch: 172, step:0, loss before: 4.88780642627e-05, loss after: 4.88780642627e-05.\n",
      "Epoch:8, weight train batch: 172, step:1, loss before: 4.5186454372e-05, loss after: 4.51641026302e-05.\n",
      "Epoch:8, weight train batch: 172, step:2, loss before: 4.70378727186e-05, loss after: 4.69968945254e-05.\n",
      "Epoch:8, weight train batch: 172, step:3, loss before: 5.18507076777e-05, loss after: 5.18246306456e-05.\n",
      "Epoch:8, weight train batch: 172, step:4, loss before: 4.51977030025e-05, loss after: 4.51977030025e-05.\n",
      "Epoch:8, weight train batch: 172, step:5, loss before: 4.68068828923e-05, loss after: 4.67435602332e-05.\n",
      "Epoch:8, weight train batch: 172, step:6, loss before: 5.34487880941e-05, loss after: 5.34227147e-05.\n",
      "Epoch:8, weight train batch: 172, step:7, loss before: 4.74290063721e-05, loss after: 4.73992076877e-05.\n",
      "Epoch:8, weight train batch: 172, step:8, loss before: 5.25050490978e-05, loss after: 5.24491733813e-05.\n",
      "Epoch:8, weight train batch: 172, step:9, loss before: 4.65498560516e-05, loss after: 4.65498560516e-05.\n",
      "Epoch:8, weight train batch: 172, step:10, loss before: 0.00021371654293, loss after: 0.000213423438254.\n",
      "Epoch:8, weight train batch: 172, step:11, loss before: 5.01445792906e-05, loss after: 5.01147769683e-05.\n",
      "Epoch:8, weight train batch: 172, step:12, loss before: 4.76040950161e-05, loss after: 4.7578021622e-05.\n",
      "Epoch:8, weight train batch: 172, step:13, loss before: 5.00142414239e-05, loss after: 4.99918896821e-05.\n",
      "Epoch:8, weight train batch: 172, step:14, loss before: 4.69186343253e-05, loss after: 4.6877656132e-05.\n",
      "Epoch:8, weight train batch: 172, step:15, loss before: 4.5622298785e-05, loss after: 4.56036759715e-05.\n",
      "Epoch:8, weight train batch: 172, step:16, loss before: 4.50113911938e-05, loss after: 4.4951790187e-05.\n",
      "Epoch:8, weight train batch: 172, step:17, loss before: 4.11857108702e-05, loss after: 4.11857108702e-05.\n",
      "Epoch:8, weight train batch: 172, step:18, loss before: 7.65174045227e-05, loss after: 7.64317519497e-05.\n",
      "Epoch:8, weight train batch: 172, step:19, loss before: 5.20220564795e-05, loss after: 5.19922541571e-05.\n",
      "Epoch:8, weight train batch: 172, step:20, loss before: 4.16438706452e-05, loss after: 4.16438706452e-05.\n",
      "Epoch:8, weight train batch: 172, step:21, loss before: 4.89525955345e-05, loss after: 4.89265221404e-05.\n",
      "Epoch:8, weight train batch: 172, step:22, loss before: 4.50598126918e-05, loss after: 4.50113875559e-05.\n",
      "Epoch:8, weight train batch: 172, step:23, loss before: 4.4776708819e-05, loss after: 4.47506354249e-05.\n",
      "Epoch:8, weight train batch: 172, step:24, loss before: 4.37113485532e-05, loss after: 4.37113485532e-05.\n",
      "Epoch:8, weight train batch: 172, step:25, loss before: 4.54174187325e-05, loss after: 4.53429165646e-05.\n",
      "Epoch:8, weight train batch: 172, step:26, loss before: 5.00365676999e-05, loss after: 4.99993184349e-05.\n",
      "Epoch:8, weight train batch: 172, step:27, loss before: 5.6197946833e-05, loss after: 5.61197157367e-05.\n",
      "Epoch:8, weight train batch: 172, step:28, loss before: 5.66568232898e-05, loss after: 5.66493727092e-05.\n",
      "Epoch:8, weight train batch: 172, step:29, loss before: 4.13980160374e-05, loss after: 4.13719390053e-05.\n",
      "Epoch:8, weight train batch: 172, step:30, loss before: 4.74737316836e-05, loss after: 4.74402040709e-05.\n",
      "Epoch:8, weight train batch: 172, step:31, loss before: 4.70080849482e-05, loss after: 4.70080849482e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 168, loss before: 4.74336484331e-05, loss after: 4.74336484331e-05.\n",
      "Epoch:8, weight train batch: 173, step:0, loss before: 4.96529028169e-05, loss after: 4.95821223012e-05.\n",
      "Epoch:8, weight train batch: 173, step:1, loss before: 4.64753466076e-05, loss after: 4.64045733679e-05.\n",
      "Epoch:8, weight train batch: 173, step:2, loss before: 4.61810850538e-05, loss after: 4.61810850538e-05.\n",
      "Epoch:8, weight train batch: 173, step:3, loss before: 5.19438435731e-05, loss after: 5.18991437275e-05.\n",
      "Epoch:8, weight train batch: 173, step:4, loss before: 4.84608899569e-05, loss after: 4.84236406919e-05.\n",
      "Epoch:8, weight train batch: 173, step:5, loss before: 4.71272651339e-05, loss after: 4.70751110697e-05.\n",
      "Epoch:8, weight train batch: 173, step:6, loss before: 4.87887082272e-05, loss after: 4.87887082272e-05.\n",
      "Epoch:8, weight train batch: 173, step:7, loss before: 4.86880780954e-05, loss after: 4.86694516439e-05.\n",
      "Epoch:8, weight train batch: 173, step:8, loss before: 4.61028394056e-05, loss after: 4.60804913018e-05.\n",
      "Epoch:8, weight train batch: 173, step:9, loss before: 0.000203999894438, loss after: 0.000203773815883.\n",
      "Epoch:8, weight train batch: 173, step:10, loss before: 4.96082211612e-05, loss after: 4.9556067097e-05.\n",
      "Epoch:8, weight train batch: 173, step:11, loss before: 4.56483649032e-05, loss after: 4.56073903479e-05.\n",
      "Epoch:8, weight train batch: 173, step:12, loss before: 4.83528201585e-05, loss after: 4.83528201585e-05.\n",
      "Epoch:8, weight train batch: 173, step:13, loss before: 5.00924579683e-05, loss after: 5.00701062265e-05.\n",
      "Epoch:8, weight train batch: 173, step:14, loss before: 4.35250658484e-05, loss after: 4.34691901319e-05.\n",
      "Epoch:8, weight train batch: 173, step:15, loss before: 4.43445751444e-05, loss after: 4.43445751444e-05.\n",
      "Epoch:8, weight train batch: 173, step:16, loss before: 4.31153093814e-05, loss after: 4.30631589552e-05.\n",
      "Epoch:8, weight train batch: 173, step:17, loss before: 4.21989134338e-05, loss after: 4.21728364017e-05.\n",
      "Epoch:8, weight train batch: 173, step:18, loss before: 4.57005480712e-05, loss after: 4.57005480712e-05.\n",
      "Epoch:8, weight train batch: 173, step:19, loss before: 5.17910957569e-05, loss after: 5.1742674259e-05.\n",
      "Epoch:8, weight train batch: 173, step:20, loss before: 4.58123213321e-05, loss after: 4.57452697447e-05.\n",
      "Epoch:8, weight train batch: 173, step:21, loss before: 4.27874838351e-05, loss after: 4.27874838351e-05.\n",
      "Epoch:8, weight train batch: 173, step:22, loss before: 5.58354113309e-05, loss after: 5.58093379368e-05.\n",
      "Epoch:8, weight train batch: 173, step:23, loss before: 4.52162785223e-05, loss after: 4.51678497484e-05.\n",
      "Epoch:8, weight train batch: 173, step:24, loss before: 4.68255311716e-05, loss after: 4.67845529784e-05.\n",
      "Epoch:8, weight train batch: 173, step:25, loss before: 4.42515229224e-05, loss after: 4.42515229224e-05.\n",
      "Epoch:8, weight train batch: 173, step:26, loss before: 4.44042161689e-05, loss after: 4.43855897174e-05.\n",
      "Epoch:8, weight train batch: 173, step:27, loss before: 4.76786408399e-05, loss after: 4.76413879369e-05.\n",
      "Epoch:8, weight train batch: 173, step:28, loss before: 4.16215625592e-05, loss after: 4.15917602368e-05.\n",
      "Epoch:8, weight train batch: 173, step:29, loss before: 0.000175786510226, loss after: 0.000175481894985.\n",
      "Epoch:8, weight train batch: 173, step:30, loss before: 4.11037290178e-05, loss after: 4.1081377276e-05.\n",
      "Epoch:8, weight train batch: 173, step:31, loss before: 4.93399638799e-05, loss after: 4.93399638799e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 169, loss before: 4.96080974699e-05, loss after: 4.27632876381e-05.\n",
      "Epoch:8, weight train batch: 174, step:0, loss before: 4.56670386484e-05, loss after: 4.56111592939e-05.\n",
      "Epoch:8, weight train batch: 174, step:1, loss before: 4.08728228649e-05, loss after: 4.08504711231e-05.\n",
      "Epoch:8, weight train batch: 174, step:2, loss before: 0.00892565492541, loss after: 0.00888060033321.\n",
      "Epoch:8, weight train batch: 174, step:3, loss before: 4.44861616415e-05, loss after: 4.42887358076e-05.\n",
      "Epoch:8, weight train batch: 174, step:4, loss before: 4.00867866119e-05, loss after: 4.00234639528e-05.\n",
      "Epoch:8, weight train batch: 174, step:5, loss before: 5.34264581802e-05, loss after: 5.32439298695e-05.\n",
      "Epoch:8, weight train batch: 174, step:6, loss before: 4.96902066516e-05, loss after: 4.95598287671e-05.\n",
      "Epoch:8, weight train batch: 174, step:7, loss before: 3.63467843272e-05, loss after: 3.63207109331e-05.\n",
      "Epoch:8, weight train batch: 174, step:8, loss before: 5.62696259294e-05, loss after: 5.62025670661e-05.\n",
      "Epoch:8, weight train batch: 174, step:9, loss before: 0.000194975116756, loss after: 0.000194967375137.\n",
      "Epoch:8, weight train batch: 174, step:10, loss before: 4.86062017444e-05, loss after: 4.8501897254e-05.\n",
      "Epoch:8, weight train batch: 174, step:11, loss before: 4.15731556132e-05, loss after: 4.15023823734e-05.\n",
      "Epoch:8, weight train batch: 174, step:12, loss before: 5.14409766765e-05, loss after: 5.13888262503e-05.\n",
      "Epoch:8, weight train batch: 174, step:13, loss before: 5.24952229171e-05, loss after: 5.23834714841e-05.\n",
      "Epoch:8, weight train batch: 174, step:14, loss before: 4.15284375777e-05, loss after: 4.14762871515e-05.\n",
      "Epoch:8, weight train batch: 174, step:15, loss before: 4.0153892769e-05, loss after: 4.01315446652e-05.\n",
      "Epoch:8, weight train batch: 174, step:16, loss before: 4.18860618083e-05, loss after: 4.18339113821e-05.\n",
      "Epoch:8, weight train batch: 174, step:17, loss before: 4.89114318043e-05, loss after: 4.88481091452e-05.\n",
      "Epoch:8, weight train batch: 174, step:18, loss before: 4.4583066483e-05, loss after: 4.45160221716e-05.\n",
      "Epoch:8, weight train batch: 174, step:19, loss before: 3.92375295633e-05, loss after: 3.91555804526e-05.\n",
      "Epoch:8, weight train batch: 174, step:20, loss before: 4.49704239145e-05, loss after: 4.49406215921e-05.\n",
      "Epoch:8, weight train batch: 174, step:21, loss before: 4.68404869025e-05, loss after: 4.68069629278e-05.\n",
      "Epoch:8, weight train batch: 174, step:22, loss before: 4.10963475588e-05, loss after: 4.10479260609e-05.\n",
      "Epoch:8, weight train batch: 174, step:23, loss before: 4.08653795603e-05, loss after: 4.08653795603e-05.\n",
      "Epoch:8, weight train batch: 174, step:24, loss before: 4.95933563798e-05, loss after: 4.95598287671e-05.\n",
      "Epoch:8, weight train batch: 174, step:25, loss before: 4.10777065554e-05, loss after: 4.10404536524e-05.\n",
      "Epoch:8, weight train batch: 174, step:26, loss before: 4.50226361863e-05, loss after: 4.49593062513e-05.\n",
      "Epoch:8, weight train batch: 174, step:27, loss before: 4.49479848612e-05, loss after: 4.49144572485e-05.\n",
      "Epoch:8, weight train batch: 174, step:28, loss before: 7.02225297573e-05, loss after: 7.01741228113e-05.\n",
      "Epoch:8, weight train batch: 174, step:29, loss before: 4.61587842437e-05, loss after: 4.61178060505e-05.\n",
      "Epoch:8, weight train batch: 174, step:30, loss before: 4.9001086154e-05, loss after: 4.89675621793e-05.\n",
      "Epoch:8, weight train batch: 174, step:31, loss before: 0.000188530917512, loss after: 0.00018841563724.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 170, loss before: 4.52152235084e-05, loss after: 8.46700713737e-05.\n",
      "Epoch:8, weight train batch: 175, step:0, loss before: 4.08542036894e-05, loss after: 4.08281266573e-05.\n",
      "Epoch:8, weight train batch: 175, step:1, loss before: 7.09577434463e-05, loss after: 7.09354135324e-05.\n",
      "Epoch:8, weight train batch: 175, step:2, loss before: 4.67585487058e-05, loss after: 4.67138524982e-05.\n",
      "Epoch:8, weight train batch: 175, step:3, loss before: 5.25921059307e-05, loss after: 5.25176074007e-05.\n",
      "Epoch:8, weight train batch: 175, step:4, loss before: 4.03215017286e-05, loss after: 4.02581717935e-05.\n",
      "Epoch:8, weight train batch: 175, step:5, loss before: 3.98334959755e-05, loss after: 3.98074262193e-05.\n",
      "Epoch:8, weight train batch: 175, step:6, loss before: 4.52945496363e-05, loss after: 4.52498461527e-05.\n",
      "Epoch:8, weight train batch: 175, step:7, loss before: 4.69373335363e-05, loss after: 4.69373335363e-05.\n",
      "Epoch:8, weight train batch: 175, step:8, loss before: 3.82875477953e-05, loss after: 3.82353973691e-05.\n",
      "Epoch:8, weight train batch: 175, step:9, loss before: 4.74886765005e-05, loss after: 4.74625994684e-05.\n",
      "Epoch:8, weight train batch: 175, step:10, loss before: 4.1271403461e-05, loss after: 4.1271403461e-05.\n",
      "Epoch:8, weight train batch: 175, step:11, loss before: 4.8751502618e-05, loss after: 4.8714249715e-05.\n",
      "Epoch:8, weight train batch: 175, step:12, loss before: 4.65797238576e-05, loss after: 4.65536504635e-05.\n",
      "Epoch:8, weight train batch: 175, step:13, loss before: 6.17691111984e-05, loss after: 6.1728147557e-05.\n",
      "Epoch:8, weight train batch: 175, step:14, loss before: 4.48512655566e-05, loss after: 4.48214632343e-05.\n",
      "Epoch:8, weight train batch: 175, step:15, loss before: 4.32419728895e-05, loss after: 4.32270717283e-05.\n",
      "Epoch:8, weight train batch: 175, step:16, loss before: 4.38343195128e-05, loss after: 4.37970702478e-05.\n",
      "Epoch:8, weight train batch: 175, step:17, loss before: 4.47171769338e-05, loss after: 4.46985504823e-05.\n",
      "Epoch:8, weight train batch: 175, step:18, loss before: 4.63413234684e-05, loss after: 4.62817188236e-05.\n",
      "Epoch:8, weight train batch: 175, step:19, loss before: 4.21803815698e-05, loss after: 4.2158029828e-05.\n",
      "Epoch:8, weight train batch: 175, step:20, loss before: 4.39423311036e-05, loss after: 4.39423311036e-05.\n",
      "Epoch:8, weight train batch: 175, step:21, loss before: 4.95598214911e-05, loss after: 4.95188432978e-05.\n",
      "Epoch:8, weight train batch: 175, step:22, loss before: 4.68293001177e-05, loss after: 4.67808749818e-05.\n",
      "Epoch:8, weight train batch: 175, step:23, loss before: 4.55441731901e-05, loss after: 4.55106455775e-05.\n",
      "Epoch:8, weight train batch: 175, step:24, loss before: 3.96249197365e-05, loss after: 3.95727693103e-05.\n",
      "Epoch:8, weight train batch: 175, step:25, loss before: 3.91592693632e-05, loss after: 3.91592693632e-05.\n",
      "Epoch:8, weight train batch: 175, step:26, loss before: 3.7602163502e-05, loss after: 3.7602163502e-05.\n",
      "Epoch:8, weight train batch: 175, step:27, loss before: 3.87942345697e-05, loss after: 3.87793334085e-05.\n",
      "Epoch:8, weight train batch: 175, step:28, loss before: 4.15359136241e-05, loss after: 4.1472587327e-05.\n",
      "Epoch:8, weight train batch: 175, step:29, loss before: 4.32420201832e-05, loss after: 4.32159431512e-05.\n",
      "Epoch:8, weight train batch: 175, step:30, loss before: 4.27055601904e-05, loss after: 4.26757651439e-05.\n",
      "Epoch:8, weight train batch: 175, step:31, loss before: 4.0027214709e-05, loss after: 3.99862365157e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 171, loss before: 7.79062829679e-05, loss after: 4.40836083726e-05.\n",
      "Epoch:8, weight train batch: 176, step:0, loss before: 4.35698420915e-05, loss after: 4.35698420915e-05.\n",
      "Epoch:8, weight train batch: 176, step:1, loss before: 4.2329349526e-05, loss after: 4.22697448812e-05.\n",
      "Epoch:8, weight train batch: 176, step:2, loss before: 4.61886229459e-05, loss after: 4.61886229459e-05.\n",
      "Epoch:8, weight train batch: 176, step:3, loss before: 4.33612221968e-05, loss after: 4.3338870455e-05.\n",
      "Epoch:8, weight train batch: 176, step:4, loss before: 4.32904416812e-05, loss after: 4.32606466347e-05.\n",
      "Epoch:8, weight train batch: 176, step:5, loss before: 5.22791815456e-05, loss after: 5.22791815456e-05.\n",
      "Epoch:8, weight train batch: 176, step:6, loss before: 4.06195467804e-05, loss after: 4.05860191677e-05.\n",
      "Epoch:8, weight train batch: 176, step:7, loss before: 4.18078525399e-05, loss after: 4.17519804614e-05.\n",
      "Epoch:8, weight train batch: 176, step:8, loss before: 0.000300871790387, loss after: 0.000300369487377.\n",
      "Epoch:8, weight train batch: 176, step:9, loss before: 4.28620624007e-05, loss after: 4.28434359492e-05.\n",
      "Epoch:8, weight train batch: 176, step:10, loss before: 3.88165281038e-05, loss after: 3.87383042835e-05.\n",
      "Epoch:8, weight train batch: 176, step:11, loss before: 4.10256325267e-05, loss after: 4.09287822549e-05.\n",
      "Epoch:8, weight train batch: 176, step:12, loss before: 4.0839331632e-05, loss after: 4.08058040193e-05.\n",
      "Epoch:8, weight train batch: 176, step:13, loss before: 7.36852089176e-05, loss after: 7.36367946956e-05.\n",
      "Epoch:8, weight train batch: 176, step:14, loss before: 4.33612658526e-05, loss after: 4.3316562369e-05.\n",
      "Epoch:8, weight train batch: 176, step:15, loss before: 4.28359635407e-05, loss after: 4.28061612183e-05.\n",
      "Epoch:8, weight train batch: 176, step:16, loss before: 3.67044121958e-05, loss after: 3.66857930203e-05.\n",
      "Epoch:8, weight train batch: 176, step:17, loss before: 4.02507212129e-05, loss after: 4.02507212129e-05.\n",
      "Epoch:8, weight train batch: 176, step:18, loss before: 4.48475620942e-05, loss after: 4.47805105068e-05.\n",
      "Epoch:8, weight train batch: 176, step:19, loss before: 4.29104984505e-05, loss after: 4.29104984505e-05.\n",
      "Epoch:8, weight train batch: 176, step:20, loss before: 3.57023527613e-05, loss after: 3.56837299478e-05.\n",
      "Epoch:8, weight train batch: 176, step:21, loss before: 4.4769330998e-05, loss after: 4.47469792562e-05.\n",
      "Epoch:8, weight train batch: 176, step:22, loss before: 4.33873356087e-05, loss after: 4.33500827057e-05.\n",
      "Epoch:8, weight train batch: 176, step:23, loss before: 4.96865141031e-05, loss after: 4.96865141031e-05.\n",
      "Epoch:8, weight train batch: 176, step:24, loss before: 9.01549792616e-05, loss after: 9.00954182725e-05.\n",
      "Epoch:8, weight train batch: 176, step:25, loss before: 4.22063640144e-05, loss after: 4.21281401941e-05.\n",
      "Epoch:8, weight train batch: 176, step:26, loss before: 4.04183665523e-05, loss after: 4.03848389396e-05.\n",
      "Epoch:8, weight train batch: 176, step:27, loss before: 4.54994624306e-05, loss after: 4.54659348179e-05.\n",
      "Epoch:8, weight train batch: 176, step:28, loss before: 3.78889599233e-05, loss after: 3.78777840524e-05.\n",
      "Epoch:8, weight train batch: 176, step:29, loss before: 0.00378944142722, loss after: 0.00378658040427.\n",
      "Epoch:8, weight train batch: 176, step:30, loss before: 4.26348415203e-05, loss after: 4.25975886174e-05.\n",
      "Epoch:8, weight train batch: 176, step:31, loss before: 4.97088622069e-05, loss after: 4.96716093039e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 172, loss before: 4.40680669271e-05, loss after: 4.40680669271e-05.\n",
      "Epoch:8, weight train batch: 177, step:0, loss before: 3.79038829124e-05, loss after: 3.78778058803e-05.\n",
      "Epoch:8, weight train batch: 177, step:1, loss before: 4.50487277703e-05, loss after: 4.49667713838e-05.\n",
      "Epoch:8, weight train batch: 177, step:2, loss before: 0.00376284704544, loss after: 0.00375671312213.\n",
      "Epoch:8, weight train batch: 177, step:3, loss before: 4.07201041526e-05, loss after: 4.06530525652e-05.\n",
      "Epoch:8, weight train batch: 177, step:4, loss before: 4.377094956e-05, loss after: 4.37821290689e-05.\n",
      "Epoch:8, weight train batch: 177, step:5, loss before: 4.79729460494e-05, loss after: 4.79207956232e-05.\n",
      "Epoch:8, weight train batch: 177, step:6, loss before: 4.05077589676e-05, loss after: 4.04183556384e-05.\n",
      "Epoch:8, weight train batch: 177, step:7, loss before: 3.90288842027e-05, loss after: 3.90065397369e-05.\n",
      "Epoch:8, weight train batch: 177, step:8, loss before: 4.00309472752e-05, loss after: 4.0016046114e-05.\n",
      "Epoch:8, weight train batch: 177, step:9, loss before: 4.30557702202e-05, loss after: 4.30110667367e-05.\n",
      "Epoch:8, weight train batch: 177, step:10, loss before: 4.29030551459e-05, loss after: 4.28620769526e-05.\n",
      "Epoch:8, weight train batch: 177, step:11, loss before: 3.96360919694e-05, loss after: 3.96137438656e-05.\n",
      "Epoch:8, weight train batch: 177, step:12, loss before: 4.54026012449e-05, loss after: 4.53243701486e-05.\n",
      "Epoch:8, weight train batch: 177, step:13, loss before: 3.64548031939e-05, loss after: 3.64324514521e-05.\n",
      "Epoch:8, weight train batch: 177, step:14, loss before: 3.45699008903e-05, loss after: 3.45401058439e-05.\n",
      "Epoch:8, weight train batch: 177, step:15, loss before: 4.17519695475e-05, loss after: 4.17519695475e-05.\n",
      "Epoch:8, weight train batch: 177, step:16, loss before: 3.80454512197e-05, loss after: 3.80193741876e-05.\n",
      "Epoch:8, weight train batch: 177, step:17, loss before: 3.94051348849e-05, loss after: 3.93827867811e-05.\n",
      "Epoch:8, weight train batch: 177, step:18, loss before: 6.60536607029e-05, loss after: 6.59903453197e-05.\n",
      "Epoch:8, weight train batch: 177, step:19, loss before: 4.16961083829e-05, loss after: 4.16663060605e-05.\n",
      "Epoch:8, weight train batch: 177, step:20, loss before: 4.3137697503e-05, loss after: 4.30780928582e-05.\n",
      "Epoch:8, weight train batch: 177, step:21, loss before: 3.58960824087e-05, loss after: 3.58811848855e-05.\n",
      "Epoch:8, weight train batch: 177, step:22, loss before: 4.35921865574e-05, loss after: 4.35549336544e-05.\n",
      "Epoch:8, weight train batch: 177, step:23, loss before: 3.73600341845e-05, loss after: 3.73600341845e-05.\n",
      "Epoch:8, weight train batch: 177, step:24, loss before: 4.17742921854e-05, loss after: 4.17742921854e-05.\n",
      "Epoch:8, weight train batch: 177, step:25, loss before: 4.10330321756e-05, loss after: 4.09399071941e-05.\n",
      "Epoch:8, weight train batch: 177, step:26, loss before: 4.02470395784e-05, loss after: 4.02470395784e-05.\n",
      "Epoch:8, weight train batch: 177, step:27, loss before: 4.22660559707e-05, loss after: 4.22511548095e-05.\n",
      "Epoch:8, weight train batch: 177, step:28, loss before: 4.05599457736e-05, loss after: 4.05338723795e-05.\n",
      "Epoch:8, weight train batch: 177, step:29, loss before: 3.82652251574e-05, loss after: 3.82652251574e-05.\n",
      "Epoch:8, weight train batch: 177, step:30, loss before: 4.58086433355e-05, loss after: 4.57862915937e-05.\n",
      "Epoch:8, weight train batch: 177, step:31, loss before: 4.40266667283e-05, loss after: 4.39782452304e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 173, loss before: 4.00551798521e-05, loss after: 4.22955854447e-05.\n",
      "Epoch:8, weight train batch: 178, step:0, loss before: 4.27950035373e-05, loss after: 4.27726517955e-05.\n",
      "Epoch:8, weight train batch: 178, step:1, loss before: 3.91182838939e-05, loss after: 3.91182838939e-05.\n",
      "Epoch:8, weight train batch: 178, step:2, loss before: 3.87383115594e-05, loss after: 3.87159598176e-05.\n",
      "Epoch:8, weight train batch: 178, step:3, loss before: 4.21617369284e-05, loss after: 4.21207623731e-05.\n",
      "Epoch:8, weight train batch: 178, step:4, loss before: 3.63989820471e-05, loss after: 3.63989820471e-05.\n",
      "Epoch:8, weight train batch: 178, step:5, loss before: 3.95765382564e-05, loss after: 3.95579118049e-05.\n",
      "Epoch:8, weight train batch: 178, step:6, loss before: 5.7187909988e-05, loss after: 5.71208584006e-05.\n",
      "Epoch:8, weight train batch: 178, step:7, loss before: 3.75016170437e-05, loss after: 3.75016170437e-05.\n",
      "Epoch:8, weight train batch: 178, step:8, loss before: 4.46240264864e-05, loss after: 4.46240264864e-05.\n",
      "Epoch:8, weight train batch: 178, step:9, loss before: 3.75016134058e-05, loss after: 3.74531882699e-05.\n",
      "Epoch:8, weight train batch: 178, step:10, loss before: 4.22437078669e-05, loss after: 4.22064549639e-05.\n",
      "Epoch:8, weight train batch: 178, step:11, loss before: 4.01427168981e-05, loss after: 4.01427168981e-05.\n",
      "Epoch:8, weight train batch: 178, step:12, loss before: 4.34618486906e-05, loss after: 4.34059693362e-05.\n",
      "Epoch:8, weight train batch: 178, step:13, loss before: 3.29121903633e-05, loss after: 3.29121903633e-05.\n",
      "Epoch:8, weight train batch: 178, step:14, loss before: 4.14316236856e-05, loss after: 4.13906491303e-05.\n",
      "Epoch:8, weight train batch: 178, step:15, loss before: 6.34558527963e-05, loss after: 6.34148964309e-05.\n",
      "Epoch:8, weight train batch: 178, step:16, loss before: 6.81805540808e-05, loss after: 6.81619421812e-05.\n",
      "Epoch:8, weight train batch: 178, step:17, loss before: 4.34878893429e-05, loss after: 4.34878893429e-05.\n",
      "Epoch:8, weight train batch: 178, step:18, loss before: 3.67789180018e-05, loss after: 3.66932363249e-05.\n",
      "Epoch:8, weight train batch: 178, step:19, loss before: 4.29098145105e-05, loss after: 4.29060928582e-05.\n",
      "Epoch:8, weight train batch: 178, step:20, loss before: 4.23331002821e-05, loss after: 4.23331002821e-05.\n",
      "Epoch:8, weight train batch: 178, step:21, loss before: 4.1647690523e-05, loss after: 4.15955364588e-05.\n",
      "Epoch:8, weight train batch: 178, step:22, loss before: 4.46724916401e-05, loss after: 4.46128906333e-05.\n",
      "Epoch:8, weight train batch: 178, step:23, loss before: 4.40540861746e-05, loss after: 4.40540861746e-05.\n",
      "Epoch:8, weight train batch: 178, step:24, loss before: 4.14018359152e-05, loss after: 4.13720335928e-05.\n",
      "Epoch:8, weight train batch: 178, step:25, loss before: 3.94461312681e-05, loss after: 3.94461312681e-05.\n",
      "Epoch:8, weight train batch: 178, step:26, loss before: 3.13066848321e-05, loss after: 3.12731572194e-05.\n",
      "Epoch:8, weight train batch: 178, step:27, loss before: 3.89804481529e-05, loss after: 3.89469241782e-05.\n",
      "Epoch:8, weight train batch: 178, step:28, loss before: 4.11299188272e-05, loss after: 4.11001201428e-05.\n",
      "Epoch:8, weight train batch: 178, step:29, loss before: 3.70992856915e-05, loss after: 3.70992856915e-05.\n",
      "Epoch:8, weight train batch: 178, step:30, loss before: 3.84850281989e-05, loss after: 3.84291488444e-05.\n",
      "Epoch:8, weight train batch: 178, step:31, loss before: 3.66634376405e-05, loss after: 3.66634376405e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 174, loss before: 0.00104682543315, loss after: 4.42588243459e-05.\n",
      "Epoch:8, weight train batch: 179, step:0, loss before: 3.88277621823e-05, loss after: 3.88016851502e-05.\n",
      "Epoch:8, weight train batch: 179, step:1, loss before: 4.18003837694e-05, loss after: 4.17556875618e-05.\n",
      "Epoch:8, weight train batch: 179, step:2, loss before: 3.50132249878e-05, loss after: 3.49759720848e-05.\n",
      "Epoch:8, weight train batch: 179, step:3, loss before: 0.0319894813001, loss after: 0.0319291427732.\n",
      "Epoch:8, weight train batch: 179, step:4, loss before: 3.61605234502e-05, loss after: 3.62387509085e-05.\n",
      "Epoch:8, weight train batch: 179, step:5, loss before: 4.29812353104e-05, loss after: 4.29775100201e-05.\n",
      "Epoch:8, weight train batch: 179, step:6, loss before: 0.000174469489139, loss after: 0.000174098822754.\n",
      "Epoch:8, weight train batch: 179, step:7, loss before: 4.26273982157e-05, loss after: 4.27205268352e-05.\n",
      "Epoch:8, weight train batch: 179, step:8, loss before: 4.14986716351e-05, loss after: 4.15023969254e-05.\n",
      "Epoch:8, weight train batch: 179, step:9, loss before: 4.28546409239e-05, loss after: 4.28583662142e-05.\n",
      "Epoch:8, weight train batch: 179, step:10, loss before: 3.86452229577e-05, loss after: 3.87085456168e-05.\n",
      "Epoch:8, weight train batch: 179, step:11, loss before: 4.10181237385e-05, loss after: 4.10740030929e-05.\n",
      "Epoch:8, weight train batch: 179, step:12, loss before: 3.83695914934e-05, loss after: 3.84180166293e-05.\n",
      "Epoch:8, weight train batch: 179, step:13, loss before: 4.2355437472e-05, loss after: 4.23405363108e-05.\n",
      "Epoch:8, weight train batch: 179, step:14, loss before: 4.24969985033e-05, loss after: 4.25193466072e-05.\n",
      "Epoch:8, weight train batch: 179, step:15, loss before: 4.64195873064e-05, loss after: 4.64344921056e-05.\n",
      "Epoch:8, weight train batch: 179, step:16, loss before: 4.19680218329e-05, loss after: 4.19419448008e-05.\n",
      "Epoch:8, weight train batch: 179, step:17, loss before: 4.11261607951e-05, loss after: 4.11596884078e-05.\n",
      "Epoch:8, weight train batch: 179, step:18, loss before: 6.00742969254e-05, loss after: 6.00742823735e-05.\n",
      "Epoch:8, weight train batch: 179, step:19, loss before: 4.08058040193e-05, loss after: 4.07760053349e-05.\n",
      "Epoch:8, weight train batch: 179, step:20, loss before: 6.27709960099e-05, loss after: 6.27300396445e-05.\n",
      "Epoch:8, weight train batch: 179, step:21, loss before: 3.43352039636e-05, loss after: 3.43538304151e-05.\n",
      "Epoch:8, weight train batch: 179, step:22, loss before: 4.21729237132e-05, loss after: 4.21431213908e-05.\n",
      "Epoch:8, weight train batch: 179, step:23, loss before: 4.04146630899e-05, loss after: 4.04146630899e-05.\n",
      "Epoch:8, weight train batch: 179, step:24, loss before: 3.85930907214e-05, loss after: 3.85223138437e-05.\n",
      "Epoch:8, weight train batch: 179, step:25, loss before: 3.99564669351e-05, loss after: 3.99564669351e-05.\n",
      "Epoch:8, weight train batch: 179, step:26, loss before: 4.33128116129e-05, loss after: 4.33128116129e-05.\n",
      "Epoch:8, weight train batch: 179, step:27, loss before: 4.06940380344e-05, loss after: 4.0664235712e-05.\n",
      "Epoch:8, weight train batch: 179, step:28, loss before: 4.07648076362e-05, loss after: 4.07648076362e-05.\n",
      "Epoch:8, weight train batch: 179, step:29, loss before: 0.000157710863277, loss after: 0.000157391346875.\n",
      "Epoch:8, weight train batch: 179, step:30, loss before: 4.24113386543e-05, loss after: 4.2381536332e-05.\n",
      "Epoch:8, weight train batch: 179, step:31, loss before: 4.3029718654e-05, loss after: 4.3029718654e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:8, struct parameters train batch: 175, loss before: 6.59632642055e-05, loss after: 4.09860149375e-05.\n",
      "Epoch:9, weight train batch: 180, step:0, loss before: 0.0308886393905, loss after: 0.0308260228485.\n",
      "Epoch:9, weight train batch: 180, step:1, loss before: 4.29216743214e-05, loss after: 4.31153857789e-05.\n",
      "Epoch:9, weight train batch: 180, step:2, loss before: 0.000309467781335, loss after: 0.000318351609167.\n",
      "Epoch:9, weight train batch: 180, step:3, loss before: 6.44072788418e-05, loss after: 6.48801506031e-05.\n",
      "Epoch:9, weight train batch: 180, step:4, loss before: 4.08206869906e-05, loss after: 4.09361673519e-05.\n",
      "Epoch:9, weight train batch: 180, step:5, loss before: 3.94163216697e-05, loss after: 3.9569054934e-05.\n",
      "Epoch:9, weight train batch: 180, step:6, loss before: 3.8809110265e-05, loss after: 3.8920865336e-05.\n",
      "Epoch:9, weight train batch: 180, step:7, loss before: 4.59278744529e-05, loss after: 4.59800285171e-05.\n",
      "Epoch:9, weight train batch: 180, step:8, loss before: 4.16886541643e-05, loss after: 4.17743358412e-05.\n",
      "Epoch:9, weight train batch: 180, step:9, loss before: 3.88314838347e-05, loss after: 3.90028399124e-05.\n",
      "Epoch:9, weight train batch: 180, step:10, loss before: 4.04109487135e-05, loss after: 4.04966303904e-05.\n",
      "Epoch:9, weight train batch: 180, step:11, loss before: 4.20388169005e-05, loss after: 4.21170479967e-05.\n",
      "Epoch:9, weight train batch: 180, step:12, loss before: 3.77363321604e-05, loss after: 3.78592631023e-05.\n",
      "Epoch:9, weight train batch: 180, step:13, loss before: 4.02470141125e-05, loss after: 4.02991681767e-05.\n",
      "Epoch:9, weight train batch: 180, step:14, loss before: 4.02954683523e-05, loss after: 4.03625163017e-05.\n",
      "Epoch:9, weight train batch: 180, step:15, loss before: 4.11297478422e-05, loss after: 4.11632754549e-05.\n",
      "Epoch:9, weight train batch: 180, step:16, loss before: 4.02805635531e-05, loss after: 4.03401645599e-05.\n",
      "Epoch:9, weight train batch: 180, step:17, loss before: 3.76208081434e-05, loss after: 3.76804091502e-05.\n",
      "Epoch:9, weight train batch: 180, step:18, loss before: 4.2944062443e-05, loss after: 4.29477877333e-05.\n",
      "Epoch:9, weight train batch: 180, step:19, loss before: 4.57368805655e-05, loss after: 4.57406058558e-05.\n",
      "Epoch:9, weight train batch: 180, step:20, loss before: 4.71609127999e-05, loss after: 4.71571838716e-05.\n",
      "Epoch:9, weight train batch: 180, step:21, loss before: 4.09697022405e-05, loss after: 4.09697022405e-05.\n",
      "Epoch:9, weight train batch: 180, step:22, loss before: 4.1524781409e-05, loss after: 4.15210561187e-05.\n",
      "Epoch:9, weight train batch: 180, step:23, loss before: 4.20053111156e-05, loss after: 4.20239375671e-05.\n",
      "Epoch:9, weight train batch: 180, step:24, loss before: 4.62147327198e-05, loss after: 4.62147327198e-05.\n",
      "Epoch:9, weight train batch: 180, step:25, loss before: 3.95168935938e-05, loss after: 3.94870949094e-05.\n",
      "Epoch:9, weight train batch: 180, step:26, loss before: 4.65462580905e-05, loss after: 4.65425328002e-05.\n",
      "Epoch:9, weight train batch: 180, step:27, loss before: 3.67752109014e-05, loss after: 3.67752109014e-05.\n",
      "Epoch:9, weight train batch: 180, step:28, loss before: 4.32122396887e-05, loss after: 4.3152635044e-05.\n",
      "Epoch:9, weight train batch: 180, step:29, loss before: 4.28993662354e-05, loss after: 4.28732892033e-05.\n",
      "Epoch:9, weight train batch: 180, step:30, loss before: 4.1997864173e-05, loss after: 4.1997864173e-05.\n",
      "Epoch:9, weight train batch: 180, step:31, loss before: 4.54882974736e-05, loss after: 4.54137953056e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 176, loss before: 4.14994865423e-05, loss after: 4.01706856792e-05.\n",
      "Epoch:9, weight train batch: 181, step:0, loss before: 3.88351909351e-05, loss after: 3.88351909351e-05.\n",
      "Epoch:9, weight train batch: 181, step:1, loss before: 6.5392581746e-05, loss after: 6.5392581746e-05.\n",
      "Epoch:9, weight train batch: 181, step:2, loss before: 4.35959373135e-05, loss after: 4.35288893641e-05.\n",
      "Epoch:9, weight train batch: 181, step:3, loss before: 4.17035844293e-05, loss after: 4.16700568167e-05.\n",
      "Epoch:9, weight train batch: 181, step:4, loss before: 3.7713922211e-05, loss after: 3.76878488169e-05.\n",
      "Epoch:9, weight train batch: 181, step:5, loss before: 4.13087291236e-05, loss after: 4.13087291236e-05.\n",
      "Epoch:9, weight train batch: 181, step:6, loss before: 7.10519307177e-05, loss after: 7.0969996159e-05.\n",
      "Epoch:9, weight train batch: 181, step:7, loss before: 3.93083173549e-05, loss after: 3.93083173549e-05.\n",
      "Epoch:9, weight train batch: 181, step:8, loss before: 0.00390389398672, loss after: 0.00387604464777.\n",
      "Epoch:9, weight train batch: 181, step:9, loss before: 4.546969285e-05, loss after: 4.5208937081e-05.\n",
      "Epoch:9, weight train batch: 181, step:10, loss before: 3.75388772227e-05, loss after: 3.72967406292e-05.\n",
      "Epoch:9, weight train batch: 181, step:11, loss before: 4.16961411247e-05, loss after: 4.14689093304e-05.\n",
      "Epoch:9, weight train batch: 181, step:12, loss before: 3.99788295908e-05, loss after: 3.98857046093e-05.\n",
      "Epoch:9, weight train batch: 181, step:13, loss before: 3.99416239816e-05, loss after: 3.98522206524e-05.\n",
      "Epoch:9, weight train batch: 181, step:14, loss before: 4.04780330427e-05, loss after: 4.04333331971e-05.\n",
      "Epoch:9, weight train batch: 181, step:15, loss before: 3.67789543816e-05, loss after: 3.67454304069e-05.\n",
      "Epoch:9, weight train batch: 181, step:16, loss before: 5.44000868103e-05, loss after: 5.43777387065e-05.\n",
      "Epoch:9, weight train batch: 181, step:17, loss before: 4.09212989325e-05, loss after: 4.08915002481e-05.\n",
      "Epoch:9, weight train batch: 181, step:18, loss before: 4.26870101364e-05, loss after: 4.26274091296e-05.\n",
      "Epoch:9, weight train batch: 181, step:19, loss before: 4.00869175792e-05, loss after: 4.00869175792e-05.\n",
      "Epoch:9, weight train batch: 181, step:20, loss before: 3.86489664379e-05, loss after: 3.85930907214e-05.\n",
      "Epoch:9, weight train batch: 181, step:21, loss before: 4.23256788054e-05, loss after: 4.23256788054e-05.\n",
      "Epoch:9, weight train batch: 181, step:22, loss before: 4.05078244512e-05, loss after: 4.04482234444e-05.\n",
      "Epoch:9, weight train batch: 181, step:23, loss before: 3.93194859498e-05, loss after: 3.93008594983e-05.\n",
      "Epoch:9, weight train batch: 181, step:24, loss before: 3.745694994e-05, loss after: 3.74234223273e-05.\n",
      "Epoch:9, weight train batch: 181, step:25, loss before: 4.1662624426e-05, loss after: 4.1662624426e-05.\n",
      "Epoch:9, weight train batch: 181, step:26, loss before: 3.6208966776e-05, loss after: 3.6208966776e-05.\n",
      "Epoch:9, weight train batch: 181, step:27, loss before: 4.74179796583e-05, loss after: 4.73434738524e-05.\n",
      "Epoch:9, weight train batch: 181, step:28, loss before: 0.000172948566615, loss after: 0.000172885382199.\n",
      "Epoch:9, weight train batch: 181, step:29, loss before: 4.20798205596e-05, loss after: 4.20798205596e-05.\n",
      "Epoch:9, weight train batch: 181, step:30, loss before: 3.59705518349e-05, loss after: 3.5959375964e-05.\n",
      "Epoch:9, weight train batch: 181, step:31, loss before: 0.00398213090375, loss after: 0.00397237576544.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 177, loss before: 3.93250811612e-05, loss after: 0.00102997710928.\n",
      "Epoch:9, weight train batch: 182, step:0, loss before: 3.87495529139e-05, loss after: 3.86974024877e-05.\n",
      "Epoch:9, weight train batch: 182, step:1, loss before: 4.43000317318e-05, loss after: 4.42739546997e-05.\n",
      "Epoch:9, weight train batch: 182, step:2, loss before: 3.89283522964e-05, loss after: 3.8898549974e-05.\n",
      "Epoch:9, weight train batch: 182, step:3, loss before: 3.89954257116e-05, loss after: 3.89283741242e-05.\n",
      "Epoch:9, weight train batch: 182, step:4, loss before: 3.8499951188e-05, loss after: 3.84403501812e-05.\n",
      "Epoch:9, weight train batch: 182, step:5, loss before: 4.37487433373e-05, loss after: 4.37114904344e-05.\n",
      "Epoch:9, weight train batch: 182, step:6, loss before: 4.51790401712e-05, loss after: 4.51045416412e-05.\n",
      "Epoch:9, weight train batch: 182, step:7, loss before: 4.39722170995e-05, loss after: 4.39461437054e-05.\n",
      "Epoch:9, weight train batch: 182, step:8, loss before: 2.93361008517e-05, loss after: 2.93100238196e-05.\n",
      "Epoch:9, weight train batch: 182, step:9, loss before: 3.50690970663e-05, loss after: 3.50430200342e-05.\n",
      "Epoch:9, weight train batch: 182, step:10, loss before: 3.65144369425e-05, loss after: 3.65144369425e-05.\n",
      "Epoch:9, weight train batch: 182, step:11, loss before: 3.71030546376e-05, loss after: 3.70322777599e-05.\n",
      "Epoch:9, weight train batch: 182, step:12, loss before: 0.00015742785763, loss after: 0.000157119546202.\n",
      "Epoch:9, weight train batch: 182, step:13, loss before: 3.69912850147e-05, loss after: 3.69912850147e-05.\n",
      "Epoch:9, weight train batch: 182, step:14, loss before: 4.0045921196e-05, loss after: 3.99751406803e-05.\n",
      "Epoch:9, weight train batch: 182, step:15, loss before: 4.10181673942e-05, loss after: 4.10181673942e-05.\n",
      "Epoch:9, weight train batch: 182, step:16, loss before: 4.01166907977e-05, loss after: 4.00235621782e-05.\n",
      "Epoch:9, weight train batch: 182, step:17, loss before: 3.80939163733e-05, loss after: 3.80939163733e-05.\n",
      "Epoch:9, weight train batch: 182, step:18, loss before: 4.3778505642e-05, loss after: 4.3778505642e-05.\n",
      "Epoch:9, weight train batch: 182, step:19, loss before: 0.000385968771297, loss after: 0.000385083607398.\n",
      "Epoch:9, weight train batch: 182, step:20, loss before: 3.90624627471e-05, loss after: 3.89954075217e-05.\n",
      "Epoch:9, weight train batch: 182, step:21, loss before: 3.8898549974e-05, loss after: 3.88426778954e-05.\n",
      "Epoch:9, weight train batch: 182, step:22, loss before: 3.80939491151e-05, loss after: 3.80939491151e-05.\n",
      "Epoch:9, weight train batch: 182, step:23, loss before: 3.53671603079e-05, loss after: 3.5292654502e-05.\n",
      "Epoch:9, weight train batch: 182, step:24, loss before: 2.98017293971e-05, loss after: 2.9749577152e-05.\n",
      "Epoch:9, weight train batch: 182, step:25, loss before: 0.000173405802343, loss after: 0.000173316628207.\n",
      "Epoch:9, weight train batch: 182, step:26, loss before: 3.9338163333e-05, loss after: 3.93195368815e-05.\n",
      "Epoch:9, weight train batch: 182, step:27, loss before: 4.34506800957e-05, loss after: 4.34357789345e-05.\n",
      "Epoch:9, weight train batch: 182, step:28, loss before: 4.71013590868e-05, loss after: 4.69896112918e-05.\n",
      "Epoch:9, weight train batch: 182, step:29, loss before: 6.39662030153e-05, loss after: 6.39178178972e-05.\n",
      "Epoch:9, weight train batch: 182, step:30, loss before: 6.4089166699e-05, loss after: 6.3981184212e-05.\n",
      "Epoch:9, weight train batch: 182, step:31, loss before: 3.73265793314e-05, loss after: 3.73265793314e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 178, loss before: 7.60062976042e-05, loss after: 3.86126630474e-05.\n",
      "Epoch:9, weight train batch: 183, step:0, loss before: 3.85707462556e-05, loss after: 3.85185958294e-05.\n",
      "Epoch:9, weight train batch: 183, step:1, loss before: 3.68646215065e-05, loss after: 3.68497203453e-05.\n",
      "Epoch:9, weight train batch: 183, step:2, loss before: 3.73526272597e-05, loss after: 3.72930262529e-05.\n",
      "Epoch:9, weight train batch: 183, step:3, loss before: 3.83733495255e-05, loss after: 3.83733495255e-05.\n",
      "Epoch:9, weight train batch: 183, step:4, loss before: 3.62946593668e-05, loss after: 3.62164319085e-05.\n",
      "Epoch:9, weight train batch: 183, step:5, loss before: 3.87384025089e-05, loss after: 3.87384025089e-05.\n",
      "Epoch:9, weight train batch: 183, step:6, loss before: 3.86191859434e-05, loss after: 3.85856583307e-05.\n",
      "Epoch:9, weight train batch: 183, step:7, loss before: 4.38567512901e-05, loss after: 4.38269489678e-05.\n",
      "Epoch:9, weight train batch: 183, step:8, loss before: 4.35848123743e-05, loss after: 4.35587353422e-05.\n",
      "Epoch:9, weight train batch: 183, step:9, loss before: 4.32420820289e-05, loss after: 4.32234555774e-05.\n",
      "Epoch:9, weight train batch: 183, step:10, loss before: 3.96696777898e-05, loss after: 3.96436043957e-05.\n",
      "Epoch:9, weight train batch: 183, step:11, loss before: 3.29644135491e-05, loss after: 3.29197137034e-05.\n",
      "Epoch:9, weight train batch: 183, step:12, loss before: 3.96398827434e-05, loss after: 3.96212562919e-05.\n",
      "Epoch:9, weight train batch: 183, step:13, loss before: 3.70173875126e-05, loss after: 3.69838671759e-05.\n",
      "Epoch:9, weight train batch: 183, step:14, loss before: 3.48679532181e-05, loss after: 3.48381508957e-05.\n",
      "Epoch:9, weight train batch: 183, step:15, loss before: 3.40111364494e-05, loss after: 3.40111364494e-05.\n",
      "Epoch:9, weight train batch: 183, step:16, loss before: 6.14276068518e-05, loss after: 6.13456795691e-05.\n",
      "Epoch:9, weight train batch: 183, step:17, loss before: 4.14614696638e-05, loss after: 4.14428432123e-05.\n",
      "Epoch:9, weight train batch: 183, step:18, loss before: 3.25285473082e-05, loss after: 3.25285473082e-05.\n",
      "Epoch:9, weight train batch: 183, step:19, loss before: 3.56837590516e-05, loss after: 3.56539603672e-05.\n",
      "Epoch:9, weight train batch: 183, step:20, loss before: 3.29420436174e-05, loss after: 3.28675414494e-05.\n",
      "Epoch:9, weight train batch: 183, step:21, loss before: 3.88650587411e-05, loss after: 3.88240805478e-05.\n",
      "Epoch:9, weight train batch: 183, step:22, loss before: 4.20351643697e-05, loss after: 4.20351643697e-05.\n",
      "Epoch:9, weight train batch: 183, step:23, loss before: 3.55645534e-05, loss after: 3.55347547156e-05.\n",
      "Epoch:9, weight train batch: 183, step:24, loss before: 3.88911066693e-05, loss after: 3.88650296372e-05.\n",
      "Epoch:9, weight train batch: 183, step:25, loss before: 3.80529636459e-05, loss after: 3.80268866138e-05.\n",
      "Epoch:9, weight train batch: 183, step:26, loss before: 3.8190788473e-05, loss after: 3.81609861506e-05.\n",
      "Epoch:9, weight train batch: 183, step:27, loss before: 3.74643641408e-05, loss after: 3.74531882699e-05.\n",
      "Epoch:9, weight train batch: 183, step:28, loss before: 3.28191235894e-05, loss after: 3.28191235894e-05.\n",
      "Epoch:9, weight train batch: 183, step:29, loss before: 3.6287245166e-05, loss after: 3.6287245166e-05.\n",
      "Epoch:9, weight train batch: 183, step:30, loss before: 3.58588440577e-05, loss after: 3.58029683412e-05.\n",
      "Epoch:9, weight train batch: 183, step:31, loss before: 6.47306005703e-05, loss after: 6.46821936243e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 179, loss before: 3.74709161406e-05, loss after: 3.74914088752e-05.\n",
      "Epoch:9, weight train batch: 184, step:0, loss before: 3.80455094273e-05, loss after: 3.80455094273e-05.\n",
      "Epoch:9, weight train batch: 184, step:1, loss before: 3.72520225937e-05, loss after: 3.72110480384e-05.\n",
      "Epoch:9, weight train batch: 184, step:2, loss before: 3.76319367206e-05, loss after: 3.75946874556e-05.\n",
      "Epoch:9, weight train batch: 184, step:3, loss before: 3.5277720599e-05, loss after: 3.52441929863e-05.\n",
      "Epoch:9, weight train batch: 184, step:4, loss before: 3.43613646692e-05, loss after: 3.43613646692e-05.\n",
      "Epoch:9, weight train batch: 184, step:5, loss before: 3.55868978659e-05, loss after: 3.55570955435e-05.\n",
      "Epoch:9, weight train batch: 184, step:6, loss before: 3.67417051166e-05, loss after: 3.67081775039e-05.\n",
      "Epoch:9, weight train batch: 184, step:7, loss before: 3.72893046006e-05, loss after: 3.72334252461e-05.\n",
      "Epoch:9, weight train batch: 184, step:8, loss before: 3.29383037752e-05, loss after: 3.29383037752e-05.\n",
      "Epoch:9, weight train batch: 184, step:9, loss before: 3.57284625352e-05, loss after: 3.57023891411e-05.\n",
      "Epoch:9, weight train batch: 184, step:10, loss before: 3.58290453732e-05, loss after: 3.58290453732e-05.\n",
      "Epoch:9, weight train batch: 184, step:11, loss before: 3.92561996705e-05, loss after: 3.91854191548e-05.\n",
      "Epoch:9, weight train batch: 184, step:12, loss before: 3.78443655791e-05, loss after: 3.78443655791e-05.\n",
      "Epoch:9, weight train batch: 184, step:13, loss before: 3.74271403416e-05, loss after: 3.74047922378e-05.\n",
      "Epoch:9, weight train batch: 184, step:14, loss before: 3.44023101206e-05, loss after: 3.44023101206e-05.\n",
      "Epoch:9, weight train batch: 184, step:15, loss before: 4.04109778174e-05, loss after: 4.0381179133e-05.\n",
      "Epoch:9, weight train batch: 184, step:16, loss before: 0.000187257712241, loss after: 0.000187031400856.\n",
      "Epoch:9, weight train batch: 184, step:17, loss before: 3.24019056279e-05, loss after: 3.23944550473e-05.\n",
      "Epoch:9, weight train batch: 184, step:18, loss before: 0.000145722500747, loss after: 0.000145343758049.\n",
      "Epoch:9, weight train batch: 184, step:19, loss before: 0.000179949827725, loss after: 0.000179282447789.\n",
      "Epoch:9, weight train batch: 184, step:20, loss before: 3.92374458897e-05, loss after: 3.91554931412e-05.\n",
      "Epoch:9, weight train batch: 184, step:21, loss before: 3.6372908653e-05, loss after: 3.63505569112e-05.\n",
      "Epoch:9, weight train batch: 184, step:22, loss before: 3.28154055751e-05, loss after: 3.28154055751e-05.\n",
      "Epoch:9, weight train batch: 184, step:23, loss before: 4.32756460214e-05, loss after: 4.32644701505e-05.\n",
      "Epoch:9, weight train batch: 184, step:24, loss before: 3.67379761883e-05, loss after: 3.6697005271e-05.\n",
      "Epoch:9, weight train batch: 184, step:25, loss before: 3.4815784602e-05, loss after: 3.4815784602e-05.\n",
      "Epoch:9, weight train batch: 184, step:26, loss before: 4.16130496887e-05, loss after: 4.15236499975e-05.\n",
      "Epoch:9, weight train batch: 184, step:27, loss before: 3.45848238794e-05, loss after: 3.45848238794e-05.\n",
      "Epoch:9, weight train batch: 184, step:28, loss before: 4.42032178398e-05, loss after: 4.41622396465e-05.\n",
      "Epoch:9, weight train batch: 184, step:29, loss before: 3.54677322321e-05, loss after: 3.54677322321e-05.\n",
      "Epoch:9, weight train batch: 184, step:30, loss before: 3.39105899911e-05, loss after: 3.38807913067e-05.\n",
      "Epoch:9, weight train batch: 184, step:31, loss before: 3.40484184562e-05, loss after: 3.40111655532e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 180, loss before: 3.72390204575e-05, loss after: 3.72390204575e-05.\n",
      "Epoch:9, weight train batch: 185, step:0, loss before: 3.62760656571e-05, loss after: 3.62201899407e-05.\n",
      "Epoch:9, weight train batch: 185, step:1, loss before: 3.68534419977e-05, loss after: 3.68124638044e-05.\n",
      "Epoch:9, weight train batch: 185, step:2, loss before: 3.8652728108e-05, loss after: 3.8652728108e-05.\n",
      "Epoch:9, weight train batch: 185, step:3, loss before: 4.43148637714e-05, loss after: 4.43148637714e-05.\n",
      "Epoch:9, weight train batch: 185, step:4, loss before: 3.79412085749e-05, loss after: 3.79151388188e-05.\n",
      "Epoch:9, weight train batch: 185, step:5, loss before: 4.00571261707e-05, loss after: 4.00198769057e-05.\n",
      "Epoch:9, weight train batch: 185, step:6, loss before: 3.81684330932e-05, loss after: 3.81684330932e-05.\n",
      "Epoch:9, weight train batch: 185, step:7, loss before: 3.58476972906e-05, loss after: 3.58067190973e-05.\n",
      "Epoch:9, weight train batch: 185, step:8, loss before: 3.79896300728e-05, loss after: 3.79225784854e-05.\n",
      "Epoch:9, weight train batch: 185, step:9, loss before: 3.99639829993e-05, loss after: 3.99639829993e-05.\n",
      "Epoch:9, weight train batch: 185, step:10, loss before: 6.47348933853e-05, loss after: 6.47125707474e-05.\n",
      "Epoch:9, weight train batch: 185, step:11, loss before: 3.87868240068e-05, loss after: 3.87868240068e-05.\n",
      "Epoch:9, weight train batch: 185, step:12, loss before: 3.72818685719e-05, loss after: 3.71850146621e-05.\n",
      "Epoch:9, weight train batch: 185, step:13, loss before: 3.39776379406e-05, loss after: 3.39776379406e-05.\n",
      "Epoch:9, weight train batch: 185, step:14, loss before: 3.82466787414e-05, loss after: 3.82466787414e-05.\n",
      "Epoch:9, weight train batch: 185, step:15, loss before: 0.000164150915225, loss after: 0.00016408036754.\n",
      "Epoch:9, weight train batch: 185, step:16, loss before: 3.14743156196e-05, loss after: 3.14258868457e-05.\n",
      "Epoch:9, weight train batch: 185, step:17, loss before: 3.89878987335e-05, loss after: 3.89618217014e-05.\n",
      "Epoch:9, weight train batch: 185, step:18, loss before: 3.78033946618e-05, loss after: 3.778104292e-05.\n",
      "Epoch:9, weight train batch: 185, step:19, loss before: 3.45513180946e-05, loss after: 3.45513180946e-05.\n",
      "Epoch:9, weight train batch: 185, step:20, loss before: 3.61308011634e-05, loss after: 3.60749254469e-05.\n",
      "Epoch:9, weight train batch: 185, step:21, loss before: 0.00365843856707, loss after: 0.00365447043441.\n",
      "Epoch:9, weight train batch: 185, step:22, loss before: 3.54975090886e-05, loss after: 3.54788826371e-05.\n",
      "Epoch:9, weight train batch: 185, step:23, loss before: 3.08559719997e-05, loss after: 3.08447961288e-05.\n",
      "Epoch:9, weight train batch: 185, step:24, loss before: 3.34971082339e-05, loss after: 3.34747564921e-05.\n",
      "Epoch:9, weight train batch: 185, step:25, loss before: 3.65889791283e-05, loss after: 3.65554551536e-05.\n",
      "Epoch:9, weight train batch: 185, step:26, loss before: 3.44768122886e-05, loss after: 3.44358377333e-05.\n",
      "Epoch:9, weight train batch: 185, step:27, loss before: 3.50020854967e-05, loss after: 3.50020854967e-05.\n",
      "Epoch:9, weight train batch: 185, step:28, loss before: 3.7706537114e-05, loss after: 3.76804600819e-05.\n",
      "Epoch:9, weight train batch: 185, step:29, loss before: 3.60674530384e-05, loss after: 3.60674530384e-05.\n",
      "Epoch:9, weight train batch: 185, step:30, loss before: 0.000347987748682, loss after: 0.000347017339664.\n",
      "Epoch:9, weight train batch: 185, step:31, loss before: 3.21523220919e-05, loss after: 3.21523220919e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 181, loss before: 3.63300787285e-05, loss after: 4.22099474235e-05.\n",
      "Epoch:9, weight train batch: 186, step:0, loss before: 4.04557140428e-05, loss after: 4.03514131904e-05.\n",
      "Epoch:9, weight train batch: 186, step:1, loss before: 3.53112736775e-05, loss after: 3.52777460648e-05.\n",
      "Epoch:9, weight train batch: 186, step:2, loss before: 3.49946130882e-05, loss after: 3.49610891135e-05.\n",
      "Epoch:9, weight train batch: 186, step:3, loss before: 3.22380001307e-05, loss after: 3.21970219375e-05.\n",
      "Epoch:9, weight train batch: 186, step:4, loss before: 3.72073700419e-05, loss after: 3.72073700419e-05.\n",
      "Epoch:9, weight train batch: 186, step:5, loss before: 4.04519596486e-05, loss after: 4.04109814554e-05.\n",
      "Epoch:9, weight train batch: 186, step:6, loss before: 3.69652116206e-05, loss after: 3.69391345885e-05.\n",
      "Epoch:9, weight train batch: 186, step:7, loss before: 0.000143011609907, loss after: 0.000142855540616.\n",
      "Epoch:9, weight train batch: 186, step:8, loss before: 3.56688942702e-05, loss after: 3.56279197149e-05.\n",
      "Epoch:9, weight train batch: 186, step:9, loss before: 3.54267394869e-05, loss after: 3.53894865839e-05.\n",
      "Epoch:9, weight train batch: 186, step:10, loss before: 2.99582115986e-05, loss after: 2.99284129142e-05.\n",
      "Epoch:9, weight train batch: 186, step:11, loss before: 3.53149844159e-05, loss after: 3.53149844159e-05.\n",
      "Epoch:9, weight train batch: 186, step:12, loss before: 3.7706540752e-05, loss after: 3.7706540752e-05.\n",
      "Epoch:9, weight train batch: 186, step:13, loss before: 3.78406402888e-05, loss after: 3.77512405976e-05.\n",
      "Epoch:9, weight train batch: 186, step:14, loss before: 3.73042421415e-05, loss after: 3.73042421415e-05.\n",
      "Epoch:9, weight train batch: 186, step:15, loss before: 3.63319413736e-05, loss after: 3.63021426892e-05.\n",
      "Epoch:9, weight train batch: 186, step:16, loss before: 6.26198889222e-05, loss after: 6.26012770226e-05.\n",
      "Epoch:9, weight train batch: 186, step:17, loss before: 3.27483394358e-05, loss after: 3.26924637193e-05.\n",
      "Epoch:9, weight train batch: 186, step:18, loss before: 3.42048770108e-05, loss after: 3.41713493981e-05.\n",
      "Epoch:9, weight train batch: 186, step:19, loss before: 3.53149916918e-05, loss after: 3.53149916918e-05.\n",
      "Epoch:9, weight train batch: 186, step:20, loss before: 3.95691131416e-05, loss after: 3.95393108192e-05.\n",
      "Epoch:9, weight train batch: 186, step:21, loss before: 3.45587832271e-05, loss after: 3.45215339621e-05.\n",
      "Epoch:9, weight train batch: 186, step:22, loss before: 3.72893264284e-05, loss after: 3.7259527744e-05.\n",
      "Epoch:9, weight train batch: 186, step:23, loss before: 5.93061413383e-05, loss after: 5.92838077864e-05.\n",
      "Epoch:9, weight train batch: 186, step:24, loss before: 3.88724911318e-05, loss after: 3.88464140997e-05.\n",
      "Epoch:9, weight train batch: 186, step:25, loss before: 3.64846673619e-05, loss after: 3.6410165194e-05.\n",
      "Epoch:9, weight train batch: 186, step:26, loss before: 3.36908269674e-05, loss after: 3.36498487741e-05.\n",
      "Epoch:9, weight train batch: 186, step:27, loss before: 3.50877453457e-05, loss after: 3.50877453457e-05.\n",
      "Epoch:9, weight train batch: 186, step:28, loss before: 3.21523075399e-05, loss after: 3.21523075399e-05.\n",
      "Epoch:9, weight train batch: 186, step:29, loss before: 3.73303046217e-05, loss after: 3.72632530343e-05.\n",
      "Epoch:9, weight train batch: 186, step:30, loss before: 3.83808073821e-05, loss after: 3.83510050597e-05.\n",
      "Epoch:9, weight train batch: 186, step:31, loss before: 3.384727097e-05, loss after: 3.384727097e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 182, loss before: 4.22257908212e-05, loss after: 3.43920874002e-05.\n",
      "Epoch:9, weight train batch: 187, step:0, loss before: 3.11875228363e-05, loss after: 3.11651747325e-05.\n",
      "Epoch:9, weight train batch: 187, step:1, loss before: 3.85484090657e-05, loss after: 3.85297826142e-05.\n",
      "Epoch:9, weight train batch: 187, step:2, loss before: 3.11688709189e-05, loss after: 3.11688709189e-05.\n",
      "Epoch:9, weight train batch: 187, step:3, loss before: 3.71663954866e-05, loss after: 3.71030691895e-05.\n",
      "Epoch:9, weight train batch: 187, step:4, loss before: 3.35604163411e-05, loss after: 3.35604163411e-05.\n",
      "Epoch:9, weight train batch: 187, step:5, loss before: 3.78592994821e-05, loss after: 3.78592994821e-05.\n",
      "Epoch:9, weight train batch: 187, step:6, loss before: 3.50467526005e-05, loss after: 3.49871552316e-05.\n",
      "Epoch:9, weight train batch: 187, step:7, loss before: 3.23609165207e-05, loss after: 3.23609165207e-05.\n",
      "Epoch:9, weight train batch: 187, step:8, loss before: 6.77227435517e-05, loss after: 6.76817871863e-05.\n",
      "Epoch:9, weight train batch: 187, step:9, loss before: 5.2528885135e-05, loss after: 5.249163587e-05.\n",
      "Epoch:9, weight train batch: 187, step:10, loss before: 4.4631131459e-05, loss after: 4.45864279754e-05.\n",
      "Epoch:9, weight train batch: 187, step:11, loss before: 3.56316159014e-05, loss after: 3.56055388693e-05.\n",
      "Epoch:9, weight train batch: 187, step:12, loss before: 3.13812124659e-05, loss after: 3.13812124659e-05.\n",
      "Epoch:9, weight train batch: 187, step:13, loss before: 0.000177729089046, loss after: 0.000177439607796.\n",
      "Epoch:9, weight train batch: 187, step:14, loss before: 4.06489307352e-05, loss after: 4.06452054449e-05.\n",
      "Epoch:9, weight train batch: 187, step:15, loss before: 3.55384909199e-05, loss after: 3.54826115654e-05.\n",
      "Epoch:9, weight train batch: 187, step:16, loss before: 3.47599307133e-05, loss after: 3.47301283909e-05.\n",
      "Epoch:9, weight train batch: 187, step:17, loss before: 3.64847292076e-05, loss after: 3.64735533367e-05.\n",
      "Epoch:9, weight train batch: 187, step:18, loss before: 3.73042348656e-05, loss after: 3.73042348656e-05.\n",
      "Epoch:9, weight train batch: 187, step:19, loss before: 3.34039687004e-05, loss after: 3.33443676936e-05.\n",
      "Epoch:9, weight train batch: 187, step:20, loss before: 3.77475153073e-05, loss after: 3.77475153073e-05.\n",
      "Epoch:9, weight train batch: 187, step:21, loss before: 3.19288192259e-05, loss after: 3.19288192259e-05.\n",
      "Epoch:9, weight train batch: 187, step:22, loss before: 3.39702128258e-05, loss after: 3.39031612384e-05.\n",
      "Epoch:9, weight train batch: 187, step:23, loss before: 3.85707608075e-05, loss after: 3.85074308724e-05.\n",
      "Epoch:9, weight train batch: 187, step:24, loss before: 3.96809045924e-05, loss after: 3.96809045924e-05.\n",
      "Epoch:9, weight train batch: 187, step:25, loss before: 3.99779019062e-05, loss after: 3.99667260353e-05.\n",
      "Epoch:9, weight train batch: 187, step:26, loss before: 3.45476000803e-05, loss after: 3.45103471773e-05.\n",
      "Epoch:9, weight train batch: 187, step:27, loss before: 4.52601852885e-05, loss after: 4.52266613138e-05.\n",
      "Epoch:9, weight train batch: 187, step:28, loss before: 3.94536764361e-05, loss after: 3.94536764361e-05.\n",
      "Epoch:9, weight train batch: 187, step:29, loss before: 3.66933054465e-05, loss after: 3.66560561815e-05.\n",
      "Epoch:9, weight train batch: 187, step:30, loss before: 3.15004072036e-05, loss after: 3.14743301715e-05.\n",
      "Epoch:9, weight train batch: 187, step:31, loss before: 4.78678230138e-05, loss after: 4.78193978779e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 183, loss before: 3.14724784403e-05, loss after: 3.80911878892e-05.\n",
      "Epoch:9, weight train batch: 188, step:0, loss before: 3.28564055962e-05, loss after: 3.28564055962e-05.\n",
      "Epoch:9, weight train batch: 188, step:1, loss before: 3.04052155116e-05, loss after: 3.03381639242e-05.\n",
      "Epoch:9, weight train batch: 188, step:2, loss before: 3.48977773683e-05, loss after: 3.48977773683e-05.\n",
      "Epoch:9, weight train batch: 188, step:3, loss before: 3.22454761772e-05, loss after: 3.22194027831e-05.\n",
      "Epoch:9, weight train batch: 188, step:4, loss before: 3.25173932652e-05, loss after: 3.24838692904e-05.\n",
      "Epoch:9, weight train batch: 188, step:5, loss before: 3.29942049575e-05, loss after: 3.29644026351e-05.\n",
      "Epoch:9, weight train batch: 188, step:6, loss before: 6.72501046211e-05, loss after: 6.72352180118e-05.\n",
      "Epoch:9, weight train batch: 188, step:7, loss before: 3.51361741195e-05, loss after: 3.50951959263e-05.\n",
      "Epoch:9, weight train batch: 188, step:8, loss before: 3.75910458388e-05, loss after: 3.75649688067e-05.\n",
      "Epoch:9, weight train batch: 188, step:9, loss before: 0.000132175817271, loss after: 0.000131971581141.\n",
      "Epoch:9, weight train batch: 188, step:10, loss before: 3.0535600672e-05, loss after: 3.0535600672e-05.\n",
      "Epoch:9, weight train batch: 188, step:11, loss before: 3.3385338611e-05, loss after: 3.33145580953e-05.\n",
      "Epoch:9, weight train batch: 188, step:12, loss before: 3.49499096046e-05, loss after: 3.48940375261e-05.\n",
      "Epoch:9, weight train batch: 188, step:13, loss before: 3.42644998454e-05, loss after: 3.42644998454e-05.\n",
      "Epoch:9, weight train batch: 188, step:14, loss before: 3.23758213199e-05, loss after: 3.23758213199e-05.\n",
      "Epoch:9, weight train batch: 188, step:15, loss before: 3.79375305783e-05, loss after: 3.79040066036e-05.\n",
      "Epoch:9, weight train batch: 188, step:16, loss before: 2.98650702462e-05, loss after: 2.98352697428e-05.\n",
      "Epoch:9, weight train batch: 188, step:17, loss before: 3.39441139658e-05, loss after: 3.39068610629e-05.\n",
      "Epoch:9, weight train batch: 188, step:18, loss before: 3.72893518943e-05, loss after: 3.72893518943e-05.\n",
      "Epoch:9, weight train batch: 188, step:19, loss before: 3.12769152515e-05, loss after: 3.1258292438e-05.\n",
      "Epoch:9, weight train batch: 188, step:20, loss before: 3.86676510971e-05, loss after: 3.86676510971e-05.\n",
      "Epoch:9, weight train batch: 188, step:21, loss before: 3.19958744512e-05, loss after: 3.19325481541e-05.\n",
      "Epoch:9, weight train batch: 188, step:22, loss before: 3.30240291078e-05, loss after: 3.29979520757e-05.\n",
      "Epoch:9, weight train batch: 188, step:23, loss before: 3.56800701411e-05, loss after: 3.56800701411e-05.\n",
      "Epoch:9, weight train batch: 188, step:24, loss before: 0.000161223200848, loss after: 0.000161171279615.\n",
      "Epoch:9, weight train batch: 188, step:25, loss before: 3.4298045648e-05, loss after: 3.42384446412e-05.\n",
      "Epoch:9, weight train batch: 188, step:26, loss before: 0.000326300127199, loss after: 0.000325598695781.\n",
      "Epoch:9, weight train batch: 188, step:27, loss before: 3.48754329025e-05, loss after: 3.48754329025e-05.\n",
      "Epoch:9, weight train batch: 188, step:28, loss before: 3.28526584781e-05, loss after: 3.28005044139e-05.\n",
      "Epoch:9, weight train batch: 188, step:29, loss before: 3.85745261156e-05, loss after: 3.85745261156e-05.\n",
      "Epoch:9, weight train batch: 188, step:30, loss before: 3.66188178305e-05, loss after: 3.65517662431e-05.\n",
      "Epoch:9, weight train batch: 188, step:31, loss before: 3.25434593833e-05, loss after: 3.25136570609e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 184, loss before: 0.00755403377116, loss after: 0.000104778344394.\n",
      "Epoch:9, weight train batch: 189, step:0, loss before: 3.34263313562e-05, loss after: 3.34263313562e-05.\n",
      "Epoch:9, weight train batch: 189, step:1, loss before: 3.51250273525e-05, loss after: 3.50765985786e-05.\n",
      "Epoch:9, weight train batch: 189, step:2, loss before: 3.6823694245e-05, loss after: 3.67864486179e-05.\n",
      "Epoch:9, weight train batch: 189, step:3, loss before: 4.34237736044e-05, loss after: 4.33902459918e-05.\n",
      "Epoch:9, weight train batch: 189, step:4, loss before: 3.01258314721e-05, loss after: 3.00923038594e-05.\n",
      "Epoch:9, weight train batch: 189, step:5, loss before: 3.04201021208e-05, loss after: 3.03418746626e-05.\n",
      "Epoch:9, weight train batch: 189, step:6, loss before: 3.5069147998e-05, loss after: 3.50654227077e-05.\n",
      "Epoch:9, weight train batch: 189, step:7, loss before: 3.35827862727e-05, loss after: 3.35343611368e-05.\n",
      "Epoch:9, weight train batch: 189, step:8, loss before: 3.62462924386e-05, loss after: 3.62164901162e-05.\n",
      "Epoch:9, weight train batch: 189, step:9, loss before: 3.31879346049e-05, loss after: 3.31879346049e-05.\n",
      "Epoch:9, weight train batch: 189, step:10, loss before: 3.19251048495e-05, loss after: 3.19251048495e-05.\n",
      "Epoch:9, weight train batch: 189, step:11, loss before: 3.4875338315e-05, loss after: 3.48492612829e-05.\n",
      "Epoch:9, weight train batch: 189, step:12, loss before: 3.52628412656e-05, loss after: 3.51957896783e-05.\n",
      "Epoch:9, weight train batch: 189, step:13, loss before: 3.37914170814e-05, loss after: 3.37914170814e-05.\n",
      "Epoch:9, weight train batch: 189, step:14, loss before: 3.30426337314e-05, loss after: 3.30426337314e-05.\n",
      "Epoch:9, weight train batch: 189, step:15, loss before: 3.48605281033e-05, loss after: 3.48270041286e-05.\n",
      "Epoch:9, weight train batch: 189, step:16, loss before: 0.000346406537574, loss after: 0.00034553851583.\n",
      "Epoch:9, weight train batch: 189, step:17, loss before: 3.56800737791e-05, loss after: 3.56502714567e-05.\n",
      "Epoch:9, weight train batch: 189, step:18, loss before: 3.15711949952e-05, loss after: 3.15525685437e-05.\n",
      "Epoch:9, weight train batch: 189, step:19, loss before: 2.95707977784e-05, loss after: 2.95707977784e-05.\n",
      "Epoch:9, weight train batch: 189, step:20, loss before: 3.25658184011e-05, loss after: 3.24913125951e-05.\n",
      "Epoch:9, weight train batch: 189, step:21, loss before: 3.57545723091e-05, loss after: 3.57545723091e-05.\n",
      "Epoch:9, weight train batch: 189, step:22, loss before: 2.93621578749e-05, loss after: 2.93174543913e-05.\n",
      "Epoch:9, weight train batch: 189, step:23, loss before: 3.44432992279e-05, loss after: 3.44432992279e-05.\n",
      "Epoch:9, weight train batch: 189, step:24, loss before: 3.41192280757e-05, loss after: 3.40968763339e-05.\n",
      "Epoch:9, weight train batch: 189, step:25, loss before: 2.98203649436e-05, loss after: 2.97942879115e-05.\n",
      "Epoch:9, weight train batch: 189, step:26, loss before: 2.96303860523e-05, loss after: 2.96303860523e-05.\n",
      "Epoch:9, weight train batch: 189, step:27, loss before: 3.47003660863e-05, loss after: 3.46668457496e-05.\n",
      "Epoch:9, weight train batch: 189, step:28, loss before: 2.97197875625e-05, loss after: 2.96862599498e-05.\n",
      "Epoch:9, weight train batch: 189, step:29, loss before: 2.88406408799e-05, loss after: 2.88145674858e-05.\n",
      "Epoch:9, weight train batch: 189, step:30, loss before: 3.45178050338e-05, loss after: 3.45178050338e-05.\n",
      "Epoch:9, weight train batch: 189, step:31, loss before: 3.28414826072e-05, loss after: 3.28414826072e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 185, loss before: 3.0691124266e-05, loss after: 3.0691124266e-05.\n",
      "Epoch:9, weight train batch: 190, step:0, loss before: 3.38584723067e-05, loss after: 3.37951423717e-05.\n",
      "Epoch:9, weight train batch: 190, step:1, loss before: 3.31804876623e-05, loss after: 3.31320625264e-05.\n",
      "Epoch:9, weight train batch: 190, step:2, loss before: 3.43501815223e-05, loss after: 3.43501815223e-05.\n",
      "Epoch:9, weight train batch: 190, step:3, loss before: 4.3840129365e-05, loss after: 4.38364040747e-05.\n",
      "Epoch:9, weight train batch: 190, step:4, loss before: 3.54267685907e-05, loss after: 3.54267685907e-05.\n",
      "Epoch:9, weight train batch: 190, step:5, loss before: 3.16680598189e-05, loss after: 3.15786601277e-05.\n",
      "Epoch:9, weight train batch: 190, step:6, loss before: 3.33183343173e-05, loss after: 3.33183343173e-05.\n",
      "Epoch:9, weight train batch: 190, step:7, loss before: 3.08485250571e-05, loss after: 3.08485250571e-05.\n",
      "Epoch:9, weight train batch: 190, step:8, loss before: 3.28601090587e-05, loss after: 3.2826581446e-05.\n",
      "Epoch:9, weight train batch: 190, step:9, loss before: 3.09267634293e-05, loss after: 3.09267634293e-05.\n",
      "Epoch:9, weight train batch: 190, step:10, loss before: 3.11986768793e-05, loss after: 3.11800504278e-05.\n",
      "Epoch:9, weight train batch: 190, step:11, loss before: 3.29606846208e-05, loss after: 3.2938332879e-05.\n",
      "Epoch:9, weight train batch: 190, step:12, loss before: 3.29458052875e-05, loss after: 3.29234535457e-05.\n",
      "Epoch:9, weight train batch: 190, step:13, loss before: 3.27111338265e-05, loss after: 3.27111338265e-05.\n",
      "Epoch:9, weight train batch: 190, step:14, loss before: 3.48232169927e-05, loss after: 3.48232169927e-05.\n",
      "Epoch:9, weight train batch: 190, step:15, loss before: 3.20256804116e-05, loss after: 3.19921564369e-05.\n",
      "Epoch:9, weight train batch: 190, step:16, loss before: 3.26552435581e-05, loss after: 3.2629170164e-05.\n",
      "Epoch:9, weight train batch: 190, step:17, loss before: 2.93658995361e-05, loss after: 2.9339822504e-05.\n",
      "Epoch:9, weight train batch: 190, step:18, loss before: 6.1359256506e-05, loss after: 6.13443626207e-05.\n",
      "Epoch:9, weight train batch: 190, step:19, loss before: 2.91721826216e-05, loss after: 2.91461074085e-05.\n",
      "Epoch:9, weight train batch: 190, step:20, loss before: 2.94180717901e-05, loss after: 2.93882694677e-05.\n",
      "Epoch:9, weight train batch: 190, step:21, loss before: 3.30836337525e-05, loss after: 3.30836337525e-05.\n",
      "Epoch:9, weight train batch: 190, step:22, loss before: 3.49350448232e-05, loss after: 3.49089677911e-05.\n",
      "Epoch:9, weight train batch: 190, step:23, loss before: 3.12731863232e-05, loss after: 3.12061347358e-05.\n",
      "Epoch:9, weight train batch: 190, step:24, loss before: 2.84160032606e-05, loss after: 2.84160032606e-05.\n",
      "Epoch:9, weight train batch: 190, step:25, loss before: 3.51101334672e-05, loss after: 3.50691589119e-05.\n",
      "Epoch:9, weight train batch: 190, step:26, loss before: 3.59370969818e-05, loss after: 3.59370969818e-05.\n",
      "Epoch:9, weight train batch: 190, step:27, loss before: 5.88857692492e-05, loss after: 5.88373513892e-05.\n",
      "Epoch:9, weight train batch: 190, step:28, loss before: 3.47636669176e-05, loss after: 3.47636669176e-05.\n",
      "Epoch:9, weight train batch: 190, step:29, loss before: 3.38994432241e-05, loss after: 3.38994432241e-05.\n",
      "Epoch:9, weight train batch: 190, step:30, loss before: 3.37280762324e-05, loss after: 3.36722005159e-05.\n",
      "Epoch:9, weight train batch: 190, step:31, loss before: 3.72968061129e-05, loss after: 3.72632785002e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 186, loss before: 3.71858586732e-05, loss after: 3.15376819344e-05.\n",
      "Epoch:9, weight train batch: 191, step:0, loss before: 8.75194236869e-05, loss after: 8.7485925178e-05.\n",
      "Epoch:9, weight train batch: 191, step:1, loss before: 3.33145871991e-05, loss after: 3.33145871991e-05.\n",
      "Epoch:9, weight train batch: 191, step:2, loss before: 3.28526912199e-05, loss after: 3.27968155034e-05.\n",
      "Epoch:9, weight train batch: 191, step:3, loss before: 2.8307964385e-05, loss after: 2.8307964385e-05.\n",
      "Epoch:9, weight train batch: 191, step:4, loss before: 3.1906485674e-05, loss after: 3.18729580613e-05.\n",
      "Epoch:9, weight train batch: 191, step:5, loss before: 2.59424741671e-05, loss after: 2.59424741671e-05.\n",
      "Epoch:9, weight train batch: 191, step:6, loss before: 3.40410042554e-05, loss after: 3.39702273777e-05.\n",
      "Epoch:9, weight train batch: 191, step:7, loss before: 3.23609383486e-05, loss after: 3.23609383486e-05.\n",
      "Epoch:9, weight train batch: 191, step:8, loss before: 3.53857831215e-05, loss after: 3.53857831215e-05.\n",
      "Epoch:9, weight train batch: 191, step:9, loss before: 3.38770914823e-05, loss after: 3.38770914823e-05.\n",
      "Epoch:9, weight train batch: 191, step:10, loss before: 3.22119449265e-05, loss after: 3.21858678944e-05.\n",
      "Epoch:9, weight train batch: 191, step:11, loss before: 3.31320625264e-05, loss after: 3.30687398673e-05.\n",
      "Epoch:9, weight train batch: 191, step:12, loss before: 3.54528528987e-05, loss after: 3.54379517375e-05.\n",
      "Epoch:9, weight train batch: 191, step:13, loss before: 3.28750102199e-05, loss after: 3.28303103743e-05.\n",
      "Epoch:9, weight train batch: 191, step:14, loss before: 0.000293824006803, loss after: 0.000293225515634.\n",
      "Epoch:9, weight train batch: 191, step:15, loss before: 3.38845493388e-05, loss after: 3.38249446941e-05.\n",
      "Epoch:9, weight train batch: 191, step:16, loss before: 3.19101964124e-05, loss after: 3.18692182191e-05.\n",
      "Epoch:9, weight train batch: 191, step:17, loss before: 2.87735965685e-05, loss after: 2.87400725938e-05.\n",
      "Epoch:9, weight train batch: 191, step:18, loss before: 3.12284973916e-05, loss after: 3.12284973916e-05.\n",
      "Epoch:9, weight train batch: 191, step:19, loss before: 3.33890857291e-05, loss after: 3.33555617544e-05.\n",
      "Epoch:9, weight train batch: 191, step:20, loss before: 2.61063942162e-05, loss after: 2.60579654423e-05.\n",
      "Epoch:9, weight train batch: 191, step:21, loss before: 3.33816460625e-05, loss after: 3.33518473781e-05.\n",
      "Epoch:9, weight train batch: 191, step:22, loss before: 3.4845645132e-05, loss after: 3.4845645132e-05.\n",
      "Epoch:9, weight train batch: 191, step:23, loss before: 0.000291383155854, loss after: 0.000290359021164.\n",
      "Epoch:9, weight train batch: 191, step:24, loss before: 0.000151756990817, loss after: 0.000151693908265.\n",
      "Epoch:9, weight train batch: 191, step:25, loss before: 2.97719470836e-05, loss after: 2.97346941807e-05.\n",
      "Epoch:9, weight train batch: 191, step:26, loss before: 2.93100383715e-05, loss after: 2.92467084364e-05.\n",
      "Epoch:9, weight train batch: 191, step:27, loss before: 3.12918236887e-05, loss after: 3.12918236887e-05.\n",
      "Epoch:9, weight train batch: 191, step:28, loss before: 3.34933974955e-05, loss after: 3.34226206178e-05.\n",
      "Epoch:9, weight train batch: 191, step:29, loss before: 3.3575361158e-05, loss after: 3.3575361158e-05.\n",
      "Epoch:9, weight train batch: 191, step:30, loss before: 2.72760989901e-05, loss after: 2.72760989901e-05.\n",
      "Epoch:9, weight train batch: 191, step:31, loss before: 3.28414935211e-05, loss after: 3.27818925143e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 187, loss before: 2.99284092762e-05, loss after: 2.99284092762e-05.\n",
      "Epoch:9, weight train batch: 192, step:0, loss before: 0.000275589176454, loss after: 0.000274484104011.\n",
      "Epoch:9, weight train batch: 192, step:1, loss before: 3.33593125106e-05, loss after: 3.32885319949e-05.\n",
      "Epoch:9, weight train batch: 192, step:2, loss before: 2.57003412116e-05, loss after: 2.56519142567e-05.\n",
      "Epoch:9, weight train batch: 192, step:3, loss before: 3.48121247953e-05, loss after: 3.48121247953e-05.\n",
      "Epoch:9, weight train batch: 192, step:4, loss before: 2.51899982686e-05, loss after: 2.5145294785e-05.\n",
      "Epoch:9, weight train batch: 192, step:5, loss before: 2.69184711215e-05, loss after: 2.69184711215e-05.\n",
      "Epoch:9, weight train batch: 192, step:6, loss before: 3.01742766169e-05, loss after: 3.0088596759e-05.\n",
      "Epoch:9, weight train batch: 192, step:7, loss before: 2.73804016615e-05, loss after: 2.73804016615e-05.\n",
      "Epoch:9, weight train batch: 192, step:8, loss before: 3.09863680741e-05, loss after: 3.09863680741e-05.\n",
      "Epoch:9, weight train batch: 192, step:9, loss before: 3.64735642506e-05, loss after: 3.64474872185e-05.\n",
      "Epoch:9, weight train batch: 192, step:10, loss before: 2.71084827546e-05, loss after: 2.71084827546e-05.\n",
      "Epoch:9, weight train batch: 192, step:11, loss before: 3.07554000756e-05, loss after: 3.06957990688e-05.\n",
      "Epoch:9, weight train batch: 192, step:12, loss before: 3.16941550409e-05, loss after: 3.16606310662e-05.\n",
      "Epoch:9, weight train batch: 192, step:13, loss before: 3.08075541398e-05, loss after: 3.08075541398e-05.\n",
      "Epoch:9, weight train batch: 192, step:14, loss before: 0.00369637529366, loss after: 0.00368628860451.\n",
      "Epoch:9, weight train batch: 192, step:15, loss before: 3.15972865792e-05, loss after: 3.15227807732e-05.\n",
      "Epoch:9, weight train batch: 192, step:16, loss before: 2.9712327887e-05, loss after: 2.9675074984e-05.\n",
      "Epoch:9, weight train batch: 192, step:17, loss before: 4.06224062317e-05, loss after: 4.05702521675e-05.\n",
      "Epoch:9, weight train batch: 192, step:18, loss before: 2.83154113276e-05, loss after: 2.82632590825e-05.\n",
      "Epoch:9, weight train batch: 192, step:19, loss before: 3.02338776237e-05, loss after: 3.01929012494e-05.\n",
      "Epoch:9, weight train batch: 192, step:20, loss before: 3.01854615827e-05, loss after: 3.01593863696e-05.\n",
      "Epoch:9, weight train batch: 192, step:21, loss before: 3.37988749379e-05, loss after: 3.3724369132e-05.\n",
      "Epoch:9, weight train batch: 192, step:22, loss before: 3.00327246805e-05, loss after: 3.00103729387e-05.\n",
      "Epoch:9, weight train batch: 192, step:23, loss before: 3.18617894663e-05, loss after: 3.18357124343e-05.\n",
      "Epoch:9, weight train batch: 192, step:24, loss before: 3.1109299016e-05, loss after: 3.10459727189e-05.\n",
      "Epoch:9, weight train batch: 192, step:25, loss before: 3.48266257788e-05, loss after: 3.47968234564e-05.\n",
      "Epoch:9, weight train batch: 192, step:26, loss before: 2.66577098955e-05, loss after: 2.66577098955e-05.\n",
      "Epoch:9, weight train batch: 192, step:27, loss before: 2.93994380627e-05, loss after: 2.93435623462e-05.\n",
      "Epoch:9, weight train batch: 192, step:28, loss before: 2.62851826847e-05, loss after: 2.62702815235e-05.\n",
      "Epoch:9, weight train batch: 192, step:29, loss before: 3.11353724101e-05, loss after: 3.11353724101e-05.\n",
      "Epoch:9, weight train batch: 192, step:30, loss before: 2.83638364635e-05, loss after: 2.83116823994e-05.\n",
      "Epoch:9, weight train batch: 192, step:31, loss before: 5.18034212291e-05, loss after: 5.17922526342e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 188, loss before: 0.000941380450968, loss after: 2.88201736112e-05.\n",
      "Epoch:9, weight train batch: 193, step:0, loss before: 2.47131683864e-05, loss after: 2.46982672252e-05.\n",
      "Epoch:9, weight train batch: 193, step:1, loss before: 2.98911654681e-05, loss after: 2.98911654681e-05.\n",
      "Epoch:9, weight train batch: 193, step:2, loss before: 2.60356100625e-05, loss after: 2.59424778051e-05.\n",
      "Epoch:9, weight train batch: 193, step:3, loss before: 2.95260942949e-05, loss after: 2.95260942949e-05.\n",
      "Epoch:9, weight train batch: 193, step:4, loss before: 3.23870190186e-05, loss after: 3.23870190186e-05.\n",
      "Epoch:9, weight train batch: 193, step:5, loss before: 3.28266105498e-05, loss after: 3.2767005905e-05.\n",
      "Epoch:9, weight train batch: 193, step:6, loss before: 2.60318629444e-05, loss after: 2.60318629444e-05.\n",
      "Epoch:9, weight train batch: 193, step:7, loss before: 3.24391730828e-05, loss after: 3.23870226566e-05.\n",
      "Epoch:9, weight train batch: 193, step:8, loss before: 2.90678981401e-05, loss after: 2.90567222692e-05.\n",
      "Epoch:9, weight train batch: 193, step:9, loss before: 3.13365453621e-05, loss after: 3.13365453621e-05.\n",
      "Epoch:9, weight train batch: 193, step:10, loss before: 3.30017064698e-05, loss after: 3.29681788571e-05.\n",
      "Epoch:9, weight train batch: 193, step:11, loss before: 3.03791675833e-05, loss after: 3.03791675833e-05.\n",
      "Epoch:9, weight train batch: 193, step:12, loss before: 5.67266361031e-05, loss after: 5.66819508094e-05.\n",
      "Epoch:9, weight train batch: 193, step:13, loss before: 3.14855496981e-05, loss after: 3.14855496981e-05.\n",
      "Epoch:9, weight train batch: 193, step:14, loss before: 2.98688191833e-05, loss after: 2.98203904094e-05.\n",
      "Epoch:9, weight train batch: 193, step:15, loss before: 2.96825674013e-05, loss after: 2.96825674013e-05.\n",
      "Epoch:9, weight train batch: 193, step:16, loss before: 3.97797884943e-05, loss after: 3.97574367526e-05.\n",
      "Epoch:9, weight train batch: 193, step:17, loss before: 3.19065002259e-05, loss after: 3.19065002259e-05.\n",
      "Epoch:9, weight train batch: 193, step:18, loss before: 3.08522903651e-05, loss after: 3.08299386234e-05.\n",
      "Epoch:9, weight train batch: 193, step:19, loss before: 2.75294023595e-05, loss after: 2.75294023595e-05.\n",
      "Epoch:9, weight train batch: 193, step:20, loss before: 3.04387722281e-05, loss after: 3.04387722281e-05.\n",
      "Epoch:9, weight train batch: 193, step:21, loss before: 3.08895214403e-05, loss after: 3.08224698529e-05.\n",
      "Epoch:9, weight train batch: 193, step:22, loss before: 3.57397075277e-05, loss after: 3.5706179915e-05.\n",
      "Epoch:9, weight train batch: 193, step:23, loss before: 3.18729580613e-05, loss after: 3.18729580613e-05.\n",
      "Epoch:9, weight train batch: 193, step:24, loss before: 2.83303197648e-05, loss after: 2.83303197648e-05.\n",
      "Epoch:9, weight train batch: 193, step:25, loss before: 3.01072323055e-05, loss after: 3.00774318021e-05.\n",
      "Epoch:9, weight train batch: 193, step:26, loss before: 3.04350396618e-05, loss after: 3.04015120491e-05.\n",
      "Epoch:9, weight train batch: 193, step:27, loss before: 3.7222285755e-05, loss after: 3.7222285755e-05.\n",
      "Epoch:9, weight train batch: 193, step:28, loss before: 2.83452354779e-05, loss after: 2.83452354779e-05.\n",
      "Epoch:9, weight train batch: 193, step:29, loss before: 2.8557566111e-05, loss after: 2.85352180072e-05.\n",
      "Epoch:9, weight train batch: 193, step:30, loss before: 2.90008665615e-05, loss after: 2.90008665615e-05.\n",
      "Epoch:9, weight train batch: 193, step:31, loss before: 2.7425112421e-05, loss after: 2.73804107565e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 189, loss before: 8.57899867697e-05, loss after: 3.1017792935e-05.\n",
      "Epoch:9, weight train batch: 194, step:0, loss before: 2.95782629109e-05, loss after: 2.95484624075e-05.\n",
      "Epoch:9, weight train batch: 194, step:1, loss before: 2.88294959319e-05, loss after: 2.88034188998e-05.\n",
      "Epoch:9, weight train batch: 194, step:2, loss before: 3.22119667544e-05, loss after: 3.22119667544e-05.\n",
      "Epoch:9, weight train batch: 194, step:3, loss before: 3.36945813615e-05, loss after: 3.36945813615e-05.\n",
      "Epoch:9, weight train batch: 194, step:4, loss before: 3.71769456251e-05, loss after: 3.71732203348e-05.\n",
      "Epoch:9, weight train batch: 194, step:5, loss before: 3.45879307133e-05, loss after: 3.45283260685e-05.\n",
      "Epoch:9, weight train batch: 194, step:6, loss before: 2.89971358143e-05, loss after: 2.89971358143e-05.\n",
      "Epoch:9, weight train batch: 194, step:7, loss before: 3.29607210006e-05, loss after: 3.29607210006e-05.\n",
      "Epoch:9, weight train batch: 194, step:8, loss before: 2.72090510407e-05, loss after: 2.71457211056e-05.\n",
      "Epoch:9, weight train batch: 194, step:9, loss before: 2.79242667602e-05, loss after: 2.78981897281e-05.\n",
      "Epoch:9, weight train batch: 194, step:10, loss before: 3.13514465233e-05, loss after: 3.13216442009e-05.\n",
      "Epoch:9, weight train batch: 194, step:11, loss before: 3.16792502417e-05, loss after: 3.16792502417e-05.\n",
      "Epoch:9, weight train batch: 194, step:12, loss before: 3.1783569284e-05, loss after: 3.1783569284e-05.\n",
      "Epoch:9, weight train batch: 194, step:13, loss before: 3.19176688208e-05, loss after: 3.18841448461e-05.\n",
      "Epoch:9, weight train batch: 194, step:14, loss before: 2.98613667837e-05, loss after: 2.98613667837e-05.\n",
      "Epoch:9, weight train batch: 194, step:15, loss before: 2.55662471318e-05, loss after: 2.55662471318e-05.\n",
      "Epoch:9, weight train batch: 194, step:16, loss before: 2.79429059447e-05, loss after: 2.79131036223e-05.\n",
      "Epoch:9, weight train batch: 194, step:17, loss before: 0.00354703562334, loss after: 0.00354371103458.\n",
      "Epoch:9, weight train batch: 194, step:18, loss before: 3.18804231938e-05, loss after: 3.18468955811e-05.\n",
      "Epoch:9, weight train batch: 194, step:19, loss before: 2.92541790259e-05, loss after: 2.92206550512e-05.\n",
      "Epoch:9, weight train batch: 194, step:20, loss before: 2.46647359745e-05, loss after: 2.45939554588e-05.\n",
      "Epoch:9, weight train batch: 194, step:21, loss before: 3.94527451135e-05, loss after: 3.94415692426e-05.\n",
      "Epoch:9, weight train batch: 194, step:22, loss before: 3.13328200718e-05, loss after: 3.13067430397e-05.\n",
      "Epoch:9, weight train batch: 194, step:23, loss before: 2.79838859569e-05, loss after: 2.79838859569e-05.\n",
      "Epoch:9, weight train batch: 194, step:24, loss before: 3.17537778756e-05, loss after: 3.17165249726e-05.\n",
      "Epoch:9, weight train batch: 194, step:25, loss before: 2.82856090053e-05, loss after: 2.82856090053e-05.\n",
      "Epoch:9, weight train batch: 194, step:26, loss before: 3.27558300341e-05, loss after: 3.26813278662e-05.\n",
      "Epoch:9, weight train batch: 194, step:27, loss before: 3.13738055411e-05, loss after: 3.13738055411e-05.\n",
      "Epoch:9, weight train batch: 194, step:28, loss before: 3.02525186271e-05, loss after: 3.01966392726e-05.\n",
      "Epoch:9, weight train batch: 194, step:29, loss before: 2.60691376752e-05, loss after: 2.60318847722e-05.\n",
      "Epoch:9, weight train batch: 194, step:30, loss before: 2.63075580733e-05, loss after: 2.63075580733e-05.\n",
      "Epoch:9, weight train batch: 194, step:31, loss before: 3.27819143422e-05, loss after: 3.27446614392e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 190, loss before: 2.91163414659e-05, loss after: 2.91163414659e-05.\n",
      "Epoch:9, weight train batch: 195, step:0, loss before: 5.14722196385e-05, loss after: 5.14573257533e-05.\n",
      "Epoch:9, weight train batch: 195, step:1, loss before: 3.01333093375e-05, loss after: 3.00997835438e-05.\n",
      "Epoch:9, weight train batch: 195, step:2, loss before: 3.15674988087e-05, loss after: 3.1533971196e-05.\n",
      "Epoch:9, weight train batch: 195, step:3, loss before: 2.52980098594e-05, loss after: 2.52980098594e-05.\n",
      "Epoch:9, weight train batch: 195, step:4, loss before: 3.89677952626e-05, loss after: 3.8923099055e-05.\n",
      "Epoch:9, weight train batch: 195, step:5, loss before: 2.79913438135e-05, loss after: 2.79913438135e-05.\n",
      "Epoch:9, weight train batch: 195, step:6, loss before: 2.7935464459e-05, loss after: 2.78795851045e-05.\n",
      "Epoch:9, weight train batch: 195, step:7, loss before: 2.84756024485e-05, loss after: 2.84756024485e-05.\n",
      "Epoch:9, weight train batch: 195, step:8, loss before: 3.30575785483e-05, loss after: 3.30575785483e-05.\n",
      "Epoch:9, weight train batch: 195, step:9, loss before: 0.00346296024509, loss after: 0.0034537028987.\n",
      "Epoch:9, weight train batch: 195, step:10, loss before: 2.89226300083e-05, loss after: 2.88704795821e-05.\n",
      "Epoch:9, weight train batch: 195, step:11, loss before: 2.91088817903e-05, loss after: 2.90716288873e-05.\n",
      "Epoch:9, weight train batch: 195, step:12, loss before: 2.79056548607e-05, loss after: 2.78237021121e-05.\n",
      "Epoch:9, weight train batch: 195, step:13, loss before: 2.56072071352e-05, loss after: 2.55960312643e-05.\n",
      "Epoch:9, weight train batch: 195, step:14, loss before: 2.86730391963e-05, loss after: 2.86581380351e-05.\n",
      "Epoch:9, weight train batch: 195, step:15, loss before: 3.39293037541e-05, loss after: 3.37840247084e-05.\n",
      "Epoch:9, weight train batch: 195, step:16, loss before: 3.09454044327e-05, loss after: 3.09156021103e-05.\n",
      "Epoch:9, weight train batch: 195, step:17, loss before: 2.81030861515e-05, loss after: 2.80770109384e-05.\n",
      "Epoch:9, weight train batch: 195, step:18, loss before: 2.7562964533e-05, loss after: 2.7562964533e-05.\n",
      "Epoch:9, weight train batch: 195, step:19, loss before: 2.73953228316e-05, loss after: 2.73394434771e-05.\n",
      "Epoch:9, weight train batch: 195, step:20, loss before: 4.12188528571e-05, loss after: 4.11629771406e-05.\n",
      "Epoch:9, weight train batch: 195, step:21, loss before: 3.13328273478e-05, loss after: 3.12992997351e-05.\n",
      "Epoch:9, weight train batch: 195, step:22, loss before: 2.63224337687e-05, loss after: 2.63224337687e-05.\n",
      "Epoch:9, weight train batch: 195, step:23, loss before: 2.91126525553e-05, loss after: 2.90679490718e-05.\n",
      "Epoch:9, weight train batch: 195, step:24, loss before: 3.11018811772e-05, loss after: 3.10534524033e-05.\n",
      "Epoch:9, weight train batch: 195, step:25, loss before: 3.74156879843e-05, loss after: 3.73709917767e-05.\n",
      "Epoch:9, weight train batch: 195, step:26, loss before: 4.78479851154e-05, loss after: 4.77846624563e-05.\n",
      "Epoch:9, weight train batch: 195, step:27, loss before: 3.05915127683e-05, loss after: 3.05915127683e-05.\n",
      "Epoch:9, weight train batch: 195, step:28, loss before: 2.66465394816e-05, loss after: 2.66465394816e-05.\n",
      "Epoch:9, weight train batch: 195, step:29, loss before: 4.779878509e-05, loss after: 4.77466383018e-05.\n",
      "Epoch:9, weight train batch: 195, step:30, loss before: 2.68700641755e-05, loss after: 2.6851439543e-05.\n",
      "Epoch:9, weight train batch: 195, step:31, loss before: 2.65087219304e-05, loss after: 2.64900954789e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 191, loss before: 2.7381342079e-05, loss after: 3.0406510632e-05.\n",
      "Epoch:9, weight train batch: 196, step:0, loss before: 2.28729459195e-05, loss after: 2.28729459195e-05.\n",
      "Epoch:9, weight train batch: 196, step:1, loss before: 2.87661805487e-05, loss after: 2.87661805487e-05.\n",
      "Epoch:9, weight train batch: 196, step:2, loss before: 2.66539827862e-05, loss after: 2.66316346824e-05.\n",
      "Epoch:9, weight train batch: 196, step:3, loss before: 2.84271918645e-05, loss after: 2.837131251e-05.\n",
      "Epoch:9, weight train batch: 196, step:4, loss before: 2.66502829618e-05, loss after: 2.66242059297e-05.\n",
      "Epoch:9, weight train batch: 196, step:5, loss before: 2.21986883844e-05, loss after: 2.21986883844e-05.\n",
      "Epoch:9, weight train batch: 196, step:6, loss before: 0.0034759787377, loss after: 0.0034726257436.\n",
      "Epoch:9, weight train batch: 196, step:7, loss before: 2.8918908356e-05, loss after: 2.88928331429e-05.\n",
      "Epoch:9, weight train batch: 196, step:8, loss before: 2.19081175601e-05, loss after: 2.18894911086e-05.\n",
      "Epoch:9, weight train batch: 196, step:9, loss before: 2.73394471151e-05, loss after: 2.73394471151e-05.\n",
      "Epoch:9, weight train batch: 196, step:10, loss before: 2.56705643551e-05, loss after: 2.56370385614e-05.\n",
      "Epoch:9, weight train batch: 196, step:11, loss before: 3.05505600409e-05, loss after: 3.04760560539e-05.\n",
      "Epoch:9, weight train batch: 196, step:12, loss before: 2.55401591858e-05, loss after: 2.54991828115e-05.\n",
      "Epoch:9, weight train batch: 196, step:13, loss before: 2.71457465715e-05, loss after: 2.71122189588e-05.\n",
      "Epoch:9, weight train batch: 196, step:14, loss before: 2.33572172874e-05, loss after: 2.33572172874e-05.\n",
      "Epoch:9, weight train batch: 196, step:15, loss before: 4.24538811785e-05, loss after: 4.23980091e-05.\n",
      "Epoch:9, weight train batch: 196, step:16, loss before: 4.55832523585e-05, loss after: 4.55683584732e-05.\n",
      "Epoch:9, weight train batch: 196, step:17, loss before: 3.17872982123e-05, loss after: 3.17872982123e-05.\n",
      "Epoch:9, weight train batch: 196, step:18, loss before: 3.72237227566e-05, loss after: 3.7179026549e-05.\n",
      "Epoch:9, weight train batch: 196, step:19, loss before: 2.46871059062e-05, loss after: 2.46573035838e-05.\n",
      "Epoch:9, weight train batch: 196, step:20, loss before: 2.94292622129e-05, loss after: 2.93994598906e-05.\n",
      "Epoch:9, weight train batch: 196, step:21, loss before: 3.15824399877e-05, loss after: 3.15824399877e-05.\n",
      "Epoch:9, weight train batch: 196, step:22, loss before: 2.89226518362e-05, loss after: 2.89226518362e-05.\n",
      "Epoch:9, weight train batch: 196, step:23, loss before: 3.03680189973e-05, loss after: 3.02935168293e-05.\n",
      "Epoch:9, weight train batch: 196, step:24, loss before: 2.38228331e-05, loss after: 2.38228331e-05.\n",
      "Epoch:9, weight train batch: 196, step:25, loss before: 2.67508657998e-05, loss after: 2.6728514058e-05.\n",
      "Epoch:9, weight train batch: 196, step:26, loss before: 2.6925928978e-05, loss after: 2.6925928978e-05.\n",
      "Epoch:9, weight train batch: 196, step:27, loss before: 2.67732320935e-05, loss after: 2.67248051387e-05.\n",
      "Epoch:9, weight train batch: 196, step:28, loss before: 2.61324821622e-05, loss after: 2.61064051301e-05.\n",
      "Epoch:9, weight train batch: 196, step:29, loss before: 2.57338961092e-05, loss after: 2.57152696577e-05.\n",
      "Epoch:9, weight train batch: 196, step:30, loss before: 2.70563195954e-05, loss after: 2.70563195954e-05.\n",
      "Epoch:9, weight train batch: 196, step:31, loss before: 2.96043817798e-05, loss after: 2.9544777135e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 192, loss before: 2.86348567897e-05, loss after: 2.81301054201e-05.\n",
      "Epoch:9, weight train batch: 197, step:0, loss before: 2.64156133198e-05, loss after: 2.64156133198e-05.\n",
      "Epoch:9, weight train batch: 197, step:1, loss before: 2.65124417638e-05, loss after: 2.65124417638e-05.\n",
      "Epoch:9, weight train batch: 197, step:2, loss before: 2.53017788054e-05, loss after: 2.53017788054e-05.\n",
      "Epoch:9, weight train batch: 197, step:3, loss before: 2.60170054389e-05, loss after: 2.59946536971e-05.\n",
      "Epoch:9, weight train batch: 197, step:4, loss before: 2.53166581388e-05, loss after: 2.5257055313e-05.\n",
      "Epoch:9, weight train batch: 197, step:5, loss before: 2.5692890631e-05, loss after: 2.5692890631e-05.\n",
      "Epoch:9, weight train batch: 197, step:6, loss before: 2.710102126e-05, loss after: 2.710102126e-05.\n",
      "Epoch:9, weight train batch: 197, step:7, loss before: 2.60803244601e-05, loss after: 2.60803244601e-05.\n",
      "Epoch:9, weight train batch: 197, step:8, loss before: 2.66614515567e-05, loss after: 2.6627927582e-05.\n",
      "Epoch:9, weight train batch: 197, step:9, loss before: 2.4932964152e-05, loss after: 2.4932964152e-05.\n",
      "Epoch:9, weight train batch: 197, step:10, loss before: 2.64789086941e-05, loss after: 2.64640075329e-05.\n",
      "Epoch:9, weight train batch: 197, step:11, loss before: 2.19565154111e-05, loss after: 2.19565154111e-05.\n",
      "Epoch:9, weight train batch: 197, step:12, loss before: 3.94783892261e-05, loss after: 3.94299640902e-05.\n",
      "Epoch:9, weight train batch: 197, step:13, loss before: 2.7302205126e-05, loss after: 2.72537781711e-05.\n",
      "Epoch:9, weight train batch: 197, step:14, loss before: 2.92653530778e-05, loss after: 2.92653530778e-05.\n",
      "Epoch:9, weight train batch: 197, step:15, loss before: 2.85389323835e-05, loss after: 2.85389323835e-05.\n",
      "Epoch:9, weight train batch: 197, step:16, loss before: 0.000126071521663, loss after: 0.000126004670165.\n",
      "Epoch:9, weight train batch: 197, step:17, loss before: 2.75331440207e-05, loss after: 2.74958947557e-05.\n",
      "Epoch:9, weight train batch: 197, step:18, loss before: 0.00334316212684, loss after: 0.00333422771655.\n",
      "Epoch:9, weight train batch: 197, step:19, loss before: 3.10981558869e-05, loss after: 3.10460054607e-05.\n",
      "Epoch:9, weight train batch: 197, step:20, loss before: 2.74139310932e-05, loss after: 2.73580517387e-05.\n",
      "Epoch:9, weight train batch: 197, step:21, loss before: 2.71829958365e-05, loss after: 2.71494682238e-05.\n",
      "Epoch:9, weight train batch: 197, step:22, loss before: 3.52551287506e-05, loss after: 3.52029746864e-05.\n",
      "Epoch:9, weight train batch: 197, step:23, loss before: 2.20794754568e-05, loss after: 2.20273250306e-05.\n",
      "Epoch:9, weight train batch: 197, step:24, loss before: 4.3951706175e-05, loss after: 4.3877211283e-05.\n",
      "Epoch:9, weight train batch: 197, step:25, loss before: 2.69855554507e-05, loss after: 2.69483061857e-05.\n",
      "Epoch:9, weight train batch: 197, step:26, loss before: 2.54880214925e-05, loss after: 2.54619480984e-05.\n",
      "Epoch:9, weight train batch: 197, step:27, loss before: 2.79168471025e-05, loss after: 2.78870484181e-05.\n",
      "Epoch:9, weight train batch: 197, step:28, loss before: 2.40836034209e-05, loss after: 2.40426270466e-05.\n",
      "Epoch:9, weight train batch: 197, step:29, loss before: 2.50521261478e-05, loss after: 2.5029778044e-05.\n",
      "Epoch:9, weight train batch: 197, step:30, loss before: 2.16473581531e-05, loss after: 2.16473581531e-05.\n",
      "Epoch:9, weight train batch: 197, step:31, loss before: 2.50596167461e-05, loss after: 2.49851127592e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 193, loss before: 2.6229336072e-05, loss after: 2.62470312009e-05.\n",
      "Epoch:9, weight train batch: 198, step:0, loss before: 2.47280768235e-05, loss after: 2.47280768235e-05.\n",
      "Epoch:9, weight train batch: 198, step:1, loss before: 2.67173454631e-05, loss after: 2.66800925601e-05.\n",
      "Epoch:9, weight train batch: 198, step:2, loss before: 2.53166508628e-05, loss after: 2.52831268881e-05.\n",
      "Epoch:9, weight train batch: 198, step:3, loss before: 2.95223926514e-05, loss after: 2.94963156193e-05.\n",
      "Epoch:9, weight train batch: 198, step:4, loss before: 4.81842071167e-05, loss after: 4.81730385218e-05.\n",
      "Epoch:9, weight train batch: 198, step:5, loss before: 0.000114837152069, loss after: 0.000114569600555.\n",
      "Epoch:9, weight train batch: 198, step:6, loss before: 2.72351026069e-05, loss after: 2.7223926736e-05.\n",
      "Epoch:9, weight train batch: 198, step:7, loss before: 2.53092148341e-05, loss after: 2.52533354796e-05.\n",
      "Epoch:9, weight train batch: 198, step:8, loss before: 2.77045255643e-05, loss after: 2.77045255643e-05.\n",
      "Epoch:9, weight train batch: 198, step:9, loss before: 0.0303621087223, loss after: 0.0302886683494.\n",
      "Epoch:9, weight train batch: 198, step:10, loss before: 3.03009601339e-05, loss after: 3.03307642753e-05.\n",
      "Epoch:9, weight train batch: 198, step:11, loss before: 2.31001704378e-05, loss after: 2.32044767472e-05.\n",
      "Epoch:9, weight train batch: 198, step:12, loss before: 2.8285650842e-05, loss after: 2.83266272163e-05.\n",
      "Epoch:9, weight train batch: 198, step:13, loss before: 2.30740843108e-05, loss after: 2.30927107623e-05.\n",
      "Epoch:9, weight train batch: 198, step:14, loss before: 2.30815494433e-05, loss after: 2.31188023463e-05.\n",
      "Epoch:9, weight train batch: 198, step:15, loss before: 2.76076862065e-05, loss after: 2.76412120002e-05.\n",
      "Epoch:9, weight train batch: 198, step:16, loss before: 3.33206480718e-05, loss after: 3.33429998136e-05.\n",
      "Epoch:9, weight train batch: 198, step:17, loss before: 2.7786467399e-05, loss after: 2.78199950117e-05.\n",
      "Epoch:9, weight train batch: 198, step:18, loss before: 3.04909481201e-05, loss after: 3.0464872907e-05.\n",
      "Epoch:9, weight train batch: 198, step:19, loss before: 2.71941626124e-05, loss after: 2.72537672572e-05.\n",
      "Epoch:9, weight train batch: 198, step:20, loss before: 2.67545983661e-05, loss after: 2.6728521334e-05.\n",
      "Epoch:9, weight train batch: 198, step:21, loss before: 3.48368121195e-05, loss after: 3.48964167642e-05.\n",
      "Epoch:9, weight train batch: 198, step:22, loss before: 2.26792399189e-05, loss after: 2.26643387577e-05.\n",
      "Epoch:9, weight train batch: 198, step:23, loss before: 3.06362344418e-05, loss after: 3.06362344418e-05.\n",
      "Epoch:9, weight train batch: 198, step:24, loss before: 2.21129957936e-05, loss after: 2.21390728257e-05.\n",
      "Epoch:9, weight train batch: 198, step:25, loss before: 2.82372075162e-05, loss after: 2.81962311419e-05.\n",
      "Epoch:9, weight train batch: 198, step:26, loss before: 2.84681809717e-05, loss after: 2.84979814751e-05.\n",
      "Epoch:9, weight train batch: 198, step:27, loss before: 2.36254381889e-05, loss after: 2.36105370277e-05.\n",
      "Epoch:9, weight train batch: 198, step:28, loss before: 2.53763009823e-05, loss after: 2.53763009823e-05.\n",
      "Epoch:9, weight train batch: 198, step:29, loss before: 2.49516124313e-05, loss after: 2.49516124313e-05.\n",
      "Epoch:9, weight train batch: 198, step:30, loss before: 2.98129780276e-05, loss after: 2.98465056403e-05.\n",
      "Epoch:9, weight train batch: 198, step:31, loss before: 2.55774357356e-05, loss after: 2.55513623415e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 194, loss before: 2.63410984189e-05, loss after: 2.63410984189e-05.\n",
      "Epoch:9, weight train batch: 199, step:0, loss before: 2.89189192699e-05, loss after: 2.89189192699e-05.\n",
      "Epoch:9, weight train batch: 199, step:1, loss before: 2.52757054113e-05, loss after: 2.52757054113e-05.\n",
      "Epoch:9, weight train batch: 199, step:2, loss before: 2.332742406e-05, loss after: 2.33087994275e-05.\n",
      "Epoch:9, weight train batch: 199, step:3, loss before: 3.79314296879e-05, loss after: 3.79351549782e-05.\n",
      "Epoch:9, weight train batch: 199, step:4, loss before: 2.99761413771e-05, loss after: 2.99724197248e-05.\n",
      "Epoch:9, weight train batch: 199, step:5, loss before: 2.51117926382e-05, loss after: 2.51117926382e-05.\n",
      "Epoch:9, weight train batch: 199, step:6, loss before: 2.75070960924e-05, loss after: 2.74772955891e-05.\n",
      "Epoch:9, weight train batch: 199, step:7, loss before: 2.40389344981e-05, loss after: 2.40389344981e-05.\n",
      "Epoch:9, weight train batch: 199, step:8, loss before: 2.6590685593e-05, loss after: 2.65720609605e-05.\n",
      "Epoch:9, weight train batch: 199, step:9, loss before: 2.5506649763e-05, loss after: 2.5506649763e-05.\n",
      "Epoch:9, weight train batch: 199, step:10, loss before: 2.49217810051e-05, loss after: 2.49217810051e-05.\n",
      "Epoch:9, weight train batch: 199, step:11, loss before: 0.000151930522406, loss after: 0.000151692976942.\n",
      "Epoch:9, weight train batch: 199, step:12, loss before: 2.63597248704e-05, loss after: 2.63373731286e-05.\n",
      "Epoch:9, weight train batch: 199, step:13, loss before: 2.40948120336e-05, loss after: 2.40650097112e-05.\n",
      "Epoch:9, weight train batch: 199, step:14, loss before: 5.15494175488e-05, loss after: 5.15419742442e-05.\n",
      "Epoch:9, weight train batch: 199, step:15, loss before: 2.66093029495e-05, loss after: 2.65683247562e-05.\n",
      "Epoch:9, weight train batch: 199, step:16, loss before: 2.68849798886e-05, loss after: 2.68849798886e-05.\n",
      "Epoch:9, weight train batch: 199, step:17, loss before: 2.01647108042e-05, loss after: 2.01647108042e-05.\n",
      "Epoch:9, weight train batch: 199, step:18, loss before: 2.71979188256e-05, loss after: 2.71979188256e-05.\n",
      "Epoch:9, weight train batch: 199, step:19, loss before: 2.32529000641e-05, loss after: 2.32529000641e-05.\n",
      "Epoch:9, weight train batch: 199, step:20, loss before: 4.50493644166e-05, loss after: 4.49860453955e-05.\n",
      "Epoch:9, weight train batch: 199, step:21, loss before: 4.37682137999e-05, loss after: 4.37160706497e-05.\n",
      "Epoch:9, weight train batch: 199, step:22, loss before: 2.36664127442e-05, loss after: 2.36664127442e-05.\n",
      "Epoch:9, weight train batch: 199, step:23, loss before: 2.67732029897e-05, loss after: 2.67545765382e-05.\n",
      "Epoch:9, weight train batch: 199, step:24, loss before: 2.67620434897e-05, loss after: 2.67620434897e-05.\n",
      "Epoch:9, weight train batch: 199, step:25, loss before: 0.0290105510503, loss after: 0.0289476104081.\n",
      "Epoch:9, weight train batch: 199, step:26, loss before: 2.37595304498e-05, loss after: 2.37483545789e-05.\n",
      "Epoch:9, weight train batch: 199, step:27, loss before: 2.55401755567e-05, loss after: 2.55327249761e-05.\n",
      "Epoch:9, weight train batch: 199, step:28, loss before: 3.06437032123e-05, loss after: 3.06399815599e-05.\n",
      "Epoch:9, weight train batch: 199, step:29, loss before: 2.74251324299e-05, loss after: 2.74363046628e-05.\n",
      "Epoch:9, weight train batch: 199, step:30, loss before: 2.68998883257e-05, loss after: 2.69296888291e-05.\n",
      "Epoch:9, weight train batch: 199, step:31, loss before: 2.26680531341e-05, loss after: 2.2679229005e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:9, struct parameters train batch: 195, loss before: 3.22761297866e-05, loss after: 2.98290615319e-05.\n",
      "Epoch:10, weight train batch: 200, step:0, loss before: 2.60617034655e-05, loss after: 2.60617052845e-05.\n",
      "Epoch:10, weight train batch: 200, step:1, loss before: 2.01908042072e-05, loss after: 2.0213155949e-05.\n",
      "Epoch:10, weight train batch: 200, step:2, loss before: 2.14946157939e-05, loss after: 2.15020645555e-05.\n",
      "Epoch:10, weight train batch: 200, step:3, loss before: 2.90791140287e-05, loss after: 2.9045586416e-05.\n",
      "Epoch:10, weight train batch: 200, step:4, loss before: 2.36030864471e-05, loss after: 2.36254381889e-05.\n",
      "Epoch:10, weight train batch: 200, step:5, loss before: 2.25898329518e-05, loss after: 2.25376807066e-05.\n",
      "Epoch:10, weight train batch: 200, step:6, loss before: 2.32864440477e-05, loss after: 2.32938946283e-05.\n",
      "Epoch:10, weight train batch: 200, step:7, loss before: 2.63336496573e-05, loss after: 2.63336496573e-05.\n",
      "Epoch:10, weight train batch: 200, step:8, loss before: 3.08294438582e-05, loss after: 3.07996451738e-05.\n",
      "Epoch:10, weight train batch: 200, step:9, loss before: 2.01758975891e-05, loss after: 2.02019709832e-05.\n",
      "Epoch:10, weight train batch: 200, step:10, loss before: 3.0267461625e-05, loss after: 3.0267461625e-05.\n",
      "Epoch:10, weight train batch: 200, step:11, loss before: 2.22322032641e-05, loss after: 2.22098515223e-05.\n",
      "Epoch:10, weight train batch: 200, step:12, loss before: 2.65832404693e-05, loss after: 2.65534399659e-05.\n",
      "Epoch:10, weight train batch: 200, step:13, loss before: 2.405010855e-05, loss after: 2.405010855e-05.\n",
      "Epoch:10, weight train batch: 200, step:14, loss before: 4.60954252048e-05, loss after: 4.60768133053e-05.\n",
      "Epoch:10, weight train batch: 200, step:15, loss before: 2.58158343058e-05, loss after: 2.58158343058e-05.\n",
      "Epoch:10, weight train batch: 200, step:16, loss before: 2.37446402025e-05, loss after: 2.37222884607e-05.\n",
      "Epoch:10, weight train batch: 200, step:17, loss before: 3.05691501126e-05, loss after: 3.05691501126e-05.\n",
      "Epoch:10, weight train batch: 200, step:18, loss before: 2.21539739869e-05, loss after: 2.21241753025e-05.\n",
      "Epoch:10, weight train batch: 200, step:19, loss before: 2.70451746474e-05, loss after: 2.70302734862e-05.\n",
      "Epoch:10, weight train batch: 200, step:20, loss before: 0.00312061631121, loss after: 0.00311154220253.\n",
      "Epoch:10, weight train batch: 200, step:21, loss before: 2.64118880295e-05, loss after: 2.6367184546e-05.\n",
      "Epoch:10, weight train batch: 200, step:22, loss before: 2.84011184704e-05, loss after: 2.84122943413e-05.\n",
      "Epoch:10, weight train batch: 200, step:23, loss before: 2.73729856417e-05, loss after: 2.72984816547e-05.\n",
      "Epoch:10, weight train batch: 200, step:24, loss before: 2.53055040957e-05, loss after: 2.52757017734e-05.\n",
      "Epoch:10, weight train batch: 200, step:25, loss before: 4.12851950387e-05, loss after: 4.12665685872e-05.\n",
      "Epoch:10, weight train batch: 200, step:26, loss before: 2.51304063568e-05, loss after: 2.5070803531e-05.\n",
      "Epoch:10, weight train batch: 200, step:27, loss before: 2.95038207696e-05, loss after: 2.94255951303e-05.\n",
      "Epoch:10, weight train batch: 200, step:28, loss before: 2.19043686229e-05, loss after: 2.19043686229e-05.\n",
      "Epoch:10, weight train batch: 200, step:29, loss before: 2.42177266045e-05, loss after: 2.41953748628e-05.\n",
      "Epoch:10, weight train batch: 200, step:30, loss before: 2.34317376453e-05, loss after: 2.34093859035e-05.\n",
      "Epoch:10, weight train batch: 200, step:31, loss before: 2.42922542384e-05, loss after: 2.42550031544e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 196, loss before: 2.59564767475e-05, loss after: 2.59564767475e-05.\n",
      "Epoch:10, weight train batch: 201, step:0, loss before: 2.59723128693e-05, loss after: 2.59723128693e-05.\n",
      "Epoch:10, weight train batch: 201, step:1, loss before: 2.57190040429e-05, loss after: 2.56780276686e-05.\n",
      "Epoch:10, weight train batch: 201, step:2, loss before: 2.61995319306e-05, loss after: 2.61846307694e-05.\n",
      "Epoch:10, weight train batch: 201, step:3, loss before: 2.5458244636e-05, loss after: 2.5458244636e-05.\n",
      "Epoch:10, weight train batch: 201, step:4, loss before: 2.86581671389e-05, loss after: 2.85389614874e-05.\n",
      "Epoch:10, weight train batch: 201, step:5, loss before: 2.44896800723e-05, loss after: 2.4485954782e-05.\n",
      "Epoch:10, weight train batch: 201, step:6, loss before: 2.6579522455e-05, loss after: 2.65273683908e-05.\n",
      "Epoch:10, weight train batch: 201, step:7, loss before: 2.6005840482e-05, loss after: 2.6005840482e-05.\n",
      "Epoch:10, weight train batch: 201, step:8, loss before: 2.73431778623e-05, loss after: 2.73431778623e-05.\n",
      "Epoch:10, weight train batch: 201, step:9, loss before: 2.46573254117e-05, loss after: 2.46312501986e-05.\n",
      "Epoch:10, weight train batch: 201, step:10, loss before: 2.48026062764e-05, loss after: 2.47765292443e-05.\n",
      "Epoch:10, weight train batch: 201, step:11, loss before: 2.5521578209e-05, loss after: 2.5521578209e-05.\n",
      "Epoch:10, weight train batch: 201, step:12, loss before: 2.87401344394e-05, loss after: 2.86917093035e-05.\n",
      "Epoch:10, weight train batch: 201, step:13, loss before: 2.74400354101e-05, loss after: 2.74102349067e-05.\n",
      "Epoch:10, weight train batch: 201, step:14, loss before: 2.74251469818e-05, loss after: 2.74251469818e-05.\n",
      "Epoch:10, weight train batch: 201, step:15, loss before: 2.48659416684e-05, loss after: 2.48435899266e-05.\n",
      "Epoch:10, weight train batch: 201, step:16, loss before: 2.51117835433e-05, loss after: 2.50857083302e-05.\n",
      "Epoch:10, weight train batch: 201, step:17, loss before: 2.5994668249e-05, loss after: 2.5994668249e-05.\n",
      "Epoch:10, weight train batch: 201, step:18, loss before: 2.39234504988e-05, loss after: 2.39234504988e-05.\n",
      "Epoch:10, weight train batch: 201, step:19, loss before: 2.70675118372e-05, loss after: 2.70675118372e-05.\n",
      "Epoch:10, weight train batch: 201, step:20, loss before: 2.31188150792e-05, loss after: 2.3066666472e-05.\n",
      "Epoch:10, weight train batch: 201, step:21, loss before: 2.56705661741e-05, loss after: 2.56333132711e-05.\n",
      "Epoch:10, weight train batch: 201, step:22, loss before: 2.44673374254e-05, loss after: 2.44673374254e-05.\n",
      "Epoch:10, weight train batch: 201, step:23, loss before: 2.50037592195e-05, loss after: 2.50037592195e-05.\n",
      "Epoch:10, weight train batch: 201, step:24, loss before: 2.4012852009e-05, loss after: 2.4012852009e-05.\n",
      "Epoch:10, weight train batch: 201, step:25, loss before: 2.42810638156e-05, loss after: 2.42251844611e-05.\n",
      "Epoch:10, weight train batch: 201, step:26, loss before: 2.44077382376e-05, loss after: 2.44077382376e-05.\n",
      "Epoch:10, weight train batch: 201, step:27, loss before: 2.62740541075e-05, loss after: 2.62740541075e-05.\n",
      "Epoch:10, weight train batch: 201, step:28, loss before: 2.18932145799e-05, loss after: 2.18932145799e-05.\n",
      "Epoch:10, weight train batch: 201, step:29, loss before: 2.52868703683e-05, loss after: 2.52868703683e-05.\n",
      "Epoch:10, weight train batch: 201, step:30, loss before: 2.33572463912e-05, loss after: 2.32901929849e-05.\n",
      "Epoch:10, weight train batch: 201, step:31, loss before: 2.36291616602e-05, loss after: 2.35956340475e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 197, loss before: 2.57646242972e-05, loss after: 2.58698637481e-05.\n",
      "Epoch:10, weight train batch: 202, step:0, loss before: 2.24445557251e-05, loss after: 2.24147534027e-05.\n",
      "Epoch:10, weight train batch: 202, step:1, loss before: 2.83117296931e-05, loss after: 2.83117296931e-05.\n",
      "Epoch:10, weight train batch: 202, step:2, loss before: 2.73357400147e-05, loss after: 2.73357400147e-05.\n",
      "Epoch:10, weight train batch: 202, step:3, loss before: 2.47280968324e-05, loss after: 2.47280968324e-05.\n",
      "Epoch:10, weight train batch: 202, step:4, loss before: 2.30256700888e-05, loss after: 2.29995966947e-05.\n",
      "Epoch:10, weight train batch: 202, step:5, loss before: 2.29437391681e-05, loss after: 2.29437391681e-05.\n",
      "Epoch:10, weight train batch: 202, step:6, loss before: 2.56817475019e-05, loss after: 2.56593957602e-05.\n",
      "Epoch:10, weight train batch: 202, step:7, loss before: 2.39681594394e-05, loss after: 2.39309083554e-05.\n",
      "Epoch:10, weight train batch: 202, step:8, loss before: 2.44673228735e-05, loss after: 2.44673228735e-05.\n",
      "Epoch:10, weight train batch: 202, step:9, loss before: 2.32193960983e-05, loss after: 2.32007696468e-05.\n",
      "Epoch:10, weight train batch: 202, step:10, loss before: 2.6378338589e-05, loss after: 2.6378338589e-05.\n",
      "Epoch:10, weight train batch: 202, step:11, loss before: 2.46126091952e-05, loss after: 2.46126091952e-05.\n",
      "Epoch:10, weight train batch: 202, step:12, loss before: 2.51453129749e-05, loss after: 2.51453129749e-05.\n",
      "Epoch:10, weight train batch: 202, step:13, loss before: 2.60021151917e-05, loss after: 2.60021151917e-05.\n",
      "Epoch:10, weight train batch: 202, step:14, loss before: 2.41805028054e-05, loss after: 2.41618799919e-05.\n",
      "Epoch:10, weight train batch: 202, step:15, loss before: 2.39569708356e-05, loss after: 2.39346190938e-05.\n",
      "Epoch:10, weight train batch: 202, step:16, loss before: 2.40240387939e-05, loss after: 2.39867877099e-05.\n",
      "Epoch:10, weight train batch: 202, step:17, loss before: 2.16063926928e-05, loss after: 2.16063926928e-05.\n",
      "Epoch:10, weight train batch: 202, step:18, loss before: 2.46163490374e-05, loss after: 2.46163490374e-05.\n",
      "Epoch:10, weight train batch: 202, step:19, loss before: 2.69185075013e-05, loss after: 2.68812582362e-05.\n",
      "Epoch:10, weight train batch: 202, step:20, loss before: 2.48510332312e-05, loss after: 2.48510332312e-05.\n",
      "Epoch:10, weight train batch: 202, step:21, loss before: 2.54656806646e-05, loss after: 2.54358819802e-05.\n",
      "Epoch:10, weight train batch: 202, step:22, loss before: 2.57115534623e-05, loss after: 2.57115534623e-05.\n",
      "Epoch:10, weight train batch: 202, step:23, loss before: 2.42885216721e-05, loss after: 2.42587193497e-05.\n",
      "Epoch:10, weight train batch: 202, step:24, loss before: 2.42587211687e-05, loss after: 2.42587211687e-05.\n",
      "Epoch:10, weight train batch: 202, step:25, loss before: 2.65571816271e-05, loss after: 2.65087546722e-05.\n",
      "Epoch:10, weight train batch: 202, step:26, loss before: 2.52682748396e-05, loss after: 2.52682748396e-05.\n",
      "Epoch:10, weight train batch: 202, step:27, loss before: 2.71084991255e-05, loss after: 2.71084991255e-05.\n",
      "Epoch:10, weight train batch: 202, step:28, loss before: 2.96633024846e-05, loss after: 2.96595790132e-05.\n",
      "Epoch:10, weight train batch: 202, step:29, loss before: 2.3502514523e-05, loss after: 2.3502514523e-05.\n",
      "Epoch:10, weight train batch: 202, step:30, loss before: 2.68514668278e-05, loss after: 2.67806899501e-05.\n",
      "Epoch:10, weight train batch: 202, step:31, loss before: 2.38862121478e-05, loss after: 2.38862121478e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 198, loss before: 2.86668764602e-05, loss after: 2.36775904341e-05.\n",
      "Epoch:10, weight train batch: 203, step:0, loss before: 2.46796880674e-05, loss after: 2.46796880674e-05.\n",
      "Epoch:10, weight train batch: 203, step:1, loss before: 2.28282515309e-05, loss after: 2.27872733376e-05.\n",
      "Epoch:10, weight train batch: 203, step:2, loss before: 2.39346318267e-05, loss after: 2.39346318267e-05.\n",
      "Epoch:10, weight train batch: 203, step:3, loss before: 2.43779304583e-05, loss after: 2.43481299549e-05.\n",
      "Epoch:10, weight train batch: 203, step:4, loss before: 2.22471262532e-05, loss after: 2.22471262532e-05.\n",
      "Epoch:10, weight train batch: 203, step:5, loss before: 2.43481299549e-05, loss after: 2.43481299549e-05.\n",
      "Epoch:10, weight train batch: 203, step:6, loss before: 2.20534002437e-05, loss after: 2.20384990826e-05.\n",
      "Epoch:10, weight train batch: 203, step:7, loss before: 2.59797634499e-05, loss after: 2.59797634499e-05.\n",
      "Epoch:10, weight train batch: 203, step:8, loss before: 2.56370476563e-05, loss after: 2.5607245334e-05.\n",
      "Epoch:10, weight train batch: 203, step:9, loss before: 4.41627271357e-05, loss after: 4.4129206799e-05.\n",
      "Epoch:10, weight train batch: 203, step:10, loss before: 2.4772796678e-05, loss after: 2.47429943556e-05.\n",
      "Epoch:10, weight train batch: 203, step:11, loss before: 2.37818931055e-05, loss after: 2.37818931055e-05.\n",
      "Epoch:10, weight train batch: 203, step:12, loss before: 2.38973825617e-05, loss after: 2.38973825617e-05.\n",
      "Epoch:10, weight train batch: 203, step:13, loss before: 2.76337614196e-05, loss after: 2.76337614196e-05.\n",
      "Epoch:10, weight train batch: 203, step:14, loss before: 2.46684903686e-05, loss after: 2.46051640715e-05.\n",
      "Epoch:10, weight train batch: 203, step:15, loss before: 2.36365940509e-05, loss after: 2.36365940509e-05.\n",
      "Epoch:10, weight train batch: 203, step:16, loss before: 2.32939037232e-05, loss after: 2.32939037232e-05.\n",
      "Epoch:10, weight train batch: 203, step:17, loss before: 2.50447355938e-05, loss after: 2.50261109613e-05.\n",
      "Epoch:10, weight train batch: 203, step:18, loss before: 2.43965660047e-05, loss after: 2.43965660047e-05.\n",
      "Epoch:10, weight train batch: 203, step:19, loss before: 2.3439164579e-05, loss after: 2.3401913495e-05.\n",
      "Epoch:10, weight train batch: 203, step:20, loss before: 2.39309210883e-05, loss after: 2.39309210883e-05.\n",
      "Epoch:10, weight train batch: 203, step:21, loss before: 3.06474394165e-05, loss after: 3.06474394165e-05.\n",
      "Epoch:10, weight train batch: 203, step:22, loss before: 2.27127675316e-05, loss after: 2.27127675316e-05.\n",
      "Epoch:10, weight train batch: 203, step:23, loss before: 2.37968160945e-05, loss after: 2.37334861595e-05.\n",
      "Epoch:10, weight train batch: 203, step:24, loss before: 2.19751927943e-05, loss after: 2.19751927943e-05.\n",
      "Epoch:10, weight train batch: 203, step:25, loss before: 2.4687144105e-05, loss after: 2.46536164923e-05.\n",
      "Epoch:10, weight train batch: 203, step:26, loss before: 2.38303364313e-05, loss after: 2.38303364313e-05.\n",
      "Epoch:10, weight train batch: 203, step:27, loss before: 2.43369631789e-05, loss after: 2.43369631789e-05.\n",
      "Epoch:10, weight train batch: 203, step:28, loss before: 2.16771659325e-05, loss after: 2.16771659325e-05.\n",
      "Epoch:10, weight train batch: 203, step:29, loss before: 2.61101376964e-05, loss after: 2.60654360318e-05.\n",
      "Epoch:10, weight train batch: 203, step:30, loss before: 2.2854328563e-05, loss after: 2.28282515309e-05.\n",
      "Epoch:10, weight train batch: 203, step:31, loss before: 2.42140267801e-05, loss after: 2.42140267801e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 199, loss before: 2.69599349849e-05, loss after: 2.8789470889e-05.\n",
      "Epoch:10, weight train batch: 204, step:0, loss before: 2.32678212342e-05, loss after: 2.32678212342e-05.\n",
      "Epoch:10, weight train batch: 204, step:1, loss before: 2.48398628173e-05, loss after: 2.47877087531e-05.\n",
      "Epoch:10, weight train batch: 204, step:2, loss before: 2.51043384196e-05, loss after: 2.50633602263e-05.\n",
      "Epoch:10, weight train batch: 204, step:3, loss before: 2.4374206987e-05, loss after: 2.4374206987e-05.\n",
      "Epoch:10, weight train batch: 204, step:4, loss before: 2.51341552939e-05, loss after: 2.51341552939e-05.\n",
      "Epoch:10, weight train batch: 204, step:5, loss before: 2.4374206987e-05, loss after: 2.4374206987e-05.\n",
      "Epoch:10, weight train batch: 204, step:6, loss before: 2.40054141614e-05, loss after: 2.40054141614e-05.\n",
      "Epoch:10, weight train batch: 204, step:7, loss before: 2.59499574895e-05, loss after: 2.58791806118e-05.\n",
      "Epoch:10, weight train batch: 204, step:8, loss before: 2.26196389121e-05, loss after: 2.26196389121e-05.\n",
      "Epoch:10, weight train batch: 204, step:9, loss before: 2.58903710346e-05, loss after: 2.58903710346e-05.\n",
      "Epoch:10, weight train batch: 204, step:10, loss before: 2.61324967141e-05, loss after: 2.61101449723e-05.\n",
      "Epoch:10, weight train batch: 204, step:11, loss before: 2.40314857365e-05, loss after: 2.40314857365e-05.\n",
      "Epoch:10, weight train batch: 204, step:12, loss before: 2.28953067563e-05, loss after: 2.28692315432e-05.\n",
      "Epoch:10, weight train batch: 204, step:13, loss before: 2.21279187826e-05, loss after: 2.21279187826e-05.\n",
      "Epoch:10, weight train batch: 204, step:14, loss before: 2.60430970229e-05, loss after: 2.60430970229e-05.\n",
      "Epoch:10, weight train batch: 204, step:15, loss before: 2.65385497187e-05, loss after: 2.65087473963e-05.\n",
      "Epoch:10, weight train batch: 204, step:16, loss before: 2.4411458071e-05, loss after: 2.4411458071e-05.\n",
      "Epoch:10, weight train batch: 204, step:17, loss before: 0.00341733591631, loss after: 0.0034138627816.\n",
      "Epoch:10, weight train batch: 204, step:18, loss before: 2.69185220532e-05, loss after: 2.68775438599e-05.\n",
      "Epoch:10, weight train batch: 204, step:19, loss before: 2.6505029382e-05, loss after: 2.64715035883e-05.\n",
      "Epoch:10, weight train batch: 204, step:20, loss before: 2.48025971814e-05, loss after: 2.47392708843e-05.\n",
      "Epoch:10, weight train batch: 204, step:21, loss before: 2.24818031711e-05, loss after: 2.24818031711e-05.\n",
      "Epoch:10, weight train batch: 204, step:22, loss before: 2.05819633265e-05, loss after: 2.05521610042e-05.\n",
      "Epoch:10, weight train batch: 204, step:23, loss before: 2.10736834561e-05, loss after: 2.10736834561e-05.\n",
      "Epoch:10, weight train batch: 204, step:24, loss before: 2.53800135397e-05, loss after: 2.53427606367e-05.\n",
      "Epoch:10, weight train batch: 204, step:25, loss before: 2.55141203525e-05, loss after: 2.55141203525e-05.\n",
      "Epoch:10, weight train batch: 204, step:26, loss before: 2.57562642219e-05, loss after: 2.57562642219e-05.\n",
      "Epoch:10, weight train batch: 204, step:27, loss before: 4.17055962316e-05, loss after: 4.1660903662e-05.\n",
      "Epoch:10, weight train batch: 204, step:28, loss before: 2.54172591667e-05, loss after: 2.53911839536e-05.\n",
      "Epoch:10, weight train batch: 204, step:29, loss before: 2.32380207308e-05, loss after: 2.32082202274e-05.\n",
      "Epoch:10, weight train batch: 204, step:30, loss before: 3.34177602781e-05, loss after: 3.34103096975e-05.\n",
      "Epoch:10, weight train batch: 204, step:31, loss before: 2.45976807491e-05, loss after: 2.45641531365e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 200, loss before: 0.000744097051211, loss after: 8.10489873402e-05.\n",
      "Epoch:10, weight train batch: 205, step:0, loss before: 2.34913404711e-05, loss after: 2.34578146774e-05.\n",
      "Epoch:10, weight train batch: 205, step:1, loss before: 2.27872369578e-05, loss after: 2.27797863772e-05.\n",
      "Epoch:10, weight train batch: 205, step:2, loss before: 2.49367130891e-05, loss after: 2.49367130891e-05.\n",
      "Epoch:10, weight train batch: 205, step:3, loss before: 2.1844794901e-05, loss after: 2.17926408368e-05.\n",
      "Epoch:10, weight train batch: 205, step:4, loss before: 3.09342940454e-05, loss after: 3.09342940454e-05.\n",
      "Epoch:10, weight train batch: 205, step:5, loss before: 3.16408477374e-05, loss after: 3.16036021104e-05.\n",
      "Epoch:10, weight train batch: 205, step:6, loss before: 2.41283505602e-05, loss after: 2.41246252699e-05.\n",
      "Epoch:10, weight train batch: 205, step:7, loss before: 0.00335739017464, loss after: 0.00334664294496.\n",
      "Epoch:10, weight train batch: 205, step:8, loss before: 2.15207146539e-05, loss after: 2.14797364606e-05.\n",
      "Epoch:10, weight train batch: 205, step:9, loss before: 2.82521468762e-05, loss after: 2.82558721665e-05.\n",
      "Epoch:10, weight train batch: 205, step:10, loss before: 3.69110202882e-05, loss after: 3.68328219338e-05.\n",
      "Epoch:10, weight train batch: 205, step:11, loss before: 2.25078765652e-05, loss after: 2.24370960495e-05.\n",
      "Epoch:10, weight train batch: 205, step:12, loss before: 2.41357920459e-05, loss after: 2.41208927036e-05.\n",
      "Epoch:10, weight train batch: 205, step:13, loss before: 2.32715556194e-05, loss after: 2.32454785873e-05.\n",
      "Epoch:10, weight train batch: 205, step:14, loss before: 3.06283873215e-05, loss after: 3.06172150886e-05.\n",
      "Epoch:10, weight train batch: 205, step:15, loss before: 2.39532600972e-05, loss after: 2.39309083554e-05.\n",
      "Epoch:10, weight train batch: 205, step:16, loss before: 2.33050686802e-05, loss after: 2.33050686802e-05.\n",
      "Epoch:10, weight train batch: 205, step:17, loss before: 2.68849598797e-05, loss after: 2.68439816864e-05.\n",
      "Epoch:10, weight train batch: 205, step:18, loss before: 2.45716437348e-05, loss after: 2.45716437348e-05.\n",
      "Epoch:10, weight train batch: 205, step:19, loss before: 2.38936572714e-05, loss after: 2.38936572714e-05.\n",
      "Epoch:10, weight train batch: 205, step:20, loss before: 2.32603670156e-05, loss after: 2.32417423831e-05.\n",
      "Epoch:10, weight train batch: 205, step:21, loss before: 2.42848018388e-05, loss after: 2.42848018388e-05.\n",
      "Epoch:10, weight train batch: 205, step:22, loss before: 2.50819957728e-05, loss after: 2.50559205597e-05.\n",
      "Epoch:10, weight train batch: 205, step:23, loss before: 1.97586832655e-05, loss after: 1.97065310203e-05.\n",
      "Epoch:10, weight train batch: 205, step:24, loss before: 2.37595468207e-05, loss after: 2.3726019208e-05.\n",
      "Epoch:10, weight train batch: 205, step:25, loss before: 2.39532637352e-05, loss after: 2.39532637352e-05.\n",
      "Epoch:10, weight train batch: 205, step:26, loss before: 2.41283305513e-05, loss after: 2.41283305513e-05.\n",
      "Epoch:10, weight train batch: 205, step:27, loss before: 2.55662671407e-05, loss after: 2.55662671407e-05.\n",
      "Epoch:10, weight train batch: 205, step:28, loss before: 2.07793855225e-05, loss after: 2.07793855225e-05.\n",
      "Epoch:10, weight train batch: 205, step:29, loss before: 2.14238498302e-05, loss after: 2.13903240365e-05.\n",
      "Epoch:10, weight train batch: 205, step:30, loss before: 2.55923623627e-05, loss after: 2.55625600403e-05.\n",
      "Epoch:10, weight train batch: 205, step:31, loss before: 2.41693087446e-05, loss after: 2.41693087446e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 201, loss before: 2.60997639998e-05, loss after: 2.4356517315e-05.\n",
      "Epoch:10, weight train batch: 206, step:0, loss before: 2.22173148359e-05, loss after: 2.22173148359e-05.\n",
      "Epoch:10, weight train batch: 206, step:1, loss before: 2.20981200982e-05, loss after: 2.20645924855e-05.\n",
      "Epoch:10, weight train batch: 206, step:2, loss before: 2.55103987001e-05, loss after: 2.55103987001e-05.\n",
      "Epoch:10, weight train batch: 206, step:3, loss before: 1.90210812434e-05, loss after: 1.90210812434e-05.\n",
      "Epoch:10, weight train batch: 206, step:4, loss before: 2.06899821933e-05, loss after: 2.06452823477e-05.\n",
      "Epoch:10, weight train batch: 206, step:5, loss before: 2.36515261349e-05, loss after: 2.36515261349e-05.\n",
      "Epoch:10, weight train batch: 206, step:6, loss before: 1.93489177036e-05, loss after: 1.93489177036e-05.\n",
      "Epoch:10, weight train batch: 206, step:7, loss before: 2.19230314542e-05, loss after: 2.19230314542e-05.\n",
      "Epoch:10, weight train batch: 206, step:8, loss before: 2.42550049734e-05, loss after: 2.42550049734e-05.\n",
      "Epoch:10, weight train batch: 206, step:9, loss before: 2.34019389609e-05, loss after: 2.33497848967e-05.\n",
      "Epoch:10, weight train batch: 206, step:10, loss before: 2.39905239141e-05, loss after: 2.39905239141e-05.\n",
      "Epoch:10, weight train batch: 206, step:11, loss before: 0.00329259387217, loss after: 0.00328903715126.\n",
      "Epoch:10, weight train batch: 206, step:12, loss before: 1.90434438991e-05, loss after: 1.90434438991e-05.\n",
      "Epoch:10, weight train batch: 206, step:13, loss before: 2.51639576163e-05, loss after: 2.51676829066e-05.\n",
      "Epoch:10, weight train batch: 206, step:14, loss before: 1.90248083527e-05, loss after: 1.90136324818e-05.\n",
      "Epoch:10, weight train batch: 206, step:15, loss before: 2.18485329242e-05, loss after: 2.18485329242e-05.\n",
      "Epoch:10, weight train batch: 206, step:16, loss before: 3.06170659314e-05, loss after: 3.05947178276e-05.\n",
      "Epoch:10, weight train batch: 206, step:17, loss before: 2.50745433732e-05, loss after: 2.50745433732e-05.\n",
      "Epoch:10, weight train batch: 206, step:18, loss before: 2.2407315555e-05, loss after: 2.2407315555e-05.\n",
      "Epoch:10, weight train batch: 206, step:19, loss before: 2.19640023715e-05, loss after: 2.19379253394e-05.\n",
      "Epoch:10, weight train batch: 206, step:20, loss before: 2.49702625297e-05, loss after: 2.49590866588e-05.\n",
      "Epoch:10, weight train batch: 206, step:21, loss before: 1.90657920029e-05, loss after: 1.90359896806e-05.\n",
      "Epoch:10, weight train batch: 206, step:22, loss before: 2.21800692088e-05, loss after: 2.2120468202e-05.\n",
      "Epoch:10, weight train batch: 206, step:23, loss before: 2.508572652e-05, loss after: 2.508572652e-05.\n",
      "Epoch:10, weight train batch: 206, step:24, loss before: 2.45493083639e-05, loss after: 2.45493083639e-05.\n",
      "Epoch:10, weight train batch: 206, step:25, loss before: 2.29176403082e-05, loss after: 2.28990174946e-05.\n",
      "Epoch:10, weight train batch: 206, step:26, loss before: 2.15207110159e-05, loss after: 2.15207110159e-05.\n",
      "Epoch:10, weight train batch: 206, step:27, loss before: 2.66241822828e-05, loss after: 2.66204569925e-05.\n",
      "Epoch:10, weight train batch: 206, step:28, loss before: 2.2194975827e-05, loss after: 2.2194975827e-05.\n",
      "Epoch:10, weight train batch: 206, step:29, loss before: 2.10923062696e-05, loss after: 2.10923062696e-05.\n",
      "Epoch:10, weight train batch: 206, step:30, loss before: 2.42959831667e-05, loss after: 2.42289279413e-05.\n",
      "Epoch:10, weight train batch: 206, step:31, loss before: 2.31299854931e-05, loss after: 2.31076355703e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 202, loss before: 2.68094445346e-05, loss after: 2.27034579439e-05.\n",
      "Epoch:10, weight train batch: 207, step:0, loss before: 2.21167265408e-05, loss after: 2.21167265408e-05.\n",
      "Epoch:10, weight train batch: 207, step:1, loss before: 2.35844672716e-05, loss after: 2.35844672716e-05.\n",
      "Epoch:10, weight train batch: 207, step:2, loss before: 2.47914067586e-05, loss after: 2.47876814683e-05.\n",
      "Epoch:10, weight train batch: 207, step:3, loss before: 2.0887437131e-05, loss after: 2.0887437131e-05.\n",
      "Epoch:10, weight train batch: 207, step:4, loss before: 1.9862978661e-05, loss after: 1.98182751774e-05.\n",
      "Epoch:10, weight train batch: 207, step:5, loss before: 2.47914431384e-05, loss after: 2.47728166869e-05.\n",
      "Epoch:10, weight train batch: 207, step:6, loss before: 2.20534075197e-05, loss after: 2.20534075197e-05.\n",
      "Epoch:10, weight train batch: 207, step:7, loss before: 2.03212002816e-05, loss after: 2.03212002816e-05.\n",
      "Epoch:10, weight train batch: 207, step:8, loss before: 2.1408948669e-05, loss after: 2.1408948669e-05.\n",
      "Epoch:10, weight train batch: 207, step:9, loss before: 2.11630867852e-05, loss after: 2.10997604881e-05.\n",
      "Epoch:10, weight train batch: 207, step:10, loss before: 0.000241021465627, loss after: 0.000240366731305.\n",
      "Epoch:10, weight train batch: 207, step:11, loss before: 2.13381772483e-05, loss after: 2.13381772483e-05.\n",
      "Epoch:10, weight train batch: 207, step:12, loss before: 2.24669165618e-05, loss after: 2.24371142394e-05.\n",
      "Epoch:10, weight train batch: 207, step:13, loss before: 2.37223102886e-05, loss after: 2.36701562244e-05.\n",
      "Epoch:10, weight train batch: 207, step:14, loss before: 2.03733397939e-05, loss after: 2.03323634196e-05.\n",
      "Epoch:10, weight train batch: 207, step:15, loss before: 2.18820514419e-05, loss after: 2.18820514419e-05.\n",
      "Epoch:10, weight train batch: 207, step:16, loss before: 2.28953103942e-05, loss after: 2.28953103942e-05.\n",
      "Epoch:10, weight train batch: 207, step:17, loss before: 2.45045976044e-05, loss after: 2.45045976044e-05.\n",
      "Epoch:10, weight train batch: 207, step:18, loss before: 0.00283625302836, loss after: 0.00282833050005.\n",
      "Epoch:10, weight train batch: 207, step:19, loss before: 2.10625039472e-05, loss after: 2.10327034438e-05.\n",
      "Epoch:10, weight train batch: 207, step:20, loss before: 1.91179569811e-05, loss after: 1.90360042325e-05.\n",
      "Epoch:10, weight train batch: 207, step:21, loss before: 2.32044985751e-05, loss after: 2.31709727814e-05.\n",
      "Epoch:10, weight train batch: 207, step:22, loss before: 2.36254527408e-05, loss after: 2.35583975154e-05.\n",
      "Epoch:10, weight train batch: 207, step:23, loss before: 2.07421398954e-05, loss after: 2.07160646823e-05.\n",
      "Epoch:10, weight train batch: 207, step:24, loss before: 2.21762966248e-05, loss after: 2.21464943024e-05.\n",
      "Epoch:10, weight train batch: 207, step:25, loss before: 3.72091817553e-05, loss after: 3.71756650566e-05.\n",
      "Epoch:10, weight train batch: 207, step:26, loss before: 2.48286742135e-05, loss after: 2.47988718911e-05.\n",
      "Epoch:10, weight train batch: 207, step:27, loss before: 1.72925920197e-05, loss after: 1.72776926775e-05.\n",
      "Epoch:10, weight train batch: 207, step:28, loss before: 2.23961305892e-05, loss after: 2.23961305892e-05.\n",
      "Epoch:10, weight train batch: 207, step:29, loss before: 2.18746172322e-05, loss after: 2.17777615035e-05.\n",
      "Epoch:10, weight train batch: 207, step:30, loss before: 2.11295591726e-05, loss after: 2.10997586692e-05.\n",
      "Epoch:10, weight train batch: 207, step:31, loss before: 2.13158291444e-05, loss after: 2.12860268221e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 203, loss before: 2.19779703912e-05, loss after: 2.19891444431e-05.\n",
      "Epoch:10, weight train batch: 208, step:0, loss before: 2.31486283155e-05, loss after: 2.31486283155e-05.\n",
      "Epoch:10, weight train batch: 208, step:1, loss before: 0.000127877457999, loss after: 0.000127832827275.\n",
      "Epoch:10, weight train batch: 208, step:2, loss before: 1.95351731236e-05, loss after: 1.95351731236e-05.\n",
      "Epoch:10, weight train batch: 208, step:3, loss before: 2.00194444915e-05, loss after: 2.00194444915e-05.\n",
      "Epoch:10, weight train batch: 208, step:4, loss before: 2.18150071305e-05, loss after: 2.17256019823e-05.\n",
      "Epoch:10, weight train batch: 208, step:5, loss before: 2.07197917916e-05, loss after: 2.07197917916e-05.\n",
      "Epoch:10, weight train batch: 208, step:6, loss before: 2.15244363062e-05, loss after: 2.15244363062e-05.\n",
      "Epoch:10, weight train batch: 208, step:7, loss before: 2.19379217015e-05, loss after: 2.19379217015e-05.\n",
      "Epoch:10, weight train batch: 208, step:8, loss before: 2.27500386245e-05, loss after: 2.27053351409e-05.\n",
      "Epoch:10, weight train batch: 208, step:9, loss before: 1.96916244022e-05, loss after: 1.96655491891e-05.\n",
      "Epoch:10, weight train batch: 208, step:10, loss before: 9.94407018879e-05, loss after: 9.92697750917e-05.\n",
      "Epoch:10, weight train batch: 208, step:11, loss before: 0.00269071292132, loss after: 0.00268231960945.\n",
      "Epoch:10, weight train batch: 208, step:12, loss before: 1.99300484383e-05, loss after: 1.99002497538e-05.\n",
      "Epoch:10, weight train batch: 208, step:13, loss before: 2.23402566917e-05, loss after: 2.22955532081e-05.\n",
      "Epoch:10, weight train batch: 208, step:14, loss before: 2.23625866056e-05, loss after: 2.23365113925e-05.\n",
      "Epoch:10, weight train batch: 208, step:15, loss before: 2.15914878936e-05, loss after: 2.15318850678e-05.\n",
      "Epoch:10, weight train batch: 208, step:16, loss before: 2.32194106502e-05, loss after: 2.31709836953e-05.\n",
      "Epoch:10, weight train batch: 208, step:17, loss before: 2.31672311202e-05, loss after: 2.3152329959e-05.\n",
      "Epoch:10, weight train batch: 208, step:18, loss before: 1.94420426851e-05, loss after: 1.94234162336e-05.\n",
      "Epoch:10, weight train batch: 208, step:19, loss before: 9.9885292002e-05, loss after: 9.95804730337e-05.\n",
      "Epoch:10, weight train batch: 208, step:20, loss before: 2.15281506826e-05, loss after: 2.14983483602e-05.\n",
      "Epoch:10, weight train batch: 208, step:21, loss before: 2.08352757909e-05, loss after: 2.08017499972e-05.\n",
      "Epoch:10, weight train batch: 208, step:22, loss before: 2.40650260821e-05, loss after: 2.40650260821e-05.\n",
      "Epoch:10, weight train batch: 208, step:23, loss before: 3.85749226552e-05, loss after: 3.85041676054e-05.\n",
      "Epoch:10, weight train batch: 208, step:24, loss before: 2.0686258722e-05, loss after: 2.0686258722e-05.\n",
      "Epoch:10, weight train batch: 208, step:25, loss before: 9.80193726718e-05, loss after: 9.76625378826e-05.\n",
      "Epoch:10, weight train batch: 208, step:26, loss before: 2.10401522054e-05, loss after: 2.10401522054e-05.\n",
      "Epoch:10, weight train batch: 208, step:27, loss before: 2.17851993511e-05, loss after: 2.17553970288e-05.\n",
      "Epoch:10, weight train batch: 208, step:28, loss before: 1.99077021534e-05, loss after: 1.9877899831e-05.\n",
      "Epoch:10, weight train batch: 208, step:29, loss before: 0.0032086239662, loss after: 0.00320399133489.\n",
      "Epoch:10, weight train batch: 208, step:30, loss before: 1.92446059373e-05, loss after: 1.92259794858e-05.\n",
      "Epoch:10, weight train batch: 208, step:31, loss before: 3.83354854421e-05, loss after: 3.83168553526e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 204, loss before: 2.2026406441e-05, loss after: 2.5968576665e-05.\n",
      "Epoch:10, weight train batch: 209, step:0, loss before: 2.17032429646e-05, loss after: 2.16734406422e-05.\n",
      "Epoch:10, weight train batch: 209, step:1, loss before: 2.10177968256e-05, loss after: 2.10177968256e-05.\n",
      "Epoch:10, weight train batch: 209, step:2, loss before: 2.02392420761e-05, loss after: 2.01945404115e-05.\n",
      "Epoch:10, weight train batch: 209, step:3, loss before: 1.88795438589e-05, loss after: 1.88497433555e-05.\n",
      "Epoch:10, weight train batch: 209, step:4, loss before: 2.08650744753e-05, loss after: 2.08650744753e-05.\n",
      "Epoch:10, weight train batch: 209, step:5, loss before: 1.94308559003e-05, loss after: 1.94085041585e-05.\n",
      "Epoch:10, weight train batch: 209, step:6, loss before: 0.000132909641252, loss after: 0.000132742614369.\n",
      "Epoch:10, weight train batch: 209, step:7, loss before: 1.92594925466e-05, loss after: 1.92296920432e-05.\n",
      "Epoch:10, weight train batch: 209, step:8, loss before: 2.21726259042e-05, loss after: 2.21726259042e-05.\n",
      "Epoch:10, weight train batch: 209, step:9, loss before: 2.11742571992e-05, loss after: 2.11742571992e-05.\n",
      "Epoch:10, weight train batch: 209, step:10, loss before: 2.47131993092e-05, loss after: 2.47131993092e-05.\n",
      "Epoch:10, weight train batch: 209, step:11, loss before: 2.31188205362e-05, loss after: 2.30443147302e-05.\n",
      "Epoch:10, weight train batch: 209, step:12, loss before: 2.40836452576e-05, loss after: 2.40836452576e-05.\n",
      "Epoch:10, weight train batch: 209, step:13, loss before: 2.2206140784e-05, loss after: 2.2206140784e-05.\n",
      "Epoch:10, weight train batch: 209, step:14, loss before: 2.14685551327e-05, loss after: 2.14685551327e-05.\n",
      "Epoch:10, weight train batch: 209, step:15, loss before: 2.17702981899e-05, loss after: 2.17032447836e-05.\n",
      "Epoch:10, weight train batch: 209, step:16, loss before: 2.14983519982e-05, loss after: 2.14983519982e-05.\n",
      "Epoch:10, weight train batch: 209, step:17, loss before: 2.11404039874e-05, loss after: 2.11329552258e-05.\n",
      "Epoch:10, weight train batch: 209, step:18, loss before: 2.21390891966e-05, loss after: 2.21390891966e-05.\n",
      "Epoch:10, weight train batch: 209, step:19, loss before: 1.8741691747e-05, loss after: 1.8741691747e-05.\n",
      "Epoch:10, weight train batch: 209, step:20, loss before: 2.02354985959e-05, loss after: 2.02354985959e-05.\n",
      "Epoch:10, weight train batch: 209, step:21, loss before: 1.98667257791e-05, loss after: 1.98443740373e-05.\n",
      "Epoch:10, weight train batch: 209, step:22, loss before: 1.99412352231e-05, loss after: 1.98928064492e-05.\n",
      "Epoch:10, weight train batch: 209, step:23, loss before: 1.93712767214e-05, loss after: 1.93451996893e-05.\n",
      "Epoch:10, weight train batch: 209, step:24, loss before: 2.25674884859e-05, loss after: 2.25488638534e-05.\n",
      "Epoch:10, weight train batch: 209, step:25, loss before: 2.00120084628e-05, loss after: 2.00120084628e-05.\n",
      "Epoch:10, weight train batch: 209, step:26, loss before: 0.00314391194843, loss after: 0.00314000435174.\n",
      "Epoch:10, weight train batch: 209, step:27, loss before: 3.05608191411e-05, loss after: 3.05272915284e-05.\n",
      "Epoch:10, weight train batch: 209, step:28, loss before: 2.20161546167e-05, loss after: 2.20161546167e-05.\n",
      "Epoch:10, weight train batch: 209, step:29, loss before: 2.08501733141e-05, loss after: 2.08166457014e-05.\n",
      "Epoch:10, weight train batch: 209, step:30, loss before: 2.08389956242e-05, loss after: 2.08389956242e-05.\n",
      "Epoch:10, weight train batch: 209, step:31, loss before: 2.03956988116e-05, loss after: 2.03547206183e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 205, loss before: 2.0405934265e-05, loss after: 2.03938288905e-05.\n",
      "Epoch:10, weight train batch: 210, step:0, loss before: 2.31188205362e-05, loss after: 2.31188205362e-05.\n",
      "Epoch:10, weight train batch: 210, step:1, loss before: 1.9065788365e-05, loss after: 1.9065788365e-05.\n",
      "Epoch:10, weight train batch: 210, step:2, loss before: 2.03398340091e-05, loss after: 2.03025811061e-05.\n",
      "Epoch:10, weight train batch: 210, step:3, loss before: 2.12301365536e-05, loss after: 2.12301365536e-05.\n",
      "Epoch:10, weight train batch: 210, step:4, loss before: 2.06676268135e-05, loss after: 2.06676268135e-05.\n",
      "Epoch:10, weight train batch: 210, step:5, loss before: 1.88981721294e-05, loss after: 1.88236681424e-05.\n",
      "Epoch:10, weight train batch: 210, step:6, loss before: 2.18969653361e-05, loss after: 2.18969653361e-05.\n",
      "Epoch:10, weight train batch: 210, step:7, loss before: 1.73633798113e-05, loss after: 1.73447533598e-05.\n",
      "Epoch:10, weight train batch: 210, step:8, loss before: 1.82648727787e-05, loss after: 1.82648727787e-05.\n",
      "Epoch:10, weight train batch: 210, step:9, loss before: 2.78709085251e-05, loss after: 2.78634597635e-05.\n",
      "Epoch:10, weight train batch: 210, step:10, loss before: 2.18373570533e-05, loss after: 2.18001041503e-05.\n",
      "Epoch:10, weight train batch: 210, step:11, loss before: 2.13009152503e-05, loss after: 2.13009152503e-05.\n",
      "Epoch:10, weight train batch: 210, step:12, loss before: 2.03621730179e-05, loss after: 2.03621730179e-05.\n",
      "Epoch:10, weight train batch: 210, step:13, loss before: 1.6674221115e-05, loss after: 1.6674221115e-05.\n",
      "Epoch:10, weight train batch: 210, step:14, loss before: 2.15244217543e-05, loss after: 2.14499177673e-05.\n",
      "Epoch:10, weight train batch: 210, step:15, loss before: 2.14685514948e-05, loss after: 2.14685514948e-05.\n",
      "Epoch:10, weight train batch: 210, step:16, loss before: 2.28319750022e-05, loss after: 2.28058979701e-05.\n",
      "Epoch:10, weight train batch: 210, step:17, loss before: 1.76352987182e-05, loss after: 1.76352987182e-05.\n",
      "Epoch:10, weight train batch: 210, step:18, loss before: 2.33013561228e-05, loss after: 2.32752790907e-05.\n",
      "Epoch:10, weight train batch: 210, step:19, loss before: 1.87975765584e-05, loss after: 1.87975765584e-05.\n",
      "Epoch:10, weight train batch: 210, step:20, loss before: 0.00250727124512, loss after: 0.00250066281296.\n",
      "Epoch:10, weight train batch: 210, step:21, loss before: 2.09656609513e-05, loss after: 2.09321333386e-05.\n",
      "Epoch:10, weight train batch: 210, step:22, loss before: 1.80823299161e-05, loss after: 1.80748793355e-05.\n",
      "Epoch:10, weight train batch: 210, step:23, loss before: 1.71659394255e-05, loss after: 1.71398642124e-05.\n",
      "Epoch:10, weight train batch: 210, step:24, loss before: 2.29660836339e-05, loss after: 2.29400066019e-05.\n",
      "Epoch:10, weight train batch: 210, step:25, loss before: 1.87305413419e-05, loss after: 1.8693288439e-05.\n",
      "Epoch:10, weight train batch: 210, step:26, loss before: 2.35844800045e-05, loss after: 2.35435018112e-05.\n",
      "Epoch:10, weight train batch: 210, step:27, loss before: 2.14797346416e-05, loss after: 2.14611081901e-05.\n",
      "Epoch:10, weight train batch: 210, step:28, loss before: 2.28506032727e-05, loss after: 2.27947239182e-05.\n",
      "Epoch:10, weight train batch: 210, step:29, loss before: 1.92818606592e-05, loss after: 1.92818606592e-05.\n",
      "Epoch:10, weight train batch: 210, step:30, loss before: 1.87826954061e-05, loss after: 1.87417172128e-05.\n",
      "Epoch:10, weight train batch: 210, step:31, loss before: 2.06639106182e-05, loss after: 2.06639106182e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 206, loss before: 1.94979147636e-05, loss after: 2.16330990952e-05.\n",
      "Epoch:10, weight train batch: 211, step:0, loss before: 2.53381040238e-05, loss after: 2.53343787335e-05.\n",
      "Epoch:10, weight train batch: 211, step:1, loss before: 2.16026528506e-05, loss after: 2.15728505282e-05.\n",
      "Epoch:10, weight train batch: 211, step:2, loss before: 1.89763904928e-05, loss after: 1.89763904928e-05.\n",
      "Epoch:10, weight train batch: 211, step:3, loss before: 2.00529830181e-05, loss after: 2.00231806957e-05.\n",
      "Epoch:10, weight train batch: 211, step:4, loss before: 2.57112515101e-05, loss after: 2.56777275354e-05.\n",
      "Epoch:10, weight train batch: 211, step:5, loss before: 2.05335236387e-05, loss after: 2.0499996026e-05.\n",
      "Epoch:10, weight train batch: 211, step:6, loss before: 2.643755397e-05, loss after: 2.64338286797e-05.\n",
      "Epoch:10, weight train batch: 211, step:7, loss before: 1.8618786271e-05, loss after: 1.8581533368e-05.\n",
      "Epoch:10, weight train batch: 211, step:8, loss before: 2.46610616159e-05, loss after: 2.46610616159e-05.\n",
      "Epoch:10, weight train batch: 211, step:9, loss before: 2.14648207475e-05, loss after: 2.13977691601e-05.\n",
      "Epoch:10, weight train batch: 211, step:10, loss before: 1.7035552446e-05, loss after: 1.7035552446e-05.\n",
      "Epoch:10, weight train batch: 211, step:11, loss before: 2.00156919163e-05, loss after: 2.00156919163e-05.\n",
      "Epoch:10, weight train batch: 211, step:12, loss before: 0.00306992582045, loss after: 0.00306669506244.\n",
      "Epoch:10, weight train batch: 211, step:13, loss before: 2.06713630178e-05, loss after: 2.06415606954e-05.\n",
      "Epoch:10, weight train batch: 211, step:14, loss before: 1.83580032171e-05, loss after: 1.83580032171e-05.\n",
      "Epoch:10, weight train batch: 211, step:15, loss before: 2.25451331062e-05, loss after: 2.25153307838e-05.\n",
      "Epoch:10, weight train batch: 211, step:16, loss before: 1.88683570741e-05, loss after: 1.88683570741e-05.\n",
      "Epoch:10, weight train batch: 211, step:17, loss before: 1.8544276827e-05, loss after: 1.85181997949e-05.\n",
      "Epoch:10, weight train batch: 211, step:18, loss before: 2.22843809752e-05, loss after: 2.22843809752e-05.\n",
      "Epoch:10, weight train batch: 211, step:19, loss before: 1.93228515855e-05, loss after: 1.9266972231e-05.\n",
      "Epoch:10, weight train batch: 211, step:20, loss before: 1.96357177629e-05, loss after: 1.96096407308e-05.\n",
      "Epoch:10, weight train batch: 211, step:21, loss before: 1.97698645934e-05, loss after: 1.97698645934e-05.\n",
      "Epoch:10, weight train batch: 211, step:22, loss before: 2.46422241617e-05, loss after: 2.46384988714e-05.\n",
      "Epoch:10, weight train batch: 211, step:23, loss before: 1.87565892702e-05, loss after: 1.87565892702e-05.\n",
      "Epoch:10, weight train batch: 211, step:24, loss before: 1.71696774487e-05, loss after: 1.71324245457e-05.\n",
      "Epoch:10, weight train batch: 211, step:25, loss before: 2.04962780117e-05, loss after: 2.04962780117e-05.\n",
      "Epoch:10, weight train batch: 211, step:26, loss before: 2.23402457777e-05, loss after: 2.23402457777e-05.\n",
      "Epoch:10, weight train batch: 211, step:27, loss before: 1.97847548407e-05, loss after: 1.9751229047e-05.\n",
      "Epoch:10, weight train batch: 211, step:28, loss before: 0.000223410723265, loss after: 0.000222910835873.\n",
      "Epoch:10, weight train batch: 211, step:29, loss before: 2.05260876101e-05, loss after: 2.05260876101e-05.\n",
      "Epoch:10, weight train batch: 211, step:30, loss before: 1.84548680409e-05, loss after: 1.84138898476e-05.\n",
      "Epoch:10, weight train batch: 211, step:31, loss before: 1.90546088561e-05, loss after: 1.90359824046e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 207, loss before: 0.00709048565477, loss after: 1.9172894099e-05.\n",
      "Epoch:10, weight train batch: 212, step:0, loss before: 1.64395241882e-05, loss after: 1.64395241882e-05.\n",
      "Epoch:10, weight train batch: 212, step:1, loss before: 2.06005752261e-05, loss after: 2.05633241421e-05.\n",
      "Epoch:10, weight train batch: 212, step:2, loss before: 1.94606636796e-05, loss after: 1.94606636796e-05.\n",
      "Epoch:10, weight train batch: 212, step:3, loss before: 1.89801157831e-05, loss after: 1.89391375898e-05.\n",
      "Epoch:10, weight train batch: 212, step:4, loss before: 1.83282081707e-05, loss after: 1.83282081707e-05.\n",
      "Epoch:10, weight train batch: 212, step:5, loss before: 1.98480884137e-05, loss after: 1.98480884137e-05.\n",
      "Epoch:10, weight train batch: 212, step:6, loss before: 2.07085977308e-05, loss after: 2.06638942473e-05.\n",
      "Epoch:10, weight train batch: 212, step:7, loss before: 1.47333539644e-05, loss after: 1.47333539644e-05.\n",
      "Epoch:10, weight train batch: 212, step:8, loss before: 1.91142244148e-05, loss after: 1.90508944797e-05.\n",
      "Epoch:10, weight train batch: 212, step:9, loss before: 1.93228279386e-05, loss after: 1.93228279386e-05.\n",
      "Epoch:10, weight train batch: 212, step:10, loss before: 2.16694297706e-05, loss after: 2.16657044803e-05.\n",
      "Epoch:10, weight train batch: 212, step:11, loss before: 1.70057537616e-05, loss after: 1.70057537616e-05.\n",
      "Epoch:10, weight train batch: 212, step:12, loss before: 2.24408322538e-05, loss after: 2.23961305892e-05.\n",
      "Epoch:10, weight train batch: 212, step:13, loss before: 3.64064107998e-05, loss after: 3.63877952623e-05.\n",
      "Epoch:10, weight train batch: 212, step:14, loss before: 1.69908526004e-05, loss after: 1.69908526004e-05.\n",
      "Epoch:10, weight train batch: 212, step:15, loss before: 1.89354195754e-05, loss after: 1.8905619072e-05.\n",
      "Epoch:10, weight train batch: 212, step:16, loss before: 2.01051316253e-05, loss after: 2.01051316253e-05.\n",
      "Epoch:10, weight train batch: 212, step:17, loss before: 1.6324032913e-05, loss after: 1.63016811712e-05.\n",
      "Epoch:10, weight train batch: 212, step:18, loss before: 0.000208025157917, loss after: 0.00020748093084.\n",
      "Epoch:10, weight train batch: 212, step:19, loss before: 0.000129470019601, loss after: 0.000129425374325.\n",
      "Epoch:10, weight train batch: 212, step:20, loss before: 0.000210812795558, loss after: 0.000209683552384.\n",
      "Epoch:10, weight train batch: 212, step:21, loss before: 1.95463508135e-05, loss after: 1.95128232008e-05.\n",
      "Epoch:10, weight train batch: 212, step:22, loss before: 1.96692890313e-05, loss after: 1.96432138182e-05.\n",
      "Epoch:10, weight train batch: 212, step:23, loss before: 0.0053490344435, loss after: 0.00533941434696.\n",
      "Epoch:10, weight train batch: 212, step:24, loss before: 2.12450468098e-05, loss after: 2.11891692743e-05.\n",
      "Epoch:10, weight train batch: 212, step:25, loss before: 1.7832750018e-05, loss after: 1.78029476956e-05.\n",
      "Epoch:10, weight train batch: 212, step:26, loss before: 1.82127223525e-05, loss after: 1.81531195267e-05.\n",
      "Epoch:10, weight train batch: 212, step:27, loss before: 1.70281055034e-05, loss after: 1.6998303181e-05.\n",
      "Epoch:10, weight train batch: 212, step:28, loss before: 1.78029531526e-05, loss after: 1.7758251488e-05.\n",
      "Epoch:10, weight train batch: 212, step:29, loss before: 1.85964145203e-05, loss after: 1.85740645975e-05.\n",
      "Epoch:10, weight train batch: 212, step:30, loss before: 1.96879045689e-05, loss after: 1.96506516659e-05.\n",
      "Epoch:10, weight train batch: 212, step:31, loss before: 1.62532705872e-05, loss after: 1.62122923939e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 208, loss before: 1.78690643224e-05, loss after: 4.4932407036e-05.\n",
      "Epoch:10, weight train batch: 213, step:0, loss before: 1.83132979146e-05, loss after: 1.83132979146e-05.\n",
      "Epoch:10, weight train batch: 213, step:1, loss before: 2.01945404115e-05, loss after: 2.01237598958e-05.\n",
      "Epoch:10, weight train batch: 213, step:2, loss before: 1.84511300176e-05, loss after: 1.84511300176e-05.\n",
      "Epoch:10, weight train batch: 213, step:3, loss before: 1.43087108881e-05, loss after: 1.42714588947e-05.\n",
      "Epoch:10, weight train batch: 213, step:4, loss before: 1.89503098227e-05, loss after: 1.89503098227e-05.\n",
      "Epoch:10, weight train batch: 213, step:5, loss before: 1.89130478248e-05, loss after: 1.8890696083e-05.\n",
      "Epoch:10, weight train batch: 213, step:6, loss before: 1.82015410246e-05, loss after: 1.82015410246e-05.\n",
      "Epoch:10, weight train batch: 213, step:7, loss before: 1.90844093595e-05, loss after: 1.90546070371e-05.\n",
      "Epoch:10, weight train batch: 213, step:8, loss before: 0.000127103354316, loss after: 0.000126850805827.\n",
      "Epoch:10, weight train batch: 213, step:9, loss before: 1.39510793815e-05, loss after: 1.39063758979e-05.\n",
      "Epoch:10, weight train batch: 213, step:10, loss before: 1.5739180526e-05, loss after: 1.5739180526e-05.\n",
      "Epoch:10, weight train batch: 213, step:11, loss before: 1.99449405045e-05, loss after: 1.99449405045e-05.\n",
      "Epoch:10, weight train batch: 213, step:12, loss before: 1.99374881049e-05, loss after: 1.98667075892e-05.\n",
      "Epoch:10, weight train batch: 213, step:13, loss before: 1.44279110827e-05, loss after: 1.44279110827e-05.\n",
      "Epoch:10, weight train batch: 213, step:14, loss before: 1.82238873094e-05, loss after: 1.82238873094e-05.\n",
      "Epoch:10, weight train batch: 213, step:15, loss before: 1.93414598471e-05, loss after: 1.93414598471e-05.\n",
      "Epoch:10, weight train batch: 213, step:16, loss before: 2.4437544198e-05, loss after: 2.4437544198e-05.\n",
      "Epoch:10, weight train batch: 213, step:17, loss before: 1.76613721123e-05, loss after: 1.763156979e-05.\n",
      "Epoch:10, weight train batch: 213, step:18, loss before: 1.72963191289e-05, loss after: 1.72702420969e-05.\n",
      "Epoch:10, weight train batch: 213, step:19, loss before: 1.88795220311e-05, loss after: 1.88199192053e-05.\n",
      "Epoch:10, weight train batch: 213, step:20, loss before: 2.54126916843e-05, loss after: 2.54052411037e-05.\n",
      "Epoch:10, weight train batch: 213, step:21, loss before: 1.84846612683e-05, loss after: 1.84846612683e-05.\n",
      "Epoch:10, weight train batch: 213, step:22, loss before: 1.92073512153e-05, loss after: 1.92073512153e-05.\n",
      "Epoch:10, weight train batch: 213, step:23, loss before: 1.61415118782e-05, loss after: 1.61415118782e-05.\n",
      "Epoch:10, weight train batch: 213, step:24, loss before: 1.82872172445e-05, loss after: 1.82536896318e-05.\n",
      "Epoch:10, weight train batch: 213, step:25, loss before: 2.41200068558e-05, loss after: 2.41162815655e-05.\n",
      "Epoch:10, weight train batch: 213, step:26, loss before: 1.9017372324e-05, loss after: 1.9017372324e-05.\n",
      "Epoch:10, weight train batch: 213, step:27, loss before: 2.02802166314e-05, loss after: 2.02802166314e-05.\n",
      "Epoch:10, weight train batch: 213, step:28, loss before: 2.29735360335e-05, loss after: 2.29735360335e-05.\n",
      "Epoch:10, weight train batch: 213, step:29, loss before: 0.00223957421258, loss after: 0.0022335445974.\n",
      "Epoch:10, weight train batch: 213, step:30, loss before: 2.16063817788e-05, loss after: 2.15877553273e-05.\n",
      "Epoch:10, weight train batch: 213, step:31, loss before: 1.74304277607e-05, loss after: 1.7396900148e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 209, loss before: 1.77284418896e-05, loss after: 1.9077804609e-05.\n",
      "Epoch:10, weight train batch: 214, step:0, loss before: 1.97586741706e-05, loss after: 1.97586741706e-05.\n",
      "Epoch:10, weight train batch: 214, step:1, loss before: 1.43347906487e-05, loss after: 1.42938124554e-05.\n",
      "Epoch:10, weight train batch: 214, step:2, loss before: 2.13456205529e-05, loss after: 2.13456205529e-05.\n",
      "Epoch:10, weight train batch: 214, step:3, loss before: 2.00790527742e-05, loss after: 2.00455251615e-05.\n",
      "Epoch:10, weight train batch: 214, step:4, loss before: 1.86113065865e-05, loss after: 1.86113065865e-05.\n",
      "Epoch:10, weight train batch: 214, step:5, loss before: 1.8778941012e-05, loss after: 1.87156128959e-05.\n",
      "Epoch:10, weight train batch: 214, step:6, loss before: 1.56497699209e-05, loss after: 1.56497699209e-05.\n",
      "Epoch:10, weight train batch: 214, step:7, loss before: 1.56497699209e-05, loss after: 1.56236928888e-05.\n",
      "Epoch:10, weight train batch: 214, step:8, loss before: 1.65438304975e-05, loss after: 1.65214787557e-05.\n",
      "Epoch:10, weight train batch: 214, step:9, loss before: 1.70169259945e-05, loss after: 1.70169259945e-05.\n",
      "Epoch:10, weight train batch: 214, step:10, loss before: 1.81121413334e-05, loss after: 1.81121413334e-05.\n",
      "Epoch:10, weight train batch: 214, step:11, loss before: 1.43608513099e-05, loss after: 1.43347751873e-05.\n",
      "Epoch:10, weight train batch: 214, step:12, loss before: 1.51617614392e-05, loss after: 1.51617614392e-05.\n",
      "Epoch:10, weight train batch: 214, step:13, loss before: 1.84921191249e-05, loss after: 1.84474156413e-05.\n",
      "Epoch:10, weight train batch: 214, step:14, loss before: 1.73819953488e-05, loss after: 1.73819953488e-05.\n",
      "Epoch:10, weight train batch: 214, step:15, loss before: 1.80748902494e-05, loss after: 1.80152874236e-05.\n",
      "Epoch:10, weight train batch: 214, step:16, loss before: 1.50649229909e-05, loss after: 1.50649229909e-05.\n",
      "Epoch:10, weight train batch: 214, step:17, loss before: 1.92297011381e-05, loss after: 1.92297011381e-05.\n",
      "Epoch:10, weight train batch: 214, step:18, loss before: 1.38802952279e-05, loss after: 1.38802952279e-05.\n",
      "Epoch:10, weight train batch: 214, step:19, loss before: 1.69275317603e-05, loss after: 1.69275317603e-05.\n",
      "Epoch:10, weight train batch: 214, step:20, loss before: 1.56832884386e-05, loss after: 1.56832884386e-05.\n",
      "Epoch:10, weight train batch: 214, step:21, loss before: 1.89465827134e-05, loss after: 1.89093298104e-05.\n",
      "Epoch:10, weight train batch: 214, step:22, loss before: 1.77135480044e-05, loss after: 1.77135480044e-05.\n",
      "Epoch:10, weight train batch: 214, step:23, loss before: 1.86373927136e-05, loss after: 1.86001416296e-05.\n",
      "Epoch:10, weight train batch: 214, step:24, loss before: 1.75496297743e-05, loss after: 1.75496297743e-05.\n",
      "Epoch:10, weight train batch: 214, step:25, loss before: 1.68716433109e-05, loss after: 1.68716433109e-05.\n",
      "Epoch:10, weight train batch: 214, step:26, loss before: 1.79221551662e-05, loss after: 1.79221551662e-05.\n",
      "Epoch:10, weight train batch: 214, step:27, loss before: 2.00566955755e-05, loss after: 2.00157192012e-05.\n",
      "Epoch:10, weight train batch: 214, step:28, loss before: 1.82872136065e-05, loss after: 1.82648618647e-05.\n",
      "Epoch:10, weight train batch: 214, step:29, loss before: 1.82611456694e-05, loss after: 1.82611456694e-05.\n",
      "Epoch:10, weight train batch: 214, step:30, loss before: 1.48078815982e-05, loss after: 1.48078815982e-05.\n",
      "Epoch:10, weight train batch: 214, step:31, loss before: 1.66034260474e-05, loss after: 1.66034260474e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 210, loss before: 2.42195801547e-05, loss after: 1.94040512724e-05.\n",
      "Epoch:10, weight train batch: 215, step:0, loss before: 1.8331931642e-05, loss after: 1.8331931642e-05.\n",
      "Epoch:10, weight train batch: 215, step:1, loss before: 3.17122721754e-05, loss after: 3.16936493618e-05.\n",
      "Epoch:10, weight train batch: 215, step:2, loss before: 2.22620219574e-05, loss after: 2.22620219574e-05.\n",
      "Epoch:10, weight train batch: 215, step:3, loss before: 1.71547562786e-05, loss after: 1.71286792465e-05.\n",
      "Epoch:10, weight train batch: 215, step:4, loss before: 1.48600211105e-05, loss after: 1.48600211105e-05.\n",
      "Epoch:10, weight train batch: 215, step:5, loss before: 0.000196427688934, loss after: 0.000195964632439.\n",
      "Epoch:10, weight train batch: 215, step:6, loss before: 1.97698573174e-05, loss after: 1.97698573174e-05.\n",
      "Epoch:10, weight train batch: 215, step:7, loss before: 1.93116502487e-05, loss after: 1.92371462617e-05.\n",
      "Epoch:10, weight train batch: 215, step:8, loss before: 1.65028559422e-05, loss after: 1.65028559422e-05.\n",
      "Epoch:10, weight train batch: 215, step:9, loss before: 1.56311452884e-05, loss after: 1.56311452884e-05.\n",
      "Epoch:10, weight train batch: 215, step:10, loss before: 1.65177480085e-05, loss after: 1.65177480085e-05.\n",
      "Epoch:10, weight train batch: 215, step:11, loss before: 1.85442495422e-05, loss after: 1.85181725101e-05.\n",
      "Epoch:10, weight train batch: 215, step:12, loss before: 1.6063275325e-05, loss after: 1.6063275325e-05.\n",
      "Epoch:10, weight train batch: 215, step:13, loss before: 2.67724371952e-05, loss after: 2.67687137239e-05.\n",
      "Epoch:10, weight train batch: 215, step:14, loss before: 2.1122104954e-05, loss after: 2.10513262573e-05.\n",
      "Epoch:10, weight train batch: 215, step:15, loss before: 1.78141253855e-05, loss after: 1.78141253855e-05.\n",
      "Epoch:10, weight train batch: 215, step:16, loss before: 1.73037751665e-05, loss after: 1.73037751665e-05.\n",
      "Epoch:10, weight train batch: 215, step:17, loss before: 2.01647235372e-05, loss after: 2.01647235372e-05.\n",
      "Epoch:10, weight train batch: 215, step:18, loss before: 1.78998016054e-05, loss after: 1.78998016054e-05.\n",
      "Epoch:10, weight train batch: 215, step:19, loss before: 1.81344948942e-05, loss after: 1.81158684427e-05.\n",
      "Epoch:10, weight train batch: 215, step:20, loss before: 2.15430591197e-05, loss after: 2.14946321648e-05.\n",
      "Epoch:10, weight train batch: 215, step:21, loss before: 2.13418716157e-05, loss after: 2.13418716157e-05.\n",
      "Epoch:10, weight train batch: 215, step:22, loss before: 1.92259722098e-05, loss after: 1.9203620468e-05.\n",
      "Epoch:10, weight train batch: 215, step:23, loss before: 2.17703018279e-05, loss after: 2.17703018279e-05.\n",
      "Epoch:10, weight train batch: 215, step:24, loss before: 1.75980530912e-05, loss after: 1.75645291165e-05.\n",
      "Epoch:10, weight train batch: 215, step:25, loss before: 1.76911944436e-05, loss after: 1.76911944436e-05.\n",
      "Epoch:10, weight train batch: 215, step:26, loss before: 2.28391854762e-05, loss after: 2.28391854762e-05.\n",
      "Epoch:10, weight train batch: 215, step:27, loss before: 2.03286454052e-05, loss after: 2.03286454052e-05.\n",
      "Epoch:10, weight train batch: 215, step:28, loss before: 3.2618700061e-05, loss after: 3.26075278281e-05.\n",
      "Epoch:10, weight train batch: 215, step:29, loss before: 3.00411920762e-05, loss after: 3.00113897538e-05.\n",
      "Epoch:10, weight train batch: 215, step:30, loss before: 1.83766223927e-05, loss after: 1.83654465218e-05.\n",
      "Epoch:10, weight train batch: 215, step:31, loss before: 1.85777789738e-05, loss after: 1.85777789738e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 211, loss before: 1.76147841557e-05, loss after: 1.6866990336e-05.\n",
      "Epoch:10, weight train batch: 216, step:0, loss before: 1.71435840457e-05, loss after: 1.71435840457e-05.\n",
      "Epoch:10, weight train batch: 216, step:1, loss before: 1.91812850971e-05, loss after: 1.91477574845e-05.\n",
      "Epoch:10, weight train batch: 216, step:2, loss before: 1.92147981579e-05, loss after: 1.92147981579e-05.\n",
      "Epoch:10, weight train batch: 216, step:3, loss before: 1.64581288118e-05, loss after: 1.64581288118e-05.\n",
      "Epoch:10, weight train batch: 216, step:4, loss before: 1.39548010338e-05, loss after: 1.39548010338e-05.\n",
      "Epoch:10, weight train batch: 216, step:5, loss before: 0.00292635709047, loss after: 0.00292225671001.\n",
      "Epoch:10, weight train batch: 216, step:6, loss before: 0.0283178724349, loss after: 0.0281899049878.\n",
      "Epoch:10, weight train batch: 216, step:7, loss before: 3.03164597426e-05, loss after: 3.07856389554e-05.\n",
      "Epoch:10, weight train batch: 216, step:8, loss before: 1.92297084141e-05, loss after: 1.93712694454e-05.\n",
      "Epoch:10, weight train batch: 216, step:9, loss before: 1.5415089365e-05, loss after: 1.54970439326e-05.\n",
      "Epoch:10, weight train batch: 216, step:10, loss before: 0.00291308481246, loss after: 0.00290817976929.\n",
      "Epoch:10, weight train batch: 216, step:11, loss before: 1.55976231326e-05, loss after: 1.5664676539e-05.\n",
      "Epoch:10, weight train batch: 216, step:12, loss before: 3.12612974085e-05, loss after: 3.17416051985e-05.\n",
      "Epoch:10, weight train batch: 216, step:13, loss before: 1.51990279846e-05, loss after: 1.52437305587e-05.\n",
      "Epoch:10, weight train batch: 216, step:14, loss before: 1.84883847396e-05, loss after: 1.84734835784e-05.\n",
      "Epoch:10, weight train batch: 216, step:15, loss before: 1.90508981177e-05, loss after: 1.90806986211e-05.\n",
      "Epoch:10, weight train batch: 216, step:16, loss before: 0.00214074645191, loss after: 0.00213615433313.\n",
      "Epoch:10, weight train batch: 216, step:17, loss before: 1.7322405256e-05, loss after: 1.73373064172e-05.\n",
      "Epoch:10, weight train batch: 216, step:18, loss before: 1.55007728608e-05, loss after: 1.54858716996e-05.\n",
      "Epoch:10, weight train batch: 216, step:19, loss before: 1.89279890037e-05, loss after: 1.89801430679e-05.\n",
      "Epoch:10, weight train batch: 216, step:20, loss before: 1.64171688084e-05, loss after: 1.64171688084e-05.\n",
      "Epoch:10, weight train batch: 216, step:21, loss before: 1.98667148652e-05, loss after: 1.98778907361e-05.\n",
      "Epoch:10, weight train batch: 216, step:22, loss before: 1.87715195352e-05, loss after: 1.87752448255e-05.\n",
      "Epoch:10, weight train batch: 216, step:23, loss before: 1.55305824592e-05, loss after: 1.55492089107e-05.\n",
      "Epoch:10, weight train batch: 216, step:24, loss before: 1.78886366484e-05, loss after: 1.79072630999e-05.\n",
      "Epoch:10, weight train batch: 216, step:25, loss before: 1.60483723448e-05, loss after: 1.60669987963e-05.\n",
      "Epoch:10, weight train batch: 216, step:26, loss before: 1.99263322429e-05, loss after: 1.99635851459e-05.\n",
      "Epoch:10, weight train batch: 216, step:27, loss before: 1.77508081833e-05, loss after: 1.77508081833e-05.\n",
      "Epoch:10, weight train batch: 216, step:28, loss before: 2.01982675208e-05, loss after: 2.02094433916e-05.\n",
      "Epoch:10, weight train batch: 216, step:29, loss before: 1.70877137862e-05, loss after: 1.70877137862e-05.\n",
      "Epoch:10, weight train batch: 216, step:30, loss before: 1.97773297259e-05, loss after: 1.97773297259e-05.\n",
      "Epoch:10, weight train batch: 216, step:31, loss before: 1.79854923772e-05, loss after: 1.79780417966e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 212, loss before: 2.17582892219e-05, loss after: 0.000725305464584.\n",
      "Epoch:10, weight train batch: 217, step:0, loss before: 1.94383319467e-05, loss after: 1.94085296243e-05.\n",
      "Epoch:10, weight train batch: 217, step:1, loss before: 1.87901387108e-05, loss after: 1.87901387108e-05.\n",
      "Epoch:10, weight train batch: 217, step:2, loss before: 1.6547526684e-05, loss after: 1.6547526684e-05.\n",
      "Epoch:10, weight train batch: 217, step:3, loss before: 2.15691470657e-05, loss after: 2.15691470657e-05.\n",
      "Epoch:10, weight train batch: 217, step:4, loss before: 1.90210957953e-05, loss after: 1.90210957953e-05.\n",
      "Epoch:10, weight train batch: 217, step:5, loss before: 0.00203493260778, loss after: 0.00202878355049.\n",
      "Epoch:10, weight train batch: 217, step:6, loss before: 1.71286919795e-05, loss after: 1.71175161086e-05.\n",
      "Epoch:10, weight train batch: 217, step:7, loss before: 1.68381320691e-05, loss after: 1.68381320691e-05.\n",
      "Epoch:10, weight train batch: 217, step:8, loss before: 1.90956088773e-05, loss after: 1.90732571355e-05.\n",
      "Epoch:10, weight train batch: 217, step:9, loss before: 1.69871345861e-05, loss after: 1.69461563928e-05.\n",
      "Epoch:10, weight train batch: 217, step:10, loss before: 1.86821089301e-05, loss after: 1.8656031898e-05.\n",
      "Epoch:10, weight train batch: 217, step:11, loss before: 1.70877319761e-05, loss after: 1.7024402041e-05.\n",
      "Epoch:10, weight train batch: 217, step:12, loss before: 1.54858735186e-05, loss after: 1.54858735186e-05.\n",
      "Epoch:10, weight train batch: 217, step:13, loss before: 1.84176242328e-05, loss after: 1.83915472007e-05.\n",
      "Epoch:10, weight train batch: 217, step:14, loss before: 1.57876256708e-05, loss after: 1.57876256708e-05.\n",
      "Epoch:10, weight train batch: 217, step:15, loss before: 1.78960799531e-05, loss after: 1.78811787919e-05.\n",
      "Epoch:10, weight train batch: 217, step:16, loss before: 1.80376482604e-05, loss after: 1.80115712283e-05.\n",
      "Epoch:10, weight train batch: 217, step:17, loss before: 3.62943828804e-05, loss after: 3.62683204003e-05.\n",
      "Epoch:10, weight train batch: 217, step:18, loss before: 1.34891615744e-05, loss after: 1.34891615744e-05.\n",
      "Epoch:10, weight train batch: 217, step:19, loss before: 1.96581167984e-05, loss after: 1.96245891857e-05.\n",
      "Epoch:10, weight train batch: 217, step:20, loss before: 1.84921191249e-05, loss after: 1.84921191249e-05.\n",
      "Epoch:10, weight train batch: 217, step:21, loss before: 1.71063511516e-05, loss after: 1.70839994098e-05.\n",
      "Epoch:10, weight train batch: 217, step:22, loss before: 3.52132119588e-05, loss after: 3.51983180735e-05.\n",
      "Epoch:10, weight train batch: 217, step:23, loss before: 1.90508999367e-05, loss after: 1.90285500139e-05.\n",
      "Epoch:10, weight train batch: 217, step:24, loss before: 3.40394035447e-05, loss after: 3.39872640325e-05.\n",
      "Epoch:10, weight train batch: 217, step:25, loss before: 1.94942058442e-05, loss after: 1.94942058442e-05.\n",
      "Epoch:10, weight train batch: 217, step:26, loss before: 1.67971465999e-05, loss after: 1.67971465999e-05.\n",
      "Epoch:10, weight train batch: 217, step:27, loss before: 1.63687436725e-05, loss after: 1.63687436725e-05.\n",
      "Epoch:10, weight train batch: 217, step:28, loss before: 1.33624880618e-05, loss after: 1.33140611069e-05.\n",
      "Epoch:10, weight train batch: 217, step:29, loss before: 1.75198365469e-05, loss after: 1.75198365469e-05.\n",
      "Epoch:10, weight train batch: 217, step:30, loss before: 1.8082344468e-05, loss after: 1.8082344468e-05.\n",
      "Epoch:10, weight train batch: 217, step:31, loss before: 1.81307805178e-05, loss after: 1.81047034857e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 213, loss before: 0.00673348363489, loss after: 0.00071892113192.\n",
      "Epoch:10, weight train batch: 218, step:0, loss before: 1.68828228198e-05, loss after: 1.68828228198e-05.\n",
      "Epoch:10, weight train batch: 218, step:1, loss before: 2.63478814304e-05, loss after: 2.63069068751e-05.\n",
      "Epoch:10, weight train batch: 218, step:2, loss before: 1.65922592714e-05, loss after: 1.65922592714e-05.\n",
      "Epoch:10, weight train batch: 218, step:3, loss before: 1.71584906639e-05, loss after: 1.71286883415e-05.\n",
      "Epoch:10, weight train batch: 218, step:4, loss before: 1.50984424181e-05, loss after: 1.50984424181e-05.\n",
      "Epoch:10, weight train batch: 218, step:5, loss before: 0.0019256665837, loss after: 0.00192058796529.\n",
      "Epoch:10, weight train batch: 218, step:6, loss before: 1.67747894011e-05, loss after: 1.67412636074e-05.\n",
      "Epoch:10, weight train batch: 218, step:7, loss before: 1.62420947163e-05, loss after: 1.61750394909e-05.\n",
      "Epoch:10, weight train batch: 218, step:8, loss before: 1.78513873834e-05, loss after: 1.78513873834e-05.\n",
      "Epoch:10, weight train batch: 218, step:9, loss before: 1.96171422431e-05, loss after: 1.95761640498e-05.\n",
      "Epoch:10, weight train batch: 218, step:10, loss before: 0.0001216425444, loss after: 0.000121646255138.\n",
      "Epoch:10, weight train batch: 218, step:11, loss before: 0.00281951436773, loss after: 0.00281633250415.\n",
      "Epoch:10, weight train batch: 218, step:12, loss before: 1.78290356416e-05, loss after: 1.78290356416e-05.\n",
      "Epoch:10, weight train batch: 218, step:13, loss before: 1.81752311619e-05, loss after: 1.81342547876e-05.\n",
      "Epoch:10, weight train batch: 218, step:14, loss before: 0.0268944278359, loss after: 0.0268279314041.\n",
      "Epoch:10, weight train batch: 218, step:15, loss before: 1.99374990189e-05, loss after: 1.98927991732e-05.\n",
      "Epoch:10, weight train batch: 218, step:16, loss before: 1.70430175785e-05, loss after: 1.70430175785e-05.\n",
      "Epoch:10, weight train batch: 218, step:17, loss before: 0.026594068855, loss after: 0.0264343544841.\n",
      "Epoch:10, weight train batch: 218, step:18, loss before: 1.68790920725e-05, loss after: 1.68716414919e-05.\n",
      "Epoch:10, weight train batch: 218, step:19, loss before: 1.74527958734e-05, loss after: 1.7460246454e-05.\n",
      "Epoch:10, weight train batch: 218, step:20, loss before: 1.65922556334e-05, loss after: 1.656245513e-05.\n",
      "Epoch:10, weight train batch: 218, step:21, loss before: 0.0258985236287, loss after: 0.0257036462426.\n",
      "Epoch:10, weight train batch: 218, step:22, loss before: 1.46476977534e-05, loss after: 1.4655148334e-05.\n",
      "Epoch:10, weight train batch: 218, step:23, loss before: 1.63687545864e-05, loss after: 1.63836557476e-05.\n",
      "Epoch:10, weight train batch: 218, step:24, loss before: 1.68455735547e-05, loss after: 1.68194983416e-05.\n",
      "Epoch:10, weight train batch: 218, step:25, loss before: 1.8220187485e-05, loss after: 1.82276380656e-05.\n",
      "Epoch:10, weight train batch: 218, step:26, loss before: 1.89465972653e-05, loss after: 1.89242455235e-05.\n",
      "Epoch:10, weight train batch: 218, step:27, loss before: 3.70446323359e-05, loss after: 3.70446578017e-05.\n",
      "Epoch:10, weight train batch: 218, step:28, loss before: 1.98704583454e-05, loss after: 1.98704619834e-05.\n",
      "Epoch:10, weight train batch: 218, step:29, loss before: 1.86485776794e-05, loss after: 1.86485776794e-05.\n",
      "Epoch:10, weight train batch: 218, step:30, loss before: 1.54746976477e-05, loss after: 1.54448971443e-05.\n",
      "Epoch:10, weight train batch: 218, step:31, loss before: 1.71659485204e-05, loss after: 1.71659485204e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 214, loss before: 1.79584858415e-05, loss after: 1.79584858415e-05.\n",
      "Epoch:10, weight train batch: 219, step:0, loss before: 8.62253000378e-05, loss after: 8.61174994498e-05.\n",
      "Epoch:10, weight train batch: 219, step:1, loss before: 1.50127871166e-05, loss after: 1.50127871166e-05.\n",
      "Epoch:10, weight train batch: 219, step:2, loss before: 1.46104403029e-05, loss after: 1.46365164255e-05.\n",
      "Epoch:10, weight train batch: 219, step:3, loss before: 1.93712839973e-05, loss after: 1.93079558812e-05.\n",
      "Epoch:10, weight train batch: 219, step:4, loss before: 1.65363817359e-05, loss after: 1.65363817359e-05.\n",
      "Epoch:10, weight train batch: 219, step:5, loss before: 1.60111339937e-05, loss after: 1.60409363161e-05.\n",
      "Epoch:10, weight train batch: 219, step:6, loss before: 1.92446150322e-05, loss after: 1.91999133676e-05.\n",
      "Epoch:10, weight train batch: 219, step:7, loss before: 1.74565193447e-05, loss after: 1.74565193447e-05.\n",
      "Epoch:10, weight train batch: 219, step:8, loss before: 1.68083315657e-05, loss after: 1.68083315657e-05.\n",
      "Epoch:10, weight train batch: 219, step:9, loss before: 2.00418053282e-05, loss after: 2.0026904167e-05.\n",
      "Epoch:10, weight train batch: 219, step:10, loss before: 1.48600402099e-05, loss after: 1.48414137584e-05.\n",
      "Epoch:10, weight train batch: 219, step:11, loss before: 1.91030703718e-05, loss after: 1.91328726942e-05.\n",
      "Epoch:10, weight train batch: 219, step:12, loss before: 1.99188943952e-05, loss after: 1.99188943952e-05.\n",
      "Epoch:10, weight train batch: 219, step:13, loss before: 1.66406935023e-05, loss after: 1.66071658896e-05.\n",
      "Epoch:10, weight train batch: 219, step:14, loss before: 1.91850176634e-05, loss after: 1.91440412891e-05.\n",
      "Epoch:10, weight train batch: 219, step:15, loss before: 1.74676897586e-05, loss after: 1.74676897586e-05.\n",
      "Epoch:10, weight train batch: 219, step:16, loss before: 1.81084215001e-05, loss after: 1.80860697583e-05.\n",
      "Epoch:10, weight train batch: 219, step:17, loss before: 1.52437351062e-05, loss after: 1.52437351062e-05.\n",
      "Epoch:10, weight train batch: 219, step:18, loss before: 1.74043507286e-05, loss after: 1.73708249349e-05.\n",
      "Epoch:10, weight train batch: 219, step:19, loss before: 1.66593254107e-05, loss after: 1.66593254107e-05.\n",
      "Epoch:10, weight train batch: 219, step:20, loss before: 1.60595536727e-05, loss after: 1.60595536727e-05.\n",
      "Epoch:10, weight train batch: 219, step:21, loss before: 1.65326728165e-05, loss after: 1.65326728165e-05.\n",
      "Epoch:10, weight train batch: 219, step:22, loss before: 1.67152029462e-05, loss after: 1.67152029462e-05.\n",
      "Epoch:10, weight train batch: 219, step:23, loss before: 1.65401161212e-05, loss after: 1.65177661984e-05.\n",
      "Epoch:10, weight train batch: 219, step:24, loss before: 1.57280119311e-05, loss after: 1.57056601893e-05.\n",
      "Epoch:10, weight train batch: 219, step:25, loss before: 1.43347933772e-05, loss after: 1.43347933772e-05.\n",
      "Epoch:10, weight train batch: 219, step:26, loss before: 1.50760934048e-05, loss after: 1.50760934048e-05.\n",
      "Epoch:10, weight train batch: 219, step:27, loss before: 3.75217750843e-05, loss after: 3.75031595468e-05.\n",
      "Epoch:10, weight train batch: 219, step:28, loss before: 1.70430248545e-05, loss after: 1.70430248545e-05.\n",
      "Epoch:10, weight train batch: 219, step:29, loss before: 1.61564057635e-05, loss after: 1.61228781508e-05.\n",
      "Epoch:10, weight train batch: 219, step:30, loss before: 1.66891313711e-05, loss after: 1.66891313711e-05.\n",
      "Epoch:10, weight train batch: 219, step:31, loss before: 1.52288248501e-05, loss after: 1.5202747818e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:10, struct parameters train batch: 215, loss before: 1.84623240784e-05, loss after: 1.84651180462e-05.\n",
      "Epoch:11, weight train batch: 220, step:0, loss before: 1.68344013218e-05, loss after: 1.68344013218e-05.\n",
      "Epoch:11, weight train batch: 220, step:1, loss before: 1.82723470061e-05, loss after: 1.82723470061e-05.\n",
      "Epoch:11, weight train batch: 220, step:2, loss before: 1.73894750333e-05, loss after: 1.73633998202e-05.\n",
      "Epoch:11, weight train batch: 220, step:3, loss before: 1.63911136042e-05, loss after: 1.63911136042e-05.\n",
      "Epoch:11, weight train batch: 220, step:4, loss before: 1.68344140548e-05, loss after: 1.68008864421e-05.\n",
      "Epoch:11, weight train batch: 220, step:5, loss before: 1.66593199538e-05, loss after: 1.66593199538e-05.\n",
      "Epoch:11, weight train batch: 220, step:6, loss before: 3.81704230676e-05, loss after: 3.8136895455e-05.\n",
      "Epoch:11, weight train batch: 220, step:7, loss before: 1.59068185894e-05, loss after: 1.59068185894e-05.\n",
      "Epoch:11, weight train batch: 220, step:8, loss before: 3.53650066245e-05, loss after: 3.53426694346e-05.\n",
      "Epoch:11, weight train batch: 220, step:9, loss before: 1.35934551508e-05, loss after: 1.35748305183e-05.\n",
      "Epoch:11, weight train batch: 220, step:10, loss before: 1.84399723366e-05, loss after: 1.84399723366e-05.\n",
      "Epoch:11, weight train batch: 220, step:11, loss before: 1.87975711015e-05, loss after: 1.87975711015e-05.\n",
      "Epoch:11, weight train batch: 220, step:12, loss before: 1.78700156539e-05, loss after: 1.78402133315e-05.\n",
      "Epoch:11, weight train batch: 220, step:13, loss before: 1.84884065675e-05, loss after: 1.84884065675e-05.\n",
      "Epoch:11, weight train batch: 220, step:14, loss before: 1.66295194504e-05, loss after: 1.66295194504e-05.\n",
      "Epoch:11, weight train batch: 220, step:15, loss before: 1.37648294185e-05, loss after: 1.37126753543e-05.\n",
      "Epoch:11, weight train batch: 220, step:16, loss before: 1.73969146999e-05, loss after: 1.73969146999e-05.\n",
      "Epoch:11, weight train batch: 220, step:17, loss before: 1.65587280208e-05, loss after: 1.65587280208e-05.\n",
      "Epoch:11, weight train batch: 220, step:18, loss before: 1.60111449077e-05, loss after: 1.60111449077e-05.\n",
      "Epoch:11, weight train batch: 220, step:19, loss before: 1.58137008839e-05, loss after: 1.58137008839e-05.\n",
      "Epoch:11, weight train batch: 220, step:20, loss before: 1.80972565431e-05, loss after: 1.80674542207e-05.\n",
      "Epoch:11, weight train batch: 220, step:21, loss before: 1.37387469294e-05, loss after: 1.37238475872e-05.\n",
      "Epoch:11, weight train batch: 220, step:22, loss before: 1.53778455569e-05, loss after: 1.53778455569e-05.\n",
      "Epoch:11, weight train batch: 220, step:23, loss before: 1.49382722157e-05, loss after: 1.49382722157e-05.\n",
      "Epoch:11, weight train batch: 220, step:24, loss before: 1.80302085937e-05, loss after: 1.80153074325e-05.\n",
      "Epoch:11, weight train batch: 220, step:25, loss before: 1.75608201971e-05, loss after: 1.75608201971e-05.\n",
      "Epoch:11, weight train batch: 220, step:26, loss before: 1.71026149474e-05, loss after: 1.71026149474e-05.\n",
      "Epoch:11, weight train batch: 220, step:27, loss before: 2.05968735827e-05, loss after: 2.05782471312e-05.\n",
      "Epoch:11, weight train batch: 220, step:28, loss before: 1.54225381266e-05, loss after: 1.5377834643e-05.\n",
      "Epoch:11, weight train batch: 220, step:29, loss before: 1.82313797268e-05, loss after: 1.82313797268e-05.\n",
      "Epoch:11, weight train batch: 220, step:30, loss before: 1.60409254022e-05, loss after: 1.60409254022e-05.\n",
      "Epoch:11, weight train batch: 220, step:31, loss before: 1.72181062226e-05, loss after: 1.72181062226e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 216, loss before: 8.78365026438e-05, loss after: 1.70495040948e-05.\n",
      "Epoch:11, weight train batch: 221, step:0, loss before: 1.85889803106e-05, loss after: 1.85889803106e-05.\n",
      "Epoch:11, weight train batch: 221, step:1, loss before: 1.82164621947e-05, loss after: 1.82164621947e-05.\n",
      "Epoch:11, weight train batch: 221, step:2, loss before: 1.89764068637e-05, loss after: 1.89317033801e-05.\n",
      "Epoch:11, weight train batch: 221, step:3, loss before: 3.38269164786e-05, loss after: 3.37785022566e-05.\n",
      "Epoch:11, weight train batch: 221, step:4, loss before: 1.72218351508e-05, loss after: 1.72218351508e-05.\n",
      "Epoch:11, weight train batch: 221, step:5, loss before: 1.63315016835e-05, loss after: 1.63315016835e-05.\n",
      "Epoch:11, weight train batch: 221, step:6, loss before: 1.79743074114e-05, loss after: 1.79743074114e-05.\n",
      "Epoch:11, weight train batch: 221, step:7, loss before: 1.53443052113e-05, loss after: 1.53107794176e-05.\n",
      "Epoch:11, weight train batch: 221, step:8, loss before: 1.5590178009e-05, loss after: 1.5590178009e-05.\n",
      "Epoch:11, weight train batch: 221, step:9, loss before: 1.80153110705e-05, loss after: 1.79855087481e-05.\n",
      "Epoch:11, weight train batch: 221, step:10, loss before: 1.72105173988e-05, loss after: 1.72067921085e-05.\n",
      "Epoch:11, weight train batch: 221, step:11, loss before: 3.38766367349e-05, loss after: 3.38244935847e-05.\n",
      "Epoch:11, weight train batch: 221, step:12, loss before: 1.49121924551e-05, loss after: 1.49121924551e-05.\n",
      "Epoch:11, weight train batch: 221, step:13, loss before: 1.58919210662e-05, loss after: 1.58621187438e-05.\n",
      "Epoch:11, weight train batch: 221, step:14, loss before: 1.67412799783e-05, loss after: 1.67412799783e-05.\n",
      "Epoch:11, weight train batch: 221, step:15, loss before: 1.59217306646e-05, loss after: 1.59217306646e-05.\n",
      "Epoch:11, weight train batch: 221, step:16, loss before: 1.74527976924e-05, loss after: 1.74155466084e-05.\n",
      "Epoch:11, weight train batch: 221, step:17, loss before: 1.31874130602e-05, loss after: 1.31874130602e-05.\n",
      "Epoch:11, weight train batch: 221, step:18, loss before: 1.64060074894e-05, loss after: 1.64060074894e-05.\n",
      "Epoch:11, weight train batch: 221, step:19, loss before: 1.72255640791e-05, loss after: 1.71957617567e-05.\n",
      "Epoch:11, weight train batch: 221, step:20, loss before: 2.00455542654e-05, loss after: 2.00455542654e-05.\n",
      "Epoch:11, weight train batch: 221, step:21, loss before: 1.63836612046e-05, loss after: 1.63799359143e-05.\n",
      "Epoch:11, weight train batch: 221, step:22, loss before: 1.8443693989e-05, loss after: 1.8443693989e-05.\n",
      "Epoch:11, weight train batch: 221, step:23, loss before: 1.60595518537e-05, loss after: 1.60297495313e-05.\n",
      "Epoch:11, weight train batch: 221, step:24, loss before: 1.67673642864e-05, loss after: 1.67673642864e-05.\n",
      "Epoch:11, weight train batch: 221, step:25, loss before: 1.77731672011e-05, loss after: 1.77359142981e-05.\n",
      "Epoch:11, weight train batch: 221, step:26, loss before: 1.84735072253e-05, loss after: 1.84735072253e-05.\n",
      "Epoch:11, weight train batch: 221, step:27, loss before: 1.66444242495e-05, loss after: 1.65997225849e-05.\n",
      "Epoch:11, weight train batch: 221, step:28, loss before: 1.33364246722e-05, loss after: 1.33364246722e-05.\n",
      "Epoch:11, weight train batch: 221, step:29, loss before: 1.47296568684e-05, loss after: 1.47296568684e-05.\n",
      "Epoch:11, weight train batch: 221, step:30, loss before: 1.48600356624e-05, loss after: 1.48600356624e-05.\n",
      "Epoch:11, weight train batch: 221, step:31, loss before: 0.00292448350228, loss after: 0.00290401210077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 217, loss before: 0.00662614498287, loss after: 3.92936781282e-05.\n",
      "Epoch:11, weight train batch: 222, step:0, loss before: 1.4569483028e-05, loss after: 1.45359563248e-05.\n",
      "Epoch:11, weight train batch: 222, step:1, loss before: 1.4543396901e-05, loss after: 1.44875193655e-05.\n",
      "Epoch:11, weight train batch: 222, step:2, loss before: 1.42565577335e-05, loss after: 1.42565577335e-05.\n",
      "Epoch:11, weight train batch: 222, step:3, loss before: 1.54039189511e-05, loss after: 1.5377841919e-05.\n",
      "Epoch:11, weight train batch: 222, step:4, loss before: 1.4200672922e-05, loss after: 1.41708705996e-05.\n",
      "Epoch:11, weight train batch: 222, step:5, loss before: 1.81717678061e-05, loss after: 1.81717678061e-05.\n",
      "Epoch:11, weight train batch: 222, step:6, loss before: 1.63464064826e-05, loss after: 1.6301702999e-05.\n",
      "Epoch:11, weight train batch: 222, step:7, loss before: 1.83803676919e-05, loss after: 1.83803676919e-05.\n",
      "Epoch:11, weight train batch: 222, step:8, loss before: 1.43496763485e-05, loss after: 1.43496763485e-05.\n",
      "Epoch:11, weight train batch: 222, step:9, loss before: 1.81419563887e-05, loss after: 1.8108430595e-05.\n",
      "Epoch:11, weight train batch: 222, step:10, loss before: 1.61601456057e-05, loss after: 1.61601456057e-05.\n",
      "Epoch:11, weight train batch: 222, step:11, loss before: 1.60409435921e-05, loss after: 1.60409435921e-05.\n",
      "Epoch:11, weight train batch: 222, step:12, loss before: 1.73969165189e-05, loss after: 1.73745665961e-05.\n",
      "Epoch:11, weight train batch: 222, step:13, loss before: 1.44241876114e-05, loss after: 1.44018367791e-05.\n",
      "Epoch:11, weight train batch: 222, step:14, loss before: 1.42677345139e-05, loss after: 1.42677345139e-05.\n",
      "Epoch:11, weight train batch: 222, step:15, loss before: 1.731123848e-05, loss after: 1.731123848e-05.\n",
      "Epoch:11, weight train batch: 222, step:16, loss before: 1.57876256708e-05, loss after: 1.57876256708e-05.\n",
      "Epoch:11, weight train batch: 222, step:17, loss before: 1.7210650185e-05, loss after: 1.7210650185e-05.\n",
      "Epoch:11, weight train batch: 222, step:18, loss before: 1.70765142684e-05, loss after: 1.70727907971e-05.\n",
      "Epoch:11, weight train batch: 222, step:19, loss before: 1.33736848511e-05, loss after: 1.33736848511e-05.\n",
      "Epoch:11, weight train batch: 222, step:20, loss before: 1.80413881026e-05, loss after: 1.80041351996e-05.\n",
      "Epoch:11, weight train batch: 222, step:21, loss before: 1.52064931171e-05, loss after: 1.51841413754e-05.\n",
      "Epoch:11, weight train batch: 222, step:22, loss before: 1.50462947204e-05, loss after: 1.50462947204e-05.\n",
      "Epoch:11, weight train batch: 222, step:23, loss before: 1.59217343025e-05, loss after: 1.59217343025e-05.\n",
      "Epoch:11, weight train batch: 222, step:24, loss before: 2.18253571802e-05, loss after: 2.17955566768e-05.\n",
      "Epoch:11, weight train batch: 222, step:25, loss before: 1.46998463606e-05, loss after: 1.46998463606e-05.\n",
      "Epoch:11, weight train batch: 222, step:26, loss before: 8.42996305437e-05, loss after: 8.41620858409e-05.\n",
      "Epoch:11, weight train batch: 222, step:27, loss before: 1.37014903885e-05, loss after: 1.36567869049e-05.\n",
      "Epoch:11, weight train batch: 222, step:28, loss before: 1.82723379112e-05, loss after: 1.82239091373e-05.\n",
      "Epoch:11, weight train batch: 222, step:29, loss before: 1.44167324834e-05, loss after: 1.44167324834e-05.\n",
      "Epoch:11, weight train batch: 222, step:30, loss before: 1.55380348588e-05, loss after: 1.55380348588e-05.\n",
      "Epoch:11, weight train batch: 222, step:31, loss before: 1.60595700436e-05, loss after: 1.60595700436e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 218, loss before: 1.62745946e-05, loss after: 1.49447860167e-05.\n",
      "Epoch:11, weight train batch: 223, step:0, loss before: 1.42342059917e-05, loss after: 1.42342059917e-05.\n",
      "Epoch:11, weight train batch: 223, step:1, loss before: 1.42863545989e-05, loss after: 1.42863545989e-05.\n",
      "Epoch:11, weight train batch: 223, step:2, loss before: 1.61638781719e-05, loss after: 1.61638781719e-05.\n",
      "Epoch:11, weight train batch: 223, step:3, loss before: 1.42602775668e-05, loss after: 1.42379267345e-05.\n",
      "Epoch:11, weight train batch: 223, step:4, loss before: 1.51990361701e-05, loss after: 1.51990361701e-05.\n",
      "Epoch:11, weight train batch: 223, step:5, loss before: 2.01200309675e-05, loss after: 2.01163074962e-05.\n",
      "Epoch:11, weight train batch: 223, step:6, loss before: 1.56386104209e-05, loss after: 1.56125333888e-05.\n",
      "Epoch:11, weight train batch: 223, step:7, loss before: 1.3034676158e-05, loss after: 1.3034676158e-05.\n",
      "Epoch:11, weight train batch: 223, step:8, loss before: 1.4256547729e-05, loss after: 1.42341959872e-05.\n",
      "Epoch:11, weight train batch: 223, step:9, loss before: 1.88571975741e-05, loss after: 1.88571975741e-05.\n",
      "Epoch:11, weight train batch: 223, step:10, loss before: 1.58099719556e-05, loss after: 1.57801714522e-05.\n",
      "Epoch:11, weight train batch: 223, step:11, loss before: 1.81792202056e-05, loss after: 1.81792202056e-05.\n",
      "Epoch:11, weight train batch: 223, step:12, loss before: 1.4617902707e-05, loss after: 1.4617902707e-05.\n",
      "Epoch:11, weight train batch: 223, step:13, loss before: 1.3403480807e-05, loss after: 1.33699531943e-05.\n",
      "Epoch:11, weight train batch: 223, step:14, loss before: 1.45881003846e-05, loss after: 1.45881003846e-05.\n",
      "Epoch:11, weight train batch: 223, step:15, loss before: 1.32060322358e-05, loss after: 1.32060322358e-05.\n",
      "Epoch:11, weight train batch: 223, step:16, loss before: 1.3645605577e-05, loss after: 1.3645605577e-05.\n",
      "Epoch:11, weight train batch: 223, step:17, loss before: 1.49494444486e-05, loss after: 1.49084671648e-05.\n",
      "Epoch:11, weight train batch: 223, step:18, loss before: 1.67301022884e-05, loss after: 1.67301022884e-05.\n",
      "Epoch:11, weight train batch: 223, step:19, loss before: 1.75161276275e-05, loss after: 1.75161276275e-05.\n",
      "Epoch:11, weight train batch: 223, step:20, loss before: 1.52847242134e-05, loss after: 1.52847242134e-05.\n",
      "Epoch:11, weight train batch: 223, step:21, loss before: 1.332152533e-05, loss after: 1.332152533e-05.\n",
      "Epoch:11, weight train batch: 223, step:22, loss before: 1.69387094502e-05, loss after: 1.69387094502e-05.\n",
      "Epoch:11, weight train batch: 223, step:23, loss before: 2.18664499698e-05, loss after: 2.18664499698e-05.\n",
      "Epoch:11, weight train batch: 223, step:24, loss before: 1.34444489959e-05, loss after: 1.34220972541e-05.\n",
      "Epoch:11, weight train batch: 223, step:25, loss before: 0.000270548189292, loss after: 0.000269642623607.\n",
      "Epoch:11, weight train batch: 223, step:26, loss before: 1.50984460561e-05, loss after: 1.50984460561e-05.\n",
      "Epoch:11, weight train batch: 223, step:27, loss before: 0.000210388068808, loss after: 0.000210291473195.\n",
      "Epoch:11, weight train batch: 223, step:28, loss before: 1.47892587847e-05, loss after: 1.47892587847e-05.\n",
      "Epoch:11, weight train batch: 223, step:29, loss before: 1.31278065965e-05, loss after: 1.30942808028e-05.\n",
      "Epoch:11, weight train batch: 223, step:30, loss before: 1.64693356055e-05, loss after: 1.64693356055e-05.\n",
      "Epoch:11, weight train batch: 223, step:31, loss before: 1.53256914928e-05, loss after: 1.53256914928e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 219, loss before: 1.40311731229e-05, loss after: 1.40339670907e-05.\n",
      "Epoch:11, weight train batch: 224, step:0, loss before: 1.53443215822e-05, loss after: 1.5303343389e-05.\n",
      "Epoch:11, weight train batch: 224, step:1, loss before: 1.33699504659e-05, loss after: 1.33364228532e-05.\n",
      "Epoch:11, weight train batch: 224, step:2, loss before: 0.00183113873936, loss after: 0.00182640610728.\n",
      "Epoch:11, weight train batch: 224, step:3, loss before: 1.3757369743e-05, loss after: 1.37536444527e-05.\n",
      "Epoch:11, weight train batch: 224, step:4, loss before: 1.68418573594e-05, loss after: 1.68195056176e-05.\n",
      "Epoch:11, weight train batch: 224, step:5, loss before: 1.41373493534e-05, loss after: 1.41038217407e-05.\n",
      "Epoch:11, weight train batch: 224, step:6, loss before: 1.28186147776e-05, loss after: 1.27776365844e-05.\n",
      "Epoch:11, weight train batch: 224, step:7, loss before: 1.34928795887e-05, loss after: 1.34705278469e-05.\n",
      "Epoch:11, weight train batch: 224, step:8, loss before: 1.26360764625e-05, loss after: 1.26360764625e-05.\n",
      "Epoch:11, weight train batch: 224, step:9, loss before: 1.51394306158e-05, loss after: 1.5117078874e-05.\n",
      "Epoch:11, weight train batch: 224, step:10, loss before: 1.44763498611e-05, loss after: 1.44130208355e-05.\n",
      "Epoch:11, weight train batch: 224, step:11, loss before: 1.49680481627e-05, loss after: 1.49643228724e-05.\n",
      "Epoch:11, weight train batch: 224, step:12, loss before: 1.28744923131e-05, loss after: 1.28744923131e-05.\n",
      "Epoch:11, weight train batch: 224, step:13, loss before: 1.50202231453e-05, loss after: 1.49866964421e-05.\n",
      "Epoch:11, weight train batch: 224, step:14, loss before: 1.7422991732e-05, loss after: 1.7422991732e-05.\n",
      "Epoch:11, weight train batch: 224, step:15, loss before: 1.53443106683e-05, loss after: 1.53443106683e-05.\n",
      "Epoch:11, weight train batch: 224, step:16, loss before: 2.81669235846e-05, loss after: 2.81036009255e-05.\n",
      "Epoch:11, weight train batch: 224, step:17, loss before: 1.4904746422e-05, loss after: 1.4904746422e-05.\n",
      "Epoch:11, weight train batch: 224, step:18, loss before: 1.45508529386e-05, loss after: 1.45173253259e-05.\n",
      "Epoch:11, weight train batch: 224, step:19, loss before: 1.49941479322e-05, loss after: 1.49941479322e-05.\n",
      "Epoch:11, weight train batch: 224, step:20, loss before: 2.83233512164e-05, loss after: 2.83047338598e-05.\n",
      "Epoch:11, weight train batch: 224, step:21, loss before: 1.59328938025e-05, loss after: 1.59328938025e-05.\n",
      "Epoch:11, weight train batch: 224, step:22, loss before: 2.11064889299e-05, loss after: 2.10804137168e-05.\n",
      "Epoch:11, weight train batch: 224, step:23, loss before: 1.35934624268e-05, loss after: 1.35934624268e-05.\n",
      "Epoch:11, weight train batch: 224, step:24, loss before: 1.9117967895e-05, loss after: 1.90583632502e-05.\n",
      "Epoch:11, weight train batch: 224, step:25, loss before: 1.30682010422e-05, loss after: 1.30682010422e-05.\n",
      "Epoch:11, weight train batch: 224, step:26, loss before: 1.44577152241e-05, loss after: 1.44204632306e-05.\n",
      "Epoch:11, weight train batch: 224, step:27, loss before: 1.68008755281e-05, loss after: 1.68008755281e-05.\n",
      "Epoch:11, weight train batch: 224, step:28, loss before: 1.5366673324e-05, loss after: 1.5366673324e-05.\n",
      "Epoch:11, weight train batch: 224, step:29, loss before: 1.38579553095e-05, loss after: 1.38579553095e-05.\n",
      "Epoch:11, weight train batch: 224, step:30, loss before: 1.87752448255e-05, loss after: 1.87528930837e-05.\n",
      "Epoch:11, weight train batch: 224, step:31, loss before: 1.73075168277e-05, loss after: 1.72665404534e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 220, loss before: 1.43403722177e-05, loss after: 1.43394408951e-05.\n",
      "Epoch:11, weight train batch: 225, step:0, loss before: 1.50947307702e-05, loss after: 1.50947307702e-05.\n",
      "Epoch:11, weight train batch: 225, step:1, loss before: 1.45508429341e-05, loss after: 1.45508429341e-05.\n",
      "Epoch:11, weight train batch: 225, step:2, loss before: 1.54747067427e-05, loss after: 1.54747067427e-05.\n",
      "Epoch:11, weight train batch: 225, step:3, loss before: 1.34854308271e-05, loss after: 1.34854308271e-05.\n",
      "Epoch:11, weight train batch: 225, step:4, loss before: 1.43720317283e-05, loss after: 1.43720317283e-05.\n",
      "Epoch:11, weight train batch: 225, step:5, loss before: 1.33475896291e-05, loss after: 1.33475896291e-05.\n",
      "Epoch:11, weight train batch: 225, step:6, loss before: 1.55976340466e-05, loss after: 1.55641064339e-05.\n",
      "Epoch:11, weight train batch: 225, step:7, loss before: 1.40442189149e-05, loss after: 1.39883413794e-05.\n",
      "Epoch:11, weight train batch: 225, step:8, loss before: 1.47780801854e-05, loss after: 1.47780801854e-05.\n",
      "Epoch:11, weight train batch: 225, step:9, loss before: 1.34370038722e-05, loss after: 1.34370038722e-05.\n",
      "Epoch:11, weight train batch: 225, step:10, loss before: 1.22300243675e-05, loss after: 1.22002220451e-05.\n",
      "Epoch:11, weight train batch: 225, step:11, loss before: 1.64656048582e-05, loss after: 1.64656048582e-05.\n",
      "Epoch:11, weight train batch: 225, step:12, loss before: 1.28856599986e-05, loss after: 1.28856599986e-05.\n",
      "Epoch:11, weight train batch: 225, step:13, loss before: 1.52549109771e-05, loss after: 1.52213860929e-05.\n",
      "Epoch:11, weight train batch: 225, step:14, loss before: 1.48414092109e-05, loss after: 1.48414092109e-05.\n",
      "Epoch:11, weight train batch: 225, step:15, loss before: 1.35450354719e-05, loss after: 1.35450354719e-05.\n",
      "Epoch:11, weight train batch: 225, step:16, loss before: 1.59813280334e-05, loss after: 1.59813280334e-05.\n",
      "Epoch:11, weight train batch: 225, step:17, loss before: 0.000106494429929, loss after: 0.000106453575427.\n",
      "Epoch:11, weight train batch: 225, step:18, loss before: 1.28446936287e-05, loss after: 1.28074407257e-05.\n",
      "Epoch:11, weight train batch: 225, step:19, loss before: 1.42081262311e-05, loss after: 1.41820501085e-05.\n",
      "Epoch:11, weight train batch: 225, step:20, loss before: 1.46104484884e-05, loss after: 1.46104484884e-05.\n",
      "Epoch:11, weight train batch: 225, step:21, loss before: 3.14262724714e-05, loss after: 3.14151038765e-05.\n",
      "Epoch:11, weight train batch: 225, step:22, loss before: 1.42453800436e-05, loss after: 1.42453800436e-05.\n",
      "Epoch:11, weight train batch: 225, step:23, loss before: 1.43981051224e-05, loss after: 1.43981051224e-05.\n",
      "Epoch:11, weight train batch: 225, step:24, loss before: 1.42118578879e-05, loss after: 1.41895070556e-05.\n",
      "Epoch:11, weight train batch: 225, step:25, loss before: 0.00277720950544, loss after: 0.00277410959825.\n",
      "Epoch:11, weight train batch: 225, step:26, loss before: 1.59775972861e-05, loss after: 1.59775972861e-05.\n",
      "Epoch:11, weight train batch: 225, step:27, loss before: 1.36344378916e-05, loss after: 1.36120870593e-05.\n",
      "Epoch:11, weight train batch: 225, step:28, loss before: 1.26025515783e-05, loss after: 1.25727492559e-05.\n",
      "Epoch:11, weight train batch: 225, step:29, loss before: 2.02012961381e-05, loss after: 2.01863986149e-05.\n",
      "Epoch:11, weight train batch: 225, step:30, loss before: 2.92768836516e-05, loss after: 2.92619897664e-05.\n",
      "Epoch:11, weight train batch: 225, step:31, loss before: 1.44577143146e-05, loss after: 1.44241876114e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 221, loss before: 7.2005437687e-05, loss after: 1.95320644707e-05.\n",
      "Epoch:11, weight train batch: 226, step:0, loss before: 1.57950598805e-05, loss after: 1.57950598805e-05.\n",
      "Epoch:11, weight train batch: 226, step:1, loss before: 1.46663296618e-05, loss after: 1.46663296618e-05.\n",
      "Epoch:11, weight train batch: 226, step:2, loss before: 1.39659859997e-05, loss after: 1.39659859997e-05.\n",
      "Epoch:11, weight train batch: 226, step:3, loss before: 2.98683044093e-05, loss after: 2.98496888718e-05.\n",
      "Epoch:11, weight train batch: 226, step:4, loss before: 1.48786739373e-05, loss after: 1.48637727762e-05.\n",
      "Epoch:11, weight train batch: 226, step:5, loss before: 1.61340576597e-05, loss after: 1.60930812854e-05.\n",
      "Epoch:11, weight train batch: 226, step:6, loss before: 1.2885671822e-05, loss after: 1.2885671822e-05.\n",
      "Epoch:11, weight train batch: 226, step:7, loss before: 1.49084607983e-05, loss after: 1.49084607983e-05.\n",
      "Epoch:11, weight train batch: 226, step:8, loss before: 1.26286231534e-05, loss after: 1.26286231534e-05.\n",
      "Epoch:11, weight train batch: 226, step:9, loss before: 1.52251132022e-05, loss after: 1.52251132022e-05.\n",
      "Epoch:11, weight train batch: 226, step:10, loss before: 1.51096355694e-05, loss after: 1.50798341565e-05.\n",
      "Epoch:11, weight train batch: 226, step:11, loss before: 1.44986934174e-05, loss after: 1.44986934174e-05.\n",
      "Epoch:11, weight train batch: 226, step:12, loss before: 0.00272457348183, loss after: 0.00271971221082.\n",
      "Epoch:11, weight train batch: 226, step:13, loss before: 0.0237890891731, loss after: 0.0237287487835.\n",
      "Epoch:11, weight train batch: 226, step:14, loss before: 1.15259626909e-05, loss after: 1.16153696581e-05.\n",
      "Epoch:11, weight train batch: 226, step:15, loss before: 1.29378204292e-05, loss after: 1.30011494548e-05.\n",
      "Epoch:11, weight train batch: 226, step:16, loss before: 1.24200105347e-05, loss after: 1.24535363284e-05.\n",
      "Epoch:11, weight train batch: 226, step:17, loss before: 1.54970512085e-05, loss after: 1.55268535309e-05.\n",
      "Epoch:11, weight train batch: 226, step:18, loss before: 1.6562466044e-05, loss after: 1.65773653862e-05.\n",
      "Epoch:11, weight train batch: 226, step:19, loss before: 1.66891240951e-05, loss after: 1.66891240951e-05.\n",
      "Epoch:11, weight train batch: 226, step:20, loss before: 1.4867488062e-05, loss after: 1.48972903844e-05.\n",
      "Epoch:11, weight train batch: 226, step:21, loss before: 1.35562177093e-05, loss after: 1.35748441608e-05.\n",
      "Epoch:11, weight train batch: 226, step:22, loss before: 1.42341996252e-05, loss after: 1.42341996252e-05.\n",
      "Epoch:11, weight train batch: 226, step:23, loss before: 0.00013264323934, loss after: 0.000132773522637.\n",
      "Epoch:11, weight train batch: 226, step:24, loss before: 1.95202992472e-05, loss after: 1.95202992472e-05.\n",
      "Epoch:11, weight train batch: 226, step:25, loss before: 1.62793567142e-05, loss after: 1.62793567142e-05.\n",
      "Epoch:11, weight train batch: 226, step:26, loss before: 1.30458538479e-05, loss after: 1.30868302222e-05.\n",
      "Epoch:11, weight train batch: 226, step:27, loss before: 1.13881278594e-05, loss after: 1.13881278594e-05.\n",
      "Epoch:11, weight train batch: 226, step:28, loss before: 1.22449328046e-05, loss after: 1.22300316434e-05.\n",
      "Epoch:11, weight train batch: 226, step:29, loss before: 1.50910000229e-05, loss after: 1.50910000229e-05.\n",
      "Epoch:11, weight train batch: 226, step:30, loss before: 1.60558374773e-05, loss after: 1.60819145094e-05.\n",
      "Epoch:11, weight train batch: 226, step:31, loss before: 0.0227685905993, loss after: 0.0227073747665.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 222, loss before: 1.37406150316e-05, loss after: 1.47035370901e-05.\n",
      "Epoch:11, weight train batch: 227, step:0, loss before: 1.31203578349e-05, loss after: 1.31203578349e-05.\n",
      "Epoch:11, weight train batch: 227, step:1, loss before: 1.43534125527e-05, loss after: 1.43273355206e-05.\n",
      "Epoch:11, weight train batch: 227, step:2, loss before: 1.41634154716e-05, loss after: 1.41224372783e-05.\n",
      "Epoch:11, weight train batch: 227, step:3, loss before: 1.52958837134e-05, loss after: 1.52958837134e-05.\n",
      "Epoch:11, weight train batch: 227, step:4, loss before: 2.99471284961e-05, loss after: 2.99508501485e-05.\n",
      "Epoch:11, weight train batch: 227, step:5, loss before: 1.48637591337e-05, loss after: 1.48637591337e-05.\n",
      "Epoch:11, weight train batch: 227, step:6, loss before: 1.40442216434e-05, loss after: 1.40218708111e-05.\n",
      "Epoch:11, weight train batch: 227, step:7, loss before: 1.57540907821e-05, loss after: 1.57540907821e-05.\n",
      "Epoch:11, weight train batch: 227, step:8, loss before: 1.61452517204e-05, loss after: 1.61452517204e-05.\n",
      "Epoch:11, weight train batch: 227, step:9, loss before: 1.43422239489e-05, loss after: 1.43422239489e-05.\n",
      "Epoch:11, weight train batch: 227, step:10, loss before: 1.53964756464e-05, loss after: 1.53964756464e-05.\n",
      "Epoch:11, weight train batch: 227, step:11, loss before: 1.72590807779e-05, loss after: 1.72590807779e-05.\n",
      "Epoch:11, weight train batch: 227, step:12, loss before: 1.53219698404e-05, loss after: 1.52884458657e-05.\n",
      "Epoch:11, weight train batch: 227, step:13, loss before: 1.42044091263e-05, loss after: 1.42044091263e-05.\n",
      "Epoch:11, weight train batch: 227, step:14, loss before: 1.35301370392e-05, loss after: 1.34966094265e-05.\n",
      "Epoch:11, weight train batch: 227, step:15, loss before: 1.60222843988e-05, loss after: 1.60222843988e-05.\n",
      "Epoch:11, weight train batch: 227, step:16, loss before: 1.53070759552e-05, loss after: 1.53070759552e-05.\n",
      "Epoch:11, weight train batch: 227, step:17, loss before: 1.40404836202e-05, loss after: 1.40404836202e-05.\n",
      "Epoch:11, weight train batch: 227, step:18, loss before: 1.39212797876e-05, loss after: 1.38914783747e-05.\n",
      "Epoch:11, weight train batch: 227, step:19, loss before: 1.57689992193e-05, loss after: 1.57689992193e-05.\n",
      "Epoch:11, weight train batch: 227, step:20, loss before: 1.51766835188e-05, loss after: 1.51766835188e-05.\n",
      "Epoch:11, weight train batch: 227, step:21, loss before: 1.34556321427e-05, loss after: 1.34556321427e-05.\n",
      "Epoch:11, weight train batch: 227, step:22, loss before: 1.47967166413e-05, loss after: 1.47967166413e-05.\n",
      "Epoch:11, weight train batch: 227, step:23, loss before: 0.000274769874522, loss after: 0.000273565063253.\n",
      "Epoch:11, weight train batch: 227, step:24, loss before: 1.42714507092e-05, loss after: 1.42155722642e-05.\n",
      "Epoch:11, weight train batch: 227, step:25, loss before: 1.42975331983e-05, loss after: 1.42975331983e-05.\n",
      "Epoch:11, weight train batch: 227, step:26, loss before: 1.56197984325e-05, loss after: 1.55862708198e-05.\n",
      "Epoch:11, weight train batch: 227, step:27, loss before: 1.53815781232e-05, loss after: 1.53815781232e-05.\n",
      "Epoch:11, weight train batch: 227, step:28, loss before: 1.66556055774e-05, loss after: 1.66183526744e-05.\n",
      "Epoch:11, weight train batch: 227, step:29, loss before: 1.24200123537e-05, loss after: 1.24200123537e-05.\n",
      "Epoch:11, weight train batch: 227, step:30, loss before: 1.28521414808e-05, loss after: 1.27999883262e-05.\n",
      "Epoch:11, weight train batch: 227, step:31, loss before: 0.00172321673017, loss after: 0.00171865022276.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 223, loss before: 9.56410513027e-05, loss after: 1.36269954965e-05.\n",
      "Epoch:11, weight train batch: 228, step:0, loss before: 1.47371083585e-05, loss after: 1.46998554555e-05.\n",
      "Epoch:11, weight train batch: 228, step:1, loss before: 1.16824212455e-05, loss after: 1.16824212455e-05.\n",
      "Epoch:11, weight train batch: 228, step:2, loss before: 1.53927503561e-05, loss after: 1.53629480337e-05.\n",
      "Epoch:11, weight train batch: 228, step:3, loss before: 1.28819492602e-05, loss after: 1.28819492602e-05.\n",
      "Epoch:11, weight train batch: 228, step:4, loss before: 3.27399975504e-05, loss after: 3.26766930812e-05.\n",
      "Epoch:11, weight train batch: 228, step:5, loss before: 1.41485188578e-05, loss after: 1.41485188578e-05.\n",
      "Epoch:11, weight train batch: 228, step:6, loss before: 1.40553875099e-05, loss after: 1.40553875099e-05.\n",
      "Epoch:11, weight train batch: 228, step:7, loss before: 1.35115096782e-05, loss after: 1.34481797431e-05.\n",
      "Epoch:11, weight train batch: 228, step:8, loss before: 1.51617887241e-05, loss after: 1.51282620209e-05.\n",
      "Epoch:11, weight train batch: 228, step:9, loss before: 1.2561573385e-05, loss after: 1.2561573385e-05.\n",
      "Epoch:11, weight train batch: 228, step:10, loss before: 1.11869676402e-05, loss after: 1.11869676402e-05.\n",
      "Epoch:11, weight train batch: 228, step:11, loss before: 1.38803061418e-05, loss after: 1.38467794386e-05.\n",
      "Epoch:11, weight train batch: 228, step:12, loss before: 1.38168716148e-05, loss after: 1.38168716148e-05.\n",
      "Epoch:11, weight train batch: 228, step:13, loss before: 1.24200196296e-05, loss after: 1.24200196296e-05.\n",
      "Epoch:11, weight train batch: 228, step:14, loss before: 1.44390951391e-05, loss after: 1.4413018107e-05.\n",
      "Epoch:11, weight train batch: 228, step:15, loss before: 1.39063831739e-05, loss after: 1.39063831739e-05.\n",
      "Epoch:11, weight train batch: 228, step:16, loss before: 1.50164996739e-05, loss after: 1.49568968482e-05.\n",
      "Epoch:11, weight train batch: 228, step:17, loss before: 1.34817037178e-05, loss after: 1.34817037178e-05.\n",
      "Epoch:11, weight train batch: 228, step:18, loss before: 1.4219300283e-05, loss after: 1.4219300283e-05.\n",
      "Epoch:11, weight train batch: 228, step:19, loss before: 1.76085759449e-05, loss after: 1.76048524736e-05.\n",
      "Epoch:11, weight train batch: 228, step:20, loss before: 0.00168047228362, loss after: 0.00167561578564.\n",
      "Epoch:11, weight train batch: 228, step:21, loss before: 1.47594628288e-05, loss after: 1.4718485545e-05.\n",
      "Epoch:11, weight train batch: 228, step:22, loss before: 1.55864563567e-05, loss after: 1.55566558533e-05.\n",
      "Epoch:11, weight train batch: 228, step:23, loss before: 1.2885666365e-05, loss after: 1.28633155327e-05.\n",
      "Epoch:11, weight train batch: 228, step:24, loss before: 3.01220061374e-05, loss after: 3.0043804145e-05.\n",
      "Epoch:11, weight train batch: 228, step:25, loss before: 1.21927787404e-05, loss after: 1.21927787404e-05.\n",
      "Epoch:11, weight train batch: 228, step:26, loss before: 1.36493408718e-05, loss after: 1.36493408718e-05.\n",
      "Epoch:11, weight train batch: 228, step:27, loss before: 2.74585472653e-05, loss after: 2.73877885775e-05.\n",
      "Epoch:11, weight train batch: 228, step:28, loss before: 1.43496890814e-05, loss after: 1.43496890814e-05.\n",
      "Epoch:11, weight train batch: 228, step:29, loss before: 1.17234048957e-05, loss after: 1.17234048957e-05.\n",
      "Epoch:11, weight train batch: 228, step:30, loss before: 1.34332804009e-05, loss after: 1.33923022076e-05.\n",
      "Epoch:11, weight train batch: 228, step:31, loss before: 1.60819163284e-05, loss after: 1.60819163284e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 224, loss before: 0.00553926546127, loss after: 1.39604017022e-05.\n",
      "Epoch:11, weight train batch: 229, step:0, loss before: 1.67189264175e-05, loss after: 1.67189264175e-05.\n",
      "Epoch:11, weight train batch: 229, step:1, loss before: 1.09262000478e-05, loss after: 1.08926724351e-05.\n",
      "Epoch:11, weight train batch: 229, step:2, loss before: 1.59180053743e-05, loss after: 1.58546772582e-05.\n",
      "Epoch:11, weight train batch: 229, step:3, loss before: 1.57838876476e-05, loss after: 1.57838876476e-05.\n",
      "Epoch:11, weight train batch: 229, step:4, loss before: 0.000116018658446, loss after: 0.000115777285828.\n",
      "Epoch:11, weight train batch: 229, step:5, loss before: 1.48376893776e-05, loss after: 1.48376893776e-05.\n",
      "Epoch:11, weight train batch: 229, step:6, loss before: 1.38803079608e-05, loss after: 1.38803079608e-05.\n",
      "Epoch:11, weight train batch: 229, step:7, loss before: 1.31613214762e-05, loss after: 1.31575961859e-05.\n",
      "Epoch:11, weight train batch: 229, step:8, loss before: 1.35599311761e-05, loss after: 1.35599311761e-05.\n",
      "Epoch:11, weight train batch: 229, step:9, loss before: 0.022099500522, loss after: 0.0220552459359.\n",
      "Epoch:11, weight train batch: 229, step:10, loss before: 1.48153394548e-05, loss after: 1.47780865518e-05.\n",
      "Epoch:11, weight train batch: 229, step:11, loss before: 1.3932462025e-05, loss after: 1.3932462025e-05.\n",
      "Epoch:11, weight train batch: 229, step:12, loss before: 1.52325537783e-05, loss after: 1.51990261656e-05.\n",
      "Epoch:11, weight train batch: 229, step:13, loss before: 1.20027916637e-05, loss after: 1.20027916637e-05.\n",
      "Epoch:11, weight train batch: 229, step:14, loss before: 1.1663787518e-05, loss after: 1.16414357763e-05.\n",
      "Epoch:11, weight train batch: 229, step:15, loss before: 1.35934633363e-05, loss after: 1.35934633363e-05.\n",
      "Epoch:11, weight train batch: 229, step:16, loss before: 1.35971840791e-05, loss after: 1.35971840791e-05.\n",
      "Epoch:11, weight train batch: 229, step:17, loss before: 1.33811190608e-05, loss after: 1.33811190608e-05.\n",
      "Epoch:11, weight train batch: 229, step:18, loss before: 1.44130117405e-05, loss after: 1.44130117405e-05.\n",
      "Epoch:11, weight train batch: 229, step:19, loss before: 1.38877603604e-05, loss after: 1.38877603604e-05.\n",
      "Epoch:11, weight train batch: 229, step:20, loss before: 2.71686440101e-05, loss after: 2.7142570616e-05.\n",
      "Epoch:11, weight train batch: 229, step:21, loss before: 1.26845006889e-05, loss after: 1.26845006889e-05.\n",
      "Epoch:11, weight train batch: 229, step:22, loss before: 1.2811164197e-05, loss after: 1.2811164197e-05.\n",
      "Epoch:11, weight train batch: 229, step:23, loss before: 1.41596992762e-05, loss after: 1.41596992762e-05.\n",
      "Epoch:11, weight train batch: 229, step:24, loss before: 1.37536453622e-05, loss after: 1.37238430398e-05.\n",
      "Epoch:11, weight train batch: 229, step:25, loss before: 1.39399035106e-05, loss after: 1.39399035106e-05.\n",
      "Epoch:11, weight train batch: 229, step:26, loss before: 1.49904271893e-05, loss after: 1.49904271893e-05.\n",
      "Epoch:11, weight train batch: 229, step:27, loss before: 2.51527981163e-05, loss after: 2.51416240644e-05.\n",
      "Epoch:11, weight train batch: 229, step:28, loss before: 1.31315273393e-05, loss after: 1.31315273393e-05.\n",
      "Epoch:11, weight train batch: 229, step:29, loss before: 1.41783220897e-05, loss after: 1.41783220897e-05.\n",
      "Epoch:11, weight train batch: 229, step:30, loss before: 1.29639047373e-05, loss after: 1.29639047373e-05.\n",
      "Epoch:11, weight train batch: 229, step:31, loss before: 1.48302378875e-05, loss after: 1.48302378875e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 225, loss before: 1.37992856253e-05, loss after: 1.38002169479e-05.\n",
      "Epoch:11, weight train batch: 230, step:0, loss before: 1.42789076563e-05, loss after: 1.42789076563e-05.\n",
      "Epoch:11, weight train batch: 230, step:1, loss before: 1.35040536406e-05, loss after: 1.35040536406e-05.\n",
      "Epoch:11, weight train batch: 230, step:2, loss before: 1.1756920685e-05, loss after: 1.1663789337e-05.\n",
      "Epoch:11, weight train batch: 230, step:3, loss before: 1.36120916068e-05, loss after: 1.36120916068e-05.\n",
      "Epoch:11, weight train batch: 230, step:4, loss before: 1.12875477498e-05, loss after: 1.12875477498e-05.\n",
      "Epoch:11, weight train batch: 230, step:5, loss before: 1.48153412738e-05, loss after: 1.48153412738e-05.\n",
      "Epoch:11, weight train batch: 230, step:6, loss before: 1.31203623823e-05, loss after: 1.31203623823e-05.\n",
      "Epoch:11, weight train batch: 230, step:7, loss before: 1.33103421831e-05, loss after: 1.33103421831e-05.\n",
      "Epoch:11, weight train batch: 230, step:8, loss before: 1.32060376927e-05, loss after: 1.32060376927e-05.\n",
      "Epoch:11, weight train batch: 230, step:9, loss before: 1.21033754112e-05, loss after: 1.21033754112e-05.\n",
      "Epoch:11, weight train batch: 230, step:10, loss before: 1.29527252284e-05, loss after: 1.29266481963e-05.\n",
      "Epoch:11, weight train batch: 230, step:11, loss before: 1.50462983584e-05, loss after: 1.50462983584e-05.\n",
      "Epoch:11, weight train batch: 230, step:12, loss before: 1.21778666653e-05, loss after: 1.21368893815e-05.\n",
      "Epoch:11, weight train batch: 230, step:13, loss before: 1.28819501697e-05, loss after: 1.28819501697e-05.\n",
      "Epoch:11, weight train batch: 230, step:14, loss before: 1.19171072583e-05, loss after: 1.19171072583e-05.\n",
      "Epoch:11, weight train batch: 230, step:15, loss before: 1.26509758047e-05, loss after: 1.26509758047e-05.\n",
      "Epoch:11, weight train batch: 230, step:16, loss before: 1.1201866073e-05, loss after: 1.1201866073e-05.\n",
      "Epoch:11, weight train batch: 230, step:17, loss before: 1.21331731862e-05, loss after: 1.21331731862e-05.\n",
      "Epoch:11, weight train batch: 230, step:18, loss before: 1.53256787598e-05, loss after: 1.52884276758e-05.\n",
      "Epoch:11, weight train batch: 230, step:19, loss before: 1.17904528452e-05, loss after: 1.17904528452e-05.\n",
      "Epoch:11, weight train batch: 230, step:20, loss before: 1.54746994667e-05, loss after: 1.54746994667e-05.\n",
      "Epoch:11, weight train batch: 230, step:21, loss before: 1.22449182527e-05, loss after: 1.22449182527e-05.\n",
      "Epoch:11, weight train batch: 230, step:22, loss before: 1.5441171854e-05, loss after: 1.5441171854e-05.\n",
      "Epoch:11, weight train batch: 230, step:23, loss before: 1.19841588457e-05, loss after: 1.19841588457e-05.\n",
      "Epoch:11, weight train batch: 230, step:24, loss before: 1.21666962514e-05, loss after: 1.21331695482e-05.\n",
      "Epoch:11, weight train batch: 230, step:25, loss before: 1.24609914565e-05, loss after: 1.24609914565e-05.\n",
      "Epoch:11, weight train batch: 230, step:26, loss before: 1.18873022075e-05, loss after: 1.18612251754e-05.\n",
      "Epoch:11, weight train batch: 230, step:27, loss before: 1.21666926134e-05, loss after: 1.21666926134e-05.\n",
      "Epoch:11, weight train batch: 230, step:28, loss before: 1.24349171529e-05, loss after: 1.24349171529e-05.\n",
      "Epoch:11, weight train batch: 230, step:29, loss before: 1.26062741401e-05, loss after: 1.26062741401e-05.\n",
      "Epoch:11, weight train batch: 230, step:30, loss before: 1.17420267998e-05, loss after: 1.17420267998e-05.\n",
      "Epoch:11, weight train batch: 230, step:31, loss before: 1.63016156876e-05, loss after: 1.63016156876e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 226, loss before: 1.30048756546e-05, loss after: 1.29694863062e-05.\n",
      "Epoch:11, weight train batch: 231, step:0, loss before: 1.37834567795e-05, loss after: 1.37834567795e-05.\n",
      "Epoch:11, weight train batch: 231, step:1, loss before: 1.36865901368e-05, loss after: 1.36865901368e-05.\n",
      "Epoch:11, weight train batch: 231, step:2, loss before: 2.68670955847e-05, loss after: 2.68298481387e-05.\n",
      "Epoch:11, weight train batch: 231, step:3, loss before: 1.31613332996e-05, loss after: 1.31613332996e-05.\n",
      "Epoch:11, weight train batch: 231, step:4, loss before: 1.27292114485e-05, loss after: 1.26956856548e-05.\n",
      "Epoch:11, weight train batch: 231, step:5, loss before: 1.11571653179e-05, loss after: 1.11571653179e-05.\n",
      "Epoch:11, weight train batch: 231, step:6, loss before: 1.14589029181e-05, loss after: 1.14589029181e-05.\n",
      "Epoch:11, weight train batch: 231, step:7, loss before: 1.27999865072e-05, loss after: 1.27999865072e-05.\n",
      "Epoch:11, weight train batch: 231, step:8, loss before: 1.16675255413e-05, loss after: 1.16675255413e-05.\n",
      "Epoch:11, weight train batch: 231, step:9, loss before: 1.54523550009e-05, loss after: 1.54523550009e-05.\n",
      "Epoch:11, weight train batch: 231, step:10, loss before: 1.38207042255e-05, loss after: 1.37871784318e-05.\n",
      "Epoch:11, weight train batch: 231, step:11, loss before: 1.24200114442e-05, loss after: 1.24200114442e-05.\n",
      "Epoch:11, weight train batch: 231, step:12, loss before: 7.15205896995e-05, loss after: 7.14127672836e-05.\n",
      "Epoch:11, weight train batch: 231, step:13, loss before: 1.38020704981e-05, loss after: 1.37983452078e-05.\n",
      "Epoch:11, weight train batch: 231, step:14, loss before: 1.21331704577e-05, loss after: 1.21331704577e-05.\n",
      "Epoch:11, weight train batch: 231, step:15, loss before: 2.81747088593e-05, loss after: 2.81411848846e-05.\n",
      "Epoch:11, weight train batch: 231, step:16, loss before: 1.17345771287e-05, loss after: 1.17345771287e-05.\n",
      "Epoch:11, weight train batch: 231, step:17, loss before: 1.30086036734e-05, loss after: 1.30086036734e-05.\n",
      "Epoch:11, weight train batch: 231, step:18, loss before: 1.21480716189e-05, loss after: 1.20661161418e-05.\n",
      "Epoch:11, weight train batch: 231, step:19, loss before: 1.46216298162e-05, loss after: 1.46216298162e-05.\n",
      "Epoch:11, weight train batch: 231, step:20, loss before: 1.41782984429e-05, loss after: 1.41782984429e-05.\n",
      "Epoch:11, weight train batch: 231, step:21, loss before: 1.38095256261e-05, loss after: 1.38095256261e-05.\n",
      "Epoch:11, weight train batch: 231, step:22, loss before: 1.47631835716e-05, loss after: 1.47631835716e-05.\n",
      "Epoch:11, weight train batch: 231, step:23, loss before: 1.08293470475e-05, loss after: 1.08293470475e-05.\n",
      "Epoch:11, weight train batch: 231, step:24, loss before: 1.5146601072e-05, loss after: 1.51428776007e-05.\n",
      "Epoch:11, weight train batch: 231, step:25, loss before: 1.43496763485e-05, loss after: 1.43496763485e-05.\n",
      "Epoch:11, weight train batch: 231, step:26, loss before: 1.32209306685e-05, loss after: 1.31799524752e-05.\n",
      "Epoch:11, weight train batch: 231, step:27, loss before: 1.4562020624e-05, loss after: 1.4562020624e-05.\n",
      "Epoch:11, weight train batch: 231, step:28, loss before: 1.05387680378e-05, loss after: 1.05387680378e-05.\n",
      "Epoch:11, weight train batch: 231, step:29, loss before: 1.26584345708e-05, loss after: 1.26584345708e-05.\n",
      "Epoch:11, weight train batch: 231, step:30, loss before: 1.57726353791e-05, loss after: 1.57689100888e-05.\n",
      "Epoch:11, weight train batch: 231, step:31, loss before: 1.08740459837e-05, loss after: 1.08740459837e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 227, loss before: 1.22086103147e-05, loss after: 1.22030223793e-05.\n",
      "Epoch:11, weight train batch: 232, step:0, loss before: 1.36903172461e-05, loss after: 1.36903172461e-05.\n",
      "Epoch:11, weight train batch: 232, step:1, loss before: 1.42714543472e-05, loss after: 1.42304779729e-05.\n",
      "Epoch:11, weight train batch: 232, step:2, loss before: 1.17047711683e-05, loss after: 1.16749688459e-05.\n",
      "Epoch:11, weight train batch: 232, step:3, loss before: 1.40367637869e-05, loss after: 1.40367637869e-05.\n",
      "Epoch:11, weight train batch: 232, step:4, loss before: 1.92738589249e-05, loss after: 1.92701336346e-05.\n",
      "Epoch:11, weight train batch: 232, step:5, loss before: 1.48525741679e-05, loss after: 1.48488497871e-05.\n",
      "Epoch:11, weight train batch: 232, step:6, loss before: 1.40814672704e-05, loss after: 1.40814672704e-05.\n",
      "Epoch:11, weight train batch: 232, step:7, loss before: 1.41112732308e-05, loss after: 1.41112732308e-05.\n",
      "Epoch:11, weight train batch: 232, step:8, loss before: 1.36046337502e-05, loss after: 1.35636564664e-05.\n",
      "Epoch:11, weight train batch: 232, step:9, loss before: 1.30495827761e-05, loss after: 1.30495827761e-05.\n",
      "Epoch:11, weight train batch: 232, step:10, loss before: 1.28819456222e-05, loss after: 1.28819456222e-05.\n",
      "Epoch:11, weight train batch: 232, step:11, loss before: 1.23157060443e-05, loss after: 1.23157060443e-05.\n",
      "Epoch:11, weight train batch: 232, step:12, loss before: 1.38281620821e-05, loss after: 1.38281620821e-05.\n",
      "Epoch:11, weight train batch: 232, step:13, loss before: 1.33438661578e-05, loss after: 1.33438661578e-05.\n",
      "Epoch:11, weight train batch: 232, step:14, loss before: 1.26398117573e-05, loss after: 1.26249105961e-05.\n",
      "Epoch:11, weight train batch: 232, step:15, loss before: 1.0155079508e-05, loss after: 1.01476289274e-05.\n",
      "Epoch:11, weight train batch: 232, step:16, loss before: 1.45843787323e-05, loss after: 1.45843787323e-05.\n",
      "Epoch:11, weight train batch: 232, step:17, loss before: 1.19916167023e-05, loss after: 1.19916167023e-05.\n",
      "Epoch:11, weight train batch: 232, step:18, loss before: 1.37499318953e-05, loss after: 1.37238557727e-05.\n",
      "Epoch:11, weight train batch: 232, step:19, loss before: 1.19618116514e-05, loss after: 1.19618116514e-05.\n",
      "Epoch:11, weight train batch: 232, step:20, loss before: 1.24572634377e-05, loss after: 1.24572634377e-05.\n",
      "Epoch:11, weight train batch: 232, step:21, loss before: 1.23976706163e-05, loss after: 1.23529680423e-05.\n",
      "Epoch:11, weight train batch: 232, step:22, loss before: 1.13732203317e-05, loss after: 1.13732203317e-05.\n",
      "Epoch:11, weight train batch: 232, step:23, loss before: 1.3422106349e-05, loss after: 1.33885787363e-05.\n",
      "Epoch:11, weight train batch: 232, step:24, loss before: 1.14961621875e-05, loss after: 1.14961621875e-05.\n",
      "Epoch:11, weight train batch: 232, step:25, loss before: 1.30085982164e-05, loss after: 1.30085982164e-05.\n",
      "Epoch:11, weight train batch: 232, step:26, loss before: 1.42379303725e-05, loss after: 1.42379303725e-05.\n",
      "Epoch:11, weight train batch: 232, step:27, loss before: 1.00731158454e-05, loss after: 1.00731158454e-05.\n",
      "Epoch:11, weight train batch: 232, step:28, loss before: 1.15930142783e-05, loss after: 1.15930142783e-05.\n",
      "Epoch:11, weight train batch: 232, step:29, loss before: 1.32246641442e-05, loss after: 1.32246641442e-05.\n",
      "Epoch:11, weight train batch: 232, step:30, loss before: 1.56237147166e-05, loss after: 1.56237147166e-05.\n",
      "Epoch:11, weight train batch: 232, step:31, loss before: 0.000103438906081, loss after: 0.000103245714854.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 228, loss before: 1.32768218464e-05, loss after: 1.32768218464e-05.\n",
      "Epoch:11, weight train batch: 233, step:0, loss before: 1.36418766488e-05, loss after: 1.36381513585e-05.\n",
      "Epoch:11, weight train batch: 233, step:1, loss before: 1.12204961624e-05, loss after: 1.12204961624e-05.\n",
      "Epoch:11, weight train batch: 233, step:2, loss before: 1.376482669e-05, loss after: 1.37462002385e-05.\n",
      "Epoch:11, weight train batch: 233, step:3, loss before: 1.40628426379e-05, loss after: 1.40628426379e-05.\n",
      "Epoch:11, weight train batch: 233, step:4, loss before: 1.21145467347e-05, loss after: 1.21145467347e-05.\n",
      "Epoch:11, weight train batch: 233, step:5, loss before: 2.62034627667e-05, loss after: 2.61997392954e-05.\n",
      "Epoch:11, weight train batch: 233, step:6, loss before: 3.02861189994e-05, loss after: 3.02786720567e-05.\n",
      "Epoch:11, weight train batch: 233, step:7, loss before: 1.35226873681e-05, loss after: 1.35226873681e-05.\n",
      "Epoch:11, weight train batch: 233, step:8, loss before: 2.69334304903e-05, loss after: 2.69073570962e-05.\n",
      "Epoch:11, weight train batch: 233, step:9, loss before: 1.3533865058e-05, loss after: 1.3533865058e-05.\n",
      "Epoch:11, weight train batch: 233, step:10, loss before: 1.22635510706e-05, loss after: 1.22635510706e-05.\n",
      "Epoch:11, weight train batch: 233, step:11, loss before: 1.14551849038e-05, loss after: 1.14551849038e-05.\n",
      "Epoch:11, weight train batch: 233, step:12, loss before: 0.00265622860752, loss after: 0.00265156943351.\n",
      "Epoch:11, weight train batch: 233, step:13, loss before: 1.01848709164e-05, loss after: 1.01625191746e-05.\n",
      "Epoch:11, weight train batch: 233, step:14, loss before: 1.71138090082e-05, loss after: 1.71138090082e-05.\n",
      "Epoch:11, weight train batch: 233, step:15, loss before: 1.32134919113e-05, loss after: 1.32134919113e-05.\n",
      "Epoch:11, weight train batch: 233, step:16, loss before: 1.23306017485e-05, loss after: 1.23306017485e-05.\n",
      "Epoch:11, weight train batch: 233, step:17, loss before: 1.17494764709e-05, loss after: 1.1701047697e-05.\n",
      "Epoch:11, weight train batch: 233, step:18, loss before: 0.000229533659876, loss after: 0.000228667995543.\n",
      "Epoch:11, weight train batch: 233, step:19, loss before: 1.14477224997e-05, loss after: 1.14290960482e-05.\n",
      "Epoch:11, weight train batch: 233, step:20, loss before: 2.53353609878e-05, loss after: 2.52795107372e-05.\n",
      "Epoch:11, weight train batch: 233, step:21, loss before: 1.31203614728e-05, loss after: 1.31054603116e-05.\n",
      "Epoch:11, weight train batch: 233, step:22, loss before: 1.23194295156e-05, loss after: 1.23194295156e-05.\n",
      "Epoch:11, weight train batch: 233, step:23, loss before: 1.29117470351e-05, loss after: 1.29117470351e-05.\n",
      "Epoch:11, weight train batch: 233, step:24, loss before: 1.32432905957e-05, loss after: 1.32097638925e-05.\n",
      "Epoch:11, weight train batch: 233, step:25, loss before: 1.05797489596e-05, loss after: 1.05462222564e-05.\n",
      "Epoch:11, weight train batch: 233, step:26, loss before: 1.35860209411e-05, loss after: 1.35860209411e-05.\n",
      "Epoch:11, weight train batch: 233, step:27, loss before: 1.57019458129e-05, loss after: 1.57205722644e-05.\n",
      "Epoch:11, weight train batch: 233, step:28, loss before: 1.19171054394e-05, loss after: 1.19171054394e-05.\n",
      "Epoch:11, weight train batch: 233, step:29, loss before: 1.31315337057e-05, loss after: 1.30905573315e-05.\n",
      "Epoch:11, weight train batch: 233, step:30, loss before: 1.49083934957e-05, loss after: 1.48785929923e-05.\n",
      "Epoch:11, weight train batch: 233, step:31, loss before: 9.88685860648e-06, loss after: 9.88685860648e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 229, loss before: 3.54493895429e-05, loss after: 1.20791573863e-05.\n",
      "Epoch:11, weight train batch: 234, step:0, loss before: 1.13397063615e-05, loss after: 1.13397063615e-05.\n",
      "Epoch:11, weight train batch: 234, step:1, loss before: 1.31576107378e-05, loss after: 1.31576107378e-05.\n",
      "Epoch:11, weight train batch: 234, step:2, loss before: 1.16749679364e-05, loss after: 1.16749679364e-05.\n",
      "Epoch:11, weight train batch: 234, step:3, loss before: 1.26286349769e-05, loss after: 1.26286349769e-05.\n",
      "Epoch:11, weight train batch: 234, step:4, loss before: 9.23735351535e-05, loss after: 9.2347523605e-05.\n",
      "Epoch:11, weight train batch: 234, step:5, loss before: 1.14141957965e-05, loss after: 1.13843934741e-05.\n",
      "Epoch:11, weight train batch: 234, step:6, loss before: 1.39138301165e-05, loss after: 1.38691302709e-05.\n",
      "Epoch:11, weight train batch: 234, step:7, loss before: 1.25950973597e-05, loss after: 1.25950973597e-05.\n",
      "Epoch:11, weight train batch: 234, step:8, loss before: 1.35003319883e-05, loss after: 1.35003319883e-05.\n",
      "Epoch:11, weight train batch: 234, step:9, loss before: 1.2237484043e-05, loss after: 1.2237484043e-05.\n",
      "Epoch:11, weight train batch: 234, step:10, loss before: 1.23604131659e-05, loss after: 1.23268864627e-05.\n",
      "Epoch:11, weight train batch: 234, step:11, loss before: 1.26174527395e-05, loss after: 1.26174527395e-05.\n",
      "Epoch:11, weight train batch: 234, step:12, loss before: 0.000123127319966, loss after: 0.000122878453112.\n",
      "Epoch:11, weight train batch: 234, step:13, loss before: 1.12540183181e-05, loss after: 1.1227943105e-05.\n",
      "Epoch:11, weight train batch: 234, step:14, loss before: 1.35934642458e-05, loss after: 1.35934642458e-05.\n",
      "Epoch:11, weight train batch: 234, step:15, loss before: 1.31278175104e-05, loss after: 1.31278175104e-05.\n",
      "Epoch:11, weight train batch: 234, step:16, loss before: 1.04456448753e-05, loss after: 1.04456448753e-05.\n",
      "Epoch:11, weight train batch: 234, step:17, loss before: 1.0728757843e-05, loss after: 1.0728757843e-05.\n",
      "Epoch:11, weight train batch: 234, step:18, loss before: 1.21443554235e-05, loss after: 1.21182793009e-05.\n",
      "Epoch:11, weight train batch: 234, step:19, loss before: 1.95644752239e-05, loss after: 1.95607535716e-05.\n",
      "Epoch:11, weight train batch: 234, step:20, loss before: 1.3571116142e-05, loss after: 1.35338641485e-05.\n",
      "Epoch:11, weight train batch: 234, step:21, loss before: 1.12540146802e-05, loss after: 1.12540146802e-05.\n",
      "Epoch:11, weight train batch: 234, step:22, loss before: 1.34108522616e-05, loss after: 1.34071269713e-05.\n",
      "Epoch:11, weight train batch: 234, step:23, loss before: 1.1227946743e-05, loss after: 1.12093202915e-05.\n",
      "Epoch:11, weight train batch: 234, step:24, loss before: 1.30197822727e-05, loss after: 1.30197822727e-05.\n",
      "Epoch:11, weight train batch: 234, step:25, loss before: 1.16116407298e-05, loss after: 1.16116407298e-05.\n",
      "Epoch:11, weight train batch: 234, step:26, loss before: 1.4904748241e-05, loss after: 1.4904748241e-05.\n",
      "Epoch:11, weight train batch: 234, step:27, loss before: 1.19245587484e-05, loss after: 1.19245587484e-05.\n",
      "Epoch:11, weight train batch: 234, step:28, loss before: 1.12391144285e-05, loss after: 1.12130373964e-05.\n",
      "Epoch:11, weight train batch: 234, step:29, loss before: 1.05983690446e-05, loss after: 1.05983690446e-05.\n",
      "Epoch:11, weight train batch: 234, step:30, loss before: 2.39983710344e-05, loss after: 2.39909240918e-05.\n",
      "Epoch:11, weight train batch: 234, step:31, loss before: 1.26696086227e-05, loss after: 1.26696086227e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 230, loss before: 1.45120611705e-05, loss after: 0.000398118776502.\n",
      "Epoch:11, weight train batch: 235, step:0, loss before: 1.19767164506e-05, loss after: 1.19767164506e-05.\n",
      "Epoch:11, weight train batch: 235, step:1, loss before: 1.22114051919e-05, loss after: 1.22114051919e-05.\n",
      "Epoch:11, weight train batch: 235, step:2, loss before: 1.27739112941e-05, loss after: 1.2747834262e-05.\n",
      "Epoch:11, weight train batch: 235, step:3, loss before: 1.12987190732e-05, loss after: 1.12987190732e-05.\n",
      "Epoch:11, weight train batch: 235, step:4, loss before: 1.25764681798e-05, loss after: 1.25354918055e-05.\n",
      "Epoch:11, weight train batch: 235, step:5, loss before: 1.07175783342e-05, loss after: 1.07175783342e-05.\n",
      "Epoch:11, weight train batch: 235, step:6, loss before: 1.05723011075e-05, loss after: 1.05723011075e-05.\n",
      "Epoch:11, weight train batch: 235, step:7, loss before: 1.0896391359e-05, loss after: 1.0896391359e-05.\n",
      "Epoch:11, weight train batch: 235, step:8, loss before: 1.16563369374e-05, loss after: 1.16414357763e-05.\n",
      "Epoch:11, weight train batch: 235, step:9, loss before: 1.02891872302e-05, loss after: 1.02891872302e-05.\n",
      "Epoch:11, weight train batch: 235, step:10, loss before: 9.76019327936e-06, loss after: 9.76019327936e-06.\n",
      "Epoch:11, weight train batch: 235, step:11, loss before: 1.28148922158e-05, loss after: 1.28148922158e-05.\n",
      "Epoch:11, weight train batch: 235, step:12, loss before: 2.34554900089e-05, loss after: 2.34219660342e-05.\n",
      "Epoch:11, weight train batch: 235, step:13, loss before: 1.07809119072e-05, loss after: 1.07809119072e-05.\n",
      "Epoch:11, weight train batch: 235, step:14, loss before: 1.26696086227e-05, loss after: 1.26696086227e-05.\n",
      "Epoch:11, weight train batch: 235, step:15, loss before: 1.06020979729e-05, loss after: 1.06020979729e-05.\n",
      "Epoch:11, weight train batch: 235, step:16, loss before: 1.15408574857e-05, loss after: 1.15408574857e-05.\n",
      "Epoch:11, weight train batch: 235, step:17, loss before: 1.06021061583e-05, loss after: 1.05648541648e-05.\n",
      "Epoch:11, weight train batch: 235, step:18, loss before: 1.04828941403e-05, loss after: 1.04828941403e-05.\n",
      "Epoch:11, weight train batch: 235, step:19, loss before: 1.14589047371e-05, loss after: 1.14589047371e-05.\n",
      "Epoch:11, weight train batch: 235, step:20, loss before: 1.17792751553e-05, loss after: 1.17792751553e-05.\n",
      "Epoch:11, weight train batch: 235, step:21, loss before: 1.11608878797e-05, loss after: 1.11608878797e-05.\n",
      "Epoch:11, weight train batch: 235, step:22, loss before: 1.34034780785e-05, loss after: 1.33625007948e-05.\n",
      "Epoch:11, weight train batch: 235, step:23, loss before: 1.25839242173e-05, loss after: 1.25839242173e-05.\n",
      "Epoch:11, weight train batch: 235, step:24, loss before: 1.06840489025e-05, loss after: 1.06840489025e-05.\n",
      "Epoch:11, weight train batch: 235, step:25, loss before: 1.40329721035e-05, loss after: 1.40292468132e-05.\n",
      "Epoch:11, weight train batch: 235, step:26, loss before: 1.28074407257e-05, loss after: 1.27850889839e-05.\n",
      "Epoch:11, weight train batch: 235, step:27, loss before: 1.31948636408e-05, loss after: 1.31948636408e-05.\n",
      "Epoch:11, weight train batch: 235, step:28, loss before: 1.22635519801e-05, loss after: 1.22635519801e-05.\n",
      "Epoch:11, weight train batch: 235, step:29, loss before: 1.26137274492e-05, loss after: 1.26137274492e-05.\n",
      "Epoch:11, weight train batch: 235, step:30, loss before: 1.04940709207e-05, loss after: 1.04754444692e-05.\n",
      "Epoch:11, weight train batch: 235, step:31, loss before: 1.23268891912e-05, loss after: 1.23268891912e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 231, loss before: 1.28046458485e-05, loss after: 1.25261876747e-05.\n",
      "Epoch:11, weight train batch: 236, step:0, loss before: 1.05573963083e-05, loss after: 1.05573963083e-05.\n",
      "Epoch:11, weight train batch: 236, step:1, loss before: 1.2904301002e-05, loss after: 1.2904301002e-05.\n",
      "Epoch:11, weight train batch: 236, step:2, loss before: 1.18873076644e-05, loss after: 1.18724065032e-05.\n",
      "Epoch:11, weight train batch: 236, step:3, loss before: 1.13210680865e-05, loss after: 1.13210680865e-05.\n",
      "Epoch:11, weight train batch: 236, step:4, loss before: 1.07064106487e-05, loss after: 1.07064106487e-05.\n",
      "Epoch:11, weight train batch: 236, step:5, loss before: 1.30942789838e-05, loss after: 1.30942789838e-05.\n",
      "Epoch:11, weight train batch: 236, step:6, loss before: 1.2107099792e-05, loss after: 1.2107099792e-05.\n",
      "Epoch:11, weight train batch: 236, step:7, loss before: 1.08740441647e-05, loss after: 1.08516924229e-05.\n",
      "Epoch:11, weight train batch: 236, step:8, loss before: 1.33177964017e-05, loss after: 1.33177964017e-05.\n",
      "Epoch:11, weight train batch: 236, step:9, loss before: 1.01140976767e-05, loss after: 1.01140976767e-05.\n",
      "Epoch:11, weight train batch: 236, step:10, loss before: 8.94809090823e-06, loss after: 8.94809090823e-06.\n",
      "Epoch:11, weight train batch: 236, step:11, loss before: 0.00258652050979, loss after: 0.0025832655374.\n",
      "Epoch:11, weight train batch: 236, step:12, loss before: 1.11310846478e-05, loss after: 1.11310846478e-05.\n",
      "Epoch:11, weight train batch: 236, step:13, loss before: 1.17345698527e-05, loss after: 1.17345698527e-05.\n",
      "Epoch:11, weight train batch: 236, step:14, loss before: 1.31799715746e-05, loss after: 1.31799715746e-05.\n",
      "Epoch:11, weight train batch: 236, step:15, loss before: 1.06989573396e-05, loss after: 1.06989573396e-05.\n",
      "Epoch:11, weight train batch: 236, step:16, loss before: 1.13918595162e-05, loss after: 1.1339705452e-05.\n",
      "Epoch:11, weight train batch: 236, step:17, loss before: 1.50983933054e-05, loss after: 1.50983933054e-05.\n",
      "Epoch:11, weight train batch: 236, step:18, loss before: 8.12724319985e-05, loss after: 8.11013596831e-05.\n",
      "Epoch:11, weight train batch: 236, step:19, loss before: 1.17978997878e-05, loss after: 1.17978997878e-05.\n",
      "Epoch:11, weight train batch: 236, step:20, loss before: 1.03748589027e-05, loss after: 1.03376069092e-05.\n",
      "Epoch:11, weight train batch: 236, step:21, loss before: 1.09597294795e-05, loss after: 1.09113007056e-05.\n",
      "Epoch:11, weight train batch: 236, step:22, loss before: 0.0025442217011, loss after: 0.00253997789696.\n",
      "Epoch:11, weight train batch: 236, step:23, loss before: 1.34630854518e-05, loss after: 1.35040627356e-05.\n",
      "Epoch:11, weight train batch: 236, step:24, loss before: 1.22561068565e-05, loss after: 1.22561068565e-05.\n",
      "Epoch:11, weight train batch: 236, step:25, loss before: 1.09969705591e-05, loss after: 1.09969705591e-05.\n",
      "Epoch:11, weight train batch: 236, step:26, loss before: 0.0243793278933, loss after: 0.024365151301.\n",
      "Epoch:11, weight train batch: 236, step:27, loss before: 9.93901085167e-06, loss after: 9.93901085167e-06.\n",
      "Epoch:11, weight train batch: 236, step:28, loss before: 1.25243213915e-05, loss after: 1.24684429466e-05.\n",
      "Epoch:11, weight train batch: 236, step:29, loss before: 0.000101057943539, loss after: 0.000100783028756.\n",
      "Epoch:11, weight train batch: 236, step:30, loss before: 0.00153925456107, loss after: 0.00153313879855.\n",
      "Epoch:11, weight train batch: 236, step:31, loss before: 1.15743823699e-05, loss after: 1.15557559184e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 232, loss before: 1.23138443087e-05, loss after: 1.20735694509e-05.\n",
      "Epoch:11, weight train batch: 237, step:0, loss before: 9.66333755059e-06, loss after: 9.66333755059e-06.\n",
      "Epoch:11, weight train batch: 237, step:1, loss before: 1.35748232424e-05, loss after: 1.35524715006e-05.\n",
      "Epoch:11, weight train batch: 237, step:2, loss before: 9.43438790273e-05, loss after: 9.4399540103e-05.\n",
      "Epoch:11, weight train batch: 237, step:3, loss before: 1.31985898406e-05, loss after: 1.31985898406e-05.\n",
      "Epoch:11, weight train batch: 237, step:4, loss before: 1.36120906973e-05, loss after: 1.35748377943e-05.\n",
      "Epoch:11, weight train batch: 237, step:5, loss before: 1.02593803604e-05, loss after: 1.02593803604e-05.\n",
      "Epoch:11, weight train batch: 237, step:6, loss before: 1.19357328003e-05, loss after: 1.19357328003e-05.\n",
      "Epoch:11, weight train batch: 237, step:7, loss before: 1.10938308353e-05, loss after: 1.10230512291e-05.\n",
      "Epoch:11, weight train batch: 237, step:8, loss before: 1.08516933324e-05, loss after: 1.08516933324e-05.\n",
      "Epoch:11, weight train batch: 237, step:9, loss before: 1.19841570267e-05, loss after: 1.19841570267e-05.\n",
      "Epoch:11, weight train batch: 237, step:10, loss before: 1.12428369903e-05, loss after: 1.12093093776e-05.\n",
      "Epoch:11, weight train batch: 237, step:11, loss before: 1.26211734823e-05, loss after: 1.26211734823e-05.\n",
      "Epoch:11, weight train batch: 237, step:12, loss before: 1.12800898933e-05, loss after: 1.12800898933e-05.\n",
      "Epoch:11, weight train batch: 237, step:13, loss before: 9.91665183392e-06, loss after: 9.89430009213e-06.\n",
      "Epoch:11, weight train batch: 237, step:14, loss before: 1.15222337627e-05, loss after: 1.15222337627e-05.\n",
      "Epoch:11, weight train batch: 237, step:15, loss before: 1.055366738e-05, loss after: 1.055366738e-05.\n",
      "Epoch:11, weight train batch: 237, step:16, loss before: 1.20102386063e-05, loss after: 1.19655360322e-05.\n",
      "Epoch:11, weight train batch: 237, step:17, loss before: 1.02668263935e-05, loss after: 1.02668263935e-05.\n",
      "Epoch:11, weight train batch: 237, step:18, loss before: 2.207344005e-05, loss after: 2.20138445002e-05.\n",
      "Epoch:11, weight train batch: 237, step:19, loss before: 1.08293379526e-05, loss after: 1.08293379526e-05.\n",
      "Epoch:11, weight train batch: 237, step:20, loss before: 2.54035294347e-05, loss after: 2.53886355495e-05.\n",
      "Epoch:11, weight train batch: 237, step:21, loss before: 1.17345653052e-05, loss after: 1.17345653052e-05.\n",
      "Epoch:11, weight train batch: 237, step:22, loss before: 9.71176632447e-06, loss after: 9.71176632447e-06.\n",
      "Epoch:11, weight train batch: 237, step:23, loss before: 1.28968440549e-05, loss after: 1.28968440549e-05.\n",
      "Epoch:11, weight train batch: 237, step:24, loss before: 1.17233976198e-05, loss after: 1.17084964586e-05.\n",
      "Epoch:11, weight train batch: 237, step:25, loss before: 1.15930179163e-05, loss after: 1.15185121103e-05.\n",
      "Epoch:11, weight train batch: 237, step:26, loss before: 1.12242078103e-05, loss after: 1.12242078103e-05.\n",
      "Epoch:11, weight train batch: 237, step:27, loss before: 1.48522503878e-05, loss after: 1.48448007167e-05.\n",
      "Epoch:11, weight train batch: 237, step:28, loss before: 1.23008012451e-05, loss after: 1.23008012451e-05.\n",
      "Epoch:11, weight train batch: 237, step:29, loss before: 1.18165253298e-05, loss after: 1.18165253298e-05.\n",
      "Epoch:11, weight train batch: 237, step:30, loss before: 1.25094120449e-05, loss after: 1.25094120449e-05.\n",
      "Epoch:11, weight train batch: 237, step:31, loss before: 1.25466731333e-05, loss after: 1.25466731333e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 233, loss before: 1.18835614558e-05, loss after: 3.17562225973e-05.\n",
      "Epoch:11, weight train batch: 238, step:0, loss before: 1.06318984763e-05, loss after: 1.06318984763e-05.\n",
      "Epoch:11, weight train batch: 238, step:1, loss before: 1.15296797958e-05, loss after: 1.14924278023e-05.\n",
      "Epoch:11, weight train batch: 238, step:2, loss before: 9.13435360417e-06, loss after: 9.11945335247e-06.\n",
      "Epoch:11, weight train batch: 238, step:3, loss before: 1.30123207782e-05, loss after: 1.30123207782e-05.\n",
      "Epoch:11, weight train batch: 238, step:4, loss before: 9.15298187465e-06, loss after: 9.15298187465e-06.\n",
      "Epoch:11, weight train batch: 238, step:5, loss before: 0.00241114245728, loss after: 0.00240812031552.\n",
      "Epoch:11, weight train batch: 238, step:6, loss before: 1.0784636288e-05, loss after: 1.0784636288e-05.\n",
      "Epoch:11, weight train batch: 238, step:7, loss before: 1.16190731205e-05, loss after: 1.15967213787e-05.\n",
      "Epoch:11, weight train batch: 238, step:8, loss before: 1.20549393614e-05, loss after: 1.20549393614e-05.\n",
      "Epoch:11, weight train batch: 238, step:9, loss before: 1.19506321425e-05, loss after: 1.19506321425e-05.\n",
      "Epoch:11, weight train batch: 238, step:10, loss before: 1.05871968117e-05, loss after: 1.05871968117e-05.\n",
      "Epoch:11, weight train batch: 238, step:11, loss before: 1.13322421385e-05, loss after: 1.13322421385e-05.\n",
      "Epoch:11, weight train batch: 238, step:12, loss before: 1.04903447209e-05, loss after: 1.04903447209e-05.\n",
      "Epoch:11, weight train batch: 238, step:13, loss before: 1.37834476845e-05, loss after: 1.37685465234e-05.\n",
      "Epoch:11, weight train batch: 238, step:14, loss before: 2.47889820457e-05, loss after: 2.47778116318e-05.\n",
      "Epoch:11, weight train batch: 238, step:15, loss before: 1.01289888335e-05, loss after: 1.01289888335e-05.\n",
      "Epoch:11, weight train batch: 238, step:16, loss before: 1.20810163935e-05, loss after: 1.20810163935e-05.\n",
      "Epoch:11, weight train batch: 238, step:17, loss before: 9.72666930465e-06, loss after: 9.72666930465e-06.\n",
      "Epoch:11, weight train batch: 238, step:18, loss before: 0.00142900808714, loss after: 0.00142478570342.\n",
      "Epoch:11, weight train batch: 238, step:19, loss before: 1.10938290163e-05, loss after: 1.1071478184e-05.\n",
      "Epoch:11, weight train batch: 238, step:20, loss before: 1.23231548059e-05, loss after: 1.23231548059e-05.\n",
      "Epoch:11, weight train batch: 238, step:21, loss before: 1.20251379485e-05, loss after: 1.19953356261e-05.\n",
      "Epoch:11, weight train batch: 238, step:22, loss before: 9.80861659627e-06, loss after: 9.80861659627e-06.\n",
      "Epoch:11, weight train batch: 238, step:23, loss before: 0.00236259773374, loss after: 0.00235863775015.\n",
      "Epoch:11, weight train batch: 238, step:24, loss before: 8.12854159449e-06, loss after: 8.0987392721e-06.\n",
      "Epoch:11, weight train batch: 238, step:25, loss before: 1.13955702545e-05, loss after: 1.13955702545e-05.\n",
      "Epoch:11, weight train batch: 238, step:26, loss before: 1.0479163393e-05, loss after: 1.04530872704e-05.\n",
      "Epoch:11, weight train batch: 238, step:27, loss before: 8.96671826922e-06, loss after: 8.92574098543e-06.\n",
      "Epoch:11, weight train batch: 238, step:28, loss before: 1.07287523861e-05, loss after: 1.06989500637e-05.\n",
      "Epoch:11, weight train batch: 238, step:29, loss before: 2.65730868705e-05, loss after: 2.65470116574e-05.\n",
      "Epoch:11, weight train batch: 238, step:30, loss before: 1.03562342701e-05, loss after: 1.03562342701e-05.\n",
      "Epoch:11, weight train batch: 238, step:31, loss before: 1.13061641969e-05, loss after: 1.13061641969e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 234, loss before: 1.04195569293e-05, loss after: 1.04195569293e-05.\n",
      "Epoch:11, weight train batch: 239, step:0, loss before: 1.1924554201e-05, loss after: 1.1924554201e-05.\n",
      "Epoch:11, weight train batch: 239, step:1, loss before: 2.20700439968e-05, loss after: 2.20625952352e-05.\n",
      "Epoch:11, weight train batch: 239, step:2, loss before: 1.1294988326e-05, loss after: 1.12651869131e-05.\n",
      "Epoch:11, weight train batch: 239, step:3, loss before: 1.17941654025e-05, loss after: 1.17941654025e-05.\n",
      "Epoch:11, weight train batch: 239, step:4, loss before: 9.28336157813e-06, loss after: 9.28336157813e-06.\n",
      "Epoch:11, weight train batch: 239, step:5, loss before: 1.1600455764e-05, loss after: 1.1600455764e-05.\n",
      "Epoch:11, weight train batch: 239, step:6, loss before: 1.11981371447e-05, loss after: 1.11981371447e-05.\n",
      "Epoch:11, weight train batch: 239, step:7, loss before: 1.06393463284e-05, loss after: 1.06393463284e-05.\n",
      "Epoch:11, weight train batch: 239, step:8, loss before: 9.60000488703e-06, loss after: 9.60000488703e-06.\n",
      "Epoch:11, weight train batch: 239, step:9, loss before: 1.13992955448e-05, loss after: 1.13992955448e-05.\n",
      "Epoch:11, weight train batch: 239, step:10, loss before: 8.87358237378e-06, loss after: 8.87358237378e-06.\n",
      "Epoch:11, weight train batch: 239, step:11, loss before: 1.12651869131e-05, loss after: 1.12353845907e-05.\n",
      "Epoch:11, weight train batch: 239, step:12, loss before: 1.04530863609e-05, loss after: 1.04270111478e-05.\n",
      "Epoch:11, weight train batch: 239, step:13, loss before: 1.04754344648e-05, loss after: 1.04754344648e-05.\n",
      "Epoch:11, weight train batch: 239, step:14, loss before: 9.51060428633e-06, loss after: 9.46962609305e-06.\n",
      "Epoch:11, weight train batch: 239, step:15, loss before: 1.37312945299e-05, loss after: 1.37312945299e-05.\n",
      "Epoch:11, weight train batch: 239, step:16, loss before: 1.20065124065e-05, loss after: 1.20065124065e-05.\n",
      "Epoch:11, weight train batch: 239, step:17, loss before: 2.18945424422e-05, loss after: 2.18833702093e-05.\n",
      "Epoch:11, weight train batch: 239, step:18, loss before: 9.9390053947e-06, loss after: 9.9390053947e-06.\n",
      "Epoch:11, weight train batch: 239, step:19, loss before: 1.12949910545e-05, loss after: 1.12949910545e-05.\n",
      "Epoch:11, weight train batch: 239, step:20, loss before: 1.18947546071e-05, loss after: 1.18947546071e-05.\n",
      "Epoch:11, weight train batch: 239, step:21, loss before: 8.90711453394e-06, loss after: 8.90711453394e-06.\n",
      "Epoch:11, weight train batch: 239, step:22, loss before: 9.98742962111e-06, loss after: 9.96135258902e-06.\n",
      "Epoch:11, weight train batch: 239, step:23, loss before: 1.03376059997e-05, loss after: 1.03376059997e-05.\n",
      "Epoch:11, weight train batch: 239, step:24, loss before: 1.10155951916e-05, loss after: 1.10155951916e-05.\n",
      "Epoch:11, weight train batch: 239, step:25, loss before: 9.81606717687e-06, loss after: 9.81606717687e-06.\n",
      "Epoch:11, weight train batch: 239, step:26, loss before: 9.83096833806e-06, loss after: 9.83096833806e-06.\n",
      "Epoch:11, weight train batch: 239, step:27, loss before: 1.40403844853e-05, loss after: 1.40403844853e-05.\n",
      "Epoch:11, weight train batch: 239, step:28, loss before: 9.0598468887e-06, loss after: 9.0598468887e-06.\n",
      "Epoch:11, weight train batch: 239, step:29, loss before: 9.50314915826e-06, loss after: 9.50314915826e-06.\n",
      "Epoch:11, weight train batch: 239, step:30, loss before: 1.59661758516e-05, loss after: 1.59661758516e-05.\n",
      "Epoch:11, weight train batch: 239, step:31, loss before: 9.5962850537e-06, loss after: 9.54040660872e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:11, struct parameters train batch: 235, loss before: 0.00542513467371, loss after: 3.172383731e-05.\n",
      "Epoch:12, weight train batch: 240, step:0, loss before: 9.59628141572e-06, loss after: 9.59628141572e-06.\n",
      "Epoch:12, weight train batch: 240, step:1, loss before: 9.27056244109e-05, loss after: 9.24938503886e-05.\n",
      "Epoch:12, weight train batch: 240, step:2, loss before: 9.55157884164e-06, loss after: 9.55157884164e-06.\n",
      "Epoch:12, weight train batch: 240, step:3, loss before: 1.13396954475e-05, loss after: 1.13396954475e-05.\n",
      "Epoch:12, weight train batch: 240, step:4, loss before: 1.19022060971e-05, loss after: 1.1887304936e-05.\n",
      "Epoch:12, weight train batch: 240, step:5, loss before: 1.04940590973e-05, loss after: 1.04940590973e-05.\n",
      "Epoch:12, weight train batch: 240, step:6, loss before: 1.09932479972e-05, loss after: 1.09932479972e-05.\n",
      "Epoch:12, weight train batch: 240, step:7, loss before: 1.01774148789e-05, loss after: 1.01774148789e-05.\n",
      "Epoch:12, weight train batch: 240, step:8, loss before: 1.23790323414e-05, loss after: 1.23343288578e-05.\n",
      "Epoch:12, weight train batch: 240, step:9, loss before: 1.06915031211e-05, loss after: 1.06617007987e-05.\n",
      "Epoch:12, weight train batch: 240, step:10, loss before: 1.20437580335e-05, loss after: 1.20437580335e-05.\n",
      "Epoch:12, weight train batch: 240, step:11, loss before: 1.08554104372e-05, loss after: 1.08554104372e-05.\n",
      "Epoch:12, weight train batch: 240, step:12, loss before: 9.84214057098e-06, loss after: 9.84214057098e-06.\n",
      "Epoch:12, weight train batch: 240, step:13, loss before: 1.3016054254e-05, loss after: 1.3016054254e-05.\n",
      "Epoch:12, weight train batch: 240, step:14, loss before: 1.26099985209e-05, loss after: 1.26099985209e-05.\n",
      "Epoch:12, weight train batch: 240, step:15, loss before: 8.77672664501e-06, loss after: 8.77672664501e-06.\n",
      "Epoch:12, weight train batch: 240, step:16, loss before: 1.47889850268e-05, loss after: 1.47591836139e-05.\n",
      "Epoch:12, weight train batch: 240, step:17, loss before: 1.00582110463e-05, loss after: 1.00582110463e-05.\n",
      "Epoch:12, weight train batch: 240, step:18, loss before: 1.13098849397e-05, loss after: 1.13098849397e-05.\n",
      "Epoch:12, weight train batch: 240, step:19, loss before: 1.16972514661e-05, loss after: 1.16972514661e-05.\n",
      "Epoch:12, weight train batch: 240, step:20, loss before: 1.16935880214e-05, loss after: 1.16935880214e-05.\n",
      "Epoch:12, weight train batch: 240, step:21, loss before: 1.12800871648e-05, loss after: 1.12800871648e-05.\n",
      "Epoch:12, weight train batch: 240, step:22, loss before: 1.08293334051e-05, loss after: 1.08069816633e-05.\n",
      "Epoch:12, weight train batch: 240, step:23, loss before: 8.60908949107e-06, loss after: 8.60908949107e-06.\n",
      "Epoch:12, weight train batch: 240, step:24, loss before: 1.25801934701e-05, loss after: 1.25317656057e-05.\n",
      "Epoch:12, weight train batch: 240, step:25, loss before: 1.01029145299e-05, loss after: 1.01029145299e-05.\n",
      "Epoch:12, weight train batch: 240, step:26, loss before: 9.387666978e-06, loss after: 9.387666978e-06.\n",
      "Epoch:12, weight train batch: 240, step:27, loss before: 8.1993148342e-06, loss after: 8.1993148342e-06.\n",
      "Epoch:12, weight train batch: 240, step:28, loss before: 1.67706421053e-05, loss after: 1.6766916815e-05.\n",
      "Epoch:12, weight train batch: 240, step:29, loss before: 1.06244442577e-05, loss after: 1.06244442577e-05.\n",
      "Epoch:12, weight train batch: 240, step:30, loss before: 1.21815983221e-05, loss after: 1.21815983221e-05.\n",
      "Epoch:12, weight train batch: 240, step:31, loss before: 9.84587495623e-06, loss after: 9.84587495623e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 236, loss before: 9.09803202376e-06, loss after: 3.185944297e-05.\n",
      "Epoch:12, weight train batch: 241, step:0, loss before: 2.09600766539e-05, loss after: 2.09265508602e-05.\n",
      "Epoch:12, weight train batch: 241, step:1, loss before: 1.05573935798e-05, loss after: 1.05573935798e-05.\n",
      "Epoch:12, weight train batch: 241, step:2, loss before: 9.59255339694e-06, loss after: 9.59255339694e-06.\n",
      "Epoch:12, weight train batch: 241, step:3, loss before: 1.0739928257e-05, loss after: 1.0739928257e-05.\n",
      "Epoch:12, weight train batch: 241, step:4, loss before: 7.99815006758e-06, loss after: 7.99815006758e-06.\n",
      "Epoch:12, weight train batch: 241, step:5, loss before: 9.11200186238e-06, loss after: 9.11200186238e-06.\n",
      "Epoch:12, weight train batch: 241, step:6, loss before: 5.87842478126e-05, loss after: 5.86465794186e-05.\n",
      "Epoch:12, weight train batch: 241, step:7, loss before: 9.56647636485e-06, loss after: 9.56647636485e-06.\n",
      "Epoch:12, weight train batch: 241, step:8, loss before: 1.04903392639e-05, loss after: 1.04605369415e-05.\n",
      "Epoch:12, weight train batch: 241, step:9, loss before: 1.1507326235e-05, loss after: 1.1507326235e-05.\n",
      "Epoch:12, weight train batch: 241, step:10, loss before: 0.0216705650091, loss after: 0.0216705650091.\n",
      "Epoch:12, weight train batch: 241, step:11, loss before: 1.03636803033e-05, loss after: 1.03338788904e-05.\n",
      "Epoch:12, weight train batch: 241, step:12, loss before: 9.65587878454e-06, loss after: 9.65587878454e-06.\n",
      "Epoch:12, weight train batch: 241, step:13, loss before: 9.93155299511e-06, loss after: 9.93155299511e-06.\n",
      "Epoch:12, weight train batch: 241, step:14, loss before: 1.33361609187e-05, loss after: 1.33361609187e-05.\n",
      "Epoch:12, weight train batch: 241, step:15, loss before: 1.13694950414e-05, loss after: 1.13694950414e-05.\n",
      "Epoch:12, weight train batch: 241, step:16, loss before: 9.38021366892e-06, loss after: 9.38021366892e-06.\n",
      "Epoch:12, weight train batch: 241, step:17, loss before: 9.34296440391e-06, loss after: 9.32061357162e-06.\n",
      "Epoch:12, weight train batch: 241, step:18, loss before: 1.04493583422e-05, loss after: 1.04493583422e-05.\n",
      "Epoch:12, weight train batch: 241, step:19, loss before: 8.97416703083e-06, loss after: 8.97416703083e-06.\n",
      "Epoch:12, weight train batch: 241, step:20, loss before: 9.81234188657e-06, loss after: 9.81234188657e-06.\n",
      "Epoch:12, weight train batch: 241, step:21, loss before: 8.11736299511e-06, loss after: 8.11736299511e-06.\n",
      "Epoch:12, weight train batch: 241, step:22, loss before: 0.0216830167919, loss after: 0.0216830130666.\n",
      "Epoch:12, weight train batch: 241, step:23, loss before: 1.13471451186e-05, loss after: 1.13471451186e-05.\n",
      "Epoch:12, weight train batch: 241, step:24, loss before: 9.17533179745e-06, loss after: 9.17533179745e-06.\n",
      "Epoch:12, weight train batch: 241, step:25, loss before: 1.02072199297e-05, loss after: 1.02072199297e-05.\n",
      "Epoch:12, weight train batch: 241, step:26, loss before: 9.00769100554e-06, loss after: 8.98533926375e-06.\n",
      "Epoch:12, weight train batch: 241, step:27, loss before: 9.97625284072e-06, loss after: 9.97625284072e-06.\n",
      "Epoch:12, weight train batch: 241, step:28, loss before: 1.03711317934e-05, loss after: 1.03711317934e-05.\n",
      "Epoch:12, weight train batch: 241, step:29, loss before: 9.618635886e-06, loss after: 9.618635886e-06.\n",
      "Epoch:12, weight train batch: 241, step:30, loss before: 1.10193232103e-05, loss after: 1.10193232103e-05.\n",
      "Epoch:12, weight train batch: 241, step:31, loss before: 9.53667949943e-06, loss after: 9.53667949943e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 237, loss before: 1.23054396681e-05, loss after: 1.16172250273e-05.\n",
      "Epoch:12, weight train batch: 242, step:0, loss before: 9.84959842754e-06, loss after: 9.84959842754e-06.\n",
      "Epoch:12, weight train batch: 242, step:1, loss before: 1.15185030154e-05, loss after: 1.14812501124e-05.\n",
      "Epoch:12, weight train batch: 242, step:2, loss before: 1.1395569345e-05, loss after: 1.1395569345e-05.\n",
      "Epoch:12, weight train batch: 242, step:3, loss before: 8.18814351078e-06, loss after: 8.17696763988e-06.\n",
      "Epoch:12, weight train batch: 242, step:4, loss before: 1.07250252768e-05, loss after: 1.06914976641e-05.\n",
      "Epoch:12, weight train batch: 242, step:5, loss before: 1.15781076602e-05, loss after: 1.15781076602e-05.\n",
      "Epoch:12, weight train batch: 242, step:6, loss before: 8.10990513855e-06, loss after: 8.10990513855e-06.\n",
      "Epoch:12, weight train batch: 242, step:7, loss before: 9.76763840299e-06, loss after: 9.76763840299e-06.\n",
      "Epoch:12, weight train batch: 242, step:8, loss before: 1.08926615212e-05, loss after: 1.08926615212e-05.\n",
      "Epoch:12, weight train batch: 242, step:9, loss before: 8.91828494787e-06, loss after: 8.88103204488e-06.\n",
      "Epoch:12, weight train batch: 242, step:10, loss before: 9.00769191503e-06, loss after: 9.00769191503e-06.\n",
      "Epoch:12, weight train batch: 242, step:11, loss before: 9.47707121668e-06, loss after: 9.47707121668e-06.\n",
      "Epoch:12, weight train batch: 242, step:12, loss before: 8.5159599621e-06, loss after: 8.4973344201e-06.\n",
      "Epoch:12, weight train batch: 242, step:13, loss before: 1.24311882246e-05, loss after: 1.24311882246e-05.\n",
      "Epoch:12, weight train batch: 242, step:14, loss before: 1.15706552606e-05, loss after: 1.15706552606e-05.\n",
      "Epoch:12, weight train batch: 242, step:15, loss before: 1.17792696983e-05, loss after: 1.17792696983e-05.\n",
      "Epoch:12, weight train batch: 242, step:16, loss before: 9.42119368119e-06, loss after: 9.42119368119e-06.\n",
      "Epoch:12, weight train batch: 242, step:17, loss before: 8.42282861413e-06, loss after: 8.42282861413e-06.\n",
      "Epoch:12, weight train batch: 242, step:18, loss before: 2.15710570046e-05, loss after: 2.15673317143e-05.\n",
      "Epoch:12, weight train batch: 242, step:19, loss before: 1.12614616228e-05, loss after: 1.12614616228e-05.\n",
      "Epoch:12, weight train batch: 242, step:20, loss before: 1.92800434888e-05, loss after: 1.92763200175e-05.\n",
      "Epoch:12, weight train batch: 242, step:21, loss before: 9.93900175672e-06, loss after: 9.90920034383e-06.\n",
      "Epoch:12, weight train batch: 242, step:22, loss before: 9.70058499661e-06, loss after: 9.70058499661e-06.\n",
      "Epoch:12, weight train batch: 242, step:23, loss before: 1.06542502181e-05, loss after: 1.06542502181e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12, weight train batch: 242, step:24, loss before: 1.12204834295e-05, loss after: 1.11944063974e-05.\n",
      "Epoch:12, weight train batch: 242, step:25, loss before: 8.81398227648e-06, loss after: 8.81398227648e-06.\n",
      "Epoch:12, weight train batch: 242, step:26, loss before: 9.34668878472e-06, loss after: 9.34668878472e-06.\n",
      "Epoch:12, weight train batch: 242, step:27, loss before: 9.39511301112e-06, loss after: 9.39511301112e-06.\n",
      "Epoch:12, weight train batch: 242, step:28, loss before: 8.54203244671e-06, loss after: 8.54203244671e-06.\n",
      "Epoch:12, weight train batch: 242, step:29, loss before: 1.18649559226e-05, loss after: 1.18649559226e-05.\n",
      "Epoch:12, weight train batch: 242, step:30, loss before: 9.9129292721e-06, loss after: 9.88685314951e-06.\n",
      "Epoch:12, weight train batch: 242, step:31, loss before: 8.89966395334e-06, loss after: 8.89966395334e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 238, loss before: 1.06086145024e-05, loss after: 1.06076831798e-05.\n",
      "Epoch:12, weight train batch: 243, step:0, loss before: 1.10416758616e-05, loss after: 1.10416758616e-05.\n",
      "Epoch:12, weight train batch: 243, step:1, loss before: 9.23493098526e-06, loss after: 9.23493098526e-06.\n",
      "Epoch:12, weight train batch: 243, step:2, loss before: 9.66705829342e-06, loss after: 9.66705829342e-06.\n",
      "Epoch:12, weight train batch: 243, step:3, loss before: 9.34668514674e-06, loss after: 9.34668514674e-06.\n",
      "Epoch:12, weight train batch: 243, step:4, loss before: 1.10416749521e-05, loss after: 1.10416749521e-05.\n",
      "Epoch:12, weight train batch: 243, step:5, loss before: 9.90174703475e-06, loss after: 9.90174703475e-06.\n",
      "Epoch:12, weight train batch: 243, step:6, loss before: 9.48079832597e-06, loss after: 9.48079832597e-06.\n",
      "Epoch:12, weight train batch: 243, step:7, loss before: 9.36531159823e-06, loss after: 9.33551018534e-06.\n",
      "Epoch:12, weight train batch: 243, step:8, loss before: 9.82724577625e-06, loss after: 9.82724577625e-06.\n",
      "Epoch:12, weight train batch: 243, step:9, loss before: 1.02072190202e-05, loss after: 1.02072190202e-05.\n",
      "Epoch:12, weight train batch: 243, step:10, loss before: 7.80071331974e-06, loss after: 7.80071331974e-06.\n",
      "Epoch:12, weight train batch: 243, step:11, loss before: 1.09708926175e-05, loss after: 1.09708926175e-05.\n",
      "Epoch:12, weight train batch: 243, step:12, loss before: 1.09857974167e-05, loss after: 1.09857974167e-05.\n",
      "Epoch:12, weight train batch: 243, step:13, loss before: 1.1950631233e-05, loss after: 1.1950631233e-05.\n",
      "Epoch:12, weight train batch: 243, step:14, loss before: 2.29491579375e-05, loss after: 2.29379857046e-05.\n",
      "Epoch:12, weight train batch: 243, step:15, loss before: 1.16600667752e-05, loss after: 1.1589287169e-05.\n",
      "Epoch:12, weight train batch: 243, step:16, loss before: 9.68196309259e-06, loss after: 9.68196309259e-06.\n",
      "Epoch:12, weight train batch: 243, step:17, loss before: 8.35949686007e-06, loss after: 8.35949686007e-06.\n",
      "Epoch:12, weight train batch: 243, step:18, loss before: 9.31688009587e-06, loss after: 9.31688009587e-06.\n",
      "Epoch:12, weight train batch: 243, step:19, loss before: 1.92425613932e-05, loss after: 1.92313891603e-05.\n",
      "Epoch:12, weight train batch: 243, step:20, loss before: 1.16041846923e-05, loss after: 1.16041846923e-05.\n",
      "Epoch:12, weight train batch: 243, step:21, loss before: 9.47707030718e-06, loss after: 9.47707030718e-06.\n",
      "Epoch:12, weight train batch: 243, step:22, loss before: 8.67986636877e-06, loss after: 8.67986636877e-06.\n",
      "Epoch:12, weight train batch: 243, step:23, loss before: 8.68732058734e-06, loss after: 8.68732058734e-06.\n",
      "Epoch:12, weight train batch: 243, step:24, loss before: 9.80489403446e-06, loss after: 9.77509262157e-06.\n",
      "Epoch:12, weight train batch: 243, step:25, loss before: 1.07883588498e-05, loss after: 1.07883588498e-05.\n",
      "Epoch:12, weight train batch: 243, step:26, loss before: 9.67823143583e-06, loss after: 9.67823143583e-06.\n",
      "Epoch:12, weight train batch: 243, step:27, loss before: 1.07511059468e-05, loss after: 1.07511059468e-05.\n",
      "Epoch:12, weight train batch: 243, step:28, loss before: 1.02966296254e-05, loss after: 1.02966296254e-05.\n",
      "Epoch:12, weight train batch: 243, step:29, loss before: 1.00358611235e-05, loss after: 1.00358611235e-05.\n",
      "Epoch:12, weight train batch: 243, step:30, loss before: 9.15670534596e-06, loss after: 9.15670534596e-06.\n",
      "Epoch:12, weight train batch: 243, step:31, loss before: 9.6260855571e-06, loss after: 9.6260855571e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 239, loss before: 1.37214510687e-05, loss after: 1.01978057501e-05.\n",
      "Epoch:12, weight train batch: 244, step:0, loss before: 1.10491237137e-05, loss after: 1.10491237137e-05.\n",
      "Epoch:12, weight train batch: 244, step:1, loss before: 8.9218330686e-05, loss after: 8.91178351594e-05.\n",
      "Epoch:12, weight train batch: 244, step:2, loss before: 8.97043719306e-06, loss after: 8.97043719306e-06.\n",
      "Epoch:12, weight train batch: 244, step:3, loss before: 9.37276581681e-06, loss after: 9.34296349442e-06.\n",
      "Epoch:12, weight train batch: 244, step:4, loss before: 1.95297652681e-05, loss after: 1.95223183255e-05.\n",
      "Epoch:12, weight train batch: 244, step:5, loss before: 1.26062777781e-05, loss after: 1.26062777781e-05.\n",
      "Epoch:12, weight train batch: 244, step:6, loss before: 8.56066981214e-06, loss after: 8.56066981214e-06.\n",
      "Epoch:12, weight train batch: 244, step:7, loss before: 9.75274087978e-06, loss after: 9.72294037638e-06.\n",
      "Epoch:12, weight train batch: 244, step:8, loss before: 1.14812528409e-05, loss after: 1.14812528409e-05.\n",
      "Epoch:12, weight train batch: 244, step:9, loss before: 1.03599541035e-05, loss after: 1.03599541035e-05.\n",
      "Epoch:12, weight train batch: 244, step:10, loss before: 8.85868394107e-06, loss after: 8.85868394107e-06.\n",
      "Epoch:12, weight train batch: 244, step:11, loss before: 5.38674503332e-05, loss after: 5.37893356523e-05.\n",
      "Epoch:12, weight train batch: 244, step:12, loss before: 1.13545975182e-05, loss after: 1.13545975182e-05.\n",
      "Epoch:12, weight train batch: 244, step:13, loss before: 1.09597222036e-05, loss after: 1.09597222036e-05.\n",
      "Epoch:12, weight train batch: 244, step:14, loss before: 8.09128141555e-06, loss after: 8.07265496405e-06.\n",
      "Epoch:12, weight train batch: 244, step:15, loss before: 9.0710218501e-06, loss after: 9.0710218501e-06.\n",
      "Epoch:12, weight train batch: 244, step:16, loss before: 9.48824890656e-06, loss after: 9.45472129388e-06.\n",
      "Epoch:12, weight train batch: 244, step:17, loss before: 8.64261892275e-06, loss after: 8.64261892275e-06.\n",
      "Epoch:12, weight train batch: 244, step:18, loss before: 1.12502912089e-05, loss after: 1.12502912089e-05.\n",
      "Epoch:12, weight train batch: 244, step:19, loss before: 8.5010588009e-06, loss after: 8.5010588009e-06.\n",
      "Epoch:12, weight train batch: 244, step:20, loss before: 8.68732240633e-06, loss after: 8.68732240633e-06.\n",
      "Epoch:12, weight train batch: 244, step:21, loss before: 1.18165289678e-05, loss after: 1.18165289678e-05.\n",
      "Epoch:12, weight train batch: 244, step:22, loss before: 1.21964985738e-05, loss after: 1.21443463286e-05.\n",
      "Epoch:12, weight train batch: 244, step:23, loss before: 0.000182032512384, loss after: 0.000181406241609.\n",
      "Epoch:12, weight train batch: 244, step:24, loss before: 9.89802902041e-06, loss after: 9.89802902041e-06.\n",
      "Epoch:12, weight train batch: 244, step:25, loss before: 1.07883570308e-05, loss after: 1.07883570308e-05.\n",
      "Epoch:12, weight train batch: 244, step:26, loss before: 9.53667768044e-06, loss after: 9.53667768044e-06.\n",
      "Epoch:12, weight train batch: 244, step:27, loss before: 2.05689138966e-05, loss after: 2.05316737265e-05.\n",
      "Epoch:12, weight train batch: 244, step:28, loss before: 1.02891781353e-05, loss after: 1.02705525933e-05.\n",
      "Epoch:12, weight train batch: 244, step:29, loss before: 9.10827566258e-06, loss after: 9.08219863049e-06.\n",
      "Epoch:12, weight train batch: 244, step:30, loss before: 1.11012805064e-05, loss after: 1.11012805064e-05.\n",
      "Epoch:12, weight train batch: 244, step:31, loss before: 8.31479883345e-06, loss after: 8.31479883345e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12, struct parameters train batch: 240, loss before: 9.64748051047e-06, loss after: 8.98347752809e-06.\n",
      "Epoch:12, weight train batch: 245, step:0, loss before: 1.05275930764e-05, loss after: 1.05275930764e-05.\n",
      "Epoch:12, weight train batch: 245, step:1, loss before: 8.69477298693e-06, loss after: 8.69477298693e-06.\n",
      "Epoch:12, weight train batch: 245, step:2, loss before: 8.70222356752e-06, loss after: 8.67242124514e-06.\n",
      "Epoch:12, weight train batch: 245, step:3, loss before: 8.63889454195e-06, loss after: 8.63889454195e-06.\n",
      "Epoch:12, weight train batch: 245, step:4, loss before: 1.15632119559e-05, loss after: 1.15632119559e-05.\n",
      "Epoch:12, weight train batch: 245, step:5, loss before: 1.01625155366e-05, loss after: 1.01252644527e-05.\n",
      "Epoch:12, weight train batch: 245, step:6, loss before: 0.00229329615831, loss after: 0.00228929938748.\n",
      "Epoch:12, weight train batch: 245, step:7, loss before: 9.26845859794e-06, loss after: 9.26845859794e-06.\n",
      "Epoch:12, weight train batch: 245, step:8, loss before: 1.05424951471e-05, loss after: 1.0553669199e-05.\n",
      "Epoch:12, weight train batch: 245, step:9, loss before: 0.00132720195688, loss after: 0.00132312322967.\n",
      "Epoch:12, weight train batch: 245, step:10, loss before: 5.37266023457e-05, loss after: 5.37228843314e-05.\n",
      "Epoch:12, weight train batch: 245, step:11, loss before: 1.06430761662e-05, loss after: 1.06058232632e-05.\n",
      "Epoch:12, weight train batch: 245, step:12, loss before: 9.29081397771e-06, loss after: 9.29081397771e-06.\n",
      "Epoch:12, weight train batch: 245, step:13, loss before: 9.0300472948e-06, loss after: 8.99279530131e-06.\n",
      "Epoch:12, weight train batch: 245, step:14, loss before: 9.91292654362e-06, loss after: 9.91292654362e-06.\n",
      "Epoch:12, weight train batch: 245, step:15, loss before: 1.05462186184e-05, loss after: 1.05462186184e-05.\n",
      "Epoch:12, weight train batch: 245, step:16, loss before: 9.76764385996e-06, loss after: 9.74156773736e-06.\n",
      "Epoch:12, weight train batch: 245, step:17, loss before: 9.9650806078e-06, loss after: 9.9650806078e-06.\n",
      "Epoch:12, weight train batch: 245, step:18, loss before: 8.564385098e-06, loss after: 8.564385098e-06.\n",
      "Epoch:12, weight train batch: 245, step:19, loss before: 1.11906847451e-05, loss after: 1.11906847451e-05.\n",
      "Epoch:12, weight train batch: 245, step:20, loss before: 8.01677379059e-06, loss after: 8.01677379059e-06.\n",
      "Epoch:12, weight train batch: 245, step:21, loss before: 1.82264411706e-05, loss after: 1.81891882676e-05.\n",
      "Epoch:12, weight train batch: 245, step:22, loss before: 8.94809272722e-06, loss after: 8.94809272722e-06.\n",
      "Epoch:12, weight train batch: 245, step:23, loss before: 8.25519146019e-06, loss after: 8.25519146019e-06.\n",
      "Epoch:12, weight train batch: 245, step:24, loss before: 9.52922709985e-06, loss after: 9.52922709985e-06.\n",
      "Epoch:12, weight train batch: 245, step:25, loss before: 1.32021414174e-05, loss after: 1.31984161271e-05.\n",
      "Epoch:12, weight train batch: 245, step:26, loss before: 9.38021184993e-06, loss after: 9.38021184993e-06.\n",
      "Epoch:12, weight train batch: 245, step:27, loss before: 9.87939529296e-06, loss after: 9.87939529296e-06.\n",
      "Epoch:12, weight train batch: 245, step:28, loss before: 1.08069853013e-05, loss after: 1.08069853013e-05.\n",
      "Epoch:12, weight train batch: 245, step:29, loss before: 1.09149314085e-05, loss after: 1.09112070277e-05.\n",
      "Epoch:12, weight train batch: 245, step:30, loss before: 6.77254774928e-06, loss after: 6.74274542689e-06.\n",
      "Epoch:12, weight train batch: 245, step:31, loss before: 1.04121063487e-05, loss after: 1.03711290649e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 241, loss before: 1.03394513644e-05, loss after: 9.94645142782e-06.\n",
      "Epoch:12, weight train batch: 246, step:0, loss before: 8.19931301521e-06, loss after: 8.19931301521e-06.\n",
      "Epoch:12, weight train batch: 246, step:1, loss before: 8.10618439573e-06, loss after: 8.10618439573e-06.\n",
      "Epoch:12, weight train batch: 246, step:2, loss before: 1.37164024636e-05, loss after: 1.37126771733e-05.\n",
      "Epoch:12, weight train batch: 246, step:3, loss before: 9.3764920166e-06, loss after: 9.3764920166e-06.\n",
      "Epoch:12, weight train batch: 246, step:4, loss before: 8.99651422515e-06, loss after: 8.97788777365e-06.\n",
      "Epoch:12, weight train batch: 246, step:5, loss before: 8.77672300703e-06, loss after: 8.77672300703e-06.\n",
      "Epoch:12, weight train batch: 246, step:6, loss before: 8.79227591213e-05, loss after: 8.78967548488e-05.\n",
      "Epoch:12, weight train batch: 246, step:7, loss before: 8.97416612133e-06, loss after: 8.97416612133e-06.\n",
      "Epoch:12, weight train batch: 246, step:8, loss before: 1.12949928734e-05, loss after: 1.12949928734e-05.\n",
      "Epoch:12, weight train batch: 246, step:9, loss before: 7.24192886992e-06, loss after: 7.23075299902e-06.\n",
      "Epoch:12, weight train batch: 246, step:10, loss before: 1.23976105897e-05, loss after: 1.23976105897e-05.\n",
      "Epoch:12, weight train batch: 246, step:11, loss before: 5.345635509e-05, loss after: 5.33596321475e-05.\n",
      "Epoch:12, weight train batch: 246, step:12, loss before: 8.85495683178e-06, loss after: 8.85495683178e-06.\n",
      "Epoch:12, weight train batch: 246, step:13, loss before: 7.62934996601e-06, loss after: 7.62934996601e-06.\n",
      "Epoch:12, weight train batch: 246, step:14, loss before: 8.71712290973e-06, loss after: 8.71712290973e-06.\n",
      "Epoch:12, weight train batch: 246, step:15, loss before: 2.21333175432e-05, loss after: 2.21258669626e-05.\n",
      "Epoch:12, weight train batch: 246, step:16, loss before: 1.03525071609e-05, loss after: 1.03152542579e-05.\n",
      "Epoch:12, weight train batch: 246, step:17, loss before: 5.14868261234e-05, loss after: 5.13045415573e-05.\n",
      "Epoch:12, weight train batch: 246, step:18, loss before: 8.64261437528e-06, loss after: 8.64261437528e-06.\n",
      "Epoch:12, weight train batch: 246, step:19, loss before: 1.00395845948e-05, loss after: 1.00395845948e-05.\n",
      "Epoch:12, weight train batch: 246, step:20, loss before: 1.04083828774e-05, loss after: 1.04083828774e-05.\n",
      "Epoch:12, weight train batch: 246, step:21, loss before: 9.07102003112e-06, loss after: 9.07102003112e-06.\n",
      "Epoch:12, weight train batch: 246, step:22, loss before: 9.22748222365e-06, loss after: 9.22748222365e-06.\n",
      "Epoch:12, weight train batch: 246, step:23, loss before: 1.01327068478e-05, loss after: 1.0128982467e-05.\n",
      "Epoch:12, weight train batch: 246, step:24, loss before: 7.67777873989e-06, loss after: 7.65915319789e-06.\n",
      "Epoch:12, weight train batch: 246, step:25, loss before: 1.06542483991e-05, loss after: 1.06542483991e-05.\n",
      "Epoch:12, weight train batch: 246, step:26, loss before: 8.67614471645e-06, loss after: 8.65006768436e-06.\n",
      "Epoch:12, weight train batch: 246, step:27, loss before: 9.18650766835e-06, loss after: 9.18650766835e-06.\n",
      "Epoch:12, weight train batch: 246, step:28, loss before: 1.03115198726e-05, loss after: 1.03115198726e-05.\n",
      "Epoch:12, weight train batch: 246, step:29, loss before: 9.17160377867e-06, loss after: 9.17160377867e-06.\n",
      "Epoch:12, weight train batch: 246, step:30, loss before: 7.62190302339e-06, loss after: 7.56974895921e-06.\n",
      "Epoch:12, weight train batch: 246, step:31, loss before: 9.6633357316e-06, loss after: 9.6633357316e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 242, loss before: 0.00542415678501, loss after: 9.09802929527e-06.\n",
      "Epoch:12, weight train batch: 247, step:0, loss before: 1.13694968604e-05, loss after: 1.13210699055e-05.\n",
      "Epoch:12, weight train batch: 247, step:1, loss before: 1.00582119558e-05, loss after: 1.00582119558e-05.\n",
      "Epoch:12, weight train batch: 247, step:2, loss before: 8.92200932867e-06, loss after: 8.90710907697e-06.\n",
      "Epoch:12, weight train batch: 247, step:3, loss before: 4.87629877171e-05, loss after: 4.86402095703e-05.\n",
      "Epoch:12, weight train batch: 247, step:4, loss before: 8.92573552846e-06, loss after: 8.92573552846e-06.\n",
      "Epoch:12, weight train batch: 247, step:5, loss before: 1.00209581433e-05, loss after: 1.00209581433e-05.\n",
      "Epoch:12, weight train batch: 247, step:6, loss before: 9.60745728662e-06, loss after: 9.60745728662e-06.\n",
      "Epoch:12, weight train batch: 247, step:7, loss before: 7.77091099735e-06, loss after: 7.77091099735e-06.\n",
      "Epoch:12, weight train batch: 247, step:8, loss before: 1.88967533177e-05, loss after: 1.88893045561e-05.\n",
      "Epoch:12, weight train batch: 247, step:9, loss before: 1.00060569821e-05, loss after: 9.9688058981e-06.\n",
      "Epoch:12, weight train batch: 247, step:10, loss before: 8.49733623909e-06, loss after: 8.49733623909e-06.\n",
      "Epoch:12, weight train batch: 247, step:11, loss before: 7.97951997811e-06, loss after: 7.97951997811e-06.\n",
      "Epoch:12, weight train batch: 247, step:12, loss before: 1.00917395685e-05, loss after: 1.00917395685e-05.\n",
      "Epoch:12, weight train batch: 247, step:13, loss before: 7.83051564213e-06, loss after: 7.83051564213e-06.\n",
      "Epoch:12, weight train batch: 247, step:14, loss before: 7.59954855312e-06, loss after: 7.59954855312e-06.\n",
      "Epoch:12, weight train batch: 247, step:15, loss before: 9.49942477746e-06, loss after: 9.49942477746e-06.\n",
      "Epoch:12, weight train batch: 247, step:16, loss before: 1.1090105545e-05, loss after: 1.1090105545e-05.\n",
      "Epoch:12, weight train batch: 247, step:17, loss before: 9.3951166491e-06, loss after: 9.3951166491e-06.\n",
      "Epoch:12, weight train batch: 247, step:18, loss before: 9.13435451366e-06, loss after: 9.13435451366e-06.\n",
      "Epoch:12, weight train batch: 247, step:19, loss before: 1.01885934782e-05, loss after: 1.0147615285e-05.\n",
      "Epoch:12, weight train batch: 247, step:20, loss before: 9.26473512664e-06, loss after: 9.26473512664e-06.\n",
      "Epoch:12, weight train batch: 247, step:21, loss before: 9.22002982406e-06, loss after: 9.22002982406e-06.\n",
      "Epoch:12, weight train batch: 247, step:22, loss before: 8.16950887383e-06, loss after: 8.16950887383e-06.\n",
      "Epoch:12, weight train batch: 247, step:23, loss before: 8.94063668966e-06, loss after: 8.94063668966e-06.\n",
      "Epoch:12, weight train batch: 247, step:24, loss before: 8.88103204488e-06, loss after: 8.88103204488e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12, weight train batch: 247, step:25, loss before: 6.45217187412e-06, loss after: 6.45217187412e-06.\n",
      "Epoch:12, weight train batch: 247, step:26, loss before: 9.94645415631e-06, loss after: 9.94645415631e-06.\n",
      "Epoch:12, weight train batch: 247, step:27, loss before: 8.04657429399e-06, loss after: 8.0018708104e-06.\n",
      "Epoch:12, weight train batch: 247, step:28, loss before: 0.00222642649896, loss after: 0.00222351495177.\n",
      "Epoch:12, weight train batch: 247, step:29, loss before: 8.47870614962e-06, loss after: 8.47870614962e-06.\n",
      "Epoch:12, weight train batch: 247, step:30, loss before: 7.10036238161e-06, loss after: 7.07428580426e-06.\n",
      "Epoch:12, weight train batch: 247, step:31, loss before: 1.050895753e-05, loss after: 1.04754308268e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 243, loss before: 8.77858838066e-06, loss after: 1.18561792988e-05.\n",
      "Epoch:12, weight train batch: 248, step:0, loss before: 8.8214283096e-06, loss after: 8.8214283096e-06.\n",
      "Epoch:12, weight train batch: 248, step:1, loss before: 8.1955895439e-06, loss after: 8.1955895439e-06.\n",
      "Epoch:12, weight train batch: 248, step:2, loss before: 8.49360822031e-06, loss after: 8.49360822031e-06.\n",
      "Epoch:12, weight train batch: 248, step:3, loss before: 9.39507117437e-06, loss after: 9.39507117437e-06.\n",
      "Epoch:12, weight train batch: 248, step:4, loss before: 7.88639226812e-06, loss after: 7.88639226812e-06.\n",
      "Epoch:12, weight train batch: 248, step:5, loss before: 1.01401619759e-05, loss after: 1.01401619759e-05.\n",
      "Epoch:12, weight train batch: 248, step:6, loss before: 7.685226592e-06, loss after: 7.685226592e-06.\n",
      "Epoch:12, weight train batch: 248, step:7, loss before: 7.84914300311e-06, loss after: 7.84914300311e-06.\n",
      "Epoch:12, weight train batch: 248, step:8, loss before: 0.00218405947089, loss after: 0.00217952113599.\n",
      "Epoch:12, weight train batch: 248, step:9, loss before: 7.647977327e-06, loss after: 7.60700004321e-06.\n",
      "Epoch:12, weight train batch: 248, step:10, loss before: 7.5101429502e-06, loss after: 7.5101429502e-06.\n",
      "Epoch:12, weight train batch: 248, step:11, loss before: 9.7005868156e-06, loss after: 9.7005868156e-06.\n",
      "Epoch:12, weight train batch: 248, step:12, loss before: 8.02795602795e-06, loss after: 8.02795602795e-06.\n",
      "Epoch:12, weight train batch: 248, step:13, loss before: 8.16950887383e-06, loss after: 8.16950887383e-06.\n",
      "Epoch:12, weight train batch: 248, step:14, loss before: 9.49569584918e-06, loss after: 9.53294875217e-06.\n",
      "Epoch:12, weight train batch: 248, step:15, loss before: 6.61980584482e-06, loss after: 6.60117939333e-06.\n",
      "Epoch:12, weight train batch: 248, step:16, loss before: 1.00135057437e-05, loss after: 1.00135057437e-05.\n",
      "Epoch:12, weight train batch: 248, step:17, loss before: 7.98697328719e-06, loss after: 7.98697328719e-06.\n",
      "Epoch:12, weight train batch: 248, step:18, loss before: 8.68359347805e-06, loss after: 8.68359347805e-06.\n",
      "Epoch:12, weight train batch: 248, step:19, loss before: 9.22375875234e-06, loss after: 9.22375875234e-06.\n",
      "Epoch:12, weight train batch: 248, step:20, loss before: 8.68359347805e-06, loss after: 8.68359347805e-06.\n",
      "Epoch:12, weight train batch: 248, step:21, loss before: 9.57765223575e-06, loss after: 9.57765223575e-06.\n",
      "Epoch:12, weight train batch: 248, step:22, loss before: 7.79326364864e-06, loss after: 7.75228545535e-06.\n",
      "Epoch:12, weight train batch: 248, step:23, loss before: 8.84378005139e-06, loss after: 8.84378005139e-06.\n",
      "Epoch:12, weight train batch: 248, step:24, loss before: 8.46007969812e-06, loss after: 8.46007969812e-06.\n",
      "Epoch:12, weight train batch: 248, step:25, loss before: 8.08010281617e-06, loss after: 8.04284991318e-06.\n",
      "Epoch:12, weight train batch: 248, step:26, loss before: 6.2845310822e-06, loss after: 6.2845310822e-06.\n",
      "Epoch:12, weight train batch: 248, step:27, loss before: 9.53294875217e-06, loss after: 9.53294875217e-06.\n",
      "Epoch:12, weight train batch: 248, step:28, loss before: 6.40374355498e-06, loss after: 6.40374355498e-06.\n",
      "Epoch:12, weight train batch: 248, step:29, loss before: 9.11199640541e-06, loss after: 9.11199640541e-06.\n",
      "Epoch:12, weight train batch: 248, step:30, loss before: 7.66660105e-06, loss after: 7.66660105e-06.\n",
      "Epoch:12, weight train batch: 248, step:31, loss before: 7.05193406247e-06, loss after: 7.01840644979e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 244, loss before: 8.96950950846e-06, loss after: 8.96950950846e-06.\n",
      "Epoch:12, weight train batch: 249, step:0, loss before: 1.75854656845e-05, loss after: 1.75780169229e-05.\n",
      "Epoch:12, weight train batch: 249, step:1, loss before: 8.66496702656e-06, loss after: 8.66496702656e-06.\n",
      "Epoch:12, weight train batch: 249, step:2, loss before: 9.30571059143e-06, loss after: 9.30571059143e-06.\n",
      "Epoch:12, weight train batch: 249, step:3, loss before: 9.61490513873e-06, loss after: 9.61490513873e-06.\n",
      "Epoch:12, weight train batch: 249, step:4, loss before: 1.00358556665e-05, loss after: 1.00358556665e-05.\n",
      "Epoch:12, weight train batch: 249, step:5, loss before: 7.68150493968e-06, loss after: 7.68150493968e-06.\n",
      "Epoch:12, weight train batch: 249, step:6, loss before: 1.06132683868e-05, loss after: 1.05648414319e-05.\n",
      "Epoch:12, weight train batch: 249, step:7, loss before: 9.55530231295e-06, loss after: 9.55530231295e-06.\n",
      "Epoch:12, weight train batch: 249, step:8, loss before: 1.028544375e-05, loss after: 1.028544375e-05.\n",
      "Epoch:12, weight train batch: 249, step:9, loss before: 1.12577381515e-05, loss after: 1.12577381515e-05.\n",
      "Epoch:12, weight train batch: 249, step:10, loss before: 0.00211365777068, loss after: 0.00211076717824.\n",
      "Epoch:12, weight train batch: 249, step:11, loss before: 9.64098308032e-06, loss after: 9.64098308032e-06.\n",
      "Epoch:12, weight train batch: 249, step:12, loss before: 8.35949867906e-06, loss after: 8.35949867906e-06.\n",
      "Epoch:12, weight train batch: 249, step:13, loss before: 0.0216682478786, loss after: 0.0216682478786.\n",
      "Epoch:12, weight train batch: 249, step:14, loss before: 8.75809928402e-06, loss after: 8.75809928402e-06.\n",
      "Epoch:12, weight train batch: 249, step:15, loss before: 7.33133038011e-06, loss after: 7.29407793187e-06.\n",
      "Epoch:12, weight train batch: 249, step:16, loss before: 9.3653161457e-06, loss after: 9.3653161457e-06.\n",
      "Epoch:12, weight train batch: 249, step:17, loss before: 8.32224668557e-06, loss after: 8.32224668557e-06.\n",
      "Epoch:12, weight train batch: 249, step:18, loss before: 9.38021094044e-06, loss after: 9.35785919864e-06.\n",
      "Epoch:12, weight train batch: 249, step:19, loss before: 9.19395370147e-06, loss after: 9.19395370147e-06.\n",
      "Epoch:12, weight train batch: 249, step:20, loss before: 9.30571150093e-06, loss after: 9.30571150093e-06.\n",
      "Epoch:12, weight train batch: 249, step:21, loss before: 9.1045476438e-06, loss after: 9.1045476438e-06.\n",
      "Epoch:12, weight train batch: 249, step:22, loss before: 1.09299180622e-05, loss after: 1.09299180622e-05.\n",
      "Epoch:12, weight train batch: 249, step:23, loss before: 8.83806060301e-05, loss after: 8.83731772774e-05.\n",
      "Epoch:12, weight train batch: 249, step:24, loss before: 8.28499378258e-06, loss after: 8.28499378258e-06.\n",
      "Epoch:12, weight train batch: 249, step:25, loss before: 0.0216798428446, loss after: 0.021679835394.\n",
      "Epoch:12, weight train batch: 249, step:26, loss before: 7.18231922292e-06, loss after: 7.18231922292e-06.\n",
      "Epoch:12, weight train batch: 249, step:27, loss before: 4.58508766314e-05, loss after: 4.57727401226e-05.\n",
      "Epoch:12, weight train batch: 249, step:28, loss before: 1.66654263012e-05, loss after: 1.66393529071e-05.\n",
      "Epoch:12, weight train batch: 249, step:29, loss before: 9.25355561776e-06, loss after: 9.25355561776e-06.\n",
      "Epoch:12, weight train batch: 249, step:30, loss before: 9.38021366892e-06, loss after: 9.38021366892e-06.\n",
      "Epoch:12, weight train batch: 249, step:31, loss before: 1.00619354271e-05, loss after: 1.00619354271e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 245, loss before: 2.55050617852e-05, loss after: 7.68802237872e-06.\n",
      "Epoch:12, weight train batch: 250, step:0, loss before: 8.58674138726e-06, loss after: 8.57184022607e-06.\n",
      "Epoch:12, weight train batch: 250, step:1, loss before: 7.24937126506e-06, loss after: 7.24937126506e-06.\n",
      "Epoch:12, weight train batch: 250, step:2, loss before: 1.75855675479e-05, loss after: 1.75594941538e-05.\n",
      "Epoch:12, weight train batch: 250, step:3, loss before: 9.64098398981e-06, loss after: 9.64098398981e-06.\n",
      "Epoch:12, weight train batch: 250, step:4, loss before: 8.38929918245e-06, loss after: 8.38929918245e-06.\n",
      "Epoch:12, weight train batch: 250, step:5, loss before: 7.45798661228e-06, loss after: 7.43563487049e-06.\n",
      "Epoch:12, weight train batch: 250, step:6, loss before: 8.7879034254e-06, loss after: 8.7879034254e-06.\n",
      "Epoch:12, weight train batch: 250, step:7, loss before: 9.08964648261e-06, loss after: 9.08964648261e-06.\n",
      "Epoch:12, weight train batch: 250, step:8, loss before: 7.33132765163e-06, loss after: 7.33132765163e-06.\n",
      "Epoch:12, weight train batch: 250, step:9, loss before: 1.00582083178e-05, loss after: 1.00544830275e-05.\n",
      "Epoch:12, weight train batch: 250, step:10, loss before: 1.02183976196e-05, loss after: 1.02183976196e-05.\n",
      "Epoch:12, weight train batch: 250, step:11, loss before: 6.92155072102e-06, loss after: 6.92155072102e-06.\n",
      "Epoch:12, weight train batch: 250, step:12, loss before: 9.58882992563e-06, loss after: 9.58882992563e-06.\n",
      "Epoch:12, weight train batch: 250, step:13, loss before: 7.84913754615e-06, loss after: 7.84913754615e-06.\n",
      "Epoch:12, weight train batch: 250, step:14, loss before: 9.70058863459e-06, loss after: 9.6633357316e-06.\n",
      "Epoch:12, weight train batch: 250, step:15, loss before: 6.00886505708e-06, loss after: 5.99768964094e-06.\n",
      "Epoch:12, weight train batch: 250, step:16, loss before: 8.30734279589e-06, loss after: 8.30734279589e-06.\n",
      "Epoch:12, weight train batch: 250, step:17, loss before: 8.59046122059e-06, loss after: 8.59046122059e-06.\n",
      "Epoch:12, weight train batch: 250, step:18, loss before: 6.60863133817e-06, loss after: 6.60863133817e-06.\n",
      "Epoch:12, weight train batch: 250, step:19, loss before: 1.0523801393e-05, loss after: 1.0523801393e-05.\n",
      "Epoch:12, weight train batch: 250, step:20, loss before: 8.61281569087e-06, loss after: 8.61281569087e-06.\n",
      "Epoch:12, weight train batch: 250, step:21, loss before: 8.70224757819e-05, loss after: 8.69890282047e-05.\n",
      "Epoch:12, weight train batch: 250, step:22, loss before: 9.43981467572e-06, loss after: 9.43981467572e-06.\n",
      "Epoch:12, weight train batch: 250, step:23, loss before: 8.40420034365e-06, loss after: 8.37439893075e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12, weight train batch: 250, step:24, loss before: 6.18767853666e-06, loss after: 6.18767853666e-06.\n",
      "Epoch:12, weight train batch: 250, step:25, loss before: 7.88639135862e-06, loss after: 7.88639135862e-06.\n",
      "Epoch:12, weight train batch: 250, step:26, loss before: 8.1993148342e-06, loss after: 8.1993148342e-06.\n",
      "Epoch:12, weight train batch: 250, step:27, loss before: 0.00122593413107, loss after: 0.00122237612959.\n",
      "Epoch:12, weight train batch: 250, step:28, loss before: 1.86734268937e-05, loss after: 1.86697016034e-05.\n",
      "Epoch:12, weight train batch: 250, step:29, loss before: 6.67568656354e-06, loss after: 6.64588424115e-06.\n",
      "Epoch:12, weight train batch: 250, step:30, loss before: 8.46753027872e-06, loss after: 8.46753027872e-06.\n",
      "Epoch:12, weight train batch: 250, step:31, loss before: 1.84269920283e-05, loss after: 1.84195432666e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 246, loss before: 8.15644580143e-06, loss after: 7.98509699962e-06.\n",
      "Epoch:12, weight train batch: 251, step:0, loss before: 8.23283880891e-06, loss after: 8.23283880891e-06.\n",
      "Epoch:12, weight train batch: 251, step:1, loss before: 8.42655390443e-06, loss after: 8.40047687234e-06.\n",
      "Epoch:12, weight train batch: 251, step:2, loss before: 8.0018708104e-06, loss after: 8.0018708104e-06.\n",
      "Epoch:12, weight train batch: 251, step:3, loss before: 1.6728634364e-05, loss after: 1.67211856024e-05.\n",
      "Epoch:12, weight train batch: 251, step:4, loss before: 7.49896253183e-06, loss after: 7.49896253183e-06.\n",
      "Epoch:12, weight train batch: 251, step:5, loss before: 8.92201205716e-06, loss after: 8.88848444447e-06.\n",
      "Epoch:12, weight train batch: 251, step:6, loss before: 7.6815013017e-06, loss after: 7.6815013017e-06.\n",
      "Epoch:12, weight train batch: 251, step:7, loss before: 9.96880407911e-06, loss after: 9.94645233732e-06.\n",
      "Epoch:12, weight train batch: 251, step:8, loss before: 9.04866828932e-06, loss after: 9.02259125724e-06.\n",
      "Epoch:12, weight train batch: 251, step:9, loss before: 8.12480539025e-06, loss after: 8.12480539025e-06.\n",
      "Epoch:12, weight train batch: 251, step:10, loss before: 1.37049173645e-05, loss after: 1.37049173645e-05.\n",
      "Epoch:12, weight train batch: 251, step:11, loss before: 7.82678671385e-06, loss after: 7.82678671385e-06.\n",
      "Epoch:12, weight train batch: 251, step:12, loss before: 1.02221220004e-05, loss after: 1.02221220004e-05.\n",
      "Epoch:12, weight train batch: 251, step:13, loss before: 8.92573734745e-06, loss after: 8.92573734745e-06.\n",
      "Epoch:12, weight train batch: 251, step:14, loss before: 9.16410317586e-06, loss after: 9.16410317586e-06.\n",
      "Epoch:12, weight train batch: 251, step:15, loss before: 7.62562240197e-06, loss after: 7.62562240197e-06.\n",
      "Epoch:12, weight train batch: 251, step:16, loss before: 7.32760327082e-06, loss after: 7.32760327082e-06.\n",
      "Epoch:12, weight train batch: 251, step:17, loss before: 9.32433795242e-06, loss after: 9.28708595893e-06.\n",
      "Epoch:12, weight train batch: 251, step:18, loss before: 7.00350483385e-06, loss after: 7.00350483385e-06.\n",
      "Epoch:12, weight train batch: 251, step:19, loss before: 1.04717137219e-05, loss after: 1.04717137219e-05.\n",
      "Epoch:12, weight train batch: 251, step:20, loss before: 8.39675067255e-06, loss after: 8.39675067255e-06.\n",
      "Epoch:12, weight train batch: 251, step:21, loss before: 7.9944220488e-06, loss after: 7.9944220488e-06.\n",
      "Epoch:12, weight train batch: 251, step:22, loss before: 7.31270574761e-06, loss after: 7.31270574761e-06.\n",
      "Epoch:12, weight train batch: 251, step:23, loss before: 8.09500397736e-06, loss after: 8.09500397736e-06.\n",
      "Epoch:12, weight train batch: 251, step:24, loss before: 1.21665498227e-05, loss after: 1.21665498227e-05.\n",
      "Epoch:12, weight train batch: 251, step:25, loss before: 9.27963264985e-06, loss after: 9.27963264985e-06.\n",
      "Epoch:12, weight train batch: 251, step:26, loss before: 8.10245728644e-06, loss after: 8.10245728644e-06.\n",
      "Epoch:12, weight train batch: 251, step:27, loss before: 8.98533835425e-06, loss after: 8.94808636076e-06.\n",
      "Epoch:12, weight train batch: 251, step:28, loss before: 9.0598477982e-06, loss after: 9.0598477982e-06.\n",
      "Epoch:12, weight train batch: 251, step:29, loss before: 9.62980539043e-06, loss after: 9.62980539043e-06.\n",
      "Epoch:12, weight train batch: 251, step:30, loss before: 8.94808636076e-06, loss after: 8.94808636076e-06.\n",
      "Epoch:12, weight train batch: 251, step:31, loss before: 6.99233260093e-06, loss after: 6.99233260093e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 247, loss before: 8.95647008292e-06, loss after: 2.55944669334e-05.\n",
      "Epoch:12, weight train batch: 252, step:0, loss before: 6.29943406238e-06, loss after: 6.29943406238e-06.\n",
      "Epoch:12, weight train batch: 252, step:1, loss before: 8.60442814883e-05, loss after: 8.60108339111e-05.\n",
      "Epoch:12, weight train batch: 252, step:2, loss before: 8.46753209771e-06, loss after: 8.46753209771e-06.\n",
      "Epoch:12, weight train batch: 252, step:3, loss before: 7.97579832579e-06, loss after: 7.91246930021e-06.\n",
      "Epoch:12, weight train batch: 252, step:4, loss before: 7.80443770054e-06, loss after: 7.78208595875e-06.\n",
      "Epoch:12, weight train batch: 252, step:5, loss before: 7.84541407484e-06, loss after: 7.84541407484e-06.\n",
      "Epoch:12, weight train batch: 252, step:6, loss before: 8.56438691699e-06, loss after: 8.5383098849e-06.\n",
      "Epoch:12, weight train batch: 252, step:7, loss before: 8.13598035165e-06, loss after: 8.13598035165e-06.\n",
      "Epoch:12, weight train batch: 252, step:8, loss before: 7.64424657973e-06, loss after: 7.64424657973e-06.\n",
      "Epoch:12, weight train batch: 252, step:9, loss before: 7.37603659218e-06, loss after: 7.37603659218e-06.\n",
      "Epoch:12, weight train batch: 252, step:10, loss before: 7.16369277143e-06, loss after: 7.14134148438e-06.\n",
      "Epoch:12, weight train batch: 252, step:11, loss before: 8.2179403762e-06, loss after: 8.2179403762e-06.\n",
      "Epoch:12, weight train batch: 252, step:12, loss before: 7.12643668521e-06, loss after: 7.12643668521e-06.\n",
      "Epoch:12, weight train batch: 252, step:13, loss before: 8.10245364846e-06, loss after: 8.10245364846e-06.\n",
      "Epoch:12, weight train batch: 252, step:14, loss before: 7.62934951126e-06, loss after: 7.62934951126e-06.\n",
      "Epoch:12, weight train batch: 252, step:15, loss before: 8.0018708104e-06, loss after: 8.0018708104e-06.\n",
      "Epoch:12, weight train batch: 252, step:16, loss before: 0.00115420098882, loss after: 0.00115044822451.\n",
      "Epoch:12, weight train batch: 252, step:17, loss before: 8.10245364846e-06, loss after: 8.10245364846e-06.\n",
      "Epoch:12, weight train batch: 252, step:18, loss before: 7.54367101763e-06, loss after: 7.54367101763e-06.\n",
      "Epoch:12, weight train batch: 252, step:19, loss before: 7.42818474464e-06, loss after: 7.39465713195e-06.\n",
      "Epoch:12, weight train batch: 252, step:20, loss before: 7.11526763553e-06, loss after: 7.11526763553e-06.\n",
      "Epoch:12, weight train batch: 252, step:21, loss before: 1.05052367871e-05, loss after: 1.05052367871e-05.\n",
      "Epoch:12, weight train batch: 252, step:22, loss before: 7.1040885814e-06, loss after: 7.1040885814e-06.\n",
      "Epoch:12, weight train batch: 252, step:23, loss before: 9.44354724197e-06, loss after: 9.44354724197e-06.\n",
      "Epoch:12, weight train batch: 252, step:24, loss before: 7.90501690062e-06, loss after: 7.89384102973e-06.\n",
      "Epoch:12, weight train batch: 252, step:25, loss before: 7.26799498807e-06, loss after: 7.26799498807e-06.\n",
      "Epoch:12, weight train batch: 252, step:26, loss before: 7.398382877e-06, loss after: 7.37230584491e-06.\n",
      "Epoch:12, weight train batch: 252, step:27, loss before: 6.00886687607e-06, loss after: 6.00886687607e-06.\n",
      "Epoch:12, weight train batch: 252, step:28, loss before: 7.44308636058e-06, loss after: 7.44308636058e-06.\n",
      "Epoch:12, weight train batch: 252, step:29, loss before: 9.60741454037e-06, loss after: 9.60741454037e-06.\n",
      "Epoch:12, weight train batch: 252, step:30, loss before: 7.72248222347e-06, loss after: 7.72248222347e-06.\n",
      "Epoch:12, weight train batch: 252, step:31, loss before: 9.28708595893e-06, loss after: 9.28708595893e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 248, loss before: 9.45069223235e-06, loss after: 7.23540415493e-06.\n",
      "Epoch:12, weight train batch: 253, step:0, loss before: 6.73901513437e-06, loss after: 6.73901513437e-06.\n",
      "Epoch:12, weight train batch: 253, step:1, loss before: 8.39675067255e-06, loss after: 8.39675067255e-06.\n",
      "Epoch:12, weight train batch: 253, step:2, loss before: 7.3685832831e-06, loss after: 7.3685832831e-06.\n",
      "Epoch:12, weight train batch: 253, step:3, loss before: 7.55111932449e-06, loss after: 7.55111932449e-06.\n",
      "Epoch:12, weight train batch: 253, step:4, loss before: 7.62562785894e-06, loss after: 7.62562785894e-06.\n",
      "Epoch:12, weight train batch: 253, step:5, loss before: 6.88430100126e-06, loss after: 6.85822396918e-06.\n",
      "Epoch:12, weight train batch: 253, step:6, loss before: 1.99581591005e-05, loss after: 1.99507121579e-05.\n",
      "Epoch:12, weight train batch: 253, step:7, loss before: 7.43563577998e-06, loss after: 7.4095587479e-06.\n",
      "Epoch:12, weight train batch: 253, step:8, loss before: 7.39837923902e-06, loss after: 7.39837923902e-06.\n",
      "Epoch:12, weight train batch: 253, step:9, loss before: 8.21421235742e-06, loss after: 8.21421235742e-06.\n",
      "Epoch:12, weight train batch: 253, step:10, loss before: 1.91353210539e-05, loss after: 1.91278704733e-05.\n",
      "Epoch:12, weight train batch: 253, step:11, loss before: 7.46543537389e-06, loss after: 7.46543537389e-06.\n",
      "Epoch:12, weight train batch: 253, step:12, loss before: 8.8177039288e-06, loss after: 8.8177039288e-06.\n",
      "Epoch:12, weight train batch: 253, step:13, loss before: 5.7220177041e-06, loss after: 5.7220177041e-06.\n",
      "Epoch:12, weight train batch: 253, step:14, loss before: 6.77254274706e-06, loss after: 6.77254274706e-06.\n",
      "Epoch:12, weight train batch: 253, step:15, loss before: 7.20839670976e-06, loss after: 7.20839670976e-06.\n",
      "Epoch:12, weight train batch: 253, step:16, loss before: 7.99442295829e-06, loss after: 7.99442295829e-06.\n",
      "Epoch:12, weight train batch: 253, step:17, loss before: 6.72783608024e-06, loss after: 6.72783608024e-06.\n",
      "Epoch:12, weight train batch: 253, step:18, loss before: 7.77835793997e-06, loss after: 7.74855561758e-06.\n",
      "Epoch:12, weight train batch: 253, step:19, loss before: 8.52340781421e-06, loss after: 8.52340781421e-06.\n",
      "Epoch:12, weight train batch: 253, step:20, loss before: 9.36531432671e-06, loss after: 9.36531432671e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12, weight train batch: 253, step:21, loss before: 7.18231694918e-06, loss after: 7.15251508154e-06.\n",
      "Epoch:12, weight train batch: 253, step:22, loss before: 8.37439620227e-06, loss after: 8.37439620227e-06.\n",
      "Epoch:12, weight train batch: 253, step:23, loss before: 8.55321286508e-06, loss after: 8.55321286508e-06.\n",
      "Epoch:12, weight train batch: 253, step:24, loss before: 6.95135304341e-06, loss after: 6.95135304341e-06.\n",
      "Epoch:12, weight train batch: 253, step:25, loss before: 9.13434996619e-06, loss after: 9.13434996619e-06.\n",
      "Epoch:12, weight train batch: 253, step:26, loss before: 7.32387752578e-06, loss after: 7.32387752578e-06.\n",
      "Epoch:12, weight train batch: 253, step:27, loss before: 6.37021275907e-06, loss after: 6.37021275907e-06.\n",
      "Epoch:12, weight train batch: 253, step:28, loss before: 7.22702043277e-06, loss after: 7.22702043277e-06.\n",
      "Epoch:12, weight train batch: 253, step:29, loss before: 7.60699549573e-06, loss after: 7.57719362809e-06.\n",
      "Epoch:12, weight train batch: 253, step:30, loss before: 5.77044966121e-06, loss after: 5.77044966121e-06.\n",
      "Epoch:12, weight train batch: 253, step:31, loss before: 8.26263931231e-06, loss after: 8.26263931231e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 249, loss before: 0.00542322779074, loss after: 8.07637843536e-06.\n",
      "Epoch:12, weight train batch: 254, step:0, loss before: 8.40313514345e-05, loss after: 8.39979111333e-05.\n",
      "Epoch:12, weight train batch: 254, step:1, loss before: 8.44890291773e-06, loss after: 8.44890291773e-06.\n",
      "Epoch:12, weight train batch: 254, step:2, loss before: 7.67032906879e-06, loss after: 7.67032906879e-06.\n",
      "Epoch:12, weight train batch: 254, step:3, loss before: 0.00108908221591, loss after: 0.00108602689579.\n",
      "Epoch:12, weight train batch: 254, step:4, loss before: 7.79326001066e-06, loss after: 7.79326001066e-06.\n",
      "Epoch:12, weight train batch: 254, step:5, loss before: 6.824693628e-06, loss after: 6.79116647007e-06.\n",
      "Epoch:12, weight train batch: 254, step:6, loss before: 7.71502891439e-06, loss after: 7.71502891439e-06.\n",
      "Epoch:12, weight train batch: 254, step:7, loss before: 7.18976843928e-06, loss after: 7.18976843928e-06.\n",
      "Epoch:12, weight train batch: 254, step:8, loss before: 8.72829514265e-06, loss after: 8.72829514265e-06.\n",
      "Epoch:12, weight train batch: 254, step:9, loss before: 8.18813623482e-06, loss after: 8.15460953163e-06.\n",
      "Epoch:12, weight train batch: 254, step:10, loss before: 9.78999742074e-06, loss after: 9.76019509835e-06.\n",
      "Epoch:12, weight train batch: 254, step:11, loss before: 7.63679963711e-06, loss after: 7.63679963711e-06.\n",
      "Epoch:12, weight train batch: 254, step:12, loss before: 9.93887988443e-06, loss after: 9.93142930383e-06.\n",
      "Epoch:12, weight train batch: 254, step:13, loss before: 4.42169839516e-05, loss after: 4.41723313997e-05.\n",
      "Epoch:12, weight train batch: 254, step:14, loss before: 8.06147727417e-06, loss after: 8.06147727417e-06.\n",
      "Epoch:12, weight train batch: 254, step:15, loss before: 4.49733852292e-05, loss after: 4.48133832833e-05.\n",
      "Epoch:12, weight train batch: 254, step:16, loss before: 4.16394686908e-05, loss after: 4.13715533796e-05.\n",
      "Epoch:12, weight train batch: 254, step:17, loss before: 7.95717005531e-06, loss after: 7.95717005531e-06.\n",
      "Epoch:12, weight train batch: 254, step:18, loss before: 6.9439033723e-06, loss after: 6.9439033723e-06.\n",
      "Epoch:12, weight train batch: 254, step:19, loss before: 1.10341725303e-05, loss after: 1.10267228592e-05.\n",
      "Epoch:12, weight train batch: 254, step:20, loss before: 7.28662598704e-06, loss after: 7.28662598704e-06.\n",
      "Epoch:12, weight train batch: 254, step:21, loss before: 9.76019146037e-06, loss after: 9.73411533778e-06.\n",
      "Epoch:12, weight train batch: 254, step:22, loss before: 7.6777769209e-06, loss after: 7.64425021771e-06.\n",
      "Epoch:12, weight train batch: 254, step:23, loss before: 6.95135349815e-06, loss after: 6.95135349815e-06.\n",
      "Epoch:12, weight train batch: 254, step:24, loss before: 8.85123063199e-06, loss after: 8.85123063199e-06.\n",
      "Epoch:12, weight train batch: 254, step:25, loss before: 8.15460953163e-06, loss after: 8.13225778984e-06.\n",
      "Epoch:12, weight train batch: 254, step:26, loss before: 6.66823325446e-06, loss after: 6.66823325446e-06.\n",
      "Epoch:12, weight train batch: 254, step:27, loss before: 7.41700796425e-06, loss after: 7.41700796425e-06.\n",
      "Epoch:12, weight train batch: 254, step:28, loss before: 6.48197192277e-06, loss after: 6.48197192277e-06.\n",
      "Epoch:12, weight train batch: 254, step:29, loss before: 7.51759034756e-06, loss after: 7.51759034756e-06.\n",
      "Epoch:12, weight train batch: 254, step:30, loss before: 8.37439802126e-06, loss after: 8.37439802126e-06.\n",
      "Epoch:12, weight train batch: 254, step:31, loss before: 1.58648781508e-05, loss after: 1.58611528605e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 250, loss before: 1.10916289486e-05, loss after: 3.23806598317e-05.\n",
      "Epoch:12, weight train batch: 255, step:0, loss before: 8.37067636894e-06, loss after: 8.37067636894e-06.\n",
      "Epoch:12, weight train batch: 255, step:1, loss before: 7.31642558094e-06, loss after: 7.28662416805e-06.\n",
      "Epoch:12, weight train batch: 255, step:2, loss before: 6.75764022162e-06, loss after: 6.75764022162e-06.\n",
      "Epoch:12, weight train batch: 255, step:3, loss before: 7.00350574334e-06, loss after: 6.97742871125e-06.\n",
      "Epoch:12, weight train batch: 255, step:4, loss before: 7.76345950726e-06, loss after: 7.76345950726e-06.\n",
      "Epoch:12, weight train batch: 255, step:5, loss before: 6.25100256002e-06, loss after: 6.25100256002e-06.\n",
      "Epoch:12, weight train batch: 255, step:6, loss before: 7.82678671385e-06, loss after: 7.82678671385e-06.\n",
      "Epoch:12, weight train batch: 255, step:7, loss before: 7.83796349424e-06, loss after: 7.83796349424e-06.\n",
      "Epoch:12, weight train batch: 255, step:8, loss before: 8.35949776956e-06, loss after: 8.35949776956e-06.\n",
      "Epoch:12, weight train batch: 255, step:9, loss before: 7.33505521566e-06, loss after: 7.33505521566e-06.\n",
      "Epoch:12, weight train batch: 255, step:10, loss before: 1.00880151876e-05, loss after: 1.00880151876e-05.\n",
      "Epoch:12, weight train batch: 255, step:11, loss before: 7.20839580026e-06, loss after: 7.18231876817e-06.\n",
      "Epoch:12, weight train batch: 255, step:12, loss before: 7.51014067646e-06, loss after: 7.51014067646e-06.\n",
      "Epoch:12, weight train batch: 255, step:13, loss before: 6.84704718878e-06, loss after: 6.84704718878e-06.\n",
      "Epoch:12, weight train batch: 255, step:14, loss before: 7.99442659627e-06, loss after: 7.99442659627e-06.\n",
      "Epoch:12, weight train batch: 255, step:15, loss before: 7.1376134656e-06, loss after: 7.1376134656e-06.\n",
      "Epoch:12, weight train batch: 255, step:16, loss before: 7.2419238677e-06, loss after: 7.2419238677e-06.\n",
      "Epoch:12, weight train batch: 255, step:17, loss before: 8.2030401245e-06, loss after: 8.2030401245e-06.\n",
      "Epoch:12, weight train batch: 255, step:18, loss before: 8.16578722151e-06, loss after: 8.16578722151e-06.\n",
      "Epoch:12, weight train batch: 255, step:19, loss before: 6.2733570303e-06, loss after: 6.2733570303e-06.\n",
      "Epoch:12, weight train batch: 255, step:20, loss before: 1.53508008225e-05, loss after: 1.53508008225e-05.\n",
      "Epoch:12, weight train batch: 255, step:21, loss before: 6.28825864624e-06, loss after: 6.28825864624e-06.\n",
      "Epoch:12, weight train batch: 255, step:22, loss before: 5.80397818339e-06, loss after: 5.7928023125e-06.\n",
      "Epoch:12, weight train batch: 255, step:23, loss before: 7.38720473237e-06, loss after: 7.38720473237e-06.\n",
      "Epoch:12, weight train batch: 255, step:24, loss before: 7.2307479968e-06, loss after: 7.2307479968e-06.\n",
      "Epoch:12, weight train batch: 255, step:25, loss before: 7.28662416805e-06, loss after: 7.28662416805e-06.\n",
      "Epoch:12, weight train batch: 255, step:26, loss before: 6.69058590574e-06, loss after: 6.69058590574e-06.\n",
      "Epoch:12, weight train batch: 255, step:27, loss before: 8.82515541889e-06, loss after: 8.82515541889e-06.\n",
      "Epoch:12, weight train batch: 255, step:28, loss before: 7.40956147638e-06, loss after: 7.40956147638e-06.\n",
      "Epoch:12, weight train batch: 255, step:29, loss before: 8.18441367301e-06, loss after: 8.18441367301e-06.\n",
      "Epoch:12, weight train batch: 255, step:30, loss before: 7.30152532924e-06, loss after: 7.30152532924e-06.\n",
      "Epoch:12, weight train batch: 255, step:31, loss before: 6.18767626293e-06, loss after: 6.18767626293e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 251, loss before: 7.50174649511e-06, loss after: 6.98674284649e-06.\n",
      "Epoch:12, weight train batch: 256, step:0, loss before: 6.96253346177e-06, loss after: 6.96253346177e-06.\n",
      "Epoch:12, weight train batch: 256, step:1, loss before: 8.41537530505e-06, loss after: 8.41537530505e-06.\n",
      "Epoch:12, weight train batch: 256, step:2, loss before: 8.1918642536e-06, loss after: 8.15833664092e-06.\n",
      "Epoch:12, weight train batch: 256, step:3, loss before: 9.02258943825e-06, loss after: 9.02258943825e-06.\n",
      "Epoch:12, weight train batch: 256, step:4, loss before: 7.61444607633e-06, loss after: 7.61444607633e-06.\n",
      "Epoch:12, weight train batch: 256, step:5, loss before: 0.0216702129692, loss after: 0.021669216454.\n",
      "Epoch:12, weight train batch: 256, step:6, loss before: 9.06729655981e-06, loss after: 9.10827384359e-06.\n",
      "Epoch:12, weight train batch: 256, step:7, loss before: 7.42445990909e-06, loss after: 7.44308636058e-06.\n",
      "Epoch:12, weight train batch: 256, step:8, loss before: 5.85612951909e-06, loss after: 5.85612951909e-06.\n",
      "Epoch:12, weight train batch: 256, step:9, loss before: 7.56974623073e-06, loss after: 7.59582280807e-06.\n",
      "Epoch:12, weight train batch: 256, step:10, loss before: 7.05938555257e-06, loss after: 7.08546258466e-06.\n",
      "Epoch:12, weight train batch: 256, step:11, loss before: 7.9422707131e-06, loss after: 7.97207212599e-06.\n",
      "Epoch:12, weight train batch: 256, step:12, loss before: 8.06892967375e-06, loss after: 8.03540297056e-06.\n",
      "Epoch:12, weight train batch: 256, step:13, loss before: 7.23447374185e-06, loss after: 7.26800135453e-06.\n",
      "Epoch:12, weight train batch: 256, step:14, loss before: 8.46380571602e-05, loss after: 8.46381444717e-05.\n",
      "Epoch:12, weight train batch: 256, step:15, loss before: 8.2440146798e-06, loss after: 8.2440146798e-06.\n",
      "Epoch:12, weight train batch: 256, step:16, loss before: 6.48197237751e-06, loss after: 6.5154999902e-06.\n",
      "Epoch:12, weight train batch: 256, step:17, loss before: 7.18232149666e-06, loss after: 7.18232149666e-06.\n",
      "Epoch:12, weight train batch: 256, step:18, loss before: 8.92573552846e-06, loss after: 8.95181256055e-06.\n",
      "Epoch:12, weight train batch: 256, step:19, loss before: 7.45053876017e-06, loss after: 7.42446263757e-06.\n",
      "Epoch:12, weight train batch: 256, step:20, loss before: 7.36858601158e-06, loss after: 7.36858601158e-06.\n",
      "Epoch:12, weight train batch: 256, step:21, loss before: 6.79861886965e-06, loss after: 6.82469590174e-06.\n",
      "Epoch:12, weight train batch: 256, step:22, loss before: 9.52923073783e-06, loss after: 9.52923073783e-06.\n",
      "Epoch:12, weight train batch: 256, step:23, loss before: 7.80071331974e-06, loss after: 7.80071331974e-06.\n",
      "Epoch:12, weight train batch: 256, step:24, loss before: 7.24192432244e-06, loss after: 7.24192432244e-06.\n",
      "Epoch:12, weight train batch: 256, step:25, loss before: 6.98861003912e-06, loss after: 7.04076364855e-06.\n",
      "Epoch:12, weight train batch: 256, step:26, loss before: 6.5453004936e-06, loss after: 6.49687262921e-06.\n",
      "Epoch:12, weight train batch: 256, step:27, loss before: 1.02407175291e-05, loss after: 1.02407175291e-05.\n",
      "Epoch:12, weight train batch: 256, step:28, loss before: 8.46007969812e-06, loss after: 8.41910150484e-06.\n",
      "Epoch:12, weight train batch: 256, step:29, loss before: 7.16742169971e-06, loss after: 7.16742169971e-06.\n",
      "Epoch:12, weight train batch: 256, step:30, loss before: 8.83260872797e-06, loss after: 8.83260872797e-06.\n",
      "Epoch:12, weight train batch: 256, step:31, loss before: 9.57762222242e-06, loss after: 9.57389693212e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 252, loss before: 1.04862265289e-05, loss after: 7.97393749963e-06.\n",
      "Epoch:12, weight train batch: 257, step:0, loss before: 7.38348308005e-06, loss after: 7.38348308005e-06.\n",
      "Epoch:12, weight train batch: 257, step:1, loss before: 7.53249560148e-06, loss after: 7.53249560148e-06.\n",
      "Epoch:12, weight train batch: 257, step:2, loss before: 2.06359000003e-05, loss after: 2.0643346943e-05.\n",
      "Epoch:12, weight train batch: 257, step:3, loss before: 6.99233351042e-06, loss after: 6.99233351042e-06.\n",
      "Epoch:12, weight train batch: 257, step:4, loss before: 8.57556369738e-06, loss after: 8.57556369738e-06.\n",
      "Epoch:12, weight train batch: 257, step:5, loss before: 7.79698893894e-06, loss after: 7.79698893894e-06.\n",
      "Epoch:12, weight train batch: 257, step:6, loss before: 8.34832462715e-06, loss after: 8.31107172417e-06.\n",
      "Epoch:12, weight train batch: 257, step:7, loss before: 1.51124058902e-05, loss after: 1.51124058902e-05.\n",
      "Epoch:12, weight train batch: 257, step:8, loss before: 8.53458641359e-06, loss after: 8.53458641359e-06.\n",
      "Epoch:12, weight train batch: 257, step:9, loss before: 8.81025698618e-06, loss after: 8.81025698618e-06.\n",
      "Epoch:12, weight train batch: 257, step:10, loss before: 1.75257628143e-05, loss after: 1.7522037524e-05.\n",
      "Epoch:12, weight train batch: 257, step:11, loss before: 8.78418268258e-06, loss after: 8.78418268258e-06.\n",
      "Epoch:12, weight train batch: 257, step:12, loss before: 8.37812604004e-06, loss after: 8.37812604004e-06.\n",
      "Epoch:12, weight train batch: 257, step:13, loss before: 8.81025698618e-06, loss after: 8.81025698618e-06.\n",
      "Epoch:12, weight train batch: 257, step:14, loss before: 9.24983669393e-06, loss after: 9.24983669393e-06.\n",
      "Epoch:12, weight train batch: 257, step:15, loss before: 6.98488383932e-06, loss after: 6.96253209753e-06.\n",
      "Epoch:12, weight train batch: 257, step:16, loss before: 7.59954946261e-06, loss after: 7.59954946261e-06.\n",
      "Epoch:12, weight train batch: 257, step:17, loss before: 6.26963355899e-06, loss after: 6.26963355899e-06.\n",
      "Epoch:12, weight train batch: 257, step:18, loss before: 6.52667768009e-06, loss after: 6.52667768009e-06.\n",
      "Epoch:12, weight train batch: 257, step:19, loss before: 7.26055213818e-06, loss after: 7.26055213818e-06.\n",
      "Epoch:12, weight train batch: 257, step:20, loss before: 7.79698711995e-06, loss after: 7.79698711995e-06.\n",
      "Epoch:12, weight train batch: 257, step:21, loss before: 8.65379752213e-06, loss after: 8.65379752213e-06.\n",
      "Epoch:12, weight train batch: 257, step:22, loss before: 7.6368023656e-06, loss after: 7.6368023656e-06.\n",
      "Epoch:12, weight train batch: 257, step:23, loss before: 7.42073871152e-06, loss after: 7.42073871152e-06.\n",
      "Epoch:12, weight train batch: 257, step:24, loss before: 8.91083800525e-06, loss after: 8.91083800525e-06.\n",
      "Epoch:12, weight train batch: 257, step:25, loss before: 8.21049434307e-06, loss after: 8.21049434307e-06.\n",
      "Epoch:12, weight train batch: 257, step:26, loss before: 7.55857399781e-06, loss after: 7.53249742047e-06.\n",
      "Epoch:12, weight train batch: 257, step:27, loss before: 7.45053648643e-06, loss after: 7.43563532524e-06.\n",
      "Epoch:12, weight train batch: 257, step:28, loss before: 6.88802720106e-06, loss after: 6.88802720106e-06.\n",
      "Epoch:12, weight train batch: 257, step:29, loss before: 8.67987364472e-06, loss after: 8.67987364472e-06.\n",
      "Epoch:12, weight train batch: 257, step:30, loss before: 8.18441640149e-06, loss after: 8.18441640149e-06.\n",
      "Epoch:12, weight train batch: 257, step:31, loss before: 7.69640791987e-06, loss after: 7.69640791987e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 253, loss before: 0.000517361680977, loss after: 7.11525717634e-06.\n",
      "Epoch:12, weight train batch: 258, step:0, loss before: 0.0216684564948, loss after: 0.0216684564948.\n",
      "Epoch:12, weight train batch: 258, step:1, loss before: 8.37440529722e-06, loss after: 8.37440529722e-06.\n",
      "Epoch:12, weight train batch: 258, step:2, loss before: 8.51596269058e-06, loss after: 8.51596269058e-06.\n",
      "Epoch:12, weight train batch: 258, step:3, loss before: 8.7655525931e-06, loss after: 8.7655525931e-06.\n",
      "Epoch:12, weight train batch: 258, step:4, loss before: 7.47661761125e-06, loss after: 7.45054148865e-06.\n",
      "Epoch:12, weight train batch: 258, step:5, loss before: 8.00932866696e-06, loss after: 8.00932866696e-06.\n",
      "Epoch:12, weight train batch: 258, step:6, loss before: 8.16951251181e-06, loss after: 8.16951251181e-06.\n",
      "Epoch:12, weight train batch: 258, step:7, loss before: 1.0758289136e-05, loss after: 1.0758289136e-05.\n",
      "Epoch:12, weight train batch: 258, step:8, loss before: 1.05274830275e-05, loss after: 1.05274830275e-05.\n",
      "Epoch:12, weight train batch: 258, step:9, loss before: 2.07211269299e-05, loss after: 2.07099546969e-05.\n",
      "Epoch:12, weight train batch: 258, step:10, loss before: 6.94762911735e-06, loss after: 6.94762911735e-06.\n",
      "Epoch:12, weight train batch: 258, step:11, loss before: 7.38348626328e-06, loss after: 7.38348626328e-06.\n",
      "Epoch:12, weight train batch: 258, step:12, loss before: 7.6479764175e-06, loss after: 7.62189984016e-06.\n",
      "Epoch:12, weight train batch: 258, step:13, loss before: 7.83051564213e-06, loss after: 7.83051564213e-06.\n",
      "Epoch:12, weight train batch: 258, step:14, loss before: 9.27579912968e-06, loss after: 9.27579912968e-06.\n",
      "Epoch:12, weight train batch: 258, step:15, loss before: 7.54366919864e-06, loss after: 7.5101420407e-06.\n",
      "Epoch:12, weight train batch: 258, step:16, loss before: 6.3925658651e-06, loss after: 6.3925658651e-06.\n",
      "Epoch:12, weight train batch: 258, step:17, loss before: 7.32015541871e-06, loss after: 7.32015541871e-06.\n",
      "Epoch:12, weight train batch: 258, step:18, loss before: 6.83587359163e-06, loss after: 6.83587359163e-06.\n",
      "Epoch:12, weight train batch: 258, step:19, loss before: 7.3052578955e-06, loss after: 7.3052578955e-06.\n",
      "Epoch:12, weight train batch: 258, step:20, loss before: 6.20257924311e-06, loss after: 6.20257924311e-06.\n",
      "Epoch:12, weight train batch: 258, step:21, loss before: 8.26902905828e-05, loss after: 8.26568357297e-05.\n",
      "Epoch:12, weight train batch: 258, step:22, loss before: 1.67137513927e-05, loss after: 1.67063026311e-05.\n",
      "Epoch:12, weight train batch: 258, step:23, loss before: 0.0216672383249, loss after: 0.0216672383249.\n",
      "Epoch:12, weight train batch: 258, step:24, loss before: 7.36485981179e-06, loss after: 7.33878368919e-06.\n",
      "Epoch:12, weight train batch: 258, step:25, loss before: 6.81352230458e-06, loss after: 6.81352230458e-06.\n",
      "Epoch:12, weight train batch: 258, step:26, loss before: 6.86939984007e-06, loss after: 6.86939984007e-06.\n",
      "Epoch:12, weight train batch: 258, step:27, loss before: 8.44890746521e-06, loss after: 8.43028101372e-06.\n",
      "Epoch:12, weight train batch: 258, step:28, loss before: 8.85868757905e-06, loss after: 8.85868757905e-06.\n",
      "Epoch:12, weight train batch: 258, step:29, loss before: 9.18278237805e-06, loss after: 9.18278237805e-06.\n",
      "Epoch:12, weight train batch: 258, step:30, loss before: 7.29407884137e-06, loss after: 7.29407884137e-06.\n",
      "Epoch:12, weight train batch: 258, step:31, loss before: 6.71666566632e-06, loss after: 6.71666566632e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 254, loss before: 6.72784062772e-06, loss after: 7.39277493267e-06.\n",
      "Epoch:12, weight train batch: 259, step:0, loss before: 9.51051333686e-06, loss after: 9.51051333686e-06.\n",
      "Epoch:12, weight train batch: 259, step:1, loss before: 7.07801473254e-06, loss after: 7.0519381552e-06.\n",
      "Epoch:12, weight train batch: 259, step:2, loss before: 7.48779348214e-06, loss after: 7.48779348214e-06.\n",
      "Epoch:12, weight train batch: 259, step:3, loss before: 5.77044966121e-06, loss after: 5.77044966121e-06.\n",
      "Epoch:12, weight train batch: 259, step:4, loss before: 6.79117238178e-06, loss after: 6.79117238178e-06.\n",
      "Epoch:12, weight train batch: 259, step:5, loss before: 7.40956238587e-06, loss after: 7.40956238587e-06.\n",
      "Epoch:12, weight train batch: 259, step:6, loss before: 0.00102013221476, loss after: 0.00101681053638.\n",
      "Epoch:12, weight train batch: 259, step:7, loss before: 1.07995110739e-05, loss after: 1.07846099127e-05.\n",
      "Epoch:12, weight train batch: 259, step:8, loss before: 7.95717369328e-06, loss after: 7.95717369328e-06.\n",
      "Epoch:12, weight train batch: 259, step:9, loss before: 7.17487137081e-06, loss after: 7.17487137081e-06.\n",
      "Epoch:12, weight train batch: 259, step:10, loss before: 6.26591099717e-06, loss after: 6.26591099717e-06.\n",
      "Epoch:12, weight train batch: 259, step:11, loss before: 7.63307980378e-06, loss after: 7.63307980378e-06.\n",
      "Epoch:12, weight train batch: 259, step:12, loss before: 6.32551473245e-06, loss after: 6.32551473245e-06.\n",
      "Epoch:12, weight train batch: 259, step:13, loss before: 7.88266879681e-06, loss after: 7.84169060353e-06.\n",
      "Epoch:12, weight train batch: 259, step:14, loss before: 6.97743053024e-06, loss after: 6.97743053024e-06.\n",
      "Epoch:12, weight train batch: 259, step:15, loss before: 7.5213179116e-06, loss after: 7.5213179116e-06.\n",
      "Epoch:12, weight train batch: 259, step:16, loss before: 7.99442750576e-06, loss after: 7.99442750576e-06.\n",
      "Epoch:12, weight train batch: 259, step:17, loss before: 0.000146821475937, loss after: 0.000146713675349.\n",
      "Epoch:12, weight train batch: 259, step:18, loss before: 7.6666019595e-06, loss after: 7.62934951126e-06.\n",
      "Epoch:12, weight train batch: 259, step:19, loss before: 6.38510800854e-06, loss after: 6.34412981526e-06.\n",
      "Epoch:12, weight train batch: 259, step:20, loss before: 8.70594976732e-06, loss after: 8.70594976732e-06.\n",
      "Epoch:12, weight train batch: 259, step:21, loss before: 8.67987455422e-06, loss after: 8.67987455422e-06.\n",
      "Epoch:12, weight train batch: 259, step:22, loss before: 5.60281387152e-06, loss after: 5.60281387152e-06.\n",
      "Epoch:12, weight train batch: 259, step:23, loss before: 8.27009534987e-06, loss after: 8.27009534987e-06.\n",
      "Epoch:12, weight train batch: 259, step:24, loss before: 6.83587404637e-06, loss after: 6.83587404637e-06.\n",
      "Epoch:12, weight train batch: 259, step:25, loss before: 8.15833664092e-06, loss after: 8.15833664092e-06.\n",
      "Epoch:12, weight train batch: 259, step:26, loss before: 6.45589807391e-06, loss after: 6.38139272269e-06.\n",
      "Epoch:12, weight train batch: 259, step:27, loss before: 6.26963446848e-06, loss after: 6.26963446848e-06.\n",
      "Epoch:12, weight train batch: 259, step:28, loss before: 7.81189010013e-06, loss after: 7.77836248744e-06.\n",
      "Epoch:12, weight train batch: 259, step:29, loss before: 7.7522781794e-06, loss after: 7.7522781794e-06.\n",
      "Epoch:12, weight train batch: 259, step:30, loss before: 6.10944789514e-06, loss after: 6.10944789514e-06.\n",
      "Epoch:12, weight train batch: 259, step:31, loss before: 7.71130544308e-06, loss after: 7.71130544308e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:12, struct parameters train batch: 255, loss before: 2.36694595515e-05, loss after: 9.87066596281e-06.\n",
      "Epoch:13, weight train batch: 260, step:0, loss before: 6.5080503191e-06, loss after: 6.5080503191e-06.\n",
      "Epoch:13, weight train batch: 260, step:1, loss before: 7.71130726207e-06, loss after: 7.71130726207e-06.\n",
      "Epoch:13, weight train batch: 260, step:2, loss before: 5.6475173551e-06, loss after: 5.6475173551e-06.\n",
      "Epoch:13, weight train batch: 260, step:3, loss before: 6.3813909037e-06, loss after: 6.3813909037e-06.\n",
      "Epoch:13, weight train batch: 260, step:4, loss before: 9.294541087e-06, loss after: 9.294541087e-06.\n",
      "Epoch:13, weight train batch: 260, step:5, loss before: 6.56392194287e-06, loss after: 6.56392194287e-06.\n",
      "Epoch:13, weight train batch: 260, step:6, loss before: 6.68313623464e-06, loss after: 6.68313623464e-06.\n",
      "Epoch:13, weight train batch: 260, step:7, loss before: 6.93645506544e-06, loss after: 6.91037803335e-06.\n",
      "Epoch:13, weight train batch: 260, step:8, loss before: 6.23238020125e-06, loss after: 6.23238020125e-06.\n",
      "Epoch:13, weight train batch: 260, step:9, loss before: 6.73901695336e-06, loss after: 6.73901695336e-06.\n",
      "Epoch:13, weight train batch: 260, step:10, loss before: 7.07801564204e-06, loss after: 7.07801564204e-06.\n",
      "Epoch:13, weight train batch: 260, step:11, loss before: 1.39167077577e-05, loss after: 1.39129824674e-05.\n",
      "Epoch:13, weight train batch: 260, step:12, loss before: 7.54739676267e-06, loss after: 7.54739676267e-06.\n",
      "Epoch:13, weight train batch: 260, step:13, loss before: 7.19349736755e-06, loss after: 7.19349736755e-06.\n",
      "Epoch:13, weight train batch: 260, step:14, loss before: 7.82306506153e-06, loss after: 7.82306506153e-06.\n",
      "Epoch:13, weight train batch: 260, step:15, loss before: 7.17859666111e-06, loss after: 7.14506950317e-06.\n",
      "Epoch:13, weight train batch: 260, step:16, loss before: 6.06847243034e-06, loss after: 6.06847243034e-06.\n",
      "Epoch:13, weight train batch: 260, step:17, loss before: 6.09454764344e-06, loss after: 6.09454764344e-06.\n",
      "Epoch:13, weight train batch: 260, step:18, loss before: 6.85822487867e-06, loss after: 6.85822487867e-06.\n",
      "Epoch:13, weight train batch: 260, step:19, loss before: 7.84169151302e-06, loss after: 7.84169151302e-06.\n",
      "Epoch:13, weight train batch: 260, step:20, loss before: 1.04306554931e-05, loss after: 1.03934025901e-05.\n",
      "Epoch:13, weight train batch: 260, step:21, loss before: 8.28127303976e-06, loss after: 8.28127303976e-06.\n",
      "Epoch:13, weight train batch: 260, step:22, loss before: 1.06802353912e-05, loss after: 1.06802353912e-05.\n",
      "Epoch:13, weight train batch: 260, step:23, loss before: 6.28826001048e-06, loss after: 6.28826001048e-06.\n",
      "Epoch:13, weight train batch: 260, step:24, loss before: 8.59046849655e-06, loss after: 8.59046849655e-06.\n",
      "Epoch:13, weight train batch: 260, step:25, loss before: 6.70921190249e-06, loss after: 6.70921190249e-06.\n",
      "Epoch:13, weight train batch: 260, step:26, loss before: 6.53040478937e-06, loss after: 6.53040478937e-06.\n",
      "Epoch:13, weight train batch: 260, step:27, loss before: 6.62353249936e-06, loss after: 6.62353249936e-06.\n",
      "Epoch:13, weight train batch: 260, step:28, loss before: 7.77091190685e-06, loss after: 7.77091190685e-06.\n",
      "Epoch:13, weight train batch: 260, step:29, loss before: 6.61980720906e-06, loss after: 6.61980720906e-06.\n",
      "Epoch:13, weight train batch: 260, step:30, loss before: 6.6794104896e-06, loss after: 6.6794104896e-06.\n",
      "Epoch:13, weight train batch: 260, step:31, loss before: 6.39256768409e-06, loss after: 6.39256768409e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 256, loss before: 7.47102922105e-06, loss after: 0.000245746079599.\n",
      "Epoch:13, weight train batch: 261, step:0, loss before: 6.42609666102e-06, loss after: 6.40747066427e-06.\n",
      "Epoch:13, weight train batch: 261, step:1, loss before: 6.29943770036e-06, loss after: 6.29943770036e-06.\n",
      "Epoch:13, weight train batch: 261, step:2, loss before: 8.06890147942e-06, loss after: 8.06890147942e-06.\n",
      "Epoch:13, weight train batch: 261, step:3, loss before: 8.63889545144e-06, loss after: 8.61281841935e-06.\n",
      "Epoch:13, weight train batch: 261, step:4, loss before: 0.0020483804401, loss after: 0.00204529170878.\n",
      "Epoch:13, weight train batch: 261, step:5, loss before: 5.88965758652e-06, loss after: 5.88965758652e-06.\n",
      "Epoch:13, weight train batch: 261, step:6, loss before: 7.16742169971e-06, loss after: 7.16742169971e-06.\n",
      "Epoch:13, weight train batch: 261, step:7, loss before: 6.74273996992e-06, loss after: 6.75019055052e-06.\n",
      "Epoch:13, weight train batch: 261, step:8, loss before: 6.76881791151e-06, loss after: 6.76881791151e-06.\n",
      "Epoch:13, weight train batch: 261, step:9, loss before: 7.9161964095e-06, loss after: 7.9161964095e-06.\n",
      "Epoch:13, weight train batch: 261, step:10, loss before: 7.5958259913e-06, loss after: 7.5958259913e-06.\n",
      "Epoch:13, weight train batch: 261, step:11, loss before: 7.037038813e-06, loss after: 7.037038813e-06.\n",
      "Epoch:13, weight train batch: 261, step:12, loss before: 7.29775729269e-06, loss after: 7.29403200239e-06.\n",
      "Epoch:13, weight train batch: 261, step:13, loss before: 7.69640610088e-06, loss after: 7.69640610088e-06.\n",
      "Epoch:13, weight train batch: 261, step:14, loss before: 7.00350892657e-06, loss after: 6.97370660419e-06.\n",
      "Epoch:13, weight train batch: 261, step:15, loss before: 5.733193575e-06, loss after: 5.733193575e-06.\n",
      "Epoch:13, weight train batch: 261, step:16, loss before: 6.366490652e-06, loss after: 6.366490652e-06.\n",
      "Epoch:13, weight train batch: 261, step:17, loss before: 8.25519600767e-06, loss after: 8.25519600767e-06.\n",
      "Epoch:13, weight train batch: 261, step:18, loss before: 6.1168971115e-06, loss after: 6.09454536971e-06.\n",
      "Epoch:13, weight train batch: 261, step:19, loss before: 7.897569958e-06, loss after: 7.897569958e-06.\n",
      "Epoch:13, weight train batch: 261, step:20, loss before: 9.13435542316e-06, loss after: 9.13435542316e-06.\n",
      "Epoch:13, weight train batch: 261, step:21, loss before: 5.71084228795e-06, loss after: 5.71084228795e-06.\n",
      "Epoch:13, weight train batch: 261, step:22, loss before: 6.89175112711e-06, loss after: 6.89175112711e-06.\n",
      "Epoch:13, weight train batch: 261, step:23, loss before: 7.12271594239e-06, loss after: 7.12271594239e-06.\n",
      "Epoch:13, weight train batch: 261, step:24, loss before: 6.53785127724e-06, loss after: 6.5080494096e-06.\n",
      "Epoch:13, weight train batch: 261, step:25, loss before: 7.52131927584e-06, loss after: 7.52131927584e-06.\n",
      "Epoch:13, weight train batch: 261, step:26, loss before: 9.55893665378e-06, loss after: 9.55893665378e-06.\n",
      "Epoch:13, weight train batch: 261, step:27, loss before: 6.9141028689e-06, loss after: 6.9141028689e-06.\n",
      "Epoch:13, weight train batch: 261, step:28, loss before: 8.10990968603e-06, loss after: 8.10990968603e-06.\n",
      "Epoch:13, weight train batch: 261, step:29, loss before: 8.12850703369e-06, loss after: 8.12850703369e-06.\n",
      "Epoch:13, weight train batch: 261, step:30, loss before: 5.54693497179e-06, loss after: 5.49105561731e-06.\n",
      "Epoch:13, weight train batch: 261, step:31, loss before: 5.69967096453e-06, loss after: 5.69967096453e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 257, loss before: 6.75484807289e-06, loss after: 6.75484807289e-06.\n",
      "Epoch:13, weight train batch: 262, step:0, loss before: 7.16369459042e-06, loss after: 7.16369459042e-06.\n",
      "Epoch:13, weight train batch: 262, step:1, loss before: 5.86730629948e-06, loss after: 5.86730629948e-06.\n",
      "Epoch:13, weight train batch: 262, step:2, loss before: 6.20630453341e-06, loss after: 6.18395279162e-06.\n",
      "Epoch:13, weight train batch: 262, step:3, loss before: 6.12434996583e-06, loss after: 6.12434996583e-06.\n",
      "Epoch:13, weight train batch: 262, step:4, loss before: 3.85594976251e-05, loss after: 3.8499951188e-05.\n",
      "Epoch:13, weight train batch: 262, step:5, loss before: 8.66497339302e-06, loss after: 8.66497339302e-06.\n",
      "Epoch:13, weight train batch: 262, step:6, loss before: 1.62331034517e-05, loss after: 1.62256565091e-05.\n",
      "Epoch:13, weight train batch: 262, step:7, loss before: 5.19303330293e-06, loss after: 5.19303330293e-06.\n",
      "Epoch:13, weight train batch: 262, step:8, loss before: 4.84285919811e-06, loss after: 4.84285919811e-06.\n",
      "Epoch:13, weight train batch: 262, step:9, loss before: 5.26008807356e-06, loss after: 5.26008807356e-06.\n",
      "Epoch:13, weight train batch: 262, step:10, loss before: 1.7931446564e-05, loss after: 1.79202743311e-05.\n",
      "Epoch:13, weight train batch: 262, step:11, loss before: 7.68895461079e-06, loss after: 7.68895461079e-06.\n",
      "Epoch:13, weight train batch: 262, step:12, loss before: 6.55648000247e-06, loss after: 6.55648000247e-06.\n",
      "Epoch:13, weight train batch: 262, step:13, loss before: 7.09290907253e-06, loss after: 7.05193087924e-06.\n",
      "Epoch:13, weight train batch: 262, step:14, loss before: 6.70921326673e-06, loss after: 6.70921326673e-06.\n",
      "Epoch:13, weight train batch: 262, step:15, loss before: 8.62399338075e-06, loss after: 8.62399338075e-06.\n",
      "Epoch:13, weight train batch: 262, step:16, loss before: 7.54739630793e-06, loss after: 7.51014431444e-06.\n",
      "Epoch:13, weight train batch: 262, step:17, loss before: 5.89710862187e-06, loss after: 5.89710862187e-06.\n",
      "Epoch:13, weight train batch: 262, step:18, loss before: 6.79117056279e-06, loss after: 6.79117056279e-06.\n",
      "Epoch:13, weight train batch: 262, step:19, loss before: 8.43020279717e-06, loss after: 8.42647750687e-06.\n",
      "Epoch:13, weight train batch: 262, step:20, loss before: 3.77706201107e-05, loss after: 3.7692465412e-05.\n",
      "Epoch:13, weight train batch: 262, step:21, loss before: 7.97394022811e-05, loss after: 7.97096727183e-05.\n",
      "Epoch:13, weight train batch: 262, step:22, loss before: 6.92900448485e-06, loss after: 6.92900448485e-06.\n",
      "Epoch:13, weight train batch: 262, step:23, loss before: 7.85659267422e-06, loss after: 7.85659267422e-06.\n",
      "Epoch:13, weight train batch: 262, step:24, loss before: 6.03121497988e-06, loss after: 6.03121497988e-06.\n",
      "Epoch:13, weight train batch: 262, step:25, loss before: 6.46334729026e-06, loss after: 6.46334729026e-06.\n",
      "Epoch:13, weight train batch: 262, step:26, loss before: 6.60863224766e-06, loss after: 6.58255567032e-06.\n",
      "Epoch:13, weight train batch: 262, step:27, loss before: 7.323882528e-06, loss after: 7.323882528e-06.\n",
      "Epoch:13, weight train batch: 262, step:28, loss before: 7.0631131166e-06, loss after: 7.0631131166e-06.\n",
      "Epoch:13, weight train batch: 262, step:29, loss before: 7.00723330738e-06, loss after: 7.00723330738e-06.\n",
      "Epoch:13, weight train batch: 262, step:30, loss before: 7.71875966166e-06, loss after: 7.71875966166e-06.\n",
      "Epoch:13, weight train batch: 262, step:31, loss before: 4.97324617754e-06, loss after: 4.97324617754e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 258, loss before: 6.62353295411e-06, loss after: 6.62260163153e-06.\n",
      "Epoch:13, weight train batch: 263, step:0, loss before: 5.94553557676e-06, loss after: 5.94553557676e-06.\n",
      "Epoch:13, weight train batch: 263, step:1, loss before: 7.02586203261e-06, loss after: 6.98115854902e-06.\n",
      "Epoch:13, weight train batch: 263, step:2, loss before: 6.86940120431e-06, loss after: 6.86940120431e-06.\n",
      "Epoch:13, weight train batch: 263, step:3, loss before: 6.213755114e-06, loss after: 6.19140428171e-06.\n",
      "Epoch:13, weight train batch: 263, step:4, loss before: 6.57137843518e-06, loss after: 6.57137843518e-06.\n",
      "Epoch:13, weight train batch: 263, step:5, loss before: 5.91201023781e-06, loss after: 5.91201023781e-06.\n",
      "Epoch:13, weight train batch: 263, step:6, loss before: 6.23610776529e-06, loss after: 6.23610776529e-06.\n",
      "Epoch:13, weight train batch: 263, step:7, loss before: 6.96253118804e-06, loss after: 6.96253118804e-06.\n",
      "Epoch:13, weight train batch: 263, step:8, loss before: 6.11689665675e-06, loss after: 6.11317136645e-06.\n",
      "Epoch:13, weight train batch: 263, step:9, loss before: 6.05729474046e-06, loss after: 6.05729474046e-06.\n",
      "Epoch:13, weight train batch: 263, step:10, loss before: 6.57137934468e-06, loss after: 6.57137934468e-06.\n",
      "Epoch:13, weight train batch: 263, step:11, loss before: 7.02958595866e-06, loss after: 7.02958595866e-06.\n",
      "Epoch:13, weight train batch: 263, step:12, loss before: 5.4202737374e-06, loss after: 5.4202737374e-06.\n",
      "Epoch:13, weight train batch: 263, step:13, loss before: 5.52085839445e-06, loss after: 5.49478136236e-06.\n",
      "Epoch:13, weight train batch: 263, step:14, loss before: 1.75253735506e-05, loss after: 1.75142013177e-05.\n",
      "Epoch:13, weight train batch: 263, step:15, loss before: 7.58464830142e-06, loss after: 7.54367101763e-06.\n",
      "Epoch:13, weight train batch: 263, step:16, loss before: 7.93482286099e-06, loss after: 7.93482286099e-06.\n",
      "Epoch:13, weight train batch: 263, step:17, loss before: 7.17859938959e-06, loss after: 7.17859938959e-06.\n",
      "Epoch:13, weight train batch: 263, step:18, loss before: 5.97906364419e-06, loss after: 5.97906364419e-06.\n",
      "Epoch:13, weight train batch: 263, step:19, loss before: 6.32551427771e-06, loss after: 6.32551427771e-06.\n",
      "Epoch:13, weight train batch: 263, step:20, loss before: 5.58791134608e-06, loss after: 5.58791134608e-06.\n",
      "Epoch:13, weight train batch: 263, step:21, loss before: 1.63558070199e-05, loss after: 1.63148324646e-05.\n",
      "Epoch:13, weight train batch: 263, step:22, loss before: 5.87475915381e-06, loss after: 5.87475915381e-06.\n",
      "Epoch:13, weight train batch: 263, step:23, loss before: 6.86940165906e-06, loss after: 6.86940165906e-06.\n",
      "Epoch:13, weight train batch: 263, step:24, loss before: 6.54902896713e-06, loss after: 6.54902896713e-06.\n",
      "Epoch:13, weight train batch: 263, step:25, loss before: 7.36858419259e-06, loss after: 7.36858419259e-06.\n",
      "Epoch:13, weight train batch: 263, step:26, loss before: 6.65706056679e-06, loss after: 6.65706056679e-06.\n",
      "Epoch:13, weight train batch: 263, step:27, loss before: 6.79862114339e-06, loss after: 6.79862114339e-06.\n",
      "Epoch:13, weight train batch: 263, step:28, loss before: 6.41864471618e-06, loss after: 6.39256768409e-06.\n",
      "Epoch:13, weight train batch: 263, step:29, loss before: 6.54902305541e-06, loss after: 6.54902305541e-06.\n",
      "Epoch:13, weight train batch: 263, step:30, loss before: 0.000955984112807, loss after: 0.000952821574174.\n",
      "Epoch:13, weight train batch: 263, step:31, loss before: 7.38348444429e-06, loss after: 7.38348444429e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 259, loss before: 6.31992588751e-06, loss after: 8.7197022367e-06.\n",
      "Epoch:13, weight train batch: 264, step:0, loss before: 6.73901649861e-06, loss after: 6.71293992127e-06.\n",
      "Epoch:13, weight train batch: 264, step:1, loss before: 5.87103113503e-06, loss after: 5.87103113503e-06.\n",
      "Epoch:13, weight train batch: 264, step:2, loss before: 7.79326364864e-06, loss after: 7.79326364864e-06.\n",
      "Epoch:13, weight train batch: 264, step:3, loss before: 7.27918040866e-06, loss after: 7.27918040866e-06.\n",
      "Epoch:13, weight train batch: 264, step:4, loss before: 3.55475458491e-05, loss after: 3.55401025445e-05.\n",
      "Epoch:13, weight train batch: 264, step:5, loss before: 5.46870069229e-06, loss after: 5.46870069229e-06.\n",
      "Epoch:13, weight train batch: 264, step:6, loss before: 6.58627868688e-06, loss after: 6.58627868688e-06.\n",
      "Epoch:13, weight train batch: 264, step:7, loss before: 7.30898091206e-06, loss after: 7.28662917027e-06.\n",
      "Epoch:13, weight train batch: 264, step:8, loss before: 9.36897413339e-06, loss after: 9.3652488431e-06.\n",
      "Epoch:13, weight train batch: 264, step:9, loss before: 5.92691048951e-06, loss after: 5.92691048951e-06.\n",
      "Epoch:13, weight train batch: 264, step:10, loss before: 5.98651649852e-06, loss after: 5.98651649852e-06.\n",
      "Epoch:13, weight train batch: 264, step:11, loss before: 5.71084456169e-06, loss after: 5.71084456169e-06.\n",
      "Epoch:13, weight train batch: 264, step:12, loss before: 5.9418116507e-06, loss after: 5.9418116507e-06.\n",
      "Epoch:13, weight train batch: 264, step:13, loss before: 6.44844567432e-06, loss after: 6.44844567432e-06.\n",
      "Epoch:13, weight train batch: 264, step:14, loss before: 7.75973512646e-06, loss after: 7.75973512646e-06.\n",
      "Epoch:13, weight train batch: 264, step:15, loss before: 8.69846098794e-06, loss after: 8.69846098794e-06.\n",
      "Epoch:13, weight train batch: 264, step:16, loss before: 0.000178841961315, loss after: 0.000177956346306.\n",
      "Epoch:13, weight train batch: 264, step:17, loss before: 6.08337040831e-06, loss after: 6.08337040831e-06.\n",
      "Epoch:13, weight train batch: 264, step:18, loss before: 6.89919943397e-06, loss after: 6.89919943397e-06.\n",
      "Epoch:13, weight train batch: 264, step:19, loss before: 6.7762684921e-06, loss after: 6.71666384733e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:13, weight train batch: 264, step:20, loss before: 8.10618530522e-06, loss after: 8.10618530522e-06.\n",
      "Epoch:13, weight train batch: 264, step:21, loss before: 7.95345113147e-06, loss after: 7.95345113147e-06.\n",
      "Epoch:13, weight train batch: 264, step:22, loss before: 6.33296167507e-06, loss after: 6.33296167507e-06.\n",
      "Epoch:13, weight train batch: 264, step:23, loss before: 7.08918878445e-06, loss after: 7.08918878445e-06.\n",
      "Epoch:13, weight train batch: 264, step:24, loss before: 5.45380225958e-06, loss after: 5.42027464689e-06.\n",
      "Epoch:13, weight train batch: 264, step:25, loss before: 6.30688509773e-06, loss after: 6.30688509773e-06.\n",
      "Epoch:13, weight train batch: 264, step:26, loss before: 7.8491448221e-06, loss after: 7.8491448221e-06.\n",
      "Epoch:13, weight train batch: 264, step:27, loss before: 3.54207877535e-05, loss after: 3.53984578396e-05.\n",
      "Epoch:13, weight train batch: 264, step:28, loss before: 1.27098646772e-05, loss after: 1.27098646772e-05.\n",
      "Epoch:13, weight train batch: 264, step:29, loss before: 5.1371553127e-06, loss after: 5.1371553127e-06.\n",
      "Epoch:13, weight train batch: 264, step:30, loss before: 6.0870956986e-06, loss after: 6.0870956986e-06.\n",
      "Epoch:13, weight train batch: 264, step:31, loss before: 6.8097942858e-06, loss after: 6.77254183756e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 260, loss before: 2.17549895751e-05, loss after: 2.17549895751e-05.\n",
      "Epoch:13, weight train batch: 265, step:0, loss before: 5.41282588529e-06, loss after: 5.41282588529e-06.\n",
      "Epoch:13, weight train batch: 265, step:1, loss before: 6.03494208917e-06, loss after: 6.00141447649e-06.\n",
      "Epoch:13, weight train batch: 265, step:2, loss before: 6.60490741211e-06, loss after: 6.57137979942e-06.\n",
      "Epoch:13, weight train batch: 265, step:3, loss before: 6.66823325446e-06, loss after: 6.66823325446e-06.\n",
      "Epoch:13, weight train batch: 265, step:4, loss before: 7.26427606423e-06, loss after: 7.26427606423e-06.\n",
      "Epoch:13, weight train batch: 265, step:5, loss before: 6.37021366856e-06, loss after: 6.37021366856e-06.\n",
      "Epoch:13, weight train batch: 265, step:6, loss before: 5.61771275898e-06, loss after: 5.61771275898e-06.\n",
      "Epoch:13, weight train batch: 265, step:7, loss before: 5.36439392818e-06, loss after: 5.36439392818e-06.\n",
      "Epoch:13, weight train batch: 265, step:8, loss before: 7.35368257665e-06, loss after: 7.35368257665e-06.\n",
      "Epoch:13, weight train batch: 265, step:9, loss before: 7.20467323845e-06, loss after: 7.20467323845e-06.\n",
      "Epoch:13, weight train batch: 265, step:10, loss before: 8.15826570033e-06, loss after: 8.15454041003e-06.\n",
      "Epoch:13, weight train batch: 265, step:11, loss before: 8.2365659182e-06, loss after: 8.2365659182e-06.\n",
      "Epoch:13, weight train batch: 265, step:12, loss before: 7.03331079421e-06, loss after: 6.99605880072e-06.\n",
      "Epoch:13, weight train batch: 265, step:13, loss before: 1.31606275318e-05, loss after: 1.3156903151e-05.\n",
      "Epoch:13, weight train batch: 265, step:14, loss before: 7.67405617808e-06, loss after: 7.67405617808e-06.\n",
      "Epoch:13, weight train batch: 265, step:15, loss before: 6.51177242617e-06, loss after: 6.51177242617e-06.\n",
      "Epoch:13, weight train batch: 265, step:16, loss before: 7.0631140261e-06, loss after: 7.0631140261e-06.\n",
      "Epoch:13, weight train batch: 265, step:17, loss before: 5.88965622228e-06, loss after: 5.88965622228e-06.\n",
      "Epoch:13, weight train batch: 265, step:18, loss before: 6.76509080222e-06, loss after: 6.76509080222e-06.\n",
      "Epoch:13, weight train batch: 265, step:19, loss before: 6.12807389189e-06, loss after: 6.12807389189e-06.\n",
      "Epoch:13, weight train batch: 265, step:20, loss before: 5.30479292138e-06, loss after: 5.30479292138e-06.\n",
      "Epoch:13, weight train batch: 265, step:21, loss before: 5.98279029873e-06, loss after: 5.98279029873e-06.\n",
      "Epoch:13, weight train batch: 265, step:22, loss before: 7.49151877244e-06, loss after: 7.45426586946e-06.\n",
      "Epoch:13, weight train batch: 265, step:23, loss before: 6.21747949481e-06, loss after: 6.21747949481e-06.\n",
      "Epoch:13, weight train batch: 265, step:24, loss before: 5.35321851203e-06, loss after: 5.35321851203e-06.\n",
      "Epoch:13, weight train batch: 265, step:25, loss before: 6.35158903606e-06, loss after: 6.32178716842e-06.\n",
      "Epoch:13, weight train batch: 265, step:26, loss before: 5.88220655118e-06, loss after: 5.88220655118e-06.\n",
      "Epoch:13, weight train batch: 265, step:27, loss before: 7.9124702097e-06, loss after: 7.9124702097e-06.\n",
      "Epoch:13, weight train batch: 265, step:28, loss before: 7.65170443628e-06, loss after: 7.65170443628e-06.\n",
      "Epoch:13, weight train batch: 265, step:29, loss before: 7.10036647433e-06, loss after: 7.10036647433e-06.\n",
      "Epoch:13, weight train batch: 265, step:30, loss before: 5.97533835389e-06, loss after: 5.97533835389e-06.\n",
      "Epoch:13, weight train batch: 265, step:31, loss before: 6.36276308796e-06, loss after: 6.36276308796e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 261, loss before: 6.11410314377e-06, loss after: 6.71664292895e-06.\n",
      "Epoch:13, weight train batch: 266, step:0, loss before: 5.84868075748e-06, loss after: 5.84868075748e-06.\n",
      "Epoch:13, weight train batch: 266, step:1, loss before: 7.07428989699e-06, loss after: 7.07428989699e-06.\n",
      "Epoch:13, weight train batch: 266, step:2, loss before: 6.16160014033e-06, loss after: 6.16160014033e-06.\n",
      "Epoch:13, weight train batch: 266, step:3, loss before: 6.50805122859e-06, loss after: 6.50805122859e-06.\n",
      "Epoch:13, weight train batch: 266, step:4, loss before: 7.7038184827e-06, loss after: 7.67774145061e-06.\n",
      "Epoch:13, weight train batch: 266, step:5, loss before: 6.29198530078e-06, loss after: 6.29198530078e-06.\n",
      "Epoch:13, weight train batch: 266, step:6, loss before: 5.52085657546e-06, loss after: 5.52085657546e-06.\n",
      "Epoch:13, weight train batch: 266, step:7, loss before: 7.71699487814e-05, loss after: 7.71327831899e-05.\n",
      "Epoch:13, weight train batch: 266, step:8, loss before: 7.8901211964e-06, loss after: 7.8901211964e-06.\n",
      "Epoch:13, weight train batch: 266, step:9, loss before: 6.88430100126e-06, loss after: 6.88430100126e-06.\n",
      "Epoch:13, weight train batch: 266, step:10, loss before: 6.44099509373e-06, loss after: 6.44099509373e-06.\n",
      "Epoch:13, weight train batch: 266, step:11, loss before: 6.50059928375e-06, loss after: 6.50059928375e-06.\n",
      "Epoch:13, weight train batch: 266, step:12, loss before: 5.86358009969e-06, loss after: 5.8375030676e-06.\n",
      "Epoch:13, weight train batch: 266, step:13, loss before: 0.000893139571417, loss after: 0.000890550436452.\n",
      "Epoch:13, weight train batch: 266, step:14, loss before: 5.06637434228e-06, loss after: 5.06637434228e-06.\n",
      "Epoch:13, weight train batch: 266, step:15, loss before: 5.11480266141e-06, loss after: 5.11480266141e-06.\n",
      "Epoch:13, weight train batch: 266, step:16, loss before: 6.13925112702e-06, loss after: 6.13925112702e-06.\n",
      "Epoch:13, weight train batch: 266, step:17, loss before: 6.66964915581e-05, loss after: 6.64993713144e-05.\n",
      "Epoch:13, weight train batch: 266, step:18, loss before: 6.62352886138e-06, loss after: 6.62352886138e-06.\n",
      "Epoch:13, weight train batch: 266, step:19, loss before: 6.46707212582e-06, loss after: 6.44099509373e-06.\n",
      "Epoch:13, weight train batch: 266, step:20, loss before: 6.7650944402e-06, loss after: 6.7650944402e-06.\n",
      "Epoch:13, weight train batch: 266, step:21, loss before: 1.67546349985e-05, loss after: 1.67471862369e-05.\n",
      "Epoch:13, weight train batch: 266, step:22, loss before: 5.82632992518e-06, loss after: 5.80770347369e-06.\n",
      "Epoch:13, weight train batch: 266, step:23, loss before: 0.000164212586242, loss after: 0.000163545308169.\n",
      "Epoch:13, weight train batch: 266, step:24, loss before: 1.53506116476e-05, loss after: 1.53059227159e-05.\n",
      "Epoch:13, weight train batch: 266, step:25, loss before: 0.0216660127044, loss after: 0.0216660127044.\n",
      "Epoch:13, weight train batch: 266, step:26, loss before: 5.49477954337e-06, loss after: 5.46125193068e-06.\n",
      "Epoch:13, weight train batch: 266, step:27, loss before: 5.06264950673e-06, loss after: 5.01422073285e-06.\n",
      "Epoch:13, weight train batch: 266, step:28, loss before: 5.24891174791e-06, loss after: 5.22656046087e-06.\n",
      "Epoch:13, weight train batch: 266, step:29, loss before: 6.23237974651e-06, loss after: 6.23237974651e-06.\n",
      "Epoch:13, weight train batch: 266, step:30, loss before: 5.91200750932e-06, loss after: 5.91200750932e-06.\n",
      "Epoch:13, weight train batch: 266, step:31, loss before: 6.38884193904e-06, loss after: 6.38884193904e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 262, loss before: 5.68011091673e-06, loss after: 5.65123991692e-06.\n",
      "Epoch:13, weight train batch: 267, step:0, loss before: 6.44472129352e-06, loss after: 6.41119368083e-06.\n",
      "Epoch:13, weight train batch: 267, step:1, loss before: 7.33871411285e-06, loss after: 7.33871411285e-06.\n",
      "Epoch:13, weight train batch: 267, step:2, loss before: 8.06520802143e-06, loss after: 8.06520802143e-06.\n",
      "Epoch:13, weight train batch: 267, step:3, loss before: 7.77836248744e-06, loss after: 7.77836248744e-06.\n",
      "Epoch:13, weight train batch: 267, step:4, loss before: 5.39419579582e-06, loss after: 5.39419579582e-06.\n",
      "Epoch:13, weight train batch: 267, step:5, loss before: 1.26354316308e-05, loss after: 1.26354316308e-05.\n",
      "Epoch:13, weight train batch: 267, step:6, loss before: 0.0216673724353, loss after: 0.0216673724353.\n",
      "Epoch:13, weight train batch: 267, step:7, loss before: 6.45962063572e-06, loss after: 6.45962063572e-06.\n",
      "Epoch:13, weight train batch: 267, step:8, loss before: 5.53948120796e-06, loss after: 5.53948120796e-06.\n",
      "Epoch:13, weight train batch: 267, step:9, loss before: 7.39466167943e-06, loss after: 7.34995865059e-06.\n",
      "Epoch:13, weight train batch: 267, step:10, loss before: 6.07219499216e-06, loss after: 6.07219499216e-06.\n",
      "Epoch:13, weight train batch: 267, step:11, loss before: 4.32132264905e-06, loss after: 4.32132264905e-06.\n",
      "Epoch:13, weight train batch: 267, step:12, loss before: 5.43145051779e-06, loss after: 5.4016481954e-06.\n",
      "Epoch:13, weight train batch: 267, step:13, loss before: 1.33357843879e-05, loss after: 1.33320590976e-05.\n",
      "Epoch:13, weight train batch: 267, step:14, loss before: 5.5692839851e-06, loss after: 5.5692839851e-06.\n",
      "Epoch:13, weight train batch: 267, step:15, loss before: 0.000149320374476, loss after: 0.000148600927787.\n",
      "Epoch:13, weight train batch: 267, step:16, loss before: 6.17650130152e-06, loss after: 6.17650130152e-06.\n",
      "Epoch:13, weight train batch: 267, step:17, loss before: 8.37813058752e-06, loss after: 8.37813058752e-06.\n",
      "Epoch:13, weight train batch: 267, step:18, loss before: 6.56020347378e-06, loss after: 6.56020347378e-06.\n",
      "Epoch:13, weight train batch: 267, step:19, loss before: 6.09454673395e-06, loss after: 6.06101957601e-06.\n",
      "Epoch:13, weight train batch: 267, step:20, loss before: 5.50967979507e-06, loss after: 5.50967979507e-06.\n",
      "Epoch:13, weight train batch: 267, step:21, loss before: 6.45962109047e-06, loss after: 6.42236864223e-06.\n",
      "Epoch:13, weight train batch: 267, step:22, loss before: 6.09827247899e-06, loss after: 6.09827247899e-06.\n",
      "Epoch:13, weight train batch: 267, step:23, loss before: 5.55065980734e-06, loss after: 5.55065980734e-06.\n",
      "Epoch:13, weight train batch: 267, step:24, loss before: 7.00350892657e-06, loss after: 7.00350892657e-06.\n",
      "Epoch:13, weight train batch: 267, step:25, loss before: 5.67359211345e-06, loss after: 5.67359211345e-06.\n",
      "Epoch:13, weight train batch: 267, step:26, loss before: 6.44472038402e-06, loss after: 6.44472038402e-06.\n",
      "Epoch:13, weight train batch: 267, step:27, loss before: 6.67444837745e-05, loss after: 6.66403211653e-05.\n",
      "Epoch:13, weight train batch: 267, step:28, loss before: 5.26381336385e-06, loss after: 5.26381336385e-06.\n",
      "Epoch:13, weight train batch: 267, step:29, loss before: 5.94553512201e-06, loss after: 5.94553512201e-06.\n",
      "Epoch:13, weight train batch: 267, step:30, loss before: 6.07964329902e-06, loss after: 6.07964329902e-06.\n",
      "Epoch:13, weight train batch: 267, step:31, loss before: 0.00198374432512, loss after: 0.00197926769033.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 263, loss before: 6.19233560428e-06, loss after: 6.19233560428e-06.\n",
      "Epoch:13, weight train batch: 268, step:0, loss before: 0.0216965321451, loss after: 0.0216670110822.\n",
      "Epoch:13, weight train batch: 268, step:1, loss before: 5.75182320972e-06, loss after: 5.78907611271e-06.\n",
      "Epoch:13, weight train batch: 268, step:2, loss before: 2.91658070637e-05, loss after: 2.95456811727e-05.\n",
      "Epoch:13, weight train batch: 268, step:3, loss before: 6.25845768809e-06, loss after: 6.28826001048e-06.\n",
      "Epoch:13, weight train batch: 268, step:4, loss before: 6.32178762316e-06, loss after: 6.35531523585e-06.\n",
      "Epoch:13, weight train batch: 268, step:5, loss before: 9.00003578863e-06, loss after: 9.02238753042e-06.\n",
      "Epoch:13, weight train batch: 268, step:6, loss before: 6.03866737947e-06, loss after: 6.03866737947e-06.\n",
      "Epoch:13, weight train batch: 268, step:7, loss before: 6.33296167507e-06, loss after: 6.35531341686e-06.\n",
      "Epoch:13, weight train batch: 268, step:8, loss before: 5.81887798035e-06, loss after: 5.85240559303e-06.\n",
      "Epoch:13, weight train batch: 268, step:9, loss before: 6.73156819175e-06, loss after: 6.73901877235e-06.\n",
      "Epoch:13, weight train batch: 268, step:10, loss before: 3.5320801544e-05, loss after: 3.52873030351e-05.\n",
      "Epoch:13, weight train batch: 268, step:11, loss before: 6.56765587337e-06, loss after: 6.60118348605e-06.\n",
      "Epoch:13, weight train batch: 268, step:12, loss before: 7.67033270677e-06, loss after: 7.69268444856e-06.\n",
      "Epoch:13, weight train batch: 268, step:13, loss before: 5.42399993719e-06, loss after: 5.42399993719e-06.\n",
      "Epoch:13, weight train batch: 268, step:14, loss before: 7.18604951544e-06, loss after: 7.21957667338e-06.\n",
      "Epoch:13, weight train batch: 268, step:15, loss before: 6.95508151694e-06, loss after: 6.95508151694e-06.\n",
      "Epoch:13, weight train batch: 268, step:16, loss before: 7.37976188248e-06, loss after: 7.37976188248e-06.\n",
      "Epoch:13, weight train batch: 268, step:17, loss before: 4.82050745632e-06, loss after: 4.854035069e-06.\n",
      "Epoch:13, weight train batch: 268, step:18, loss before: 6.30316253591e-06, loss after: 6.30316253591e-06.\n",
      "Epoch:13, weight train batch: 268, step:19, loss before: 3.50492737198e-05, loss after: 3.49748370354e-05.\n",
      "Epoch:13, weight train batch: 268, step:20, loss before: 9.8084237834e-06, loss after: 9.8009732028e-06.\n",
      "Epoch:13, weight train batch: 268, step:21, loss before: 5.13715485795e-06, loss after: 5.16323143529e-06.\n",
      "Epoch:13, weight train batch: 268, step:22, loss before: 6.97370796843e-06, loss after: 6.97370796843e-06.\n",
      "Epoch:13, weight train batch: 268, step:23, loss before: 6.72411579217e-06, loss after: 6.72411579217e-06.\n",
      "Epoch:13, weight train batch: 268, step:24, loss before: 5.05892421643e-06, loss after: 5.05892421643e-06.\n",
      "Epoch:13, weight train batch: 268, step:25, loss before: 5.72574754187e-06, loss after: 5.70339580008e-06.\n",
      "Epoch:13, weight train batch: 268, step:26, loss before: 6.03866737947e-06, loss after: 6.03866737947e-06.\n",
      "Epoch:13, weight train batch: 268, step:27, loss before: 5.67731876799e-06, loss after: 5.71457121623e-06.\n",
      "Epoch:13, weight train batch: 268, step:28, loss before: 5.79652623856e-06, loss after: 5.79652623856e-06.\n",
      "Epoch:13, weight train batch: 268, step:29, loss before: 5.42027601114e-06, loss after: 5.42027601114e-06.\n",
      "Epoch:13, weight train batch: 268, step:30, loss before: 5.71457121623e-06, loss after: 5.71457121623e-06.\n",
      "Epoch:13, weight train batch: 268, step:31, loss before: 5.08872653882e-06, loss after: 5.08872653882e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 264, loss before: 6.15857788944e-05, loss after: 6.32178944215e-06.\n",
      "Epoch:13, weight train batch: 269, step:0, loss before: 6.06474441156e-06, loss after: 6.06474441156e-06.\n",
      "Epoch:13, weight train batch: 269, step:1, loss before: 7.38348808227e-06, loss after: 7.38348808227e-06.\n",
      "Epoch:13, weight train batch: 269, step:2, loss before: 6.60863224766e-06, loss after: 6.60863224766e-06.\n",
      "Epoch:13, weight train batch: 269, step:3, loss before: 6.19885440756e-06, loss after: 6.19885440756e-06.\n",
      "Epoch:13, weight train batch: 269, step:4, loss before: 5.90828494751e-06, loss after: 5.90828494751e-06.\n",
      "Epoch:13, weight train batch: 269, step:5, loss before: 6.85450004312e-06, loss after: 6.85450004312e-06.\n",
      "Epoch:13, weight train batch: 269, step:6, loss before: 8.85434055817e-05, loss after: 8.85062254383e-05.\n",
      "Epoch:13, weight train batch: 269, step:7, loss before: 5.4165484471e-06, loss after: 5.39047186976e-06.\n",
      "Epoch:13, weight train batch: 269, step:8, loss before: 4.94344067192e-06, loss after: 4.94344067192e-06.\n",
      "Epoch:13, weight train batch: 269, step:9, loss before: 5.40165092389e-06, loss after: 5.40165092389e-06.\n",
      "Epoch:13, weight train batch: 269, step:10, loss before: 6.19140428171e-06, loss after: 6.19140428171e-06.\n",
      "Epoch:13, weight train batch: 269, step:11, loss before: 7.71503619035e-06, loss after: 7.71503619035e-06.\n",
      "Epoch:13, weight train batch: 269, step:12, loss before: 5.47242871107e-06, loss after: 5.47242871107e-06.\n",
      "Epoch:13, weight train batch: 269, step:13, loss before: 6.64961225993e-06, loss after: 6.64961225993e-06.\n",
      "Epoch:13, weight train batch: 269, step:14, loss before: 5.53203426534e-06, loss after: 5.53203426534e-06.\n",
      "Epoch:13, weight train batch: 269, step:15, loss before: 4.69384849566e-06, loss after: 4.67522249892e-06.\n",
      "Epoch:13, weight train batch: 269, step:16, loss before: 6.66823825668e-06, loss after: 6.66823825668e-06.\n",
      "Epoch:13, weight train batch: 269, step:17, loss before: 5.33459433427e-06, loss after: 5.31596833753e-06.\n",
      "Epoch:13, weight train batch: 269, step:18, loss before: 5.9529875216e-06, loss after: 5.9529875216e-06.\n",
      "Epoch:13, weight train batch: 269, step:19, loss before: 1.56113255798e-05, loss after: 1.55964280566e-05.\n",
      "Epoch:13, weight train batch: 269, step:20, loss before: 7.02958914189e-06, loss after: 7.02958914189e-06.\n",
      "Epoch:13, weight train batch: 269, step:21, loss before: 5.88966076975e-06, loss after: 5.88966076975e-06.\n",
      "Epoch:13, weight train batch: 269, step:22, loss before: 6.29198757451e-06, loss after: 6.29198757451e-06.\n",
      "Epoch:13, weight train batch: 269, step:23, loss before: 6.03121816312e-06, loss after: 6.03121816312e-06.\n",
      "Epoch:13, weight train batch: 269, step:24, loss before: 5.89710907661e-06, loss after: 5.89710907661e-06.\n",
      "Epoch:13, weight train batch: 269, step:25, loss before: 6.26591008768e-06, loss after: 6.26591008768e-06.\n",
      "Epoch:13, weight train batch: 269, step:26, loss before: 7.01468707121e-06, loss after: 7.01468707121e-06.\n",
      "Epoch:13, weight train batch: 269, step:27, loss before: 5.84867939324e-06, loss after: 5.84867939324e-06.\n",
      "Epoch:13, weight train batch: 269, step:28, loss before: 5.08127595822e-06, loss after: 5.08127595822e-06.\n",
      "Epoch:13, weight train batch: 269, step:29, loss before: 5.05519892613e-06, loss after: 5.05519892613e-06.\n",
      "Epoch:13, weight train batch: 269, step:30, loss before: 6.23983305559e-06, loss after: 6.21003164269e-06.\n",
      "Epoch:13, weight train batch: 269, step:31, loss before: 5.2712643992e-06, loss after: 5.25263794771e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 265, loss before: 6.54623772789e-06, loss after: 6.54623772789e-06.\n",
      "Epoch:13, weight train batch: 270, step:0, loss before: 7.4281920206e-06, loss after: 7.4281920206e-06.\n",
      "Epoch:13, weight train batch: 270, step:1, loss before: 5.97533926339e-06, loss after: 5.97533926339e-06.\n",
      "Epoch:13, weight train batch: 270, step:2, loss before: 6.06101912126e-06, loss after: 6.06101912126e-06.\n",
      "Epoch:13, weight train batch: 270, step:3, loss before: 6.51825175737e-05, loss after: 6.50076981401e-05.\n",
      "Epoch:13, weight train batch: 270, step:4, loss before: 6.01259307587e-06, loss after: 6.01259307587e-06.\n",
      "Epoch:13, weight train batch: 270, step:5, loss before: 6.44472129352e-06, loss after: 6.44472129352e-06.\n",
      "Epoch:13, weight train batch: 270, step:6, loss before: 6.82469817548e-06, loss after: 6.82469817548e-06.\n",
      "Epoch:13, weight train batch: 270, step:7, loss before: 6.62353613734e-06, loss after: 6.62353613734e-06.\n",
      "Epoch:13, weight train batch: 270, step:8, loss before: 6.08337086305e-06, loss after: 6.08337086305e-06.\n",
      "Epoch:13, weight train batch: 270, step:9, loss before: 6.70921281198e-06, loss after: 6.70921281198e-06.\n",
      "Epoch:13, weight train batch: 270, step:10, loss before: 6.12062376604e-06, loss after: 6.12062376604e-06.\n",
      "Epoch:13, weight train batch: 270, step:11, loss before: 6.54530322208e-06, loss after: 6.5043250288e-06.\n",
      "Epoch:13, weight train batch: 270, step:12, loss before: 6.43727116767e-06, loss after: 6.43727116767e-06.\n",
      "Epoch:13, weight train batch: 270, step:13, loss before: 7.21957576388e-06, loss after: 7.21957576388e-06.\n",
      "Epoch:13, weight train batch: 270, step:14, loss before: 6.96998313288e-06, loss after: 6.96998313288e-06.\n",
      "Epoch:13, weight train batch: 270, step:15, loss before: 6.29198621027e-06, loss after: 6.29198621027e-06.\n",
      "Epoch:13, weight train batch: 270, step:16, loss before: 6.94017944625e-06, loss after: 6.94017944625e-06.\n",
      "Epoch:13, weight train batch: 270, step:17, loss before: 6.33296349406e-06, loss after: 6.33296349406e-06.\n",
      "Epoch:13, weight train batch: 270, step:18, loss before: 5.45007560504e-06, loss after: 5.45007560504e-06.\n",
      "Epoch:13, weight train batch: 270, step:19, loss before: 5.36439756615e-06, loss after: 5.36439756615e-06.\n",
      "Epoch:13, weight train batch: 270, step:20, loss before: 6.21375693299e-06, loss after: 6.21375693299e-06.\n",
      "Epoch:13, weight train batch: 270, step:21, loss before: 5.19675995747e-06, loss after: 5.19675995747e-06.\n",
      "Epoch:13, weight train batch: 270, step:22, loss before: 6.79862296238e-06, loss after: 6.79862296238e-06.\n",
      "Epoch:13, weight train batch: 270, step:23, loss before: 5.68477025809e-06, loss after: 5.68477025809e-06.\n",
      "Epoch:13, weight train batch: 270, step:24, loss before: 5.55066162633e-06, loss after: 5.53203517484e-06.\n",
      "Epoch:13, weight train batch: 270, step:25, loss before: 6.55648091197e-06, loss after: 6.53040387988e-06.\n",
      "Epoch:13, weight train batch: 270, step:26, loss before: 5.20420917383e-06, loss after: 5.20420917383e-06.\n",
      "Epoch:13, weight train batch: 270, step:27, loss before: 6.93644869898e-06, loss after: 6.93644869898e-06.\n",
      "Epoch:13, weight train batch: 270, step:28, loss before: 5.6400667745e-06, loss after: 5.6400667745e-06.\n",
      "Epoch:13, weight train batch: 270, step:29, loss before: 5.69594612898e-06, loss after: 5.69594612898e-06.\n",
      "Epoch:13, weight train batch: 270, step:30, loss before: 5.85985071666e-06, loss after: 5.85985071666e-06.\n",
      "Epoch:13, weight train batch: 270, step:31, loss before: 6.88057843945e-06, loss after: 6.88057843945e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 266, loss before: 5.84681856708e-06, loss after: 5.84681856708e-06.\n",
      "Epoch:13, weight train batch: 271, step:0, loss before: 6.02749196332e-06, loss after: 6.02749196332e-06.\n",
      "Epoch:13, weight train batch: 271, step:1, loss before: 6.92155481374e-06, loss after: 6.92155481374e-06.\n",
      "Epoch:13, weight train batch: 271, step:2, loss before: 5.33086858923e-06, loss after: 5.33086858923e-06.\n",
      "Epoch:13, weight train batch: 271, step:3, loss before: 5.53948302695e-06, loss after: 5.53948302695e-06.\n",
      "Epoch:13, weight train batch: 271, step:4, loss before: 4.23936671723e-06, loss after: 4.23936671723e-06.\n",
      "Epoch:13, weight train batch: 271, step:5, loss before: 6.35159130979e-06, loss after: 6.35159130979e-06.\n",
      "Epoch:13, weight train batch: 271, step:6, loss before: 5.34577156941e-06, loss after: 5.32714511792e-06.\n",
      "Epoch:13, weight train batch: 271, step:7, loss before: 6.13180054643e-06, loss after: 6.13180054643e-06.\n",
      "Epoch:13, weight train batch: 271, step:8, loss before: 5.73692341277e-06, loss after: 5.73692341277e-06.\n",
      "Epoch:13, weight train batch: 271, step:9, loss before: 5.58418696528e-06, loss after: 5.58418696528e-06.\n",
      "Epoch:13, weight train batch: 271, step:10, loss before: 5.93436288909e-06, loss after: 5.93436288909e-06.\n",
      "Epoch:13, weight train batch: 271, step:11, loss before: 5.30106581209e-06, loss after: 5.30106581209e-06.\n",
      "Epoch:13, weight train batch: 271, step:12, loss before: 6.96251117915e-06, loss after: 6.9587863436e-06.\n",
      "Epoch:13, weight train batch: 271, step:13, loss before: 6.68313941787e-06, loss after: 6.68313941787e-06.\n",
      "Epoch:13, weight train batch: 271, step:14, loss before: 5.64751553611e-06, loss after: 5.64751553611e-06.\n",
      "Epoch:13, weight train batch: 271, step:15, loss before: 5.7816264416e-06, loss after: 5.7816264416e-06.\n",
      "Epoch:13, weight train batch: 271, step:16, loss before: 5.3904741435e-06, loss after: 5.36439711141e-06.\n",
      "Epoch:13, weight train batch: 271, step:17, loss before: 5.9380872699e-06, loss after: 5.9380872699e-06.\n",
      "Epoch:13, weight train batch: 271, step:18, loss before: 6.13180054643e-06, loss after: 6.13180054643e-06.\n",
      "Epoch:13, weight train batch: 271, step:19, loss before: 6.2025810621e-06, loss after: 6.2025810621e-06.\n",
      "Epoch:13, weight train batch: 271, step:20, loss before: 1.28659512484e-05, loss after: 1.28585024868e-05.\n",
      "Epoch:13, weight train batch: 271, step:21, loss before: 4.99559519085e-06, loss after: 4.99559519085e-06.\n",
      "Epoch:13, weight train batch: 271, step:22, loss before: 6.08709706285e-06, loss after: 6.05356945016e-06.\n",
      "Epoch:13, weight train batch: 271, step:23, loss before: 4.69757469546e-06, loss after: 4.69757469546e-06.\n",
      "Epoch:13, weight train batch: 271, step:24, loss before: 1.43597753777e-05, loss after: 1.43486031448e-05.\n",
      "Epoch:13, weight train batch: 271, step:25, loss before: 5.97534017288e-06, loss after: 5.97534017288e-06.\n",
      "Epoch:13, weight train batch: 271, step:26, loss before: 5.3755729823e-06, loss after: 5.3755729823e-06.\n",
      "Epoch:13, weight train batch: 271, step:27, loss before: 3.25924847857e-05, loss after: 3.25589862769e-05.\n",
      "Epoch:13, weight train batch: 271, step:28, loss before: 5.43145233678e-06, loss after: 5.43145233678e-06.\n",
      "Epoch:13, weight train batch: 271, step:29, loss before: 1.80615916179e-05, loss after: 1.80541446753e-05.\n",
      "Epoch:13, weight train batch: 271, step:30, loss before: 5.31969362783e-06, loss after: 5.31969362783e-06.\n",
      "Epoch:13, weight train batch: 271, step:31, loss before: 5.92690958001e-06, loss after: 5.92690958001e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 267, loss before: 5.80677306061e-06, loss after: 5.82074289923e-06.\n",
      "Epoch:13, weight train batch: 272, step:0, loss before: 5.82633083468e-06, loss after: 5.82633083468e-06.\n",
      "Epoch:13, weight train batch: 272, step:1, loss before: 6.66078994982e-06, loss after: 6.66078994982e-06.\n",
      "Epoch:13, weight train batch: 272, step:2, loss before: 6.03525368206e-05, loss after: 6.01925821684e-05.\n",
      "Epoch:13, weight train batch: 272, step:3, loss before: 5.58791180083e-06, loss after: 5.58791180083e-06.\n",
      "Epoch:13, weight train batch: 272, step:4, loss before: 5.69221901969e-06, loss after: 5.69221901969e-06.\n",
      "Epoch:13, weight train batch: 272, step:5, loss before: 5.90083391216e-06, loss after: 5.90083391216e-06.\n",
      "Epoch:13, weight train batch: 272, step:6, loss before: 5.88593229622e-06, loss after: 5.85240559303e-06.\n",
      "Epoch:13, weight train batch: 272, step:7, loss before: 5.36067000212e-06, loss after: 5.36067000212e-06.\n",
      "Epoch:13, weight train batch: 272, step:8, loss before: 6.13552629147e-06, loss after: 6.13552629147e-06.\n",
      "Epoch:13, weight train batch: 272, step:9, loss before: 6.07592346569e-06, loss after: 6.07592346569e-06.\n",
      "Epoch:13, weight train batch: 272, step:10, loss before: 1.18196430776e-05, loss after: 1.18196430776e-05.\n",
      "Epoch:13, weight train batch: 272, step:11, loss before: 5.33831916982e-06, loss after: 5.30106672159e-06.\n",
      "Epoch:13, weight train batch: 272, step:12, loss before: 0.0216664075851, loss after: 0.0216664075851.\n",
      "Epoch:13, weight train batch: 272, step:13, loss before: 5.38302128916e-06, loss after: 5.38302128916e-06.\n",
      "Epoch:13, weight train batch: 272, step:14, loss before: 6.38512028672e-06, loss after: 6.38512028672e-06.\n",
      "Epoch:13, weight train batch: 272, step:15, loss before: 5.37929599886e-06, loss after: 5.37929599886e-06.\n",
      "Epoch:13, weight train batch: 272, step:16, loss before: 6.20258151685e-06, loss after: 6.20258151685e-06.\n",
      "Epoch:13, weight train batch: 272, step:17, loss before: 5.87103295402e-06, loss after: 5.83378005103e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:13, weight train batch: 272, step:18, loss before: 4.69757287647e-06, loss after: 4.69757287647e-06.\n",
      "Epoch:13, weight train batch: 272, step:19, loss before: 6.93646006766e-06, loss after: 6.93646006766e-06.\n",
      "Epoch:13, weight train batch: 272, step:20, loss before: 4.70502527605e-06, loss after: 4.70502527605e-06.\n",
      "Epoch:13, weight train batch: 272, step:21, loss before: 5.58418742003e-06, loss after: 5.58418742003e-06.\n",
      "Epoch:13, weight train batch: 272, step:22, loss before: 6.38139317743e-06, loss after: 6.34041498415e-06.\n",
      "Epoch:13, weight train batch: 272, step:23, loss before: 5.658693226e-06, loss after: 5.658693226e-06.\n",
      "Epoch:13, weight train batch: 272, step:24, loss before: 6.11689847574e-06, loss after: 6.11689847574e-06.\n",
      "Epoch:13, weight train batch: 272, step:25, loss before: 5.26754138264e-06, loss after: 5.26754138264e-06.\n",
      "Epoch:13, weight train batch: 272, step:26, loss before: 4.68639973406e-06, loss after: 4.68639973406e-06.\n",
      "Epoch:13, weight train batch: 272, step:27, loss before: 6.41864608042e-06, loss after: 6.41864608042e-06.\n",
      "Epoch:13, weight train batch: 272, step:28, loss before: 6.92155754223e-06, loss after: 6.92155754223e-06.\n",
      "Epoch:13, weight train batch: 272, step:29, loss before: 6.40747202851e-06, loss after: 6.40747202851e-06.\n",
      "Epoch:13, weight train batch: 272, step:30, loss before: 6.21748222329e-06, loss after: 6.21748222329e-06.\n",
      "Epoch:13, weight train batch: 272, step:31, loss before: 4.7534508667e-06, loss after: 4.74227545055e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 268, loss before: 5.36346578883e-06, loss after: 7.95302912593e-06.\n",
      "Epoch:13, weight train batch: 273, step:0, loss before: 5.82632856094e-06, loss after: 5.82632856094e-06.\n",
      "Epoch:13, weight train batch: 273, step:1, loss before: 5.33831916982e-06, loss after: 5.33831916982e-06.\n",
      "Epoch:13, weight train batch: 273, step:2, loss before: 5.36812058272e-06, loss after: 5.36812058272e-06.\n",
      "Epoch:13, weight train batch: 273, step:3, loss before: 5.31224168299e-06, loss after: 5.31224168299e-06.\n",
      "Epoch:13, weight train batch: 273, step:4, loss before: 6.22119932814e-06, loss after: 6.21747403784e-06.\n",
      "Epoch:13, weight train batch: 273, step:5, loss before: 5.04402305523e-06, loss after: 5.01794602314e-06.\n",
      "Epoch:13, weight train batch: 273, step:6, loss before: 5.04774925503e-06, loss after: 5.04774925503e-06.\n",
      "Epoch:13, weight train batch: 273, step:7, loss before: 4.63797096018e-06, loss after: 4.63797096018e-06.\n",
      "Epoch:13, weight train batch: 273, step:8, loss before: 7.26800590201e-06, loss after: 7.26800590201e-06.\n",
      "Epoch:13, weight train batch: 273, step:9, loss before: 4.9769691941e-06, loss after: 4.9769691941e-06.\n",
      "Epoch:13, weight train batch: 273, step:10, loss before: 6.80979883327e-06, loss after: 6.80979883327e-06.\n",
      "Epoch:13, weight train batch: 273, step:11, loss before: 5.71084729017e-06, loss after: 5.71084729017e-06.\n",
      "Epoch:13, weight train batch: 273, step:12, loss before: 5.20420917383e-06, loss after: 5.20420917383e-06.\n",
      "Epoch:13, weight train batch: 273, step:13, loss before: 6.10945153312e-06, loss after: 6.10945153312e-06.\n",
      "Epoch:13, weight train batch: 273, step:14, loss before: 5.04029867443e-06, loss after: 5.04029867443e-06.\n",
      "Epoch:13, weight train batch: 273, step:15, loss before: 5.02912371303e-06, loss after: 5.02912371303e-06.\n",
      "Epoch:13, weight train batch: 273, step:16, loss before: 5.89710907661e-06, loss after: 5.89710907661e-06.\n",
      "Epoch:13, weight train batch: 273, step:17, loss before: 7.12272139936e-06, loss after: 7.12272139936e-06.\n",
      "Epoch:13, weight train batch: 273, step:18, loss before: 6.15414774074e-06, loss after: 6.15414774074e-06.\n",
      "Epoch:13, weight train batch: 273, step:19, loss before: 5.83005521548e-06, loss after: 5.83005521548e-06.\n",
      "Epoch:13, weight train batch: 273, step:20, loss before: 5.80770392844e-06, loss after: 5.80770392844e-06.\n",
      "Epoch:13, weight train batch: 273, step:21, loss before: 1.84863565664e-05, loss after: 1.84044074558e-05.\n",
      "Epoch:13, weight train batch: 273, step:22, loss before: 6.6123598117e-06, loss after: 6.6123598117e-06.\n",
      "Epoch:13, weight train batch: 273, step:23, loss before: 5.77417313252e-06, loss after: 5.77417313252e-06.\n",
      "Epoch:13, weight train batch: 273, step:24, loss before: 5.00304577145e-06, loss after: 5.00304577145e-06.\n",
      "Epoch:13, weight train batch: 273, step:25, loss before: 6.21003164269e-06, loss after: 6.21003164269e-06.\n",
      "Epoch:13, weight train batch: 273, step:26, loss before: 4.87638681079e-06, loss after: 4.87638681079e-06.\n",
      "Epoch:13, weight train batch: 273, step:27, loss before: 6.12059420746e-06, loss after: 6.12059420746e-06.\n",
      "Epoch:13, weight train batch: 273, step:28, loss before: 5.89711135035e-06, loss after: 5.89711135035e-06.\n",
      "Epoch:13, weight train batch: 273, step:29, loss before: 4.64542154077e-06, loss after: 4.64542154077e-06.\n",
      "Epoch:13, weight train batch: 273, step:30, loss before: 6.80979837853e-06, loss after: 6.80979837853e-06.\n",
      "Epoch:13, weight train batch: 273, step:31, loss before: 6.80979792378e-06, loss after: 6.80979792378e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 269, loss before: 5.77138143854e-06, loss after: 5.76951879339e-06.\n",
      "Epoch:13, weight train batch: 274, step:0, loss before: 7.57116431487e-05, loss after: 7.56781882956e-05.\n",
      "Epoch:13, weight train batch: 274, step:1, loss before: 4.50758761872e-06, loss after: 4.50758761872e-06.\n",
      "Epoch:13, weight train batch: 274, step:2, loss before: 5.62144032301e-06, loss after: 5.59163800062e-06.\n",
      "Epoch:13, weight train batch: 274, step:3, loss before: 6.16905390416e-06, loss after: 6.16905390416e-06.\n",
      "Epoch:13, weight train batch: 274, step:4, loss before: 6.14670261712e-06, loss after: 6.14670261712e-06.\n",
      "Epoch:13, weight train batch: 274, step:5, loss before: 6.11317500443e-06, loss after: 6.11317500443e-06.\n",
      "Epoch:13, weight train batch: 274, step:6, loss before: 5.6363423937e-06, loss after: 5.6363423937e-06.\n",
      "Epoch:13, weight train batch: 274, step:7, loss before: 5.54320922674e-06, loss after: 5.5134073591e-06.\n",
      "Epoch:13, weight train batch: 274, step:8, loss before: 5.08872653882e-06, loss after: 5.08872653882e-06.\n",
      "Epoch:13, weight train batch: 274, step:9, loss before: 4.63051947008e-06, loss after: 4.63051947008e-06.\n",
      "Epoch:13, weight train batch: 274, step:10, loss before: 5.62516561331e-06, loss after: 5.62516561331e-06.\n",
      "Epoch:13, weight train batch: 274, step:11, loss before: 6.13925158177e-06, loss after: 6.13925158177e-06.\n",
      "Epoch:13, weight train batch: 274, step:12, loss before: 6.00507119088e-05, loss after: 5.99055965722e-05.\n",
      "Epoch:13, weight train batch: 274, step:13, loss before: 7.06611608621e-05, loss after: 7.06239879946e-05.\n",
      "Epoch:13, weight train batch: 274, step:14, loss before: 5.90456056671e-06, loss after: 5.90456056671e-06.\n",
      "Epoch:13, weight train batch: 274, step:15, loss before: 7.05939146428e-06, loss after: 7.05939146428e-06.\n",
      "Epoch:13, weight train batch: 274, step:16, loss before: 5.70712199988e-06, loss after: 5.70712199988e-06.\n",
      "Epoch:13, weight train batch: 274, step:17, loss before: 5.62144168725e-06, loss after: 5.62144168725e-06.\n",
      "Epoch:13, weight train batch: 274, step:18, loss before: 5.26008898305e-06, loss after: 5.26008898305e-06.\n",
      "Epoch:13, weight train batch: 274, step:19, loss before: 5.68104405829e-06, loss after: 5.68104405829e-06.\n",
      "Epoch:13, weight train batch: 274, step:20, loss before: 5.84868121223e-06, loss after: 5.84868121223e-06.\n",
      "Epoch:13, weight train batch: 274, step:21, loss before: 0.00195570569485, loss after: 0.0019496952882.\n",
      "Epoch:13, weight train batch: 274, step:22, loss before: 5.50968343305e-06, loss after: 5.50968343305e-06.\n",
      "Epoch:13, weight train batch: 274, step:23, loss before: 5.42772613699e-06, loss after: 5.42772613699e-06.\n",
      "Epoch:13, weight train batch: 274, step:24, loss before: 6.60863497615e-06, loss after: 6.60863497615e-06.\n",
      "Epoch:13, weight train batch: 274, step:25, loss before: 5.37184678251e-06, loss after: 5.37184678251e-06.\n",
      "Epoch:13, weight train batch: 274, step:26, loss before: 1.22182791529e-05, loss after: 1.2207105101e-05.\n",
      "Epoch:13, weight train batch: 274, step:27, loss before: 5.64006586501e-06, loss after: 5.61771457797e-06.\n",
      "Epoch:13, weight train batch: 274, step:28, loss before: 5.09245228386e-06, loss after: 5.1222541515e-06.\n",
      "Epoch:13, weight train batch: 274, step:29, loss before: 5.84495592193e-06, loss after: 5.84495592193e-06.\n",
      "Epoch:13, weight train batch: 274, step:30, loss before: 6.38511801299e-06, loss after: 6.38511801299e-06.\n",
      "Epoch:13, weight train batch: 274, step:31, loss before: 5.16323234478e-06, loss after: 5.16323234478e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 270, loss before: 4.83261555928e-06, loss after: 4.83261555928e-06.\n",
      "Epoch:13, weight train batch: 275, step:0, loss before: 6.05729655945e-06, loss after: 6.05729655945e-06.\n",
      "Epoch:13, weight train batch: 275, step:1, loss before: 3.11362200591e-05, loss after: 3.11548319587e-05.\n",
      "Epoch:13, weight train batch: 275, step:2, loss before: 5.12598035129e-06, loss after: 5.12598035129e-06.\n",
      "Epoch:13, weight train batch: 275, step:3, loss before: 4.73482714369e-06, loss after: 4.73482714369e-06.\n",
      "Epoch:13, weight train batch: 275, step:4, loss before: 5.30479201188e-06, loss after: 5.30479201188e-06.\n",
      "Epoch:13, weight train batch: 275, step:5, loss before: 5.4202737374e-06, loss after: 5.4202737374e-06.\n",
      "Epoch:13, weight train batch: 275, step:6, loss before: 5.62516470382e-06, loss after: 5.62516470382e-06.\n",
      "Epoch:13, weight train batch: 275, step:7, loss before: 4.99187081004e-06, loss after: 4.99187081004e-06.\n",
      "Epoch:13, weight train batch: 275, step:8, loss before: 5.39419943379e-06, loss after: 5.39419943379e-06.\n",
      "Epoch:13, weight train batch: 275, step:9, loss before: 5.13343184139e-06, loss after: 5.13343184139e-06.\n",
      "Epoch:13, weight train batch: 275, step:10, loss before: 5.06264905198e-06, loss after: 5.06264905198e-06.\n",
      "Epoch:13, weight train batch: 275, step:11, loss before: 5.35694607606e-06, loss after: 5.32714375368e-06.\n",
      "Epoch:13, weight train batch: 275, step:12, loss before: 5.78162598686e-06, loss after: 5.75927424507e-06.\n",
      "Epoch:13, weight train batch: 275, step:13, loss before: 5.77417631575e-06, loss after: 5.77417631575e-06.\n",
      "Epoch:13, weight train batch: 275, step:14, loss before: 5.8114278545e-06, loss after: 5.8114278545e-06.\n",
      "Epoch:13, weight train batch: 275, step:15, loss before: 6.0721963564e-06, loss after: 6.0721963564e-06.\n",
      "Epoch:13, weight train batch: 275, step:16, loss before: 5.99769100518e-06, loss after: 5.99769100518e-06.\n",
      "Epoch:13, weight train batch: 275, step:17, loss before: 5.43145142728e-06, loss after: 5.43145142728e-06.\n",
      "Epoch:13, weight train batch: 275, step:18, loss before: 4.96951770401e-06, loss after: 4.96951770401e-06.\n",
      "Epoch:13, weight train batch: 275, step:19, loss before: 6.18395461061e-06, loss after: 6.18395461061e-06.\n",
      "Epoch:13, weight train batch: 275, step:20, loss before: 5.95298934059e-06, loss after: 5.95298934059e-06.\n",
      "Epoch:13, weight train batch: 275, step:21, loss before: 4.64914501208e-06, loss after: 4.64914501208e-06.\n",
      "Epoch:13, weight train batch: 275, step:22, loss before: 5.72947283217e-06, loss after: 5.72947283217e-06.\n",
      "Epoch:13, weight train batch: 275, step:23, loss before: 5.07382583237e-06, loss after: 5.07382583237e-06.\n",
      "Epoch:13, weight train batch: 275, step:24, loss before: 7.2046477726e-06, loss after: 7.2046477726e-06.\n",
      "Epoch:13, weight train batch: 275, step:25, loss before: 5.08127777721e-06, loss after: 5.08127777721e-06.\n",
      "Epoch:13, weight train batch: 275, step:26, loss before: 1.92239458556e-05, loss after: 1.9216498913e-05.\n",
      "Epoch:13, weight train batch: 275, step:27, loss before: 5.7965276028e-06, loss after: 5.7965276028e-06.\n",
      "Epoch:13, weight train batch: 275, step:28, loss before: 6.48197601549e-06, loss after: 6.48197601549e-06.\n",
      "Epoch:13, weight train batch: 275, step:29, loss before: 5.42400084669e-06, loss after: 5.39419897905e-06.\n",
      "Epoch:13, weight train batch: 275, step:30, loss before: 6.05729655945e-06, loss after: 6.05729655945e-06.\n",
      "Epoch:13, weight train batch: 275, step:31, loss before: 5.76672482566e-06, loss after: 5.76672482566e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 271, loss before: 5.40537530469e-06, loss after: 5.40537530469e-06.\n",
      "Epoch:13, weight train batch: 276, step:0, loss before: 1.33913563332e-05, loss after: 1.33839075716e-05.\n",
      "Epoch:13, weight train batch: 276, step:1, loss before: 0.00187808112241, loss after: 0.00187467061915.\n",
      "Epoch:13, weight train batch: 276, step:2, loss before: 4.55228837382e-06, loss after: 4.55228837382e-06.\n",
      "Epoch:13, weight train batch: 276, step:3, loss before: 5.72202134208e-06, loss after: 5.69594430999e-06.\n",
      "Epoch:13, weight train batch: 276, step:4, loss before: 5.27126576344e-06, loss after: 5.26381518284e-06.\n",
      "Epoch:13, weight train batch: 276, step:5, loss before: 5.39047368875e-06, loss after: 5.39047368875e-06.\n",
      "Epoch:13, weight train batch: 276, step:6, loss before: 6.1802129494e-06, loss after: 6.1764876591e-06.\n",
      "Epoch:13, weight train batch: 276, step:7, loss before: 5.33087131771e-06, loss after: 5.33087131771e-06.\n",
      "Epoch:13, weight train batch: 276, step:8, loss before: 5.83005430599e-06, loss after: 5.83005430599e-06.\n",
      "Epoch:13, weight train batch: 276, step:9, loss before: 5.39419806955e-06, loss after: 5.39419806955e-06.\n",
      "Epoch:13, weight train batch: 276, step:10, loss before: 4.5634660637e-06, loss after: 4.5634660637e-06.\n",
      "Epoch:13, weight train batch: 276, step:11, loss before: 4.69384895041e-06, loss after: 4.69384895041e-06.\n",
      "Epoch:13, weight train batch: 276, step:12, loss before: 4.60444334749e-06, loss after: 4.60444334749e-06.\n",
      "Epoch:13, weight train batch: 276, step:13, loss before: 5.01794784213e-06, loss after: 5.01794784213e-06.\n",
      "Epoch:13, weight train batch: 276, step:14, loss before: 5.00677197124e-06, loss after: 5.00677197124e-06.\n",
      "Epoch:13, weight train batch: 276, step:15, loss before: 5.27499105374e-06, loss after: 5.27499105374e-06.\n",
      "Epoch:13, weight train batch: 276, step:16, loss before: 5.93091790506e-05, loss after: 5.91306343267e-05.\n",
      "Epoch:13, weight train batch: 276, step:17, loss before: 4.92481649417e-06, loss after: 4.92481649417e-06.\n",
      "Epoch:13, weight train batch: 276, step:18, loss before: 6.41492124487e-06, loss after: 6.41492124487e-06.\n",
      "Epoch:13, weight train batch: 276, step:19, loss before: 6.69059136271e-06, loss after: 6.69059136271e-06.\n",
      "Epoch:13, weight train batch: 276, step:20, loss before: 5.55065889785e-06, loss after: 5.55065889785e-06.\n",
      "Epoch:13, weight train batch: 276, step:21, loss before: 4.99187081004e-06, loss after: 4.96951906825e-06.\n",
      "Epoch:13, weight train batch: 276, step:22, loss before: 4.3287727749e-06, loss after: 4.3287727749e-06.\n",
      "Epoch:13, weight train batch: 276, step:23, loss before: 5.13342956765e-06, loss after: 5.13342956765e-06.\n",
      "Epoch:13, weight train batch: 276, step:24, loss before: 5.66986636841e-06, loss after: 5.66986636841e-06.\n",
      "Epoch:13, weight train batch: 276, step:25, loss before: 0.0216668955982, loss after: 0.0216668955982.\n",
      "Epoch:13, weight train batch: 276, step:26, loss before: 0.000820743560325, loss after: 0.00081802776549.\n",
      "Epoch:13, weight train batch: 276, step:27, loss before: 5.74437308387e-06, loss after: 5.74437308387e-06.\n",
      "Epoch:13, weight train batch: 276, step:28, loss before: 5.15950841873e-06, loss after: 5.11480538989e-06.\n",
      "Epoch:13, weight train batch: 276, step:29, loss before: 6.0759216467e-06, loss after: 6.0759216467e-06.\n",
      "Epoch:13, weight train batch: 276, step:30, loss before: 0.000211381033296, loss after: 0.00021012275829.\n",
      "Epoch:13, weight train batch: 276, step:31, loss before: 4.75345132145e-06, loss after: 4.75345132145e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 272, loss before: 5.16043883181e-06, loss after: 5.15857618666e-06.\n",
      "Epoch:13, weight train batch: 277, step:0, loss before: 4.90618913318e-06, loss after: 4.88756268169e-06.\n",
      "Epoch:13, weight train batch: 277, step:1, loss before: 1.34473066282e-05, loss after: 1.33802623168e-05.\n",
      "Epoch:13, weight train batch: 277, step:2, loss before: 5.75182411922e-06, loss after: 5.75182411922e-06.\n",
      "Epoch:13, weight train batch: 277, step:3, loss before: 1.57300510182e-05, loss after: 1.56555634021e-05.\n",
      "Epoch:13, weight train batch: 277, step:4, loss before: 4.47405864179e-06, loss after: 4.47405864179e-06.\n",
      "Epoch:13, weight train batch: 277, step:5, loss before: 6.22120705884e-06, loss after: 6.22120705884e-06.\n",
      "Epoch:13, weight train batch: 277, step:6, loss before: 5.30106717633e-06, loss after: 5.30106717633e-06.\n",
      "Epoch:13, weight train batch: 277, step:7, loss before: 5.07755066792e-06, loss after: 5.05892421643e-06.\n",
      "Epoch:13, weight train batch: 277, step:8, loss before: 5.54320831725e-06, loss after: 5.54320831725e-06.\n",
      "Epoch:13, weight train batch: 277, step:9, loss before: 4.97696782986e-06, loss after: 4.97696782986e-06.\n",
      "Epoch:13, weight train batch: 277, step:10, loss before: 4.52993663203e-06, loss after: 4.52993663203e-06.\n",
      "Epoch:13, weight train batch: 277, step:11, loss before: 0.00180910807103, loss after: 0.00180581328459.\n",
      "Epoch:13, weight train batch: 277, step:12, loss before: 3.95624556404e-06, loss after: 3.95624556404e-06.\n",
      "Epoch:13, weight train batch: 277, step:13, loss before: 5.47615445612e-06, loss after: 5.47615445612e-06.\n",
      "Epoch:13, weight train batch: 277, step:14, loss before: 6.04984506936e-06, loss after: 5.99396571488e-06.\n",
      "Epoch:13, weight train batch: 277, step:15, loss before: 5.40909832125e-06, loss after: 5.40909832125e-06.\n",
      "Epoch:13, weight train batch: 277, step:16, loss before: 5.56928625883e-06, loss after: 5.56928625883e-06.\n",
      "Epoch:13, weight train batch: 277, step:17, loss before: 5.78535036766e-06, loss after: 5.78535036766e-06.\n",
      "Epoch:13, weight train batch: 277, step:18, loss before: 5.70339398109e-06, loss after: 5.70339398109e-06.\n",
      "Epoch:13, weight train batch: 277, step:19, loss before: 5.73922661715e-05, loss after: 5.72435019421e-05.\n",
      "Epoch:13, weight train batch: 277, step:20, loss before: 5.44262684343e-06, loss after: 5.44262684343e-06.\n",
      "Epoch:13, weight train batch: 277, step:21, loss before: 5.26753865415e-06, loss after: 5.26753865415e-06.\n",
      "Epoch:13, weight train batch: 277, step:22, loss before: 5.38302219866e-06, loss after: 5.38302219866e-06.\n",
      "Epoch:13, weight train batch: 277, step:23, loss before: 4.64169488623e-06, loss after: 4.64169488623e-06.\n",
      "Epoch:13, weight train batch: 277, step:24, loss before: 4.79070513393e-06, loss after: 4.79070513393e-06.\n",
      "Epoch:13, weight train batch: 277, step:25, loss before: 0.000188132646144, loss after: 0.000187062236364.\n",
      "Epoch:13, weight train batch: 277, step:26, loss before: 5.42772477274e-06, loss after: 5.42772477274e-06.\n",
      "Epoch:13, weight train batch: 277, step:27, loss before: 4.8689362302e-06, loss after: 4.8689362302e-06.\n",
      "Epoch:13, weight train batch: 277, step:28, loss before: 6.32178944215e-06, loss after: 6.32178944215e-06.\n",
      "Epoch:13, weight train batch: 277, step:29, loss before: 5.17440821568e-06, loss after: 5.1371553127e-06.\n",
      "Epoch:13, weight train batch: 277, step:30, loss before: 7.65170443628e-06, loss after: 7.65170443628e-06.\n",
      "Epoch:13, weight train batch: 277, step:31, loss before: 5.03657292938e-06, loss after: 5.03657292938e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 273, loss before: 4.95554832014e-06, loss after: 0.000196588109247.\n",
      "Epoch:13, weight train batch: 278, step:0, loss before: 8.00543875812e-06, loss after: 8.00543875812e-06.\n",
      "Epoch:13, weight train batch: 278, step:1, loss before: 3.98977408622e-06, loss after: 3.95997176383e-06.\n",
      "Epoch:13, weight train batch: 278, step:2, loss before: 5.20048433827e-06, loss after: 5.16695672559e-06.\n",
      "Epoch:13, weight train batch: 278, step:3, loss before: 4.50758579973e-06, loss after: 4.50758579973e-06.\n",
      "Epoch:13, weight train batch: 278, step:4, loss before: 4.20583910454e-06, loss after: 4.20583910454e-06.\n",
      "Epoch:13, weight train batch: 278, step:5, loss before: 4.63051992483e-06, loss after: 4.63051992483e-06.\n",
      "Epoch:13, weight train batch: 278, step:6, loss before: 5.48360367247e-06, loss after: 5.48360367247e-06.\n",
      "Epoch:13, weight train batch: 278, step:7, loss before: 4.90618822369e-06, loss after: 4.90618822369e-06.\n",
      "Epoch:13, weight train batch: 278, step:8, loss before: 6.64958088237e-06, loss after: 6.64958088237e-06.\n",
      "Epoch:13, weight train batch: 278, step:9, loss before: 5.72947192268e-06, loss after: 5.69967005504e-06.\n",
      "Epoch:13, weight train batch: 278, step:10, loss before: 3.63959861716e-06, loss after: 3.63959861716e-06.\n",
      "Epoch:13, weight train batch: 278, step:11, loss before: 0.0216649677604, loss after: 0.0216649398208.\n",
      "Epoch:13, weight train batch: 278, step:12, loss before: 4.8801102821e-06, loss after: 4.89873673359e-06.\n",
      "Epoch:13, weight train batch: 278, step:13, loss before: 4.88383784614e-06, loss after: 4.91736500408e-06.\n",
      "Epoch:13, weight train batch: 278, step:14, loss before: 6.87308238412e-06, loss after: 6.90288470651e-06.\n",
      "Epoch:13, weight train batch: 278, step:15, loss before: 5.6847675296e-06, loss after: 5.6847675296e-06.\n",
      "Epoch:13, weight train batch: 278, step:16, loss before: 6.05724926572e-06, loss after: 6.09450216871e-06.\n",
      "Epoch:13, weight train batch: 278, step:17, loss before: 6.65706329528e-06, loss after: 6.66451342113e-06.\n",
      "Epoch:13, weight train batch: 278, step:18, loss before: 5.49478090761e-06, loss after: 5.49478090761e-06.\n",
      "Epoch:13, weight train batch: 278, step:19, loss before: 4.6007162382e-06, loss after: 4.5969909479e-06.\n",
      "Epoch:13, weight train batch: 278, step:20, loss before: 5.40910059499e-06, loss after: 5.40910059499e-06.\n",
      "Epoch:13, weight train batch: 278, step:21, loss before: 5.0142202781e-06, loss after: 5.03284672959e-06.\n",
      "Epoch:13, weight train batch: 278, step:22, loss before: 4.12015788243e-06, loss after: 4.12015788243e-06.\n",
      "Epoch:13, weight train batch: 278, step:23, loss before: 5.69966960029e-06, loss after: 5.72202088733e-06.\n",
      "Epoch:13, weight train batch: 278, step:24, loss before: 5.01422118759e-06, loss after: 5.01422118759e-06.\n",
      "Epoch:13, weight train batch: 278, step:25, loss before: 4.64169534098e-06, loss after: 4.64169534098e-06.\n",
      "Epoch:13, weight train batch: 278, step:26, loss before: 5.31224259248e-06, loss after: 5.31224259248e-06.\n",
      "Epoch:13, weight train batch: 278, step:27, loss before: 6.87308329361e-06, loss after: 6.9066109063e-06.\n",
      "Epoch:13, weight train batch: 278, step:28, loss before: 5.85985617363e-06, loss after: 5.85985617363e-06.\n",
      "Epoch:13, weight train batch: 278, step:29, loss before: 5.94926359554e-06, loss after: 5.94926359554e-06.\n",
      "Epoch:13, weight train batch: 278, step:30, loss before: 4.4517069e-06, loss after: 4.4517069e-06.\n",
      "Epoch:13, weight train batch: 278, step:31, loss before: 6.14670079813e-06, loss after: 6.14670079813e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 274, loss before: 5.67080041947e-06, loss after: 5.67080041947e-06.\n",
      "Epoch:13, weight train batch: 279, step:0, loss before: 4.04565116696e-06, loss after: 4.04565116696e-06.\n",
      "Epoch:13, weight train batch: 279, step:1, loss before: 4.78698075312e-06, loss after: 4.78698075312e-06.\n",
      "Epoch:13, weight train batch: 279, step:2, loss before: 0.0216655097902, loss after: 0.0216655097902.\n",
      "Epoch:13, weight train batch: 279, step:3, loss before: 5.75233825657e-05, loss after: 5.73522484046e-05.\n",
      "Epoch:13, weight train batch: 279, step:4, loss before: 4.28034400102e-06, loss after: 4.28034400102e-06.\n",
      "Epoch:13, weight train batch: 279, step:5, loss before: 4.44425495516e-06, loss after: 4.44425495516e-06.\n",
      "Epoch:13, weight train batch: 279, step:6, loss before: 4.50385959994e-06, loss after: 4.53738721262e-06.\n",
      "Epoch:13, weight train batch: 279, step:7, loss before: 5.04402532897e-06, loss after: 5.04402532897e-06.\n",
      "Epoch:13, weight train batch: 279, step:8, loss before: 4.85403552375e-06, loss after: 4.85403552375e-06.\n",
      "Epoch:13, weight train batch: 279, step:9, loss before: 7.15622536518e-06, loss after: 7.15250007488e-06.\n",
      "Epoch:13, weight train batch: 279, step:10, loss before: 5.82260463489e-06, loss after: 5.82260463489e-06.\n",
      "Epoch:13, weight train batch: 279, step:11, loss before: 6.37762286715e-06, loss after: 6.37762286715e-06.\n",
      "Epoch:13, weight train batch: 279, step:12, loss before: 4.60444243799e-06, loss after: 4.60444243799e-06.\n",
      "Epoch:13, weight train batch: 279, step:13, loss before: 4.29524425272e-06, loss after: 4.29524425272e-06.\n",
      "Epoch:13, weight train batch: 279, step:14, loss before: 4.28034400102e-06, loss after: 4.28034400102e-06.\n",
      "Epoch:13, weight train batch: 279, step:15, loss before: 5.96043992118e-06, loss after: 5.96043992118e-06.\n",
      "Epoch:13, weight train batch: 279, step:16, loss before: 4.8801111916e-06, loss after: 4.8801111916e-06.\n",
      "Epoch:13, weight train batch: 279, step:17, loss before: 4.66032270197e-06, loss after: 4.66032270197e-06.\n",
      "Epoch:13, weight train batch: 279, step:18, loss before: 4.42935515821e-06, loss after: 4.42935515821e-06.\n",
      "Epoch:13, weight train batch: 279, step:19, loss before: 4.8428601076e-06, loss after: 4.8428601076e-06.\n",
      "Epoch:13, weight train batch: 279, step:20, loss before: 4.317596904e-06, loss after: 4.317596904e-06.\n",
      "Epoch:13, weight train batch: 279, step:21, loss before: 0.00175671314355, loss after: 0.0017529836623.\n",
      "Epoch:13, weight train batch: 279, step:22, loss before: 5.1148044804e-06, loss after: 5.14460680279e-06.\n",
      "Epoch:13, weight train batch: 279, step:23, loss before: 4.54111386716e-06, loss after: 4.54111386716e-06.\n",
      "Epoch:13, weight train batch: 279, step:24, loss before: 5.48733078176e-06, loss after: 5.48733078176e-06.\n",
      "Epoch:13, weight train batch: 279, step:25, loss before: 3.95251981899e-06, loss after: 3.95251981899e-06.\n",
      "Epoch:13, weight train batch: 279, step:26, loss before: 5.62143850402e-06, loss after: 5.62143850402e-06.\n",
      "Epoch:13, weight train batch: 279, step:27, loss before: 5.86358282817e-06, loss after: 5.86358282817e-06.\n",
      "Epoch:13, weight train batch: 279, step:28, loss before: 5.96416475673e-06, loss after: 5.96416475673e-06.\n",
      "Epoch:13, weight train batch: 279, step:29, loss before: 5.71084638068e-06, loss after: 5.71084638068e-06.\n",
      "Epoch:13, weight train batch: 279, step:30, loss before: 4.77207913718e-06, loss after: 4.77207913718e-06.\n",
      "Epoch:13, weight train batch: 279, step:31, loss before: 5.71829650653e-06, loss after: 5.71829650653e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:13, struct parameters train batch: 275, loss before: 5.17534044775e-06, loss after: 5.35694516657e-06.\n",
      "Epoch:14, weight train batch: 280, step:0, loss before: 5.15578176419e-06, loss after: 5.15578176419e-06.\n",
      "Epoch:14, weight train batch: 280, step:1, loss before: 5.2451882766e-06, loss after: 5.2451882766e-06.\n",
      "Epoch:14, weight train batch: 280, step:2, loss before: 5.24891311215e-06, loss after: 5.24891311215e-06.\n",
      "Epoch:14, weight train batch: 280, step:3, loss before: 7.32756780053e-06, loss after: 7.32756780053e-06.\n",
      "Epoch:14, weight train batch: 280, step:4, loss before: 1.63555723702e-05, loss after: 1.63518488989e-05.\n",
      "Epoch:14, weight train batch: 280, step:5, loss before: 3.72155409423e-06, loss after: 3.68802670891e-06.\n",
      "Epoch:14, weight train batch: 280, step:6, loss before: 4.96579377796e-06, loss after: 4.96579377796e-06.\n",
      "Epoch:14, weight train batch: 280, step:7, loss before: 4.8428523769e-06, loss after: 4.8428523769e-06.\n",
      "Epoch:14, weight train batch: 280, step:8, loss before: 6.28081124887e-06, loss after: 6.28081124887e-06.\n",
      "Epoch:14, weight train batch: 280, step:9, loss before: 5.56183567824e-06, loss after: 5.56183567824e-06.\n",
      "Epoch:14, weight train batch: 280, step:10, loss before: 5.53203244635e-06, loss after: 5.53203244635e-06.\n",
      "Epoch:14, weight train batch: 280, step:11, loss before: 5.06637388753e-06, loss after: 5.06637388753e-06.\n",
      "Epoch:14, weight train batch: 280, step:12, loss before: 4.51876076113e-06, loss after: 4.49268463854e-06.\n",
      "Epoch:14, weight train batch: 280, step:13, loss before: 4.91736409458e-06, loss after: 4.91736409458e-06.\n",
      "Epoch:14, weight train batch: 280, step:14, loss before: 1.63224285643e-05, loss after: 1.62777287187e-05.\n",
      "Epoch:14, weight train batch: 280, step:15, loss before: 4.7162006922e-06, loss after: 4.68639836981e-06.\n",
      "Epoch:14, weight train batch: 280, step:16, loss before: 5.42400039194e-06, loss after: 5.42400039194e-06.\n",
      "Epoch:14, weight train batch: 280, step:17, loss before: 5.94553921474e-06, loss after: 5.94553921474e-06.\n",
      "Epoch:14, weight train batch: 280, step:18, loss before: 4.92853905598e-06, loss after: 4.92853905598e-06.\n",
      "Epoch:14, weight train batch: 280, step:19, loss before: 4.94344203616e-06, loss after: 4.94344203616e-06.\n",
      "Epoch:14, weight train batch: 280, step:20, loss before: 5.45007787878e-06, loss after: 5.45007787878e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14, weight train batch: 280, step:21, loss before: 5.94553921474e-06, loss after: 5.94553921474e-06.\n",
      "Epoch:14, weight train batch: 280, step:22, loss before: 5.006770607e-06, loss after: 5.006770607e-06.\n",
      "Epoch:14, weight train batch: 280, step:23, loss before: 5.78162689635e-06, loss after: 5.78162689635e-06.\n",
      "Epoch:14, weight train batch: 280, step:24, loss before: 4.83540816276e-06, loss after: 4.83540816276e-06.\n",
      "Epoch:14, weight train batch: 280, step:25, loss before: 5.65124310015e-06, loss after: 5.65124310015e-06.\n",
      "Epoch:14, weight train batch: 280, step:26, loss before: 4.93599191032e-06, loss after: 4.93599191032e-06.\n",
      "Epoch:14, weight train batch: 280, step:27, loss before: 5.19303512192e-06, loss after: 5.19303512192e-06.\n",
      "Epoch:14, weight train batch: 280, step:28, loss before: 4.3473974074e-06, loss after: 4.3473974074e-06.\n",
      "Epoch:14, weight train batch: 280, step:29, loss before: 5.83750534133e-06, loss after: 5.81142830924e-06.\n",
      "Epoch:14, weight train batch: 280, step:30, loss before: 6.39999689156e-06, loss after: 6.39999689156e-06.\n",
      "Epoch:14, weight train batch: 280, step:31, loss before: 5.10362724526e-06, loss after: 5.07010008732e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 276, loss before: 4.86521139464e-06, loss after: 4.86521139464e-06.\n",
      "Epoch:14, weight train batch: 281, step:0, loss before: 4.23564188168e-06, loss after: 4.23564188168e-06.\n",
      "Epoch:14, weight train batch: 281, step:1, loss before: 5.3979229051e-06, loss after: 5.3979229051e-06.\n",
      "Epoch:14, weight train batch: 281, step:2, loss before: 5.6549670262e-06, loss after: 5.6549670262e-06.\n",
      "Epoch:14, weight train batch: 281, step:3, loss before: 6.90287924954e-06, loss after: 6.90287924954e-06.\n",
      "Epoch:14, weight train batch: 281, step:4, loss before: 4.93599100082e-06, loss after: 4.93599100082e-06.\n",
      "Epoch:14, weight train batch: 281, step:5, loss before: 5.58046122023e-06, loss after: 5.58046122023e-06.\n",
      "Epoch:14, weight train batch: 281, step:6, loss before: 4.91736500408e-06, loss after: 4.91736500408e-06.\n",
      "Epoch:14, weight train batch: 281, step:7, loss before: 5.50223057871e-06, loss after: 5.50223057871e-06.\n",
      "Epoch:14, weight train batch: 281, step:8, loss before: 4.99559610034e-06, loss after: 4.99559610034e-06.\n",
      "Epoch:14, weight train batch: 281, step:9, loss before: 4.60444243799e-06, loss after: 4.60444243799e-06.\n",
      "Epoch:14, weight train batch: 281, step:10, loss before: 4.49268372904e-06, loss after: 4.49268372904e-06.\n",
      "Epoch:14, weight train batch: 281, step:11, loss before: 4.41072916146e-06, loss after: 4.41072916146e-06.\n",
      "Epoch:14, weight train batch: 281, step:12, loss before: 5.78161279918e-06, loss after: 5.78161279918e-06.\n",
      "Epoch:14, weight train batch: 281, step:13, loss before: 5.01422164234e-06, loss after: 5.01422164234e-06.\n",
      "Epoch:14, weight train batch: 281, step:14, loss before: 5.48360503672e-06, loss after: 5.48360503672e-06.\n",
      "Epoch:14, weight train batch: 281, step:15, loss before: 4.89873855258e-06, loss after: 4.8689362302e-06.\n",
      "Epoch:14, weight train batch: 281, step:16, loss before: 4.24309200753e-06, loss after: 4.24309200753e-06.\n",
      "Epoch:14, weight train batch: 281, step:17, loss before: 4.46660669695e-06, loss after: 4.46660669695e-06.\n",
      "Epoch:14, weight train batch: 281, step:18, loss before: 5.76672573516e-06, loss after: 5.76672573516e-06.\n",
      "Epoch:14, weight train batch: 281, step:19, loss before: 5.56928807782e-06, loss after: 5.56928807782e-06.\n",
      "Epoch:14, weight train batch: 281, step:20, loss before: 4.17976116296e-06, loss after: 4.15740942117e-06.\n",
      "Epoch:14, weight train batch: 281, step:21, loss before: 4.89128842673e-06, loss after: 4.89128842673e-06.\n",
      "Epoch:14, weight train batch: 281, step:22, loss before: 5.62422064831e-05, loss after: 5.61008819204e-05.\n",
      "Epoch:14, weight train batch: 281, step:23, loss before: 4.36975005869e-06, loss after: 4.36975005869e-06.\n",
      "Epoch:14, weight train batch: 281, step:24, loss before: 4.52993754152e-06, loss after: 4.52993754152e-06.\n",
      "Epoch:14, weight train batch: 281, step:25, loss before: 5.46870251128e-06, loss after: 5.46870251128e-06.\n",
      "Epoch:14, weight train batch: 281, step:26, loss before: 1.71450519701e-05, loss after: 1.71338797372e-05.\n",
      "Epoch:14, weight train batch: 281, step:27, loss before: 4.41817928731e-06, loss after: 4.41817928731e-06.\n",
      "Epoch:14, weight train batch: 281, step:28, loss before: 5.05519938088e-06, loss after: 5.05519938088e-06.\n",
      "Epoch:14, weight train batch: 281, step:29, loss before: 5.49778451386e-05, loss after: 5.47100571566e-05.\n",
      "Epoch:14, weight train batch: 281, step:30, loss before: 5.11852795171e-06, loss after: 5.11852795171e-06.\n",
      "Epoch:14, weight train batch: 281, step:31, loss before: 4.46660851594e-06, loss after: 4.46660851594e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 277, loss before: 4.53459369965e-06, loss after: 4.38092729382e-06.\n",
      "Epoch:14, weight train batch: 282, step:0, loss before: 4.76835339214e-06, loss after: 4.7385515245e-06.\n",
      "Epoch:14, weight train batch: 282, step:1, loss before: 3.68057590094e-06, loss after: 3.68057590094e-06.\n",
      "Epoch:14, weight train batch: 282, step:2, loss before: 4.29897090726e-06, loss after: 4.29897090726e-06.\n",
      "Epoch:14, weight train batch: 282, step:3, loss before: 4.70129907626e-06, loss after: 4.70129907626e-06.\n",
      "Epoch:14, weight train batch: 282, step:4, loss before: 5.88593502471e-06, loss after: 5.88593502471e-06.\n",
      "Epoch:14, weight train batch: 282, step:5, loss before: 5.09617802891e-06, loss after: 5.09617802891e-06.\n",
      "Epoch:14, weight train batch: 282, step:6, loss before: 4.49268418379e-06, loss after: 4.49268418379e-06.\n",
      "Epoch:14, weight train batch: 282, step:7, loss before: 4.50758625448e-06, loss after: 4.50758625448e-06.\n",
      "Epoch:14, weight train batch: 282, step:8, loss before: 3.71782834918e-06, loss after: 3.71782834918e-06.\n",
      "Epoch:14, weight train batch: 282, step:9, loss before: 5.58791271033e-06, loss after: 5.58791271033e-06.\n",
      "Epoch:14, weight train batch: 282, step:10, loss before: 5.08127595822e-06, loss after: 5.08127595822e-06.\n",
      "Epoch:14, weight train batch: 282, step:11, loss before: 4.96206848766e-06, loss after: 4.96206848766e-06.\n",
      "Epoch:14, weight train batch: 282, step:12, loss before: 5.61771639696e-06, loss after: 5.61771639696e-06.\n",
      "Epoch:14, weight train batch: 282, step:13, loss before: 0.00168412935454, loss after: 0.00168111082166.\n",
      "Epoch:14, weight train batch: 282, step:14, loss before: 4.16486182075e-06, loss after: 4.16486182075e-06.\n",
      "Epoch:14, weight train batch: 282, step:15, loss before: 4.76835566587e-06, loss after: 4.76835566587e-06.\n",
      "Epoch:14, weight train batch: 282, step:16, loss before: 5.03657429363e-06, loss after: 5.03657429363e-06.\n",
      "Epoch:14, weight train batch: 282, step:17, loss before: 6.63096670905e-06, loss after: 6.63096670905e-06.\n",
      "Epoch:14, weight train batch: 282, step:18, loss before: 5.92318838244e-06, loss after: 5.8859359342e-06.\n",
      "Epoch:14, weight train batch: 282, step:19, loss before: 4.1872121983e-06, loss after: 4.1872121983e-06.\n",
      "Epoch:14, weight train batch: 282, step:20, loss before: 5.1110800996e-06, loss after: 5.0924536481e-06.\n",
      "Epoch:14, weight train batch: 282, step:21, loss before: 3.86683905162e-06, loss after: 3.86683905162e-06.\n",
      "Epoch:14, weight train batch: 282, step:22, loss before: 5.9269123085e-06, loss after: 5.89710998611e-06.\n",
      "Epoch:14, weight train batch: 282, step:23, loss before: 5.39420125278e-06, loss after: 5.39420125278e-06.\n",
      "Epoch:14, weight train batch: 282, step:24, loss before: 5.30851866642e-06, loss after: 5.30851866642e-06.\n",
      "Epoch:14, weight train batch: 282, step:25, loss before: 5.23401286046e-06, loss after: 5.23401286046e-06.\n",
      "Epoch:14, weight train batch: 282, step:26, loss before: 4.89873855258e-06, loss after: 4.89873855258e-06.\n",
      "Epoch:14, weight train batch: 282, step:27, loss before: 5.97161533733e-06, loss after: 5.97161533733e-06.\n",
      "Epoch:14, weight train batch: 282, step:28, loss before: 4.02702471547e-06, loss after: 4.02702471547e-06.\n",
      "Epoch:14, weight train batch: 282, step:29, loss before: 5.2600894378e-06, loss after: 5.2600894378e-06.\n",
      "Epoch:14, weight train batch: 282, step:30, loss before: 5.01049635204e-06, loss after: 5.01049635204e-06.\n",
      "Epoch:14, weight train batch: 282, step:31, loss before: 5.11107828061e-06, loss after: 5.11107828061e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 278, loss before: 0.000411325105233, loss after: 4.57929218101e-06.\n",
      "Epoch:14, weight train batch: 283, step:0, loss before: 4.51131109003e-06, loss after: 4.51131109003e-06.\n",
      "Epoch:14, weight train batch: 283, step:1, loss before: 4.89873809784e-06, loss after: 4.89873809784e-06.\n",
      "Epoch:14, weight train batch: 283, step:2, loss before: 1.81249251909e-05, loss after: 1.81100294867e-05.\n",
      "Epoch:14, weight train batch: 283, step:3, loss before: 4.16113607571e-06, loss after: 4.16113607571e-06.\n",
      "Epoch:14, weight train batch: 283, step:4, loss before: 5.11107828061e-06, loss after: 5.11107828061e-06.\n",
      "Epoch:14, weight train batch: 283, step:5, loss before: 3.43843362316e-06, loss after: 3.43843362316e-06.\n",
      "Epoch:14, weight train batch: 283, step:6, loss before: 0.000236095525906, loss after: 0.000234305640333.\n",
      "Epoch:14, weight train batch: 283, step:7, loss before: 5.73319812247e-06, loss after: 5.73319812247e-06.\n",
      "Epoch:14, weight train batch: 283, step:8, loss before: 4.91363925903e-06, loss after: 4.89128751724e-06.\n",
      "Epoch:14, weight train batch: 283, step:9, loss before: 5.00677197124e-06, loss after: 4.97696964885e-06.\n",
      "Epoch:14, weight train batch: 283, step:10, loss before: 5.6549670262e-06, loss after: 5.6549670262e-06.\n",
      "Epoch:14, weight train batch: 283, step:11, loss before: 5.06637570652e-06, loss after: 5.03657338413e-06.\n",
      "Epoch:14, weight train batch: 283, step:12, loss before: 4.49640947409e-06, loss after: 4.52621134173e-06.\n",
      "Epoch:14, weight train batch: 283, step:13, loss before: 4.28406974606e-06, loss after: 4.28406974606e-06.\n",
      "Epoch:14, weight train batch: 283, step:14, loss before: 4.69012411486e-06, loss after: 4.69012411486e-06.\n",
      "Epoch:14, weight train batch: 283, step:15, loss before: 1.46908705574e-05, loss after: 1.46052052514e-05.\n",
      "Epoch:14, weight train batch: 283, step:16, loss before: 3.9152678255e-06, loss after: 3.9152678255e-06.\n",
      "Epoch:14, weight train batch: 283, step:17, loss before: 5.33086904397e-06, loss after: 5.33086904397e-06.\n",
      "Epoch:14, weight train batch: 283, step:18, loss before: 4.97324435855e-06, loss after: 4.97324435855e-06.\n",
      "Epoch:14, weight train batch: 283, step:19, loss before: 1.60875242727e-05, loss after: 1.60502841027e-05.\n",
      "Epoch:14, weight train batch: 283, step:20, loss before: 3.77743231184e-06, loss after: 3.75508102479e-06.\n",
      "Epoch:14, weight train batch: 283, step:21, loss before: 4.29152078141e-06, loss after: 4.29152078141e-06.\n",
      "Epoch:14, weight train batch: 283, step:22, loss before: 4.69384849566e-06, loss after: 4.69384849566e-06.\n",
      "Epoch:14, weight train batch: 283, step:23, loss before: 0.000209026416996, loss after: 0.000207046148716.\n",
      "Epoch:14, weight train batch: 283, step:24, loss before: 4.18721174356e-06, loss after: 4.16113471147e-06.\n",
      "Epoch:14, weight train batch: 283, step:25, loss before: 4.17603632741e-06, loss after: 4.17603632741e-06.\n",
      "Epoch:14, weight train batch: 283, step:26, loss before: 4.34739968114e-06, loss after: 4.3026966523e-06.\n",
      "Epoch:14, weight train batch: 283, step:27, loss before: 4.26544374932e-06, loss after: 4.26544374932e-06.\n",
      "Epoch:14, weight train batch: 283, step:28, loss before: 5.08872608407e-06, loss after: 5.08872608407e-06.\n",
      "Epoch:14, weight train batch: 283, step:29, loss before: 4.67149720862e-06, loss after: 4.67149720862e-06.\n",
      "Epoch:14, weight train batch: 283, step:30, loss before: 4.14250916947e-06, loss after: 4.11270684708e-06.\n",
      "Epoch:14, weight train batch: 283, step:31, loss before: 4.8614856496e-06, loss after: 4.8614856496e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 279, loss before: 3.9208562157e-06, loss after: 4.42189093519e-06.\n",
      "Epoch:14, weight train batch: 284, step:0, loss before: 5.46497903997e-06, loss after: 5.46497903997e-06.\n",
      "Epoch:14, weight train batch: 284, step:1, loss before: 4.48895934824e-06, loss after: 4.48895934824e-06.\n",
      "Epoch:14, weight train batch: 284, step:2, loss before: 3.95997176383e-06, loss after: 3.95997176383e-06.\n",
      "Epoch:14, weight train batch: 284, step:3, loss before: 4.04565207646e-06, loss after: 4.01584975407e-06.\n",
      "Epoch:14, weight train batch: 284, step:4, loss before: 4.8577603593e-06, loss after: 4.82423365611e-06.\n",
      "Epoch:14, weight train batch: 284, step:5, loss before: 1.26981822177e-05, loss after: 1.26683889903e-05.\n",
      "Epoch:14, weight train batch: 284, step:6, loss before: 4.06055460189e-06, loss after: 4.06055460189e-06.\n",
      "Epoch:14, weight train batch: 284, step:7, loss before: 4.87266106575e-06, loss after: 4.87266106575e-06.\n",
      "Epoch:14, weight train batch: 284, step:8, loss before: 4.74972785014e-06, loss after: 4.74972785014e-06.\n",
      "Epoch:14, weight train batch: 284, step:9, loss before: 4.80188191432e-06, loss after: 4.80188191432e-06.\n",
      "Epoch:14, weight train batch: 284, step:10, loss before: 0.000749364902731, loss after: 0.000746774079744.\n",
      "Epoch:14, weight train batch: 284, step:11, loss before: 4.67149720862e-06, loss after: 4.67149720862e-06.\n",
      "Epoch:14, weight train batch: 284, step:12, loss before: 3.69547774426e-06, loss after: 3.69547774426e-06.\n",
      "Epoch:14, weight train batch: 284, step:13, loss before: 4.36975005869e-06, loss after: 4.36975005869e-06.\n",
      "Epoch:14, weight train batch: 284, step:14, loss before: 3.30804869009e-06, loss after: 3.25961991621e-06.\n",
      "Epoch:14, weight train batch: 284, step:15, loss before: 4.10898246628e-06, loss after: 4.10898246628e-06.\n",
      "Epoch:14, weight train batch: 284, step:16, loss before: 4.35857418779e-06, loss after: 4.35857418779e-06.\n",
      "Epoch:14, weight train batch: 284, step:17, loss before: 5.49850574316e-06, loss after: 5.49850574316e-06.\n",
      "Epoch:14, weight train batch: 284, step:18, loss before: 3.70292741536e-06, loss after: 3.70292741536e-06.\n",
      "Epoch:14, weight train batch: 284, step:19, loss before: 4.47033198725e-06, loss after: 4.47033198725e-06.\n",
      "Epoch:14, weight train batch: 284, step:20, loss before: 4.9769691941e-06, loss after: 4.9769691941e-06.\n",
      "Epoch:14, weight train batch: 284, step:21, loss before: 4.9955956456e-06, loss after: 4.9955956456e-06.\n",
      "Epoch:14, weight train batch: 284, step:22, loss before: 4.67149766337e-06, loss after: 4.67149766337e-06.\n",
      "Epoch:14, weight train batch: 284, step:23, loss before: 3.5352904888e-06, loss after: 3.5352904888e-06.\n",
      "Epoch:14, weight train batch: 284, step:24, loss before: 4.52248650618e-06, loss after: 4.52248650618e-06.\n",
      "Epoch:14, weight train batch: 284, step:25, loss before: 5.96043901169e-06, loss after: 5.96043901169e-06.\n",
      "Epoch:14, weight train batch: 284, step:26, loss before: 5.61026445212e-06, loss after: 5.61026445212e-06.\n",
      "Epoch:14, weight train batch: 284, step:27, loss before: 5.12598035129e-06, loss after: 5.12598035129e-06.\n",
      "Epoch:14, weight train batch: 284, step:28, loss before: 5.64167057746e-05, loss after: 5.62716631975e-05.\n",
      "Epoch:14, weight train batch: 284, step:29, loss before: 4.0568274926e-06, loss after: 4.0568274926e-06.\n",
      "Epoch:14, weight train batch: 284, step:30, loss before: 4.3324980652e-06, loss after: 4.3324980652e-06.\n",
      "Epoch:14, weight train batch: 284, step:31, loss before: 3.36392758982e-06, loss after: 3.33040043188e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 280, loss before: 3.95345205106e-06, loss after: 9.02250903891e-05.\n",
      "Epoch:14, weight train batch: 285, step:0, loss before: 3.1925658277e-06, loss after: 3.18138995681e-06.\n",
      "Epoch:14, weight train batch: 285, step:1, loss before: 3.28197097588e-06, loss after: 3.28197097588e-06.\n",
      "Epoch:14, weight train batch: 285, step:2, loss before: 4.70129907626e-06, loss after: 4.70129907626e-06.\n",
      "Epoch:14, weight train batch: 285, step:3, loss before: 4.5820906962e-06, loss after: 4.5820906962e-06.\n",
      "Epoch:14, weight train batch: 285, step:4, loss before: 4.78325455333e-06, loss after: 4.78325455333e-06.\n",
      "Epoch:14, weight train batch: 285, step:5, loss before: 4.2244623728e-06, loss after: 4.2244623728e-06.\n",
      "Epoch:14, weight train batch: 285, step:6, loss before: 4.76090372103e-06, loss after: 4.76090372103e-06.\n",
      "Epoch:14, weight train batch: 285, step:7, loss before: 4.29151896242e-06, loss after: 4.26916767537e-06.\n",
      "Epoch:14, weight train batch: 285, step:8, loss before: 3.12550992021e-06, loss after: 3.12550992021e-06.\n",
      "Epoch:14, weight train batch: 285, step:9, loss before: 4.54483779322e-06, loss after: 4.54483779322e-06.\n",
      "Epoch:14, weight train batch: 285, step:10, loss before: 4.67149629912e-06, loss after: 4.67149629912e-06.\n",
      "Epoch:14, weight train batch: 285, step:11, loss before: 4.20211290475e-06, loss after: 4.20211290475e-06.\n",
      "Epoch:14, weight train batch: 285, step:12, loss before: 4.69757333121e-06, loss after: 4.69757333121e-06.\n",
      "Epoch:14, weight train batch: 285, step:13, loss before: 5.02167131344e-06, loss after: 5.02167131344e-06.\n",
      "Epoch:14, weight train batch: 285, step:14, loss before: 4.49640992883e-06, loss after: 4.49640992883e-06.\n",
      "Epoch:14, weight train batch: 285, step:15, loss before: 4.83168332721e-06, loss after: 4.83168332721e-06.\n",
      "Epoch:14, weight train batch: 285, step:16, loss before: 3.36765333486e-06, loss after: 3.36765333486e-06.\n",
      "Epoch:14, weight train batch: 285, step:17, loss before: 5.61026445212e-06, loss after: 5.61026445212e-06.\n",
      "Epoch:14, weight train batch: 285, step:18, loss before: 3.94506969315e-06, loss after: 3.94506969315e-06.\n",
      "Epoch:14, weight train batch: 285, step:19, loss before: 3.87801492252e-06, loss after: 3.87801492252e-06.\n",
      "Epoch:14, weight train batch: 285, step:20, loss before: 4.28034354627e-06, loss after: 4.25054167863e-06.\n",
      "Epoch:14, weight train batch: 285, step:21, loss before: 5.49478090761e-06, loss after: 5.49478090761e-06.\n",
      "Epoch:14, weight train batch: 285, step:22, loss before: 4.85775944981e-06, loss after: 4.85775944981e-06.\n",
      "Epoch:14, weight train batch: 285, step:23, loss before: 4.88756268169e-06, loss after: 4.88756268169e-06.\n",
      "Epoch:14, weight train batch: 285, step:24, loss before: 3.98977363147e-06, loss after: 3.98977363147e-06.\n",
      "Epoch:14, weight train batch: 285, step:25, loss before: 4.50385959994e-06, loss after: 4.50385959994e-06.\n",
      "Epoch:14, weight train batch: 285, step:26, loss before: 4.05310265705e-06, loss after: 4.05310265705e-06.\n",
      "Epoch:14, weight train batch: 285, step:27, loss before: 5.23028666066e-06, loss after: 5.23028666066e-06.\n",
      "Epoch:14, weight train batch: 285, step:28, loss before: 4.63424385089e-06, loss after: 4.63424385089e-06.\n",
      "Epoch:14, weight train batch: 285, step:29, loss before: 4.18348645326e-06, loss after: 4.18348645326e-06.\n",
      "Epoch:14, weight train batch: 285, step:30, loss before: 4.5932656576e-06, loss after: 4.5932656576e-06.\n",
      "Epoch:14, weight train batch: 285, step:31, loss before: 4.97696873936e-06, loss after: 4.97696873936e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 281, loss before: 0.0004090978764, loss after: 4.0661411731e-06.\n",
      "Epoch:14, weight train batch: 286, step:0, loss before: 3.04243221763e-05, loss after: 3.03610431729e-05.\n",
      "Epoch:14, weight train batch: 286, step:1, loss before: 5.62516515856e-06, loss after: 5.62516515856e-06.\n",
      "Epoch:14, weight train batch: 286, step:2, loss before: 6.03867010796e-06, loss after: 6.02004365646e-06.\n",
      "Epoch:14, weight train batch: 286, step:3, loss before: 4.13133057009e-06, loss after: 4.13133057009e-06.\n",
      "Epoch:14, weight train batch: 286, step:4, loss before: 3.27824659507e-06, loss after: 3.26334566125e-06.\n",
      "Epoch:14, weight train batch: 286, step:5, loss before: 4.3213221943e-06, loss after: 4.3213221943e-06.\n",
      "Epoch:14, weight train batch: 286, step:6, loss before: 0.000175399705768, loss after: 0.000174495726242.\n",
      "Epoch:14, weight train batch: 286, step:7, loss before: 3.71037867808e-06, loss after: 3.6694004848e-06.\n",
      "Epoch:14, weight train batch: 286, step:8, loss before: 5.06637479702e-06, loss after: 5.06637479702e-06.\n",
      "Epoch:14, weight train batch: 286, step:9, loss before: 3.75880563297e-06, loss after: 3.79605830858e-06.\n",
      "Epoch:14, weight train batch: 286, step:10, loss before: 3.6843007365e-06, loss after: 3.6843007365e-06.\n",
      "Epoch:14, weight train batch: 286, step:11, loss before: 4.09780568589e-06, loss after: 4.09780568589e-06.\n",
      "Epoch:14, weight train batch: 286, step:12, loss before: 4.57836540591e-06, loss after: 4.57836540591e-06.\n",
      "Epoch:14, weight train batch: 286, step:13, loss before: 3.43843294104e-06, loss after: 3.41235590895e-06.\n",
      "Epoch:14, weight train batch: 286, step:14, loss before: 3.27824682245e-06, loss after: 3.27824682245e-06.\n",
      "Epoch:14, weight train batch: 286, step:15, loss before: 3.94507060264e-06, loss after: 3.94507060264e-06.\n",
      "Epoch:14, weight train batch: 286, step:16, loss before: 4.89128797199e-06, loss after: 4.89128797199e-06.\n",
      "Epoch:14, weight train batch: 286, step:17, loss before: 3.26334566125e-06, loss after: 3.26334566125e-06.\n",
      "Epoch:14, weight train batch: 286, step:18, loss before: 3.86683859688e-06, loss after: 3.86683859688e-06.\n",
      "Epoch:14, weight train batch: 286, step:19, loss before: 3.87428917747e-06, loss after: 3.87428917747e-06.\n",
      "Epoch:14, weight train batch: 286, step:20, loss before: 3.64332345271e-06, loss after: 3.62469722859e-06.\n",
      "Epoch:14, weight train batch: 286, step:21, loss before: 4.24681775257e-06, loss after: 4.24681775257e-06.\n",
      "Epoch:14, weight train batch: 286, step:22, loss before: 3.64332208846e-06, loss after: 3.64332208846e-06.\n",
      "Epoch:14, weight train batch: 286, step:23, loss before: 4.57464011561e-06, loss after: 4.57464011561e-06.\n",
      "Epoch:14, weight train batch: 286, step:24, loss before: 0.000161418036441, loss after: 0.000160305935424.\n",
      "Epoch:14, weight train batch: 286, step:25, loss before: 4.45543173555e-06, loss after: 4.45543173555e-06.\n",
      "Epoch:14, weight train batch: 286, step:26, loss before: 3.54274038727e-06, loss after: 3.54274038727e-06.\n",
      "Epoch:14, weight train batch: 286, step:27, loss before: 3.22981804857e-06, loss after: 3.22981804857e-06.\n",
      "Epoch:14, weight train batch: 286, step:28, loss before: 4.63795731775e-06, loss after: 4.63795731775e-06.\n",
      "Epoch:14, weight train batch: 286, step:29, loss before: 3.82586176784e-06, loss after: 3.78115828426e-06.\n",
      "Epoch:14, weight train batch: 286, step:30, loss before: 3.65077357856e-06, loss after: 3.65077357856e-06.\n",
      "Epoch:14, weight train batch: 286, step:31, loss before: 3.55019187737e-06, loss after: 3.55019187737e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 282, loss before: 4.02423256674e-06, loss after: 5.5914870245e-06.\n",
      "Epoch:14, weight train batch: 287, step:0, loss before: 3.67685038327e-06, loss after: 3.67685038327e-06.\n",
      "Epoch:14, weight train batch: 287, step:1, loss before: 4.31759644925e-06, loss after: 4.31759644925e-06.\n",
      "Epoch:14, weight train batch: 287, step:2, loss before: 4.24309155278e-06, loss after: 4.24309155278e-06.\n",
      "Epoch:14, weight train batch: 287, step:3, loss before: 3.62469631909e-06, loss after: 3.62469631909e-06.\n",
      "Epoch:14, weight train batch: 287, step:4, loss before: 4.41817792307e-06, loss after: 4.38092547483e-06.\n",
      "Epoch:14, weight train batch: 287, step:5, loss before: 4.53738721262e-06, loss after: 4.53738721262e-06.\n",
      "Epoch:14, weight train batch: 287, step:6, loss before: 3.21864172292e-06, loss after: 3.21864172292e-06.\n",
      "Epoch:14, weight train batch: 287, step:7, loss before: 3.34902688337e-06, loss after: 3.34902688337e-06.\n",
      "Epoch:14, weight train batch: 287, step:8, loss before: 4.81678307551e-06, loss after: 4.78698075312e-06.\n",
      "Epoch:14, weight train batch: 287, step:9, loss before: 4.42190457761e-06, loss after: 4.42190457761e-06.\n",
      "Epoch:14, weight train batch: 287, step:10, loss before: 3.30599941663e-05, loss after: 3.30339426e-05.\n",
      "Epoch:14, weight train batch: 287, step:11, loss before: 4.36229947809e-06, loss after: 4.36229947809e-06.\n",
      "Epoch:14, weight train batch: 287, step:12, loss before: 3.9301680772e-06, loss after: 3.9301680772e-06.\n",
      "Epoch:14, weight train batch: 287, step:13, loss before: 3.52783945345e-06, loss after: 3.52783945345e-06.\n",
      "Epoch:14, weight train batch: 287, step:14, loss before: 0.021664172411, loss after: 0.021664172411.\n",
      "Epoch:14, weight train batch: 287, step:15, loss before: 2.8796425795e-06, loss after: 2.8796425795e-06.\n",
      "Epoch:14, weight train batch: 287, step:16, loss before: 3.49803735844e-06, loss after: 3.49803735844e-06.\n",
      "Epoch:14, weight train batch: 287, step:17, loss before: 3.87056434192e-06, loss after: 3.87056434192e-06.\n",
      "Epoch:14, weight train batch: 287, step:18, loss before: 4.4591565711e-06, loss after: 4.4591565711e-06.\n",
      "Epoch:14, weight train batch: 287, step:19, loss before: 1.2616598724e-05, loss after: 1.26091499624e-05.\n",
      "Epoch:14, weight train batch: 287, step:20, loss before: 3.16648856824e-06, loss after: 3.16648856824e-06.\n",
      "Epoch:14, weight train batch: 287, step:21, loss before: 4.68639791507e-06, loss after: 4.68639791507e-06.\n",
      "Epoch:14, weight train batch: 287, step:22, loss before: 4.05583705287e-05, loss after: 4.04764832638e-05.\n",
      "Epoch:14, weight train batch: 287, step:23, loss before: 3.68057499145e-06, loss after: 3.65449841411e-06.\n",
      "Epoch:14, weight train batch: 287, step:24, loss before: 4.16486091126e-06, loss after: 4.16486091126e-06.\n",
      "Epoch:14, weight train batch: 287, step:25, loss before: 4.00094859287e-06, loss after: 4.00094859287e-06.\n",
      "Epoch:14, weight train batch: 287, step:26, loss before: 3.17393937621e-06, loss after: 3.17393937621e-06.\n",
      "Epoch:14, weight train batch: 287, step:27, loss before: 4.22819039159e-06, loss after: 4.22819039159e-06.\n",
      "Epoch:14, weight train batch: 287, step:28, loss before: 4.25426696893e-06, loss after: 4.25426696893e-06.\n",
      "Epoch:14, weight train batch: 287, step:29, loss before: 3.92644324165e-06, loss after: 3.92644324165e-06.\n",
      "Epoch:14, weight train batch: 287, step:30, loss before: 4.29151987191e-06, loss after: 4.29151987191e-06.\n",
      "Epoch:14, weight train batch: 287, step:31, loss before: 3.50548771166e-06, loss after: 3.50548771166e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 283, loss before: 5.68926952838e-06, loss after: 4.09873700846e-06.\n",
      "Epoch:14, weight train batch: 288, step:0, loss before: 6.80229459249e-06, loss after: 6.79857021169e-06.\n",
      "Epoch:14, weight train batch: 288, step:1, loss before: 3.90409240936e-06, loss after: 3.90409240936e-06.\n",
      "Epoch:14, weight train batch: 288, step:2, loss before: 4.8577612688e-06, loss after: 4.8577612688e-06.\n",
      "Epoch:14, weight train batch: 288, step:3, loss before: 4.97324435855e-06, loss after: 4.97324435855e-06.\n",
      "Epoch:14, weight train batch: 288, step:4, loss before: 3.97487201553e-06, loss after: 3.97487201553e-06.\n",
      "Epoch:14, weight train batch: 288, step:5, loss before: 3.87801537727e-06, loss after: 3.87801537727e-06.\n",
      "Epoch:14, weight train batch: 288, step:6, loss before: 1.09253560368e-05, loss after: 1.09179072751e-05.\n",
      "Epoch:14, weight train batch: 288, step:7, loss before: 3.81841073249e-06, loss after: 3.7886084101e-06.\n",
      "Epoch:14, weight train batch: 288, step:8, loss before: 4.5969918574e-06, loss after: 4.5969918574e-06.\n",
      "Epoch:14, weight train batch: 288, step:9, loss before: 3.91526555177e-06, loss after: 3.91526555177e-06.\n",
      "Epoch:14, weight train batch: 288, step:10, loss before: 4.67149720862e-06, loss after: 4.67149720862e-06.\n",
      "Epoch:14, weight train batch: 288, step:11, loss before: 3.2707957871e-06, loss after: 3.25216956298e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14, weight train batch: 288, step:12, loss before: 4.38092592958e-06, loss after: 4.38092592958e-06.\n",
      "Epoch:14, weight train batch: 288, step:13, loss before: 5.2526388572e-06, loss after: 5.2526388572e-06.\n",
      "Epoch:14, weight train batch: 288, step:14, loss before: 3.09198298964e-06, loss after: 3.09198298964e-06.\n",
      "Epoch:14, weight train batch: 288, step:15, loss before: 4.32132173955e-06, loss after: 4.32132173955e-06.\n",
      "Epoch:14, weight train batch: 288, step:16, loss before: 7.78566845838e-06, loss after: 7.78194316808e-06.\n",
      "Epoch:14, weight train batch: 288, step:17, loss before: 3.17766375701e-06, loss after: 3.17766375701e-06.\n",
      "Epoch:14, weight train batch: 288, step:18, loss before: 4.67149675387e-06, loss after: 4.67149675387e-06.\n",
      "Epoch:14, weight train batch: 288, step:19, loss before: 3.04355353364e-06, loss after: 3.04355353364e-06.\n",
      "Epoch:14, weight train batch: 288, step:20, loss before: 3.97114672523e-06, loss after: 3.97114672523e-06.\n",
      "Epoch:14, weight train batch: 288, step:21, loss before: 3.59861996913e-06, loss after: 3.56136752089e-06.\n",
      "Epoch:14, weight train batch: 288, step:22, loss before: 3.52038841811e-06, loss after: 3.52038841811e-06.\n",
      "Epoch:14, weight train batch: 288, step:23, loss before: 3.44588443113e-06, loss after: 3.44588443113e-06.\n",
      "Epoch:14, weight train batch: 288, step:24, loss before: 3.79233392778e-06, loss after: 3.79233392778e-06.\n",
      "Epoch:14, weight train batch: 288, step:25, loss before: 4.83540861751e-06, loss after: 4.83540861751e-06.\n",
      "Epoch:14, weight train batch: 288, step:26, loss before: 3.5203893276e-06, loss after: 3.5203893276e-06.\n",
      "Epoch:14, weight train batch: 288, step:27, loss before: 4.13878478867e-06, loss after: 4.13878478867e-06.\n",
      "Epoch:14, weight train batch: 288, step:28, loss before: 3.72155363948e-06, loss after: 3.72155363948e-06.\n",
      "Epoch:14, weight train batch: 288, step:29, loss before: 3.28197188537e-06, loss after: 3.28197188537e-06.\n",
      "Epoch:14, weight train batch: 288, step:30, loss before: 3.80723417948e-06, loss after: 3.77743231184e-06.\n",
      "Epoch:14, weight train batch: 288, step:31, loss before: 5.48499156139e-05, loss after: 5.47160234419e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 284, loss before: 4.19745720137e-06, loss after: 4.19745720137e-06.\n",
      "Epoch:14, weight train batch: 289, step:0, loss before: 4.09035601479e-06, loss after: 4.09035601479e-06.\n",
      "Epoch:14, weight train batch: 289, step:1, loss before: 3.97487156079e-06, loss after: 3.97487156079e-06.\n",
      "Epoch:14, weight train batch: 289, step:2, loss before: 3.62097284778e-06, loss after: 3.62097284778e-06.\n",
      "Epoch:14, weight train batch: 289, step:3, loss before: 3.86311421607e-06, loss after: 3.86311421607e-06.\n",
      "Epoch:14, weight train batch: 289, step:4, loss before: 4.04565207646e-06, loss after: 4.04565207646e-06.\n",
      "Epoch:14, weight train batch: 289, step:5, loss before: 4.20211290475e-06, loss after: 4.20211290475e-06.\n",
      "Epoch:14, weight train batch: 289, step:6, loss before: 4.66032179247e-06, loss after: 4.66032179247e-06.\n",
      "Epoch:14, weight train batch: 289, step:7, loss before: 4.66404617327e-06, loss after: 4.66404617327e-06.\n",
      "Epoch:14, weight train batch: 289, step:8, loss before: 1.01469449874e-05, loss after: 1.01469449874e-05.\n",
      "Epoch:14, weight train batch: 289, step:9, loss before: 5.17068383488e-06, loss after: 5.17068383488e-06.\n",
      "Epoch:14, weight train batch: 289, step:10, loss before: 3.72527938453e-06, loss after: 3.72527938453e-06.\n",
      "Epoch:14, weight train batch: 289, step:11, loss before: 1.0374114936e-05, loss after: 1.03703914647e-05.\n",
      "Epoch:14, weight train batch: 289, step:12, loss before: 3.82586085834e-06, loss after: 3.82586085834e-06.\n",
      "Epoch:14, weight train batch: 289, step:13, loss before: 7.89349360275e-06, loss after: 7.89349360275e-06.\n",
      "Epoch:14, weight train batch: 289, step:14, loss before: 4.24309109803e-06, loss after: 4.24309109803e-06.\n",
      "Epoch:14, weight train batch: 289, step:15, loss before: 4.10898155678e-06, loss after: 4.10898155678e-06.\n",
      "Epoch:14, weight train batch: 289, step:16, loss before: 4.3473983169e-06, loss after: 4.3473983169e-06.\n",
      "Epoch:14, weight train batch: 289, step:17, loss before: 4.00094904762e-06, loss after: 4.00094904762e-06.\n",
      "Epoch:14, weight train batch: 289, step:18, loss before: 3.73645480067e-06, loss after: 3.71037822333e-06.\n",
      "Epoch:14, weight train batch: 289, step:19, loss before: 3.4123563637e-06, loss after: 3.4123563637e-06.\n",
      "Epoch:14, weight train batch: 289, step:20, loss before: 3.46823640029e-06, loss after: 3.46823640029e-06.\n",
      "Epoch:14, weight train batch: 289, step:21, loss before: 3.86311421607e-06, loss after: 3.86311421607e-06.\n",
      "Epoch:14, weight train batch: 289, step:22, loss before: 3.34902642862e-06, loss after: 3.34902642862e-06.\n",
      "Epoch:14, weight train batch: 289, step:23, loss before: 3.44960926668e-06, loss after: 3.44960926668e-06.\n",
      "Epoch:14, weight train batch: 289, step:24, loss before: 8.80991137819e-06, loss after: 8.8061860879e-06.\n",
      "Epoch:14, weight train batch: 289, step:25, loss before: 3.60607123184e-06, loss after: 3.60607123184e-06.\n",
      "Epoch:14, weight train batch: 289, step:26, loss before: 3.32667514158e-06, loss after: 3.32667514158e-06.\n",
      "Epoch:14, weight train batch: 289, step:27, loss before: 3.6619499042e-06, loss after: 3.6619499042e-06.\n",
      "Epoch:14, weight train batch: 289, step:28, loss before: 5.37156920473e-05, loss after: 5.35855178896e-05.\n",
      "Epoch:14, weight train batch: 289, step:29, loss before: 3.52411507265e-06, loss after: 3.52411507265e-06.\n",
      "Epoch:14, weight train batch: 289, step:30, loss before: 4.72365081805e-06, loss after: 4.72365081805e-06.\n",
      "Epoch:14, weight train batch: 289, step:31, loss before: 3.25589530803e-06, loss after: 3.25589530803e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 285, loss before: 3.55205384039e-06, loss after: 3.55205384039e-06.\n",
      "Epoch:14, weight train batch: 290, step:0, loss before: 3.28569740304e-06, loss after: 3.28569740304e-06.\n",
      "Epoch:14, weight train batch: 290, step:1, loss before: 3.09198367177e-06, loss after: 3.09198367177e-06.\n",
      "Epoch:14, weight train batch: 290, step:2, loss before: 4.39582800027e-06, loss after: 4.39582800027e-06.\n",
      "Epoch:14, weight train batch: 290, step:3, loss before: 3.67312532035e-06, loss after: 3.67312532035e-06.\n",
      "Epoch:14, weight train batch: 290, step:4, loss before: 3.66194944945e-06, loss after: 3.66194944945e-06.\n",
      "Epoch:14, weight train batch: 290, step:5, loss before: 4.08663072449e-06, loss after: 4.08663072449e-06.\n",
      "Epoch:14, weight train batch: 290, step:6, loss before: 3.55391716766e-06, loss after: 3.55391716766e-06.\n",
      "Epoch:14, weight train batch: 290, step:7, loss before: 4.54111341242e-06, loss after: 4.54111341242e-06.\n",
      "Epoch:14, weight train batch: 290, step:8, loss before: 3.46823480868e-06, loss after: 3.44215823134e-06.\n",
      "Epoch:14, weight train batch: 290, step:9, loss before: 3.2856969483e-06, loss after: 3.2856969483e-06.\n",
      "Epoch:14, weight train batch: 290, step:10, loss before: 4.68267353426e-06, loss after: 4.68267353426e-06.\n",
      "Epoch:14, weight train batch: 290, step:11, loss before: 4.95834365211e-06, loss after: 4.95834365211e-06.\n",
      "Epoch:14, weight train batch: 290, step:12, loss before: 4.0642789827e-06, loss after: 4.0642789827e-06.\n",
      "Epoch:14, weight train batch: 290, step:13, loss before: 4.049378731e-06, loss after: 4.049378731e-06.\n",
      "Epoch:14, weight train batch: 290, step:14, loss before: 3.90409240936e-06, loss after: 3.90409240936e-06.\n",
      "Epoch:14, weight train batch: 290, step:15, loss before: 3.84448776458e-06, loss after: 3.84448776458e-06.\n",
      "Epoch:14, weight train batch: 290, step:16, loss before: 5.13715667694e-06, loss after: 5.13715667694e-06.\n",
      "Epoch:14, weight train batch: 290, step:17, loss before: 1.14022450362e-05, loss after: 1.13985206553e-05.\n",
      "Epoch:14, weight train batch: 290, step:18, loss before: 3.69920189769e-06, loss after: 3.69920189769e-06.\n",
      "Epoch:14, weight train batch: 290, step:19, loss before: 3.28942223859e-06, loss after: 3.28942223859e-06.\n",
      "Epoch:14, weight train batch: 290, step:20, loss before: 5.02539887748e-06, loss after: 5.02539887748e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14, weight train batch: 290, step:21, loss before: 4.43680528406e-06, loss after: 4.43680528406e-06.\n",
      "Epoch:14, weight train batch: 290, step:22, loss before: 4.969519523e-06, loss after: 4.969519523e-06.\n",
      "Epoch:14, weight train batch: 290, step:23, loss before: 3.29687350131e-06, loss after: 3.29687350131e-06.\n",
      "Epoch:14, weight train batch: 290, step:24, loss before: 3.97114763473e-06, loss after: 3.97114763473e-06.\n",
      "Epoch:14, weight train batch: 290, step:25, loss before: 4.28407020081e-06, loss after: 4.28407020081e-06.\n",
      "Epoch:14, weight train batch: 290, step:26, loss before: 3.44588397638e-06, loss after: 3.44588397638e-06.\n",
      "Epoch:14, weight train batch: 290, step:27, loss before: 3.714103741e-06, loss after: 3.68802693629e-06.\n",
      "Epoch:14, weight train batch: 290, step:28, loss before: 3.51293851963e-06, loss after: 3.51293851963e-06.\n",
      "Epoch:14, weight train batch: 290, step:29, loss before: 3.3937299122e-06, loss after: 3.3937299122e-06.\n",
      "Epoch:14, weight train batch: 290, step:30, loss before: 3.78488425667e-06, loss after: 3.78488425667e-06.\n",
      "Epoch:14, weight train batch: 290, step:31, loss before: 2.91689548249e-06, loss after: 2.91689548249e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 286, loss before: 4.23005349148e-06, loss after: 5.86993610341e-06.\n",
      "Epoch:14, weight train batch: 291, step:0, loss before: 2.8647423278e-06, loss after: 2.8647423278e-06.\n",
      "Epoch:14, weight train batch: 291, step:1, loss before: 4.01212491852e-06, loss after: 4.01212491852e-06.\n",
      "Epoch:14, weight train batch: 291, step:2, loss before: 3.94134531234e-06, loss after: 3.90409240936e-06.\n",
      "Epoch:14, weight train batch: 291, step:3, loss before: 3.3341264043e-06, loss after: 3.3341264043e-06.\n",
      "Epoch:14, weight train batch: 291, step:4, loss before: 4.23564051744e-06, loss after: 4.23564051744e-06.\n",
      "Epoch:14, weight train batch: 291, step:5, loss before: 3.63959816241e-06, loss after: 3.63959816241e-06.\n",
      "Epoch:14, weight train batch: 291, step:6, loss before: 3.12551037496e-06, loss after: 3.12551037496e-06.\n",
      "Epoch:14, weight train batch: 291, step:7, loss before: 4.09408130508e-06, loss after: 4.09408130508e-06.\n",
      "Epoch:14, weight train batch: 291, step:8, loss before: 4.01957549911e-06, loss after: 4.01957549911e-06.\n",
      "Epoch:14, weight train batch: 291, step:9, loss before: 3.18138904731e-06, loss after: 3.18138904731e-06.\n",
      "Epoch:14, weight train batch: 291, step:10, loss before: 4.09035556004e-06, loss after: 4.09035556004e-06.\n",
      "Epoch:14, weight train batch: 291, step:11, loss before: 6.65300249238e-05, loss after: 6.65002808091e-05.\n",
      "Epoch:14, weight train batch: 291, step:12, loss before: 4.23936626248e-06, loss after: 4.23936626248e-06.\n",
      "Epoch:14, weight train batch: 291, step:13, loss before: 1.03444190245e-05, loss after: 1.03406946437e-05.\n",
      "Epoch:14, weight train batch: 291, step:14, loss before: 4.37347671323e-06, loss after: 4.33622381024e-06.\n",
      "Epoch:14, weight train batch: 291, step:15, loss before: 4.3064219426e-06, loss after: 4.3064219426e-06.\n",
      "Epoch:14, weight train batch: 291, step:16, loss before: 3.44215891346e-06, loss after: 3.44215891346e-06.\n",
      "Epoch:14, weight train batch: 291, step:17, loss before: 3.2186419503e-06, loss after: 3.2186419503e-06.\n",
      "Epoch:14, weight train batch: 291, step:18, loss before: 3.94134485759e-06, loss after: 3.94134485759e-06.\n",
      "Epoch:14, weight train batch: 291, step:19, loss before: 1.2191829228e-05, loss after: 1.21843804664e-05.\n",
      "Epoch:14, weight train batch: 291, step:20, loss before: 2.76415948974e-06, loss after: 2.76415948974e-06.\n",
      "Epoch:14, weight train batch: 291, step:21, loss before: 4.74600346934e-06, loss after: 4.74600346934e-06.\n",
      "Epoch:14, weight train batch: 291, step:22, loss before: 3.94134440285e-06, loss after: 3.94134440285e-06.\n",
      "Epoch:14, weight train batch: 291, step:23, loss before: 3.88174021282e-06, loss after: 3.88174021282e-06.\n",
      "Epoch:14, weight train batch: 291, step:24, loss before: 1.03071779449e-05, loss after: 1.02997291833e-05.\n",
      "Epoch:14, weight train batch: 291, step:25, loss before: 3.39745565725e-06, loss after: 3.39745565725e-06.\n",
      "Epoch:14, weight train batch: 291, step:26, loss before: 3.24844427269e-06, loss after: 3.24844427269e-06.\n",
      "Epoch:14, weight train batch: 291, step:27, loss before: 4.46288322564e-06, loss after: 4.46288322564e-06.\n",
      "Epoch:14, weight train batch: 291, step:28, loss before: 3.47196123585e-06, loss after: 3.4496099488e-06.\n",
      "Epoch:14, weight train batch: 291, step:29, loss before: 3.46823571817e-06, loss after: 3.46823571817e-06.\n",
      "Epoch:14, weight train batch: 291, step:30, loss before: 5.01418935528e-06, loss after: 5.01418935528e-06.\n",
      "Epoch:14, weight train batch: 291, step:31, loss before: 3.39000530403e-06, loss after: 3.39000530403e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 287, loss before: 3.33040043188e-06, loss after: 3.43377655554e-06.\n",
      "Epoch:14, weight train batch: 292, step:0, loss before: 0.000138883769978, loss after: 0.000138171584695.\n",
      "Epoch:14, weight train batch: 292, step:1, loss before: 3.95252118324e-06, loss after: 3.95252118324e-06.\n",
      "Epoch:14, weight train batch: 292, step:2, loss before: 4.21328968514e-06, loss after: 4.20211381424e-06.\n",
      "Epoch:14, weight train batch: 292, step:3, loss before: 3.74390583602e-06, loss after: 3.74390583602e-06.\n",
      "Epoch:14, weight train batch: 292, step:4, loss before: 4.51503728982e-06, loss after: 4.51503728982e-06.\n",
      "Epoch:14, weight train batch: 292, step:5, loss before: 2.99885186905e-06, loss after: 2.99885186905e-06.\n",
      "Epoch:14, weight train batch: 292, step:6, loss before: 3.69920235244e-06, loss after: 3.69920235244e-06.\n",
      "Epoch:14, weight train batch: 292, step:7, loss before: 0.00163057656027, loss after: 0.00162611331325.\n",
      "Epoch:14, weight train batch: 292, step:8, loss before: 4.02330124416e-06, loss after: 4.02330124416e-06.\n",
      "Epoch:14, weight train batch: 292, step:9, loss before: 3.68430210074e-06, loss after: 3.68430210074e-06.\n",
      "Epoch:14, weight train batch: 292, step:10, loss before: 3.64332322533e-06, loss after: 3.61352090295e-06.\n",
      "Epoch:14, weight train batch: 292, step:11, loss before: 3.71037822333e-06, loss after: 3.71037822333e-06.\n",
      "Epoch:14, weight train batch: 292, step:12, loss before: 3.799784281e-06, loss after: 3.799784281e-06.\n",
      "Epoch:14, weight train batch: 292, step:13, loss before: 2.97277438221e-06, loss after: 2.97277438221e-06.\n",
      "Epoch:14, weight train batch: 292, step:14, loss before: 4.60071805719e-06, loss after: 4.60071805719e-06.\n",
      "Epoch:14, weight train batch: 292, step:15, loss before: 3.56881832886e-06, loss after: 3.56881832886e-06.\n",
      "Epoch:14, weight train batch: 292, step:16, loss before: 3.37510414283e-06, loss after: 3.37510414283e-06.\n",
      "Epoch:14, weight train batch: 292, step:17, loss before: 2.87964303425e-06, loss after: 2.87964303425e-06.\n",
      "Epoch:14, weight train batch: 292, step:18, loss before: 3.75135641661e-06, loss after: 3.75135641661e-06.\n",
      "Epoch:14, weight train batch: 292, step:19, loss before: 2.86474096356e-06, loss after: 2.86474096356e-06.\n",
      "Epoch:14, weight train batch: 292, step:20, loss before: 0.0217147395015, loss after: 0.0217146798968.\n",
      "Epoch:14, weight train batch: 292, step:21, loss before: 3.49058723259e-06, loss after: 3.49058723259e-06.\n",
      "Epoch:14, weight train batch: 292, step:22, loss before: 4.1723119466e-06, loss after: 4.1723119466e-06.\n",
      "Epoch:14, weight train batch: 292, step:23, loss before: 2.87591706183e-06, loss after: 2.87591706183e-06.\n",
      "Epoch:14, weight train batch: 292, step:24, loss before: 4.45170735475e-06, loss after: 4.45170735475e-06.\n",
      "Epoch:14, weight train batch: 292, step:25, loss before: 3.78115896638e-06, loss after: 3.78115896638e-06.\n",
      "Epoch:14, weight train batch: 292, step:26, loss before: 5.38300582775e-06, loss after: 5.37928053745e-06.\n",
      "Epoch:14, weight train batch: 292, step:27, loss before: 4.0568284021e-06, loss after: 4.0568284021e-06.\n",
      "Epoch:14, weight train batch: 292, step:28, loss before: 3.75135618924e-06, loss after: 3.75135618924e-06.\n",
      "Epoch:14, weight train batch: 292, step:29, loss before: 3.24844472743e-06, loss after: 3.24844472743e-06.\n",
      "Epoch:14, weight train batch: 292, step:30, loss before: 4.29152078141e-06, loss after: 4.29152078141e-06.\n",
      "Epoch:14, weight train batch: 292, step:31, loss before: 4.02702607971e-06, loss after: 4.02702607971e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 288, loss before: 3.67964298675e-06, loss after: 3.51200833393e-06.\n",
      "Epoch:14, weight train batch: 293, step:0, loss before: 4.23936671723e-06, loss after: 4.23936671723e-06.\n",
      "Epoch:14, weight train batch: 293, step:1, loss before: 3.53156542587e-06, loss after: 3.53156542587e-06.\n",
      "Epoch:14, weight train batch: 293, step:2, loss before: 0.00156429130584, loss after: 0.00156075647101.\n",
      "Epoch:14, weight train batch: 293, step:3, loss before: 0.00156131153926, loss after: 0.00155205640476.\n",
      "Epoch:14, weight train batch: 293, step:4, loss before: 4.32877322964e-06, loss after: 4.31014677815e-06.\n",
      "Epoch:14, weight train batch: 293, step:5, loss before: 3.35647700922e-06, loss after: 3.33412526743e-06.\n",
      "Epoch:14, weight train batch: 293, step:6, loss before: 9.63669663179e-06, loss after: 9.66277366388e-06.\n",
      "Epoch:14, weight train batch: 293, step:7, loss before: 2.93739067274e-05, loss after: 2.9239910873e-05.\n",
      "Epoch:14, weight train batch: 293, step:8, loss before: 3.31177352564e-06, loss after: 3.31177352564e-06.\n",
      "Epoch:14, weight train batch: 293, step:9, loss before: 2.86846670861e-06, loss after: 2.86846670861e-06.\n",
      "Epoch:14, weight train batch: 293, step:10, loss before: 3.37510300596e-06, loss after: 3.37510300596e-06.\n",
      "Epoch:14, weight train batch: 293, step:11, loss before: 3.25962037095e-06, loss after: 3.25962037095e-06.\n",
      "Epoch:14, weight train batch: 293, step:12, loss before: 2.68965322903e-06, loss after: 2.68965322903e-06.\n",
      "Epoch:14, weight train batch: 293, step:13, loss before: 3.10688346872e-06, loss after: 3.10688346872e-06.\n",
      "Epoch:14, weight train batch: 293, step:14, loss before: 4.14995884057e-06, loss after: 4.14995884057e-06.\n",
      "Epoch:14, weight train batch: 293, step:15, loss before: 3.03982869809e-06, loss after: 3.03982869809e-06.\n",
      "Epoch:14, weight train batch: 293, step:16, loss before: 3.63214689969e-06, loss after: 3.63214689969e-06.\n",
      "Epoch:14, weight train batch: 293, step:17, loss before: 2.80886160908e-06, loss after: 2.80886160908e-06.\n",
      "Epoch:14, weight train batch: 293, step:18, loss before: 4.17603587266e-06, loss after: 4.17603587266e-06.\n",
      "Epoch:14, weight train batch: 293, step:19, loss before: 5.33459569851e-06, loss after: 5.30851866642e-06.\n",
      "Epoch:14, weight train batch: 293, step:20, loss before: 3.52038864548e-06, loss after: 3.52038864548e-06.\n",
      "Epoch:14, weight train batch: 293, step:21, loss before: 3.73645434593e-06, loss after: 3.73645434593e-06.\n",
      "Epoch:14, weight train batch: 293, step:22, loss before: 2.27614827963e-06, loss after: 2.27614827963e-06.\n",
      "Epoch:14, weight train batch: 293, step:23, loss before: 3.82958614864e-06, loss after: 3.82958614864e-06.\n",
      "Epoch:14, weight train batch: 293, step:24, loss before: 3.82586131309e-06, loss after: 3.82586131309e-06.\n",
      "Epoch:14, weight train batch: 293, step:25, loss before: 7.60671900935e-06, loss after: 7.60299462854e-06.\n",
      "Epoch:14, weight train batch: 293, step:26, loss before: 3.50921254721e-06, loss after: 3.50921254721e-06.\n",
      "Epoch:14, weight train batch: 293, step:27, loss before: 4.47405818704e-06, loss after: 4.47405818704e-06.\n",
      "Epoch:14, weight train batch: 293, step:28, loss before: 3.82958614864e-06, loss after: 3.82958614864e-06.\n",
      "Epoch:14, weight train batch: 293, step:29, loss before: 3.51666312781e-06, loss after: 3.51666312781e-06.\n",
      "Epoch:14, weight train batch: 293, step:30, loss before: 2.61514742306e-06, loss after: 2.61514742306e-06.\n",
      "Epoch:14, weight train batch: 293, step:31, loss before: 4.23564051744e-06, loss after: 4.23564051744e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 289, loss before: 3.48127423422e-06, loss after: 3.48127423422e-06.\n",
      "Epoch:14, weight train batch: 294, step:0, loss before: 3.56136661139e-06, loss after: 3.56136661139e-06.\n",
      "Epoch:14, weight train batch: 294, step:1, loss before: 2.53691655416e-06, loss after: 2.53691655416e-06.\n",
      "Epoch:14, weight train batch: 294, step:2, loss before: 3.34157630277e-06, loss after: 3.34157630277e-06.\n",
      "Epoch:14, weight train batch: 294, step:3, loss before: 3.49431138602e-06, loss after: 3.49431138602e-06.\n",
      "Epoch:14, weight train batch: 294, step:4, loss before: 3.45705893778e-06, loss after: 3.45705893778e-06.\n",
      "Epoch:14, weight train batch: 294, step:5, loss before: 3.54274084202e-06, loss after: 3.54274084202e-06.\n",
      "Epoch:14, weight train batch: 294, step:6, loss before: 3.8072339521e-06, loss after: 3.8072339521e-06.\n",
      "Epoch:14, weight train batch: 294, step:7, loss before: 3.41980648955e-06, loss after: 3.41980648955e-06.\n",
      "Epoch:14, weight train batch: 294, step:8, loss before: 3.40863061865e-06, loss after: 3.40863061865e-06.\n",
      "Epoch:14, weight train batch: 294, step:9, loss before: 5.2190880524e-06, loss after: 5.2190880524e-06.\n",
      "Epoch:14, weight train batch: 294, step:10, loss before: 3.1515869523e-06, loss after: 3.1515869523e-06.\n",
      "Epoch:14, weight train batch: 294, step:11, loss before: 3.82958614864e-06, loss after: 3.82958614864e-06.\n",
      "Epoch:14, weight train batch: 294, step:12, loss before: 4.08662981499e-06, loss after: 4.08662981499e-06.\n",
      "Epoch:14, weight train batch: 294, step:13, loss before: 3.87801401303e-06, loss after: 3.87801401303e-06.\n",
      "Epoch:14, weight train batch: 294, step:14, loss before: 3.09198230752e-06, loss after: 3.09198230752e-06.\n",
      "Epoch:14, weight train batch: 294, step:15, loss before: 3.40490532835e-06, loss after: 3.40490532835e-06.\n",
      "Epoch:14, weight train batch: 294, step:16, loss before: 4.00839962822e-06, loss after: 4.00839962822e-06.\n",
      "Epoch:14, weight train batch: 294, step:17, loss before: 4.05310265705e-06, loss after: 4.05310265705e-06.\n",
      "Epoch:14, weight train batch: 294, step:18, loss before: 2.96159805657e-06, loss after: 2.94297205983e-06.\n",
      "Epoch:14, weight train batch: 294, step:19, loss before: 3.88174066757e-06, loss after: 3.88174066757e-06.\n",
      "Epoch:14, weight train batch: 294, step:20, loss before: 3.71410305888e-06, loss after: 3.71410305888e-06.\n",
      "Epoch:14, weight train batch: 294, step:21, loss before: 3.83331189369e-06, loss after: 3.83331189369e-06.\n",
      "Epoch:14, weight train batch: 294, step:22, loss before: 3.75880608772e-06, loss after: 3.75880608772e-06.\n",
      "Epoch:14, weight train batch: 294, step:23, loss before: 3.72900376533e-06, loss after: 3.72900376533e-06.\n",
      "Epoch:14, weight train batch: 294, step:24, loss before: 3.28197188537e-06, loss after: 3.28197188537e-06.\n",
      "Epoch:14, weight train batch: 294, step:25, loss before: 3.27824591295e-06, loss after: 3.27824591295e-06.\n",
      "Epoch:14, weight train batch: 294, step:26, loss before: 2.92061940854e-06, loss after: 2.92061940854e-06.\n",
      "Epoch:14, weight train batch: 294, step:27, loss before: 2.90199386654e-06, loss after: 2.90199386654e-06.\n",
      "Epoch:14, weight train batch: 294, step:28, loss before: 2.57417013927e-06, loss after: 2.57417013927e-06.\n",
      "Epoch:14, weight train batch: 294, step:29, loss before: 3.76253137802e-06, loss after: 3.76253137802e-06.\n",
      "Epoch:14, weight train batch: 294, step:30, loss before: 3.62842138202e-06, loss after: 3.62842138202e-06.\n",
      "Epoch:14, weight train batch: 294, step:31, loss before: 3.33785055773e-06, loss after: 3.33785055773e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 290, loss before: 3.55671136276e-06, loss after: 3.55671136276e-06.\n",
      "Epoch:14, weight train batch: 295, step:0, loss before: 2.6933787467e-06, loss after: 2.6933787467e-06.\n",
      "Epoch:14, weight train batch: 295, step:1, loss before: 2.60024717136e-06, loss after: 2.60024717136e-06.\n",
      "Epoch:14, weight train batch: 295, step:2, loss before: 3.25961968883e-06, loss after: 3.25961968883e-06.\n",
      "Epoch:14, weight train batch: 295, step:3, loss before: 3.98604788643e-06, loss after: 3.98604788643e-06.\n",
      "Epoch:14, weight train batch: 295, step:4, loss before: 2.3506540856e-06, loss after: 2.3506540856e-06.\n",
      "Epoch:14, weight train batch: 295, step:5, loss before: 4.38837741967e-06, loss after: 4.38837741967e-06.\n",
      "Epoch:14, weight train batch: 295, step:6, loss before: 3.65822324966e-06, loss after: 3.65822324966e-06.\n",
      "Epoch:14, weight train batch: 295, step:7, loss before: 3.92271795135e-06, loss after: 3.92271795135e-06.\n",
      "Epoch:14, weight train batch: 295, step:8, loss before: 3.69547728951e-06, loss after: 3.66567496712e-06.\n",
      "Epoch:14, weight train batch: 295, step:9, loss before: 6.77083517076e-05, loss after: 6.76748968544e-05.\n",
      "Epoch:14, weight train batch: 295, step:10, loss before: 3.80351002605e-06, loss after: 3.80351002605e-06.\n",
      "Epoch:14, weight train batch: 295, step:11, loss before: 3.22609230352e-06, loss after: 3.22609230352e-06.\n",
      "Epoch:14, weight train batch: 295, step:12, loss before: 3.55764177584e-06, loss after: 3.55764177584e-06.\n",
      "Epoch:14, weight train batch: 295, step:13, loss before: 3.74390538127e-06, loss after: 3.74390538127e-06.\n",
      "Epoch:14, weight train batch: 295, step:14, loss before: 3.08453218167e-06, loss after: 3.08453218167e-06.\n",
      "Epoch:14, weight train batch: 295, step:15, loss before: 3.32294962391e-06, loss after: 3.32294962391e-06.\n",
      "Epoch:14, weight train batch: 295, step:16, loss before: 0.00144266476855, loss after: 0.00143995718099.\n",
      "Epoch:14, weight train batch: 295, step:17, loss before: 3.88174066757e-06, loss after: 3.88174066757e-06.\n",
      "Epoch:14, weight train batch: 295, step:18, loss before: 3.04727950606e-06, loss after: 3.04727950606e-06.\n",
      "Epoch:14, weight train batch: 295, step:19, loss before: 2.9392469969e-06, loss after: 2.9392469969e-06.\n",
      "Epoch:14, weight train batch: 295, step:20, loss before: 4.40327858087e-06, loss after: 4.40327858087e-06.\n",
      "Epoch:14, weight train batch: 295, step:21, loss before: 3.62469631909e-06, loss after: 3.62469631909e-06.\n",
      "Epoch:14, weight train batch: 295, step:22, loss before: 3.51293829226e-06, loss after: 3.51293829226e-06.\n",
      "Epoch:14, weight train batch: 295, step:23, loss before: 3.79978450837e-06, loss after: 3.79978450837e-06.\n",
      "Epoch:14, weight train batch: 295, step:24, loss before: 2.89826880362e-06, loss after: 2.86474119093e-06.\n",
      "Epoch:14, weight train batch: 295, step:25, loss before: 3.6172457385e-06, loss after: 3.6172457385e-06.\n",
      "Epoch:14, weight train batch: 295, step:26, loss before: 3.57254248229e-06, loss after: 3.57254248229e-06.\n",
      "Epoch:14, weight train batch: 295, step:27, loss before: 3.28942201122e-06, loss after: 3.28942201122e-06.\n",
      "Epoch:14, weight train batch: 295, step:28, loss before: 2.97277392747e-06, loss after: 2.97277392747e-06.\n",
      "Epoch:14, weight train batch: 295, step:29, loss before: 2.90199409392e-06, loss after: 2.90199409392e-06.\n",
      "Epoch:14, weight train batch: 295, step:30, loss before: 0.0216649062932, loss after: 0.0216648876667.\n",
      "Epoch:14, weight train batch: 295, step:31, loss before: 3.91154298995e-06, loss after: 3.91154298995e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 291, loss before: 3.50828236151e-06, loss after: 3.50828236151e-06.\n",
      "Epoch:14, weight train batch: 296, step:0, loss before: 4.27289387517e-06, loss after: 4.27289387517e-06.\n",
      "Epoch:14, weight train batch: 296, step:1, loss before: 2.73808154816e-06, loss after: 2.73808154816e-06.\n",
      "Epoch:14, weight train batch: 296, step:2, loss before: 3.95251981899e-06, loss after: 3.95251981899e-06.\n",
      "Epoch:14, weight train batch: 296, step:3, loss before: 3.59116893378e-06, loss after: 3.59116893378e-06.\n",
      "Epoch:14, weight train batch: 296, step:4, loss before: 3.59116847903e-06, loss after: 3.59116847903e-06.\n",
      "Epoch:14, weight train batch: 296, step:5, loss before: 0.000127278282889, loss after: 0.000126669750898.\n",
      "Epoch:14, weight train batch: 296, step:6, loss before: 3.60979538527e-06, loss after: 3.60979538527e-06.\n",
      "Epoch:14, weight train batch: 296, step:7, loss before: 0.000681631499901, loss after: 0.00067946978379.\n",
      "Epoch:14, weight train batch: 296, step:8, loss before: 6.78358856021e-06, loss after: 6.78731339576e-06.\n",
      "Epoch:14, weight train batch: 296, step:9, loss before: 4.17603678216e-06, loss after: 4.17603678216e-06.\n",
      "Epoch:14, weight train batch: 296, step:10, loss before: 0.0216644406319, loss after: 0.0216644406319.\n",
      "Epoch:14, weight train batch: 296, step:11, loss before: 3.79978382625e-06, loss after: 3.79978382625e-06.\n",
      "Epoch:14, weight train batch: 296, step:12, loss before: 8.51199638419e-06, loss after: 8.49709704198e-06.\n",
      "Epoch:14, weight train batch: 296, step:13, loss before: 3.17393823934e-06, loss after: 3.14786120725e-06.\n",
      "Epoch:14, weight train batch: 296, step:14, loss before: 3.95252027374e-06, loss after: 3.95252027374e-06.\n",
      "Epoch:14, weight train batch: 296, step:15, loss before: 2.60024671661e-06, loss after: 2.60024671661e-06.\n",
      "Epoch:14, weight train batch: 296, step:16, loss before: 3.36392736244e-06, loss after: 3.36392736244e-06.\n",
      "Epoch:14, weight train batch: 296, step:17, loss before: 3.29687281919e-06, loss after: 3.2745210774e-06.\n",
      "Epoch:14, weight train batch: 296, step:18, loss before: 3.73645411855e-06, loss after: 3.73645411855e-06.\n",
      "Epoch:14, weight train batch: 296, step:19, loss before: 3.55764109372e-06, loss after: 3.55764109372e-06.\n",
      "Epoch:14, weight train batch: 296, step:20, loss before: 2.81631218968e-06, loss after: 2.81631218968e-06.\n",
      "Epoch:14, weight train batch: 296, step:21, loss before: 3.04355421576e-06, loss after: 3.02120270135e-06.\n",
      "Epoch:14, weight train batch: 296, step:22, loss before: 2.80513677353e-06, loss after: 2.80513677353e-06.\n",
      "Epoch:14, weight train batch: 296, step:23, loss before: 3.03610386254e-06, loss after: 3.03610386254e-06.\n",
      "Epoch:14, weight train batch: 296, step:24, loss before: 3.97114672523e-06, loss after: 3.97114672523e-06.\n",
      "Epoch:14, weight train batch: 296, step:25, loss before: 4.00467433792e-06, loss after: 4.00467433792e-06.\n",
      "Epoch:14, weight train batch: 296, step:26, loss before: 3.36392736244e-06, loss after: 3.36392736244e-06.\n",
      "Epoch:14, weight train batch: 296, step:27, loss before: 6.73796457704e-05, loss after: 6.735361967e-05.\n",
      "Epoch:14, weight train batch: 296, step:28, loss before: 3.49058655047e-06, loss after: 3.49058655047e-06.\n",
      "Epoch:14, weight train batch: 296, step:29, loss before: 4.35484980699e-06, loss after: 4.35484980699e-06.\n",
      "Epoch:14, weight train batch: 296, step:30, loss before: 3.29687281919e-06, loss after: 3.29687281919e-06.\n",
      "Epoch:14, weight train batch: 296, step:31, loss before: 3.95252027374e-06, loss after: 3.95252027374e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 292, loss before: 1.7315700461e-05, loss after: 3.59582554665e-06.\n",
      "Epoch:14, weight train batch: 297, step:0, loss before: 3.1441363717e-06, loss after: 3.1441363717e-06.\n",
      "Epoch:14, weight train batch: 297, step:1, loss before: 4.54856399301e-06, loss after: 4.54856399301e-06.\n",
      "Epoch:14, weight train batch: 297, step:2, loss before: 2.84611451207e-06, loss after: 2.84611451207e-06.\n",
      "Epoch:14, weight train batch: 297, step:3, loss before: 2.94297160508e-06, loss after: 2.94297160508e-06.\n",
      "Epoch:14, weight train batch: 297, step:4, loss before: 3.59861951438e-06, loss after: 3.59861951438e-06.\n",
      "Epoch:14, weight train batch: 297, step:5, loss before: 3.05845514958e-06, loss after: 3.0323781175e-06.\n",
      "Epoch:14, weight train batch: 297, step:6, loss before: 3.3415760754e-06, loss after: 3.3415760754e-06.\n",
      "Epoch:14, weight train batch: 297, step:7, loss before: 3.18884008266e-06, loss after: 3.18884008266e-06.\n",
      "Epoch:14, weight train batch: 297, step:8, loss before: 8.5602987383e-06, loss after: 8.5565743575e-06.\n",
      "Epoch:14, weight train batch: 297, step:9, loss before: 4.55227018392e-06, loss after: 4.55227018392e-06.\n",
      "Epoch:14, weight train batch: 297, step:10, loss before: 4.50758670922e-06, loss after: 4.50758670922e-06.\n",
      "Epoch:14, weight train batch: 297, step:11, loss before: 3.44215709447e-06, loss after: 3.44215709447e-06.\n",
      "Epoch:14, weight train batch: 297, step:12, loss before: 3.09198230752e-06, loss after: 3.09198230752e-06.\n",
      "Epoch:14, weight train batch: 297, step:13, loss before: 3.01375212075e-06, loss after: 3.01375212075e-06.\n",
      "Epoch:14, weight train batch: 297, step:14, loss before: 3.90036620956e-06, loss after: 3.90036620956e-06.\n",
      "Epoch:14, weight train batch: 297, step:15, loss before: 3.933894277e-06, loss after: 3.933894277e-06.\n",
      "Epoch:14, weight train batch: 297, step:16, loss before: 2.93179596156e-06, loss after: 2.89826834887e-06.\n",
      "Epoch:14, weight train batch: 297, step:17, loss before: 2.80886160908e-06, loss after: 2.80886160908e-06.\n",
      "Epoch:14, weight train batch: 297, step:18, loss before: 2.92807067126e-06, loss after: 2.92807067126e-06.\n",
      "Epoch:14, weight train batch: 297, step:19, loss before: 4.60444107375e-06, loss after: 4.60444107375e-06.\n",
      "Epoch:14, weight train batch: 297, step:20, loss before: 4.17231149186e-06, loss after: 4.17231149186e-06.\n",
      "Epoch:14, weight train batch: 297, step:21, loss before: 3.4235313251e-06, loss after: 3.4235313251e-06.\n",
      "Epoch:14, weight train batch: 297, step:22, loss before: 3.00257624986e-06, loss after: 2.98022473544e-06.\n",
      "Epoch:14, weight train batch: 297, step:23, loss before: 2.96532357424e-06, loss after: 2.96532357424e-06.\n",
      "Epoch:14, weight train batch: 297, step:24, loss before: 4.34367484559e-06, loss after: 4.34367484559e-06.\n",
      "Epoch:14, weight train batch: 297, step:25, loss before: 2.90571915684e-06, loss after: 2.90571915684e-06.\n",
      "Epoch:14, weight train batch: 297, step:26, loss before: 4.14249370806e-06, loss after: 4.14249370806e-06.\n",
      "Epoch:14, weight train batch: 297, step:27, loss before: 3.46450974575e-06, loss after: 3.46450974575e-06.\n",
      "Epoch:14, weight train batch: 297, step:28, loss before: 3.04727950606e-06, loss after: 3.04727950606e-06.\n",
      "Epoch:14, weight train batch: 297, step:29, loss before: 4.28779458161e-06, loss after: 4.28779458161e-06.\n",
      "Epoch:14, weight train batch: 297, step:30, loss before: 3.67312509297e-06, loss after: 3.67312509297e-06.\n",
      "Epoch:14, weight train batch: 297, step:31, loss before: 2.47358730121e-06, loss after: 2.47358730121e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 293, loss before: 4.89681906402e-06, loss after: 3.91247476728e-06.\n",
      "Epoch:14, weight train batch: 298, step:0, loss before: 4.4554321903e-06, loss after: 4.4554321903e-06.\n",
      "Epoch:14, weight train batch: 298, step:1, loss before: 0.00138760125265, loss after: 0.00138496735599.\n",
      "Epoch:14, weight train batch: 298, step:2, loss before: 3.00257579511e-06, loss after: 3.00257579511e-06.\n",
      "Epoch:14, weight train batch: 298, step:3, loss before: 3.47941090695e-06, loss after: 3.47941090695e-06.\n",
      "Epoch:14, weight train batch: 298, step:4, loss before: 3.97114672523e-06, loss after: 3.95252027374e-06.\n",
      "Epoch:14, weight train batch: 298, step:5, loss before: 3.82586085834e-06, loss after: 3.82586085834e-06.\n",
      "Epoch:14, weight train batch: 298, step:6, loss before: 4.29524516221e-06, loss after: 4.29524516221e-06.\n",
      "Epoch:14, weight train batch: 298, step:7, loss before: 2.86101567326e-06, loss after: 2.86101567326e-06.\n",
      "Epoch:14, weight train batch: 298, step:8, loss before: 3.44960881193e-06, loss after: 3.44960881193e-06.\n",
      "Epoch:14, weight train batch: 298, step:9, loss before: 9.56580242928e-06, loss after: 9.55835275818e-06.\n",
      "Epoch:14, weight train batch: 298, step:10, loss before: 2.92434583571e-06, loss after: 2.92434583571e-06.\n",
      "Epoch:14, weight train batch: 298, step:11, loss before: 6.7127202783e-06, loss after: 6.7089958975e-06.\n",
      "Epoch:14, weight train batch: 298, step:12, loss before: 3.32667468683e-06, loss after: 3.32667468683e-06.\n",
      "Epoch:14, weight train batch: 298, step:13, loss before: 6.60468867864e-06, loss after: 6.59723900753e-06.\n",
      "Epoch:14, weight train batch: 298, step:14, loss before: 3.22236701322e-06, loss after: 3.22236701322e-06.\n",
      "Epoch:14, weight train batch: 298, step:15, loss before: 7.54345865062e-06, loss after: 7.49875562178e-06.\n",
      "Epoch:14, weight train batch: 298, step:16, loss before: 3.46450997313e-06, loss after: 3.46450997313e-06.\n",
      "Epoch:14, weight train batch: 298, step:17, loss before: 2.77905928669e-06, loss after: 2.77905928669e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14, weight train batch: 298, step:18, loss before: 2.14576380131e-06, loss after: 2.14576380131e-06.\n",
      "Epoch:14, weight train batch: 298, step:19, loss before: 3.88919124816e-06, loss after: 3.88919124816e-06.\n",
      "Epoch:14, weight train batch: 298, step:20, loss before: 4.04565207646e-06, loss after: 4.04565207646e-06.\n",
      "Epoch:14, weight train batch: 298, step:21, loss before: 4.02330078941e-06, loss after: 4.02330078941e-06.\n",
      "Epoch:14, weight train batch: 298, step:22, loss before: 2.59652119894e-06, loss after: 2.59652119894e-06.\n",
      "Epoch:14, weight train batch: 298, step:23, loss before: 3.08080689138e-06, loss after: 3.08080689138e-06.\n",
      "Epoch:14, weight train batch: 298, step:24, loss before: 0.0216641873121, loss after: 0.0216641873121.\n",
      "Epoch:14, weight train batch: 298, step:25, loss before: 3.0249275369e-06, loss after: 3.0249275369e-06.\n",
      "Epoch:14, weight train batch: 298, step:26, loss before: 2.60769706983e-06, loss after: 2.60769706983e-06.\n",
      "Epoch:14, weight train batch: 298, step:27, loss before: 3.30059788212e-06, loss after: 3.30059788212e-06.\n",
      "Epoch:14, weight train batch: 298, step:28, loss before: 3.69920212506e-06, loss after: 3.69920212506e-06.\n",
      "Epoch:14, weight train batch: 298, step:29, loss before: 2.86474096356e-06, loss after: 2.86474096356e-06.\n",
      "Epoch:14, weight train batch: 298, step:30, loss before: 4.07172956329e-06, loss after: 4.07172956329e-06.\n",
      "Epoch:14, weight train batch: 298, step:31, loss before: 3.62842160939e-06, loss after: 3.62842160939e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 294, loss before: 3.7886093196e-06, loss after: 3.7886093196e-06.\n",
      "Epoch:14, weight train batch: 299, step:0, loss before: 3.35275126417e-06, loss after: 3.35275126417e-06.\n",
      "Epoch:14, weight train batch: 299, step:1, loss before: 2.89454328595e-06, loss after: 2.89454328595e-06.\n",
      "Epoch:14, weight train batch: 299, step:2, loss before: 2.59652097157e-06, loss after: 2.59652097157e-06.\n",
      "Epoch:14, weight train batch: 299, step:3, loss before: 3.66194944945e-06, loss after: 3.66194944945e-06.\n",
      "Epoch:14, weight train batch: 299, step:4, loss before: 3.06217998514e-06, loss after: 3.06217998514e-06.\n",
      "Epoch:14, weight train batch: 299, step:5, loss before: 2.94669712275e-06, loss after: 2.92434560833e-06.\n",
      "Epoch:14, weight train batch: 299, step:6, loss before: 3.22981759382e-06, loss after: 3.22981759382e-06.\n",
      "Epoch:14, weight train batch: 299, step:7, loss before: 2.83866393147e-06, loss after: 2.83866393147e-06.\n",
      "Epoch:14, weight train batch: 299, step:8, loss before: 3.07708160108e-06, loss after: 3.07708160108e-06.\n",
      "Epoch:14, weight train batch: 299, step:9, loss before: 3.15158672493e-06, loss after: 3.15158672493e-06.\n",
      "Epoch:14, weight train batch: 299, step:10, loss before: 3.22609230352e-06, loss after: 3.22609230352e-06.\n",
      "Epoch:14, weight train batch: 299, step:11, loss before: 2.70455393547e-06, loss after: 2.70455393547e-06.\n",
      "Epoch:14, weight train batch: 299, step:12, loss before: 3.45705939253e-06, loss after: 3.45705939253e-06.\n",
      "Epoch:14, weight train batch: 299, step:13, loss before: 3.69175108972e-06, loss after: 3.69175108972e-06.\n",
      "Epoch:14, weight train batch: 299, step:14, loss before: 2.99140015159e-06, loss after: 2.99140015159e-06.\n",
      "Epoch:14, weight train batch: 299, step:15, loss before: 2.92061940854e-06, loss after: 2.92061940854e-06.\n",
      "Epoch:14, weight train batch: 299, step:16, loss before: 3.15531201522e-06, loss after: 3.15531201522e-06.\n",
      "Epoch:14, weight train batch: 299, step:17, loss before: 3.33039997713e-06, loss after: 3.33039997713e-06.\n",
      "Epoch:14, weight train batch: 299, step:18, loss before: 2.86101567326e-06, loss after: 2.86101567326e-06.\n",
      "Epoch:14, weight train batch: 299, step:19, loss before: 3.40118026543e-06, loss after: 3.40118026543e-06.\n",
      "Epoch:14, weight train batch: 299, step:20, loss before: 3.49058700522e-06, loss after: 3.49058700522e-06.\n",
      "Epoch:14, weight train batch: 299, step:21, loss before: 3.43470765074e-06, loss after: 3.43470765074e-06.\n",
      "Epoch:14, weight train batch: 299, step:22, loss before: 2.72318084171e-06, loss after: 2.72318084171e-06.\n",
      "Epoch:14, weight train batch: 299, step:23, loss before: 5.93787171965e-06, loss after: 5.93787171965e-06.\n",
      "Epoch:14, weight train batch: 299, step:24, loss before: 3.19256491821e-06, loss after: 3.19256491821e-06.\n",
      "Epoch:14, weight train batch: 299, step:25, loss before: 3.03982869809e-06, loss after: 3.03982869809e-06.\n",
      "Epoch:14, weight train batch: 299, step:26, loss before: 2.8945428312e-06, loss after: 2.8945428312e-06.\n",
      "Epoch:14, weight train batch: 299, step:27, loss before: 2.57416945715e-06, loss after: 2.57416945715e-06.\n",
      "Epoch:14, weight train batch: 299, step:28, loss before: 2.24261975745e-06, loss after: 2.24261975745e-06.\n",
      "Epoch:14, weight train batch: 299, step:29, loss before: 3.98977317673e-06, loss after: 3.94507014789e-06.\n",
      "Epoch:14, weight train batch: 299, step:30, loss before: 3.78488357455e-06, loss after: 3.78488357455e-06.\n",
      "Epoch:14, weight train batch: 299, step:31, loss before: 0.0216638557613, loss after: 0.0216638557613.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:14, struct parameters train batch: 295, loss before: 3.24751340486e-06, loss after: 3.25123869516e-06.\n",
      "Epoch:15, weight train batch: 300, step:0, loss before: 3.40490555573e-06, loss after: 3.40490555573e-06.\n",
      "Epoch:15, weight train batch: 300, step:1, loss before: 2.44751004175e-06, loss after: 2.44751004175e-06.\n",
      "Epoch:15, weight train batch: 300, step:2, loss before: 3.69547456103e-06, loss after: 3.69547456103e-06.\n",
      "Epoch:15, weight train batch: 300, step:3, loss before: 3.63586536878e-06, loss after: 3.5948871755e-06.\n",
      "Epoch:15, weight train batch: 300, step:4, loss before: 2.65985067927e-06, loss after: 2.65985067927e-06.\n",
      "Epoch:15, weight train batch: 300, step:5, loss before: 3.26707004206e-06, loss after: 3.26707004206e-06.\n",
      "Epoch:15, weight train batch: 300, step:6, loss before: 3.24844450006e-06, loss after: 3.24844450006e-06.\n",
      "Epoch:15, weight train batch: 300, step:7, loss before: 2.94669689538e-06, loss after: 2.94669689538e-06.\n",
      "Epoch:15, weight train batch: 300, step:8, loss before: 2.71945509667e-06, loss after: 2.71945509667e-06.\n",
      "Epoch:15, weight train batch: 300, step:9, loss before: 3.32667468683e-06, loss after: 3.32667468683e-06.\n",
      "Epoch:15, weight train batch: 300, step:10, loss before: 3.26707004206e-06, loss after: 3.26707004206e-06.\n",
      "Epoch:15, weight train batch: 300, step:11, loss before: 3.93389473174e-06, loss after: 3.93389473174e-06.\n",
      "Epoch:15, weight train batch: 300, step:12, loss before: 3.40118026543e-06, loss after: 3.40118026543e-06.\n",
      "Epoch:15, weight train batch: 300, step:13, loss before: 6.15402313997e-06, loss after: 6.15029784967e-06.\n",
      "Epoch:15, weight train batch: 300, step:14, loss before: 3.09943288812e-06, loss after: 3.09943288812e-06.\n",
      "Epoch:15, weight train batch: 300, step:15, loss before: 3.50921300196e-06, loss after: 3.50921300196e-06.\n",
      "Epoch:15, weight train batch: 300, step:16, loss before: 3.59861974175e-06, loss after: 3.59861974175e-06.\n",
      "Epoch:15, weight train batch: 300, step:17, loss before: 3.18883962791e-06, loss after: 3.18883962791e-06.\n",
      "Epoch:15, weight train batch: 300, step:18, loss before: 3.94879498344e-06, loss after: 3.94879498344e-06.\n",
      "Epoch:15, weight train batch: 300, step:19, loss before: 2.97649899039e-06, loss after: 2.97649899039e-06.\n",
      "Epoch:15, weight train batch: 300, step:20, loss before: 2.70455393547e-06, loss after: 2.68220242106e-06.\n",
      "Epoch:15, weight train batch: 300, step:21, loss before: 3.20373965224e-06, loss after: 3.20373965224e-06.\n",
      "Epoch:15, weight train batch: 300, step:22, loss before: 2.53319171861e-06, loss after: 2.53319171861e-06.\n",
      "Epoch:15, weight train batch: 300, step:23, loss before: 4.06800427299e-06, loss after: 4.06800427299e-06.\n",
      "Epoch:15, weight train batch: 300, step:24, loss before: 4.41444035459e-06, loss after: 4.41071551904e-06.\n",
      "Epoch:15, weight train batch: 300, step:25, loss before: 3.12923543788e-06, loss after: 3.12923543788e-06.\n",
      "Epoch:15, weight train batch: 300, step:26, loss before: 3.51666403731e-06, loss after: 3.51666403731e-06.\n",
      "Epoch:15, weight train batch: 300, step:27, loss before: 3.3974552025e-06, loss after: 3.3974552025e-06.\n",
      "Epoch:15, weight train batch: 300, step:28, loss before: 4.00839962822e-06, loss after: 4.00839962822e-06.\n",
      "Epoch:15, weight train batch: 300, step:29, loss before: 3.0100263757e-06, loss after: 3.0100263757e-06.\n",
      "Epoch:15, weight train batch: 300, step:30, loss before: 3.57999351763e-06, loss after: 3.57999351763e-06.\n",
      "Epoch:15, weight train batch: 300, step:31, loss before: 2.71200474344e-06, loss after: 2.71200474344e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 296, loss before: 9.42708356888e-06, loss after: 3.12737302011e-06.\n",
      "Epoch:15, weight train batch: 301, step:0, loss before: 4.18348554376e-06, loss after: 4.18348554376e-06.\n",
      "Epoch:15, weight train batch: 301, step:1, loss before: 3.48686126017e-06, loss after: 3.48686126017e-06.\n",
      "Epoch:15, weight train batch: 301, step:2, loss before: 3.87429008697e-06, loss after: 3.87429008697e-06.\n",
      "Epoch:15, weight train batch: 301, step:3, loss before: 3.84448776458e-06, loss after: 3.84448776458e-06.\n",
      "Epoch:15, weight train batch: 301, step:4, loss before: 2.59279613601e-06, loss after: 2.59279613601e-06.\n",
      "Epoch:15, weight train batch: 301, step:5, loss before: 3.21864172292e-06, loss after: 3.21864172292e-06.\n",
      "Epoch:15, weight train batch: 301, step:6, loss before: 3.12923521051e-06, loss after: 3.12923521051e-06.\n",
      "Epoch:15, weight train batch: 301, step:7, loss before: 2.66730125986e-06, loss after: 2.66730125986e-06.\n",
      "Epoch:15, weight train batch: 301, step:8, loss before: 2.81631264443e-06, loss after: 2.79396090264e-06.\n",
      "Epoch:15, weight train batch: 301, step:9, loss before: 3.41980648955e-06, loss after: 3.41980648955e-06.\n",
      "Epoch:15, weight train batch: 301, step:10, loss before: 3.76623961529e-06, loss after: 3.76623961529e-06.\n",
      "Epoch:15, weight train batch: 301, step:11, loss before: 0.0216640457511, loss after: 0.0216640457511.\n",
      "Epoch:15, weight train batch: 301, step:12, loss before: 3.2745210774e-06, loss after: 3.2745210774e-06.\n",
      "Epoch:15, weight train batch: 301, step:13, loss before: 2.54436758951e-06, loss after: 2.54436758951e-06.\n",
      "Epoch:15, weight train batch: 301, step:14, loss before: 3.15531201522e-06, loss after: 3.15531201522e-06.\n",
      "Epoch:15, weight train batch: 301, step:15, loss before: 2.36555388256e-06, loss after: 2.36555388256e-06.\n",
      "Epoch:15, weight train batch: 301, step:16, loss before: 3.0249275369e-06, loss after: 3.0249275369e-06.\n",
      "Epoch:15, weight train batch: 301, step:17, loss before: 2.95414793072e-06, loss after: 2.95414793072e-06.\n",
      "Epoch:15, weight train batch: 301, step:18, loss before: 3.39000416716e-06, loss after: 3.39000416716e-06.\n",
      "Epoch:15, weight train batch: 301, step:19, loss before: 3.01375234812e-06, loss after: 3.01375234812e-06.\n",
      "Epoch:15, weight train batch: 301, step:20, loss before: 2.92434560833e-06, loss after: 2.92434560833e-06.\n",
      "Epoch:15, weight train batch: 301, step:21, loss before: 2.95042218568e-06, loss after: 2.95042218568e-06.\n",
      "Epoch:15, weight train batch: 301, step:22, loss before: 2.71945555141e-06, loss after: 2.71945555141e-06.\n",
      "Epoch:15, weight train batch: 301, step:23, loss before: 2.80513631878e-06, loss after: 2.80513631878e-06.\n",
      "Epoch:15, weight train batch: 301, step:24, loss before: 3.44960881193e-06, loss after: 3.44960881193e-06.\n",
      "Epoch:15, weight train batch: 301, step:25, loss before: 3.44960881193e-06, loss after: 3.44960881193e-06.\n",
      "Epoch:15, weight train batch: 301, step:26, loss before: 2.64494951807e-06, loss after: 2.64494951807e-06.\n",
      "Epoch:15, weight train batch: 301, step:27, loss before: 3.12923566526e-06, loss after: 3.12923566526e-06.\n",
      "Epoch:15, weight train batch: 301, step:28, loss before: 3.12923543788e-06, loss after: 3.12923543788e-06.\n",
      "Epoch:15, weight train batch: 301, step:29, loss before: 3.30432339979e-06, loss after: 3.30432339979e-06.\n",
      "Epoch:15, weight train batch: 301, step:30, loss before: 3.17021294904e-06, loss after: 3.17021294904e-06.\n",
      "Epoch:15, weight train batch: 301, step:31, loss before: 6.40362031845e-06, loss after: 6.40362031845e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 297, loss before: 2.58068939729e-06, loss after: 0.00541773065925.\n",
      "Epoch:15, weight train batch: 302, step:0, loss before: 3.46450997313e-06, loss after: 3.42725752489e-06.\n",
      "Epoch:15, weight train batch: 302, step:1, loss before: 3.36765288012e-06, loss after: 3.36765288012e-06.\n",
      "Epoch:15, weight train batch: 302, step:2, loss before: 3.34530159307e-06, loss after: 3.34530159307e-06.\n",
      "Epoch:15, weight train batch: 302, step:3, loss before: 3.89664182876e-06, loss after: 3.89664182876e-06.\n",
      "Epoch:15, weight train batch: 302, step:4, loss before: 2.20536730922e-06, loss after: 2.20536730922e-06.\n",
      "Epoch:15, weight train batch: 302, step:5, loss before: 0.0216637142003, loss after: 0.0216637142003.\n",
      "Epoch:15, weight train batch: 302, step:6, loss before: 0.000110369110189, loss after: 0.000109856766358.\n",
      "Epoch:15, weight train batch: 302, step:7, loss before: 0.00133565673605, loss after: 0.00133309711237.\n",
      "Epoch:15, weight train batch: 302, step:8, loss before: 3.9040851334e-06, loss after: 3.9040851334e-06.\n",
      "Epoch:15, weight train batch: 302, step:9, loss before: 3.24099346471e-06, loss after: 3.20374056173e-06.\n",
      "Epoch:15, weight train batch: 302, step:10, loss before: 3.2223672406e-06, loss after: 3.2223672406e-06.\n",
      "Epoch:15, weight train batch: 302, step:11, loss before: 2.71200497082e-06, loss after: 2.71200497082e-06.\n",
      "Epoch:15, weight train batch: 302, step:12, loss before: 2.45123555942e-06, loss after: 2.45123555942e-06.\n",
      "Epoch:15, weight train batch: 302, step:13, loss before: 2.83121357825e-06, loss after: 2.83121357825e-06.\n",
      "Epoch:15, weight train batch: 302, step:14, loss before: 3.16648788612e-06, loss after: 3.16648788612e-06.\n",
      "Epoch:15, weight train batch: 302, step:15, loss before: 3.22981782119e-06, loss after: 3.22981782119e-06.\n",
      "Epoch:15, weight train batch: 302, step:16, loss before: 2.98767486129e-06, loss after: 2.98767486129e-06.\n",
      "Epoch:15, weight train batch: 302, step:17, loss before: 2.48103788181e-06, loss after: 2.48103788181e-06.\n",
      "Epoch:15, weight train batch: 302, step:18, loss before: 2.26124666369e-06, loss after: 2.26124666369e-06.\n",
      "Epoch:15, weight train batch: 302, step:19, loss before: 4.33620971307e-06, loss after: 4.33620971307e-06.\n",
      "Epoch:15, weight train batch: 302, step:20, loss before: 3.85938892578e-06, loss after: 3.85938892578e-06.\n",
      "Epoch:15, weight train batch: 302, step:21, loss before: 0.000101567879028, loss after: 0.000100936587842.\n",
      "Epoch:15, weight train batch: 302, step:22, loss before: 3.01375189338e-06, loss after: 3.01375189338e-06.\n",
      "Epoch:15, weight train batch: 302, step:23, loss before: 3.97487247028e-06, loss after: 3.97487247028e-06.\n",
      "Epoch:15, weight train batch: 302, step:24, loss before: 2.4996643333e-06, loss after: 2.45868614002e-06.\n",
      "Epoch:15, weight train batch: 302, step:25, loss before: 2.73435625786e-06, loss after: 2.73435625786e-06.\n",
      "Epoch:15, weight train batch: 302, step:26, loss before: 3.06963124785e-06, loss after: 3.06963124785e-06.\n",
      "Epoch:15, weight train batch: 302, step:27, loss before: 3.79604398404e-06, loss after: 3.79604398404e-06.\n",
      "Epoch:15, weight train batch: 302, step:28, loss before: 3.74763089894e-06, loss after: 3.74763089894e-06.\n",
      "Epoch:15, weight train batch: 302, step:29, loss before: 8.00518864708e-06, loss after: 7.99029112386e-06.\n",
      "Epoch:15, weight train batch: 302, step:30, loss before: 2.9578725389e-06, loss after: 2.9578725389e-06.\n",
      "Epoch:15, weight train batch: 302, step:31, loss before: 3.68802625417e-06, loss after: 3.68802625417e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 298, loss before: 4.2960718929e-06, loss after: 0.00541814509779.\n",
      "Epoch:15, weight train batch: 303, step:0, loss before: 3.18883962791e-06, loss after: 3.18883962791e-06.\n",
      "Epoch:15, weight train batch: 303, step:1, loss before: 2.77905974144e-06, loss after: 2.77905974144e-06.\n",
      "Epoch:15, weight train batch: 303, step:2, loss before: 2.54809219769e-06, loss after: 2.54809219769e-06.\n",
      "Epoch:15, weight train batch: 303, step:3, loss before: 2.76415858025e-06, loss after: 2.76415858025e-06.\n",
      "Epoch:15, weight train batch: 303, step:4, loss before: 9.37328586588e-05, loss after: 9.31311151362e-05.\n",
      "Epoch:15, weight train batch: 303, step:5, loss before: 2.22026847041e-06, loss after: 2.22026847041e-06.\n",
      "Epoch:15, weight train batch: 303, step:6, loss before: 2.78650986729e-06, loss after: 2.78650986729e-06.\n",
      "Epoch:15, weight train batch: 303, step:7, loss before: 3.05472940454e-06, loss after: 3.04355353364e-06.\n",
      "Epoch:15, weight train batch: 303, step:8, loss before: 4.24681729783e-06, loss after: 4.24681729783e-06.\n",
      "Epoch:15, weight train batch: 303, step:9, loss before: 3.00630108541e-06, loss after: 3.00630108541e-06.\n",
      "Epoch:15, weight train batch: 303, step:10, loss before: 2.77905974144e-06, loss after: 2.77905974144e-06.\n",
      "Epoch:15, weight train batch: 303, step:11, loss before: 2.76788364317e-06, loss after: 2.69337806458e-06.\n",
      "Epoch:15, weight train batch: 303, step:12, loss before: 6.60904770484e-05, loss after: 6.6053304181e-05.\n",
      "Epoch:15, weight train batch: 303, step:13, loss before: 3.44215823134e-06, loss after: 3.44215823134e-06.\n",
      "Epoch:15, weight train batch: 303, step:14, loss before: 2.90944399239e-06, loss after: 2.90944399239e-06.\n",
      "Epoch:15, weight train batch: 303, step:15, loss before: 6.64196431899e-06, loss after: 6.64196431899e-06.\n",
      "Epoch:15, weight train batch: 303, step:16, loss before: 3.25589439854e-06, loss after: 3.25589439854e-06.\n",
      "Epoch:15, weight train batch: 303, step:17, loss before: 3.04355376102e-06, loss after: 3.04355376102e-06.\n",
      "Epoch:15, weight train batch: 303, step:18, loss before: 2.71200451607e-06, loss after: 2.71200451607e-06.\n",
      "Epoch:15, weight train batch: 303, step:19, loss before: 3.61724596587e-06, loss after: 3.61724596587e-06.\n",
      "Epoch:15, weight train batch: 303, step:20, loss before: 2.46986155616e-06, loss after: 2.46986155616e-06.\n",
      "Epoch:15, weight train batch: 303, step:21, loss before: 2.70082864517e-06, loss after: 2.70082864517e-06.\n",
      "Epoch:15, weight train batch: 303, step:22, loss before: 2.56671910392e-06, loss after: 2.56671910392e-06.\n",
      "Epoch:15, weight train batch: 303, step:23, loss before: 2.75298270935e-06, loss after: 2.75298270935e-06.\n",
      "Epoch:15, weight train batch: 303, step:24, loss before: 2.76043328995e-06, loss after: 2.73435671261e-06.\n",
      "Epoch:15, weight train batch: 303, step:25, loss before: 3.04727927869e-06, loss after: 3.04727927869e-06.\n",
      "Epoch:15, weight train batch: 303, step:26, loss before: 2.3804554985e-06, loss after: 2.3804554985e-06.\n",
      "Epoch:15, weight train batch: 303, step:27, loss before: 0.00128695892636, loss after: 0.00128446321469.\n",
      "Epoch:15, weight train batch: 303, step:28, loss before: 2.68220264843e-06, loss after: 2.68220264843e-06.\n",
      "Epoch:15, weight train batch: 303, step:29, loss before: 3.56509235644e-06, loss after: 3.56509235644e-06.\n",
      "Epoch:15, weight train batch: 303, step:30, loss before: 3.06218043988e-06, loss after: 3.0957078252e-06.\n",
      "Epoch:15, weight train batch: 303, step:31, loss before: 2.68592748398e-06, loss after: 2.68592748398e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 299, loss before: 3.15717488775e-06, loss after: 4.17224873672e-06.\n",
      "Epoch:15, weight train batch: 304, step:0, loss before: 3.24844381794e-06, loss after: 3.24844381794e-06.\n",
      "Epoch:15, weight train batch: 304, step:1, loss before: 3.45333410223e-06, loss after: 3.45333410223e-06.\n",
      "Epoch:15, weight train batch: 304, step:2, loss before: 2.35810375671e-06, loss after: 2.35810375671e-06.\n",
      "Epoch:15, weight train batch: 304, step:3, loss before: 2.69337806458e-06, loss after: 2.69337806458e-06.\n",
      "Epoch:15, weight train batch: 304, step:4, loss before: 2.55181794273e-06, loss after: 2.55181794273e-06.\n",
      "Epoch:15, weight train batch: 304, step:5, loss before: 2.66357574219e-06, loss after: 2.66357574219e-06.\n",
      "Epoch:15, weight train batch: 304, step:6, loss before: 2.73063096756e-06, loss after: 2.73063096756e-06.\n",
      "Epoch:15, weight train batch: 304, step:7, loss before: 3.08825747197e-06, loss after: 3.08825747197e-06.\n",
      "Epoch:15, weight train batch: 304, step:8, loss before: 2.53319149124e-06, loss after: 2.53319149124e-06.\n",
      "Epoch:15, weight train batch: 304, step:9, loss before: 0.00125018658582, loss after: 0.00124662846792.\n",
      "Epoch:15, weight train batch: 304, step:10, loss before: 3.47941113432e-06, loss after: 3.47941113432e-06.\n",
      "Epoch:15, weight train batch: 304, step:11, loss before: 2.8908175409e-06, loss after: 2.8908175409e-06.\n",
      "Epoch:15, weight train batch: 304, step:12, loss before: 2.70082887255e-06, loss after: 2.70082887255e-06.\n",
      "Epoch:15, weight train batch: 304, step:13, loss before: 3.05128050968e-05, loss after: 3.03899796563e-05.\n",
      "Epoch:15, weight train batch: 304, step:14, loss before: 2.6337734198e-06, loss after: 2.6337734198e-06.\n",
      "Epoch:15, weight train batch: 304, step:15, loss before: 2.93552102448e-06, loss after: 2.93552102448e-06.\n",
      "Epoch:15, weight train batch: 304, step:16, loss before: 2.14203760152e-06, loss after: 2.14203760152e-06.\n",
      "Epoch:15, weight train batch: 304, step:17, loss before: 2.35065317611e-06, loss after: 2.35065317611e-06.\n",
      "Epoch:15, weight train batch: 304, step:18, loss before: 0.000621312647127, loss after: 0.000619051861577.\n",
      "Epoch:15, weight train batch: 304, step:19, loss before: 3.43470742337e-06, loss after: 3.40863061865e-06.\n",
      "Epoch:15, weight train batch: 304, step:20, loss before: 3.22236701322e-06, loss after: 3.22236701322e-06.\n",
      "Epoch:15, weight train batch: 304, step:21, loss before: 2.43260888055e-06, loss after: 2.43260888055e-06.\n",
      "Epoch:15, weight train batch: 304, step:22, loss before: 2.5667184218e-06, loss after: 2.5667184218e-06.\n",
      "Epoch:15, weight train batch: 304, step:23, loss before: 2.67102632279e-06, loss after: 2.67102632279e-06.\n",
      "Epoch:15, weight train batch: 304, step:24, loss before: 3.42353200722e-06, loss after: 3.42353200722e-06.\n",
      "Epoch:15, weight train batch: 304, step:25, loss before: 3.26334497913e-06, loss after: 3.23354288412e-06.\n",
      "Epoch:15, weight train batch: 304, step:26, loss before: 2.62632283921e-06, loss after: 2.62632283921e-06.\n",
      "Epoch:15, weight train batch: 304, step:27, loss before: 3.00630108541e-06, loss after: 3.00630108541e-06.\n",
      "Epoch:15, weight train batch: 304, step:28, loss before: 8.55677499203e-05, loss after: 8.52705197758e-05.\n",
      "Epoch:15, weight train batch: 304, step:29, loss before: 2.98394934362e-06, loss after: 2.98394934362e-06.\n",
      "Epoch:15, weight train batch: 304, step:30, loss before: 4.89488229505e-06, loss after: 4.89488229505e-06.\n",
      "Epoch:15, weight train batch: 304, step:31, loss before: 2.27614737014e-06, loss after: 2.27614737014e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 300, loss before: 2.76136438515e-06, loss after: 2.76136438515e-06.\n",
      "Epoch:15, weight train batch: 305, step:0, loss before: 2.61887248598e-06, loss after: 2.61887248598e-06.\n",
      "Epoch:15, weight train batch: 305, step:1, loss before: 3.03610318042e-06, loss after: 3.03610318042e-06.\n",
      "Epoch:15, weight train batch: 305, step:2, loss before: 2.58907016359e-06, loss after: 2.58907016359e-06.\n",
      "Epoch:15, weight train batch: 305, step:3, loss before: 2.04145476346e-06, loss after: 2.04145476346e-06.\n",
      "Epoch:15, weight train batch: 305, step:4, loss before: 2.43633417085e-06, loss after: 2.43633417085e-06.\n",
      "Epoch:15, weight train batch: 305, step:5, loss before: 2.65612538897e-06, loss after: 2.65612538897e-06.\n",
      "Epoch:15, weight train batch: 305, step:6, loss before: 2.45868591264e-06, loss after: 2.41770771936e-06.\n",
      "Epoch:15, weight train batch: 305, step:7, loss before: 3.17393823934e-06, loss after: 3.17393823934e-06.\n",
      "Epoch:15, weight train batch: 305, step:8, loss before: 3.03237789012e-06, loss after: 3.03237789012e-06.\n",
      "Epoch:15, weight train batch: 305, step:9, loss before: 2.02655382964e-06, loss after: 2.02655382964e-06.\n",
      "Epoch:15, weight train batch: 305, step:10, loss before: 2.8237625429e-06, loss after: 2.8237625429e-06.\n",
      "Epoch:15, weight train batch: 305, step:11, loss before: 2.77905928669e-06, loss after: 2.77905928669e-06.\n",
      "Epoch:15, weight train batch: 305, step:12, loss before: 3.88919033867e-06, loss after: 3.88919033867e-06.\n",
      "Epoch:15, weight train batch: 305, step:13, loss before: 0.000582839711569, loss after: 0.000580517516937.\n",
      "Epoch:15, weight train batch: 305, step:14, loss before: 2.95787231153e-06, loss after: 2.95787231153e-06.\n",
      "Epoch:15, weight train batch: 305, step:15, loss before: 3.90781724491e-06, loss after: 3.90781724491e-06.\n",
      "Epoch:15, weight train batch: 305, step:16, loss before: 2.83866347672e-06, loss after: 2.83866347672e-06.\n",
      "Epoch:15, weight train batch: 305, step:17, loss before: 2.79023515759e-06, loss after: 2.79023515759e-06.\n",
      "Epoch:15, weight train batch: 305, step:18, loss before: 2.35810330196e-06, loss after: 2.35810330196e-06.\n",
      "Epoch:15, weight train batch: 305, step:19, loss before: 3.03610340779e-06, loss after: 3.03610340779e-06.\n",
      "Epoch:15, weight train batch: 305, step:20, loss before: 2.78278457699e-06, loss after: 2.78278457699e-06.\n",
      "Epoch:15, weight train batch: 305, step:21, loss before: 2.3916304599e-06, loss after: 2.3916304599e-06.\n",
      "Epoch:15, weight train batch: 305, step:22, loss before: 3.19256491821e-06, loss after: 3.19256491821e-06.\n",
      "Epoch:15, weight train batch: 305, step:23, loss before: 2.80886138171e-06, loss after: 2.80886138171e-06.\n",
      "Epoch:15, weight train batch: 305, step:24, loss before: 3.25216910824e-06, loss after: 3.25216910824e-06.\n",
      "Epoch:15, weight train batch: 305, step:25, loss before: 6.62920574541e-05, loss after: 6.62734673824e-05.\n",
      "Epoch:15, weight train batch: 305, step:26, loss before: 2.54064161709e-06, loss after: 2.54064161709e-06.\n",
      "Epoch:15, weight train batch: 305, step:27, loss before: 2.24634504775e-06, loss after: 2.24634504775e-06.\n",
      "Epoch:15, weight train batch: 305, step:28, loss before: 3.01036070596e-05, loss after: 3.00366100419e-05.\n",
      "Epoch:15, weight train batch: 305, step:29, loss before: 2.81631218968e-06, loss after: 2.81631218968e-06.\n",
      "Epoch:15, weight train batch: 305, step:30, loss before: 2.62632329395e-06, loss after: 2.60024626186e-06.\n",
      "Epoch:15, weight train batch: 305, step:31, loss before: 3.3453013657e-06, loss after: 3.31922433361e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 301, loss before: 2.93552102448e-06, loss after: 2.93552102448e-06.\n",
      "Epoch:15, weight train batch: 306, step:0, loss before: 4.01957004215e-06, loss after: 4.01957004215e-06.\n",
      "Epoch:15, weight train batch: 306, step:1, loss before: 3.33412526743e-06, loss after: 3.33412526743e-06.\n",
      "Epoch:15, weight train batch: 306, step:2, loss before: 2.21281743507e-06, loss after: 2.21281743507e-06.\n",
      "Epoch:15, weight train batch: 306, step:3, loss before: 3.50176264874e-06, loss after: 3.50176264874e-06.\n",
      "Epoch:15, weight train batch: 306, step:4, loss before: 2.47358661909e-06, loss after: 2.47358661909e-06.\n",
      "Epoch:15, weight train batch: 306, step:5, loss before: 3.09198230752e-06, loss after: 3.09198230752e-06.\n",
      "Epoch:15, weight train batch: 306, step:6, loss before: 2.53319103649e-06, loss after: 2.53319103649e-06.\n",
      "Epoch:15, weight train batch: 306, step:7, loss before: 2.35065272136e-06, loss after: 2.35065272136e-06.\n",
      "Epoch:15, weight train batch: 306, step:8, loss before: 2.16438911593e-06, loss after: 2.16438911593e-06.\n",
      "Epoch:15, weight train batch: 306, step:9, loss before: 3.29314707415e-06, loss after: 3.29314707415e-06.\n",
      "Epoch:15, weight train batch: 306, step:10, loss before: 2.55554277828e-06, loss after: 2.55554277828e-06.\n",
      "Epoch:15, weight train batch: 306, step:11, loss before: 1.97067447516e-06, loss after: 1.97067447516e-06.\n",
      "Epoch:15, weight train batch: 306, step:12, loss before: 5.62502964385e-06, loss after: 5.62502964385e-06.\n",
      "Epoch:15, weight train batch: 306, step:13, loss before: 3.10315795105e-06, loss after: 3.06217998514e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:15, weight train batch: 306, step:14, loss before: 1.92597144633e-06, loss after: 1.92597144633e-06.\n",
      "Epoch:15, weight train batch: 306, step:15, loss before: 2.08615801967e-06, loss after: 2.08615801967e-06.\n",
      "Epoch:15, weight train batch: 306, step:16, loss before: 1.76950970854e-06, loss after: 1.76950970854e-06.\n",
      "Epoch:15, weight train batch: 306, step:17, loss before: 2.97277165373e-06, loss after: 2.94669484902e-06.\n",
      "Epoch:15, weight train batch: 306, step:18, loss before: 2.25752069127e-06, loss after: 2.25752069127e-06.\n",
      "Epoch:15, weight train batch: 306, step:19, loss before: 2.72318038697e-06, loss after: 2.72318038697e-06.\n",
      "Epoch:15, weight train batch: 306, step:20, loss before: 1.96322412194e-06, loss after: 1.96322412194e-06.\n",
      "Epoch:15, weight train batch: 306, step:21, loss before: 2.65239987129e-06, loss after: 2.65239987129e-06.\n",
      "Epoch:15, weight train batch: 306, step:22, loss before: 1.91479557543e-06, loss after: 1.91479557543e-06.\n",
      "Epoch:15, weight train batch: 306, step:23, loss before: 6.67913172947e-06, loss after: 6.67540643917e-06.\n",
      "Epoch:15, weight train batch: 306, step:24, loss before: 2.65985045189e-06, loss after: 2.65985045189e-06.\n",
      "Epoch:15, weight train batch: 306, step:25, loss before: 2.29477359426e-06, loss after: 2.29477359426e-06.\n",
      "Epoch:15, weight train batch: 306, step:26, loss before: 3.25589439854e-06, loss after: 3.25589439854e-06.\n",
      "Epoch:15, weight train batch: 306, step:27, loss before: 2.9019934118e-06, loss after: 2.9019934118e-06.\n",
      "Epoch:15, weight train batch: 306, step:28, loss before: 2.63004835688e-06, loss after: 2.63004835688e-06.\n",
      "Epoch:15, weight train batch: 306, step:29, loss before: 2.65985045189e-06, loss after: 2.65985045189e-06.\n",
      "Epoch:15, weight train batch: 306, step:30, loss before: 3.05472985929e-06, loss after: 3.05472985929e-06.\n",
      "Epoch:15, weight train batch: 306, step:31, loss before: 3.2782463677e-06, loss after: 3.2782463677e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 302, loss before: 2.90013076665e-06, loss after: 0.000298871775158.\n",
      "Epoch:15, weight train batch: 307, step:0, loss before: 2.50711423178e-06, loss after: 2.50711423178e-06.\n",
      "Epoch:15, weight train batch: 307, step:1, loss before: 2.14203737414e-06, loss after: 2.14203737414e-06.\n",
      "Epoch:15, weight train batch: 307, step:2, loss before: 2.8870922506e-06, loss after: 2.8870922506e-06.\n",
      "Epoch:15, weight train batch: 307, step:3, loss before: 3.22236701322e-06, loss after: 3.22236701322e-06.\n",
      "Epoch:15, weight train batch: 307, step:4, loss before: 7.97751490609e-05, loss after: 7.94741499703e-05.\n",
      "Epoch:15, weight train batch: 307, step:5, loss before: 2.12341092265e-06, loss after: 2.12341092265e-06.\n",
      "Epoch:15, weight train batch: 307, step:6, loss before: 2.14203737414e-06, loss after: 2.10478447116e-06.\n",
      "Epoch:15, weight train batch: 307, step:7, loss before: 3.05100434161e-06, loss after: 3.05100434161e-06.\n",
      "Epoch:15, weight train batch: 307, step:8, loss before: 3.58371880793e-06, loss after: 3.58371880793e-06.\n",
      "Epoch:15, weight train batch: 307, step:9, loss before: 3.05845469484e-06, loss after: 3.05845469484e-06.\n",
      "Epoch:15, weight train batch: 307, step:10, loss before: 2.4363337161e-06, loss after: 2.41025691139e-06.\n",
      "Epoch:15, weight train batch: 307, step:11, loss before: 1.87009209185e-06, loss after: 1.87009209185e-06.\n",
      "Epoch:15, weight train batch: 307, step:12, loss before: 2.40653162109e-06, loss after: 2.40653162109e-06.\n",
      "Epoch:15, weight train batch: 307, step:13, loss before: 2.27242185247e-06, loss after: 2.27242185247e-06.\n",
      "Epoch:15, weight train batch: 307, step:14, loss before: 2.65240009867e-06, loss after: 2.65240009867e-06.\n",
      "Epoch:15, weight train batch: 307, step:15, loss before: 2.49966365118e-06, loss after: 2.49966365118e-06.\n",
      "Epoch:15, weight train batch: 307, step:16, loss before: 2.6374987101e-06, loss after: 2.6374987101e-06.\n",
      "Epoch:15, weight train batch: 307, step:17, loss before: 2.32085062635e-06, loss after: 2.32085062635e-06.\n",
      "Epoch:15, weight train batch: 307, step:18, loss before: 2.99139992421e-06, loss after: 2.99139992421e-06.\n",
      "Epoch:15, weight train batch: 307, step:19, loss before: 2.59279545389e-06, loss after: 2.59279545389e-06.\n",
      "Epoch:15, weight train batch: 307, step:20, loss before: 5.77769424126e-06, loss after: 5.77396940571e-06.\n",
      "Epoch:15, weight train batch: 307, step:21, loss before: 3.38255404131e-06, loss after: 3.38255404131e-06.\n",
      "Epoch:15, weight train batch: 307, step:22, loss before: 2.62259777628e-06, loss after: 2.62259777628e-06.\n",
      "Epoch:15, weight train batch: 307, step:23, loss before: 2.32085062635e-06, loss after: 2.32085062635e-06.\n",
      "Epoch:15, weight train batch: 307, step:24, loss before: 2.62259777628e-06, loss after: 2.62259777628e-06.\n",
      "Epoch:15, weight train batch: 307, step:25, loss before: 3.02120201923e-06, loss after: 3.02120201923e-06.\n",
      "Epoch:15, weight train batch: 307, step:26, loss before: 3.55764177584e-06, loss after: 3.55764177584e-06.\n",
      "Epoch:15, weight train batch: 307, step:27, loss before: 2.13458679355e-06, loss after: 2.13458679355e-06.\n",
      "Epoch:15, weight train batch: 307, step:28, loss before: 2.42515807258e-06, loss after: 2.42515807258e-06.\n",
      "Epoch:15, weight train batch: 307, step:29, loss before: 3.13296027343e-06, loss after: 3.13296027343e-06.\n",
      "Epoch:15, weight train batch: 307, step:30, loss before: 3.72527915715e-06, loss after: 3.72527915715e-06.\n",
      "Epoch:15, weight train batch: 307, step:31, loss before: 2.64122422777e-06, loss after: 2.64122422777e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 303, loss before: 2.72783722721e-06, loss after: 0.00541788525879.\n",
      "Epoch:15, weight train batch: 308, step:0, loss before: 2.57044393948e-06, loss after: 2.57044393948e-06.\n",
      "Epoch:15, weight train batch: 308, step:1, loss before: 3.11060694003e-06, loss after: 3.08080484501e-06.\n",
      "Epoch:15, weight train batch: 308, step:2, loss before: 2.74925719168e-06, loss after: 2.74925719168e-06.\n",
      "Epoch:15, weight train batch: 308, step:3, loss before: 3.28942178385e-06, loss after: 3.28942178385e-06.\n",
      "Epoch:15, weight train batch: 308, step:4, loss before: 2.78650963992e-06, loss after: 2.78650963992e-06.\n",
      "Epoch:15, weight train batch: 308, step:5, loss before: 2.59652097157e-06, loss after: 2.59652097157e-06.\n",
      "Epoch:15, weight train batch: 308, step:6, loss before: 2.35810307458e-06, loss after: 2.35810307458e-06.\n",
      "Epoch:15, weight train batch: 308, step:7, loss before: 2.43633394348e-06, loss after: 2.43633394348e-06.\n",
      "Epoch:15, weight train batch: 308, step:8, loss before: 1.86636680155e-06, loss after: 1.86636680155e-06.\n",
      "Epoch:15, weight train batch: 308, step:9, loss before: 2.56299335888e-06, loss after: 2.56299335888e-06.\n",
      "Epoch:15, weight train batch: 308, step:10, loss before: 2.7753339964e-06, loss after: 2.7753339964e-06.\n",
      "Epoch:15, weight train batch: 308, step:11, loss before: 2.56299335888e-06, loss after: 2.56299335888e-06.\n",
      "Epoch:15, weight train batch: 308, step:12, loss before: 2.03027889256e-06, loss after: 2.03027889256e-06.\n",
      "Epoch:15, weight train batch: 308, step:13, loss before: 1.51991628172e-06, loss after: 1.51991628172e-06.\n",
      "Epoch:15, weight train batch: 308, step:14, loss before: 2.5741690024e-06, loss after: 2.5741690024e-06.\n",
      "Epoch:15, weight train batch: 308, step:15, loss before: 2.06008121495e-06, loss after: 2.06008121495e-06.\n",
      "Epoch:15, weight train batch: 308, step:16, loss before: 2.7641581255e-06, loss after: 2.7641581255e-06.\n",
      "Epoch:15, weight train batch: 308, step:17, loss before: 3.11805933961e-06, loss after: 3.11805933961e-06.\n",
      "Epoch:15, weight train batch: 308, step:18, loss before: 5.46856972505e-06, loss after: 5.46856972505e-06.\n",
      "Epoch:15, weight train batch: 308, step:19, loss before: 3.31921910401e-06, loss after: 3.31921910401e-06.\n",
      "Epoch:15, weight train batch: 308, step:20, loss before: 6.31776947557e-06, loss after: 6.31776947557e-06.\n",
      "Epoch:15, weight train batch: 308, step:21, loss before: 3.31549904331e-06, loss after: 3.31549904331e-06.\n",
      "Epoch:15, weight train batch: 308, step:22, loss before: 2.25379562835e-06, loss after: 2.25379562835e-06.\n",
      "Epoch:15, weight train batch: 308, step:23, loss before: 2.98394957099e-06, loss after: 2.98394957099e-06.\n",
      "Epoch:15, weight train batch: 308, step:24, loss before: 2.20536685447e-06, loss after: 2.20536685447e-06.\n",
      "Epoch:15, weight train batch: 308, step:25, loss before: 3.3304002045e-06, loss after: 3.3304002045e-06.\n",
      "Epoch:15, weight train batch: 308, step:26, loss before: 2.7753339964e-06, loss after: 2.74180661108e-06.\n",
      "Epoch:15, weight train batch: 308, step:27, loss before: 2.68592748398e-06, loss after: 2.68592748398e-06.\n",
      "Epoch:15, weight train batch: 308, step:28, loss before: 2.55554277828e-06, loss after: 2.55554277828e-06.\n",
      "Epoch:15, weight train batch: 308, step:29, loss before: 6.85425129632e-06, loss after: 6.85052646077e-06.\n",
      "Epoch:15, weight train batch: 308, step:30, loss before: 2.76415835287e-06, loss after: 2.76415835287e-06.\n",
      "Epoch:15, weight train batch: 308, step:31, loss before: 3.10688346872e-06, loss after: 3.10688346872e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 304, loss before: 2.64029313257e-06, loss after: 2.64029313257e-06.\n",
      "Epoch:15, weight train batch: 309, step:0, loss before: 2.39908126787e-06, loss after: 2.39908126787e-06.\n",
      "Epoch:15, weight train batch: 309, step:1, loss before: 2.76788387055e-06, loss after: 2.76788387055e-06.\n",
      "Epoch:15, weight train batch: 309, step:2, loss before: 2.39163091464e-06, loss after: 2.39163091464e-06.\n",
      "Epoch:15, weight train batch: 309, step:3, loss before: 2.7082789984e-06, loss after: 2.7082789984e-06.\n",
      "Epoch:15, weight train batch: 309, step:4, loss before: 0.000542503898032, loss after: 0.000540760986041.\n",
      "Epoch:15, weight train batch: 309, step:5, loss before: 2.39163068727e-06, loss after: 2.39163068727e-06.\n",
      "Epoch:15, weight train batch: 309, step:6, loss before: 1.79186122296e-06, loss after: 1.79186122296e-06.\n",
      "Epoch:15, weight train batch: 309, step:7, loss before: 3.63959816241e-06, loss after: 3.63959816241e-06.\n",
      "Epoch:15, weight train batch: 309, step:8, loss before: 2.39908126787e-06, loss after: 2.39908126787e-06.\n",
      "Epoch:15, weight train batch: 309, step:9, loss before: 2.58534510067e-06, loss after: 2.58534510067e-06.\n",
      "Epoch:15, weight train batch: 309, step:10, loss before: 2.74180661108e-06, loss after: 2.74180661108e-06.\n",
      "Epoch:15, weight train batch: 309, step:11, loss before: 2.37300446315e-06, loss after: 2.37300446315e-06.\n",
      "Epoch:15, weight train batch: 309, step:12, loss before: 2.8870922506e-06, loss after: 2.8870922506e-06.\n",
      "Epoch:15, weight train batch: 309, step:13, loss before: 2.06380673262e-06, loss after: 2.06380673262e-06.\n",
      "Epoch:15, weight train batch: 309, step:14, loss before: 1.89244383364e-06, loss after: 1.89244383364e-06.\n",
      "Epoch:15, weight train batch: 309, step:15, loss before: 2.60024626186e-06, loss after: 2.60024626186e-06.\n",
      "Epoch:15, weight train batch: 309, step:16, loss before: 2.37672975345e-06, loss after: 2.37672975345e-06.\n",
      "Epoch:15, weight train batch: 309, step:17, loss before: 2.00420208785e-06, loss after: 2.00420208785e-06.\n",
      "Epoch:15, weight train batch: 309, step:18, loss before: 3.2782463677e-06, loss after: 3.2782463677e-06.\n",
      "Epoch:15, weight train batch: 309, step:19, loss before: 2.74180661108e-06, loss after: 2.74180661108e-06.\n",
      "Epoch:15, weight train batch: 309, step:20, loss before: 2.90944399239e-06, loss after: 2.90944399239e-06.\n",
      "Epoch:15, weight train batch: 309, step:21, loss before: 3.080806664e-06, loss after: 3.080806664e-06.\n",
      "Epoch:15, weight train batch: 309, step:22, loss before: 2.58161981037e-06, loss after: 2.58161981037e-06.\n",
      "Epoch:15, weight train batch: 309, step:23, loss before: 2.36182859226e-06, loss after: 2.33575156017e-06.\n",
      "Epoch:15, weight train batch: 309, step:24, loss before: 2.56299335888e-06, loss after: 2.56299335888e-06.\n",
      "Epoch:15, weight train batch: 309, step:25, loss before: 2.73435625786e-06, loss after: 2.73435625786e-06.\n",
      "Epoch:15, weight train batch: 309, step:26, loss before: 2.86474050881e-06, loss after: 2.86474050881e-06.\n",
      "Epoch:15, weight train batch: 309, step:27, loss before: 2.68592748398e-06, loss after: 2.68592748398e-06.\n",
      "Epoch:15, weight train batch: 309, step:28, loss before: 5.89698629483e-06, loss after: 5.89698629483e-06.\n",
      "Epoch:15, weight train batch: 309, step:29, loss before: 3.39000462191e-06, loss after: 3.39000462191e-06.\n",
      "Epoch:15, weight train batch: 309, step:30, loss before: 0.000510684098117, loss after: 0.000508862431161.\n",
      "Epoch:15, weight train batch: 309, step:31, loss before: 2.56671864918e-06, loss after: 2.56671864918e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 305, loss before: 2.34972185353e-06, loss after: 3.24560141962e-06.\n",
      "Epoch:15, weight train batch: 310, step:0, loss before: 2.71945486929e-06, loss after: 2.68592748398e-06.\n",
      "Epoch:15, weight train batch: 310, step:1, loss before: 2.66357574219e-06, loss after: 2.66357574219e-06.\n",
      "Epoch:15, weight train batch: 310, step:2, loss before: 2.12713598557e-06, loss after: 2.12713598557e-06.\n",
      "Epoch:15, weight train batch: 310, step:3, loss before: 0.0216634944081, loss after: 0.0216634944081.\n",
      "Epoch:15, weight train batch: 310, step:4, loss before: 3.54274061465e-06, loss after: 3.54274061465e-06.\n",
      "Epoch:15, weight train batch: 310, step:5, loss before: 2.90199363917e-06, loss after: 2.86474096356e-06.\n",
      "Epoch:15, weight train batch: 310, step:6, loss before: 2.10478447116e-06, loss after: 2.10478447116e-06.\n",
      "Epoch:15, weight train batch: 310, step:7, loss before: 1.60187232723e-06, loss after: 1.60187232723e-06.\n",
      "Epoch:15, weight train batch: 310, step:8, loss before: 2.28359772336e-06, loss after: 2.28359772336e-06.\n",
      "Epoch:15, weight train batch: 310, step:9, loss before: 2.10478447116e-06, loss after: 2.10478447116e-06.\n",
      "Epoch:15, weight train batch: 310, step:10, loss before: 2.29477359426e-06, loss after: 2.29477359426e-06.\n",
      "Epoch:15, weight train batch: 310, step:11, loss before: 1.79186122296e-06, loss after: 1.79186122296e-06.\n",
      "Epoch:15, weight train batch: 310, step:12, loss before: 2.10478447116e-06, loss after: 2.10478447116e-06.\n",
      "Epoch:15, weight train batch: 310, step:13, loss before: 0.000489852158353, loss after: 0.000487695127958.\n",
      "Epoch:15, weight train batch: 310, step:14, loss before: 2.26124598157e-06, loss after: 2.26124598157e-06.\n",
      "Epoch:15, weight train batch: 310, step:15, loss before: 3.19629043588e-06, loss after: 3.19629043588e-06.\n",
      "Epoch:15, weight train batch: 310, step:16, loss before: 2.12713621295e-06, loss after: 2.12713621295e-06.\n",
      "Epoch:15, weight train batch: 310, step:17, loss before: 3.01002660308e-06, loss after: 3.01002660308e-06.\n",
      "Epoch:15, weight train batch: 310, step:18, loss before: 1.99302621695e-06, loss after: 1.99302621695e-06.\n",
      "Epoch:15, weight train batch: 310, step:19, loss before: 2.48476271736e-06, loss after: 2.48476271736e-06.\n",
      "Epoch:15, weight train batch: 310, step:20, loss before: 2.64122422777e-06, loss after: 2.64122422777e-06.\n",
      "Epoch:15, weight train batch: 310, step:21, loss before: 2.86474096356e-06, loss after: 2.86474096356e-06.\n",
      "Epoch:15, weight train batch: 310, step:22, loss before: 2.27614714277e-06, loss after: 2.27614714277e-06.\n",
      "Epoch:15, weight train batch: 310, step:23, loss before: 6.55251415083e-06, loss after: 6.55251415083e-06.\n",
      "Epoch:15, weight train batch: 310, step:24, loss before: 2.30594946515e-06, loss after: 2.27987243306e-06.\n",
      "Epoch:15, weight train batch: 310, step:25, loss before: 1.89989418686e-06, loss after: 1.89989418686e-06.\n",
      "Epoch:15, weight train batch: 310, step:26, loss before: 2.25379540097e-06, loss after: 2.25379540097e-06.\n",
      "Epoch:15, weight train batch: 310, step:27, loss before: 2.43633394348e-06, loss after: 2.43633394348e-06.\n",
      "Epoch:15, weight train batch: 310, step:28, loss before: 2.10478447116e-06, loss after: 2.10478447116e-06.\n",
      "Epoch:15, weight train batch: 310, step:29, loss before: 2.06753156817e-06, loss after: 2.06753156817e-06.\n",
      "Epoch:15, weight train batch: 310, step:30, loss before: 2.28359749599e-06, loss after: 2.28359749599e-06.\n",
      "Epoch:15, weight train batch: 310, step:31, loss before: 2.44378452408e-06, loss after: 2.44378452408e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 306, loss before: 2.35158404394e-06, loss after: 1.49031648107e-05.\n",
      "Epoch:15, weight train batch: 311, step:0, loss before: 6.87661440679e-06, loss after: 6.87661440679e-06.\n",
      "Epoch:15, weight train batch: 311, step:1, loss before: 2.45496039497e-06, loss after: 2.45496039497e-06.\n",
      "Epoch:15, weight train batch: 311, step:2, loss before: 2.44378452408e-06, loss after: 2.44378452408e-06.\n",
      "Epoch:15, weight train batch: 311, step:3, loss before: 4.11638347941e-06, loss after: 4.11638347941e-06.\n",
      "Epoch:15, weight train batch: 311, step:4, loss before: 2.72690522252e-06, loss after: 2.72690522252e-06.\n",
      "Epoch:15, weight train batch: 311, step:5, loss before: 2.97649899039e-06, loss after: 2.97649899039e-06.\n",
      "Epoch:15, weight train batch: 311, step:6, loss before: 3.47568584402e-06, loss after: 3.47568584402e-06.\n",
      "Epoch:15, weight train batch: 311, step:7, loss before: 2.24261953008e-06, loss after: 2.24261953008e-06.\n",
      "Epoch:15, weight train batch: 311, step:8, loss before: 2.77905928669e-06, loss after: 2.77905928669e-06.\n",
      "Epoch:15, weight train batch: 311, step:9, loss before: 6.74247166899e-06, loss after: 6.73874728818e-06.\n",
      "Epoch:15, weight train batch: 311, step:10, loss before: 2.46241097557e-06, loss after: 2.46241097557e-06.\n",
      "Epoch:15, weight train batch: 311, step:11, loss before: 2.79768573819e-06, loss after: 2.79768573819e-06.\n",
      "Epoch:15, weight train batch: 311, step:12, loss before: 1.91852063836e-06, loss after: 1.91852063836e-06.\n",
      "Epoch:15, weight train batch: 311, step:13, loss before: 2.26869656217e-06, loss after: 2.26869656217e-06.\n",
      "Epoch:15, weight train batch: 311, step:14, loss before: 3.00630131278e-06, loss after: 3.00630131278e-06.\n",
      "Epoch:15, weight train batch: 311, step:15, loss before: 1.37835559144e-06, loss after: 1.37835559144e-06.\n",
      "Epoch:15, weight train batch: 311, step:16, loss before: 2.29104830396e-06, loss after: 2.26497149924e-06.\n",
      "Epoch:15, weight train batch: 311, step:17, loss before: 6.95848257237e-06, loss after: 6.95475773682e-06.\n",
      "Epoch:15, weight train batch: 311, step:18, loss before: 1.73598209585e-06, loss after: 1.73598209585e-06.\n",
      "Epoch:15, weight train batch: 311, step:19, loss before: 3.11060921376e-06, loss after: 3.11060921376e-06.\n",
      "Epoch:15, weight train batch: 311, step:20, loss before: 2.93924063044e-06, loss after: 2.93924063044e-06.\n",
      "Epoch:15, weight train batch: 311, step:21, loss before: 2.56671864918e-06, loss after: 2.56671864918e-06.\n",
      "Epoch:15, weight train batch: 311, step:22, loss before: 3.11805979436e-06, loss after: 3.11805979436e-06.\n",
      "Epoch:15, weight train batch: 311, step:23, loss before: 2.73063051281e-06, loss after: 2.73063051281e-06.\n",
      "Epoch:15, weight train batch: 311, step:24, loss before: 2.36555388256e-06, loss after: 2.36555388256e-06.\n",
      "Epoch:15, weight train batch: 311, step:25, loss before: 7.73240390117e-05, loss after: 7.68366589909e-05.\n",
      "Epoch:15, weight train batch: 311, step:26, loss before: 2.38418033405e-06, loss after: 2.38418033405e-06.\n",
      "Epoch:15, weight train batch: 311, step:27, loss before: 6.51599111734e-05, loss after: 6.512273103e-05.\n",
      "Epoch:15, weight train batch: 311, step:28, loss before: 2.30594946515e-06, loss after: 2.30594946515e-06.\n",
      "Epoch:15, weight train batch: 311, step:29, loss before: 2.53319103649e-06, loss after: 2.53319103649e-06.\n",
      "Epoch:15, weight train batch: 311, step:30, loss before: 0.00118083076086, loss after: 0.00117790326476.\n",
      "Epoch:15, weight train batch: 311, step:31, loss before: 1.75833406502e-06, loss after: 1.75833406502e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 307, loss before: 2.45402929977e-06, loss after: 2.45402929977e-06.\n",
      "Epoch:15, weight train batch: 312, step:0, loss before: 2.24261975745e-06, loss after: 2.24261975745e-06.\n",
      "Epoch:15, weight train batch: 312, step:1, loss before: 2.44378475145e-06, loss after: 2.44378475145e-06.\n",
      "Epoch:15, weight train batch: 312, step:2, loss before: 0.00116536417045, loss after: 0.00115968182217.\n",
      "Epoch:15, weight train batch: 312, step:3, loss before: 2.00047657017e-06, loss after: 1.95204779629e-06.\n",
      "Epoch:15, weight train batch: 312, step:4, loss before: 2.35437801166e-06, loss after: 2.35437801166e-06.\n",
      "Epoch:15, weight train batch: 312, step:5, loss before: 2.39908149524e-06, loss after: 2.39908149524e-06.\n",
      "Epoch:15, weight train batch: 312, step:6, loss before: 5.38293670616e-06, loss after: 5.37548658031e-06.\n",
      "Epoch:15, weight train batch: 312, step:7, loss before: 2.02655337489e-06, loss after: 2.02655337489e-06.\n",
      "Epoch:15, weight train batch: 312, step:8, loss before: 2.9057187021e-06, loss after: 2.9057187021e-06.\n",
      "Epoch:15, weight train batch: 312, step:9, loss before: 2.8908175409e-06, loss after: 2.8908175409e-06.\n",
      "Epoch:15, weight train batch: 312, step:10, loss before: 2.71200451607e-06, loss after: 2.74925696431e-06.\n",
      "Epoch:15, weight train batch: 312, step:11, loss before: 2.80886160908e-06, loss after: 2.80886160908e-06.\n",
      "Epoch:15, weight train batch: 312, step:12, loss before: 3.29687259182e-06, loss after: 3.29687259182e-06.\n",
      "Epoch:15, weight train batch: 312, step:13, loss before: 2.24634482038e-06, loss after: 2.24634482038e-06.\n",
      "Epoch:15, weight train batch: 312, step:14, loss before: 2.12341092265e-06, loss after: 2.12341092265e-06.\n",
      "Epoch:15, weight train batch: 312, step:15, loss before: 2.79396044789e-06, loss after: 2.79396044789e-06.\n",
      "Epoch:15, weight train batch: 312, step:16, loss before: 0.021663069725, loss after: 0.021663069725.\n",
      "Epoch:15, weight train batch: 312, step:17, loss before: 2.56671864918e-06, loss after: 2.56671864918e-06.\n",
      "Epoch:15, weight train batch: 312, step:18, loss before: 3.1590375329e-06, loss after: 3.1590375329e-06.\n",
      "Epoch:15, weight train batch: 312, step:19, loss before: 2.59652097157e-06, loss after: 2.59652097157e-06.\n",
      "Epoch:15, weight train batch: 312, step:20, loss before: 2.41398220169e-06, loss after: 2.41398220169e-06.\n",
      "Epoch:15, weight train batch: 312, step:21, loss before: 3.31177375301e-06, loss after: 3.31177375301e-06.\n",
      "Epoch:15, weight train batch: 312, step:22, loss before: 3.12923521051e-06, loss after: 3.08453218167e-06.\n",
      "Epoch:15, weight train batch: 312, step:23, loss before: 2.36927894548e-06, loss after: 2.36927894548e-06.\n",
      "Epoch:15, weight train batch: 312, step:24, loss before: 1.86264151125e-06, loss after: 1.86264151125e-06.\n",
      "Epoch:15, weight train batch: 312, step:25, loss before: 2.87591637971e-06, loss after: 2.87591637971e-06.\n",
      "Epoch:15, weight train batch: 312, step:26, loss before: 2.48848755291e-06, loss after: 2.48848755291e-06.\n",
      "Epoch:15, weight train batch: 312, step:27, loss before: 0.00109168421477, loss after: 0.00108900736086.\n",
      "Epoch:15, weight train batch: 312, step:28, loss before: 2.53319126386e-06, loss after: 2.53319126386e-06.\n",
      "Epoch:15, weight train batch: 312, step:29, loss before: 2.05635592465e-06, loss after: 2.07870743907e-06.\n",
      "Epoch:15, weight train batch: 312, step:30, loss before: 2.59652074419e-06, loss after: 2.5667184218e-06.\n",
      "Epoch:15, weight train batch: 312, step:31, loss before: 3.1515869523e-06, loss after: 3.1515869523e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 308, loss before: 2.08980000025e-05, loss after: 2.46799891102e-06.\n",
      "Epoch:15, weight train batch: 313, step:0, loss before: 2.62259777628e-06, loss after: 2.62259777628e-06.\n",
      "Epoch:15, weight train batch: 313, step:1, loss before: 1.98930047191e-06, loss after: 1.98930047191e-06.\n",
      "Epoch:15, weight train batch: 313, step:2, loss before: 2.17928959501e-06, loss after: 2.17928959501e-06.\n",
      "Epoch:15, weight train batch: 313, step:3, loss before: 2.56299313151e-06, loss after: 2.56299313151e-06.\n",
      "Epoch:15, weight train batch: 313, step:4, loss before: 2.45496039497e-06, loss after: 2.45496039497e-06.\n",
      "Epoch:15, weight train batch: 313, step:5, loss before: 2.7641581255e-06, loss after: 2.7641581255e-06.\n",
      "Epoch:15, weight train batch: 313, step:6, loss before: 2.88336673293e-06, loss after: 2.88336673293e-06.\n",
      "Epoch:15, weight train batch: 313, step:7, loss before: 2.14203691939e-06, loss after: 2.14203691939e-06.\n",
      "Epoch:15, weight train batch: 313, step:8, loss before: 2.21281720769e-06, loss after: 2.21281720769e-06.\n",
      "Epoch:15, weight train batch: 313, step:9, loss before: 2.63749848273e-06, loss after: 2.63749848273e-06.\n",
      "Epoch:15, weight train batch: 313, step:10, loss before: 2.42515807258e-06, loss after: 2.42515807258e-06.\n",
      "Epoch:15, weight train batch: 313, step:11, loss before: 2.03027866519e-06, loss after: 2.03027866519e-06.\n",
      "Epoch:15, weight train batch: 313, step:12, loss before: 1.63167396749e-06, loss after: 1.63167396749e-06.\n",
      "Epoch:15, weight train batch: 313, step:13, loss before: 2.34692697632e-06, loss after: 2.34692697632e-06.\n",
      "Epoch:15, weight train batch: 313, step:14, loss before: 1.68010274137e-06, loss after: 1.68010274137e-06.\n",
      "Epoch:15, weight train batch: 313, step:15, loss before: 2.74925696431e-06, loss after: 2.74925696431e-06.\n",
      "Epoch:15, weight train batch: 313, step:16, loss before: 4.29520878242e-06, loss after: 4.29148349212e-06.\n",
      "Epoch:15, weight train batch: 313, step:17, loss before: 2.05263040698e-06, loss after: 2.03027889256e-06.\n",
      "Epoch:15, weight train batch: 313, step:18, loss before: 2.50711423178e-06, loss after: 2.50711423178e-06.\n",
      "Epoch:15, weight train batch: 313, step:19, loss before: 2.46241052082e-06, loss after: 2.46241052082e-06.\n",
      "Epoch:15, weight train batch: 313, step:20, loss before: 2.49221307058e-06, loss after: 2.49221307058e-06.\n",
      "Epoch:15, weight train batch: 313, step:21, loss before: 4.17600085711e-06, loss after: 4.17600085711e-06.\n",
      "Epoch:15, weight train batch: 313, step:22, loss before: 2.74553212876e-06, loss after: 2.74553212876e-06.\n",
      "Epoch:15, weight train batch: 313, step:23, loss before: 0.0216633453965, loss after: 0.0216633453965.\n",
      "Epoch:15, weight train batch: 313, step:24, loss before: 2.18301511268e-06, loss after: 2.18301511268e-06.\n",
      "Epoch:15, weight train batch: 313, step:25, loss before: 2.84983957499e-06, loss after: 2.84983957499e-06.\n",
      "Epoch:15, weight train batch: 313, step:26, loss before: 3.0249275369e-06, loss after: 3.0249275369e-06.\n",
      "Epoch:15, weight train batch: 313, step:27, loss before: 2.59652097157e-06, loss after: 2.59652097157e-06.\n",
      "Epoch:15, weight train batch: 313, step:28, loss before: 3.05845514958e-06, loss after: 3.05845514958e-06.\n",
      "Epoch:15, weight train batch: 313, step:29, loss before: 2.08615801967e-06, loss after: 2.08615801967e-06.\n",
      "Epoch:15, weight train batch: 313, step:30, loss before: 1.96694918486e-06, loss after: 1.96694918486e-06.\n",
      "Epoch:15, weight train batch: 313, step:31, loss before: 2.23516917686e-06, loss after: 2.23516917686e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 309, loss before: 2.43726526605e-06, loss after: 2.43726526605e-06.\n",
      "Epoch:15, weight train batch: 314, step:0, loss before: 2.0004763428e-06, loss after: 2.0004763428e-06.\n",
      "Epoch:15, weight train batch: 314, step:1, loss before: 2.19046569327e-06, loss after: 2.19046569327e-06.\n",
      "Epoch:15, weight train batch: 314, step:2, loss before: 0.00104562030174, loss after: 0.00104355928488.\n",
      "Epoch:15, weight train batch: 314, step:3, loss before: 2.05263040698e-06, loss after: 2.05263040698e-06.\n",
      "Epoch:15, weight train batch: 314, step:4, loss before: 2.59652097157e-06, loss after: 2.59652097157e-06.\n",
      "Epoch:15, weight train batch: 314, step:5, loss before: 2.23889446715e-06, loss after: 2.23889446715e-06.\n",
      "Epoch:15, weight train batch: 314, step:6, loss before: 2.20536685447e-06, loss after: 2.20536685447e-06.\n",
      "Epoch:15, weight train batch: 314, step:7, loss before: 2.60769684246e-06, loss after: 2.60769684246e-06.\n",
      "Epoch:15, weight train batch: 314, step:8, loss before: 3.2186419503e-06, loss after: 3.2186419503e-06.\n",
      "Epoch:15, weight train batch: 314, step:9, loss before: 5.114700798e-06, loss after: 5.1109764172e-06.\n",
      "Epoch:15, weight train batch: 314, step:10, loss before: 2.5108392947e-06, loss after: 2.5108392947e-06.\n",
      "Epoch:15, weight train batch: 314, step:11, loss before: 2.59652097157e-06, loss after: 2.59652097157e-06.\n",
      "Epoch:15, weight train batch: 314, step:12, loss before: 1.89244360627e-06, loss after: 1.88871854334e-06.\n",
      "Epoch:15, weight train batch: 314, step:13, loss before: 2.28732278629e-06, loss after: 2.28732278629e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:15, weight train batch: 314, step:14, loss before: 2.53319103649e-06, loss after: 2.53319103649e-06.\n",
      "Epoch:15, weight train batch: 314, step:15, loss before: 4.62032330688e-05, loss after: 4.59949114884e-05.\n",
      "Epoch:15, weight train batch: 314, step:16, loss before: 2.29477336688e-06, loss after: 2.29477336688e-06.\n",
      "Epoch:15, weight train batch: 314, step:17, loss before: 2.15693808059e-06, loss after: 2.15693808059e-06.\n",
      "Epoch:15, weight train batch: 314, step:18, loss before: 1.95949860426e-06, loss after: 1.95949860426e-06.\n",
      "Epoch:15, weight train batch: 314, step:19, loss before: 2.3841798793e-06, loss after: 2.3841798793e-06.\n",
      "Epoch:15, weight train batch: 314, step:20, loss before: 0.00101131619886, loss after: 0.00100878055673.\n",
      "Epoch:15, weight train batch: 314, step:21, loss before: 2.13458656617e-06, loss after: 2.13458656617e-06.\n",
      "Epoch:15, weight train batch: 314, step:22, loss before: 1.45658611928e-06, loss after: 1.41188274938e-06.\n",
      "Epoch:15, weight train batch: 314, step:23, loss before: 2.34320214076e-06, loss after: 2.34320214076e-06.\n",
      "Epoch:15, weight train batch: 314, step:24, loss before: 2.01537773137e-06, loss after: 2.01537773137e-06.\n",
      "Epoch:15, weight train batch: 314, step:25, loss before: 2.98022405332e-06, loss after: 2.98022405332e-06.\n",
      "Epoch:15, weight train batch: 314, step:26, loss before: 1.9408719254e-06, loss after: 1.9408719254e-06.\n",
      "Epoch:15, weight train batch: 314, step:27, loss before: 3.14413614433e-06, loss after: 3.14413614433e-06.\n",
      "Epoch:15, weight train batch: 314, step:28, loss before: 1.79558617219e-06, loss after: 1.79558617219e-06.\n",
      "Epoch:15, weight train batch: 314, step:29, loss before: 2.52574045589e-06, loss after: 2.52574045589e-06.\n",
      "Epoch:15, weight train batch: 314, step:30, loss before: 1.59442129188e-06, loss after: 1.59442129188e-06.\n",
      "Epoch:15, weight train batch: 314, step:31, loss before: 2.2500698833e-06, loss after: 2.2500698833e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 310, loss before: 4.01760735258e-06, loss after: 2.10105918086e-06.\n",
      "Epoch:15, weight train batch: 315, step:0, loss before: 6.76934505464e-05, loss after: 6.76934505464e-05.\n",
      "Epoch:15, weight train batch: 315, step:1, loss before: 2.03027184398e-06, loss after: 2.03027184398e-06.\n",
      "Epoch:15, weight train batch: 315, step:2, loss before: 1.97812482838e-06, loss after: 1.97812482838e-06.\n",
      "Epoch:15, weight train batch: 315, step:3, loss before: 2.14203691939e-06, loss after: 2.14203691939e-06.\n",
      "Epoch:15, weight train batch: 315, step:4, loss before: 2.7082789984e-06, loss after: 2.7082789984e-06.\n",
      "Epoch:15, weight train batch: 315, step:5, loss before: 2.48848755291e-06, loss after: 2.48848755291e-06.\n",
      "Epoch:15, weight train batch: 315, step:6, loss before: 2.3245754619e-06, loss after: 2.3245754619e-06.\n",
      "Epoch:15, weight train batch: 315, step:7, loss before: 2.11595988731e-06, loss after: 2.11595988731e-06.\n",
      "Epoch:15, weight train batch: 315, step:8, loss before: 2.17928982238e-06, loss after: 2.17928982238e-06.\n",
      "Epoch:15, weight train batch: 315, step:9, loss before: 3.07335631078e-06, loss after: 3.07335631078e-06.\n",
      "Epoch:15, weight train batch: 315, step:10, loss before: 6.80254161125e-05, loss after: 6.79808072164e-05.\n",
      "Epoch:15, weight train batch: 315, step:11, loss before: 3.18138904731e-06, loss after: 3.18138904731e-06.\n",
      "Epoch:15, weight train batch: 315, step:12, loss before: 6.79362347e-05, loss after: 6.78507349221e-05.\n",
      "Epoch:15, weight train batch: 315, step:13, loss before: 2.43260842581e-06, loss after: 2.39908104049e-06.\n",
      "Epoch:15, weight train batch: 315, step:14, loss before: 4.06052595281e-06, loss after: 4.06052595281e-06.\n",
      "Epoch:15, weight train batch: 315, step:15, loss before: 2.65239987129e-06, loss after: 2.65239987129e-06.\n",
      "Epoch:15, weight train batch: 315, step:16, loss before: 2.83121335087e-06, loss after: 2.83121335087e-06.\n",
      "Epoch:15, weight train batch: 315, step:17, loss before: 2.23889401241e-06, loss after: 2.23889401241e-06.\n",
      "Epoch:15, weight train batch: 315, step:18, loss before: 2.19046592065e-06, loss after: 2.19046592065e-06.\n",
      "Epoch:15, weight train batch: 315, step:19, loss before: 3.17021317642e-06, loss after: 3.17021317642e-06.\n",
      "Epoch:15, weight train batch: 315, step:20, loss before: 2.99139992421e-06, loss after: 2.99139992421e-06.\n",
      "Epoch:15, weight train batch: 315, step:21, loss before: 2.13458656617e-06, loss after: 2.13458656617e-06.\n",
      "Epoch:15, weight train batch: 315, step:22, loss before: 1.79558628588e-06, loss after: 1.77696006176e-06.\n",
      "Epoch:15, weight train batch: 315, step:23, loss before: 2.28359772336e-06, loss after: 2.28359772336e-06.\n",
      "Epoch:15, weight train batch: 315, step:24, loss before: 2.12713621295e-06, loss after: 2.12713621295e-06.\n",
      "Epoch:15, weight train batch: 315, step:25, loss before: 1.38953100759e-06, loss after: 1.38953100759e-06.\n",
      "Epoch:15, weight train batch: 315, step:26, loss before: 2.98394957099e-06, loss after: 2.98394957099e-06.\n",
      "Epoch:15, weight train batch: 315, step:27, loss before: 2.24634482038e-06, loss after: 2.24634482038e-06.\n",
      "Epoch:15, weight train batch: 315, step:28, loss before: 2.30222417485e-06, loss after: 2.30222417485e-06.\n",
      "Epoch:15, weight train batch: 315, step:29, loss before: 2.26124598157e-06, loss after: 2.26124598157e-06.\n",
      "Epoch:15, weight train batch: 315, step:30, loss before: 1.73970715878e-06, loss after: 1.73970715878e-06.\n",
      "Epoch:15, weight train batch: 315, step:31, loss before: 2.07125685847e-06, loss after: 2.07125685847e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 311, loss before: 2.19325943362e-06, loss after: 2.19325943362e-06.\n",
      "Epoch:15, weight train batch: 316, step:0, loss before: 2.07125685847e-06, loss after: 2.07125685847e-06.\n",
      "Epoch:15, weight train batch: 316, step:1, loss before: 2.3841798793e-06, loss after: 2.3841798793e-06.\n",
      "Epoch:15, weight train batch: 316, step:2, loss before: 2.20909214477e-06, loss after: 2.20909214477e-06.\n",
      "Epoch:15, weight train batch: 316, step:3, loss before: 1.97067447516e-06, loss after: 1.97067447516e-06.\n",
      "Epoch:15, weight train batch: 316, step:4, loss before: 2.08988330996e-06, loss after: 2.08988330996e-06.\n",
      "Epoch:15, weight train batch: 316, step:5, loss before: 2.26497127187e-06, loss after: 2.26497127187e-06.\n",
      "Epoch:15, weight train batch: 316, step:6, loss before: 2.63377364718e-06, loss after: 2.63377364718e-06.\n",
      "Epoch:15, weight train batch: 316, step:7, loss before: 2.20909191739e-06, loss after: 2.20909191739e-06.\n",
      "Epoch:15, weight train batch: 316, step:8, loss before: 2.7716087061e-06, loss after: 2.73063096756e-06.\n",
      "Epoch:15, weight train batch: 316, step:9, loss before: 2.21654272536e-06, loss after: 2.21654272536e-06.\n",
      "Epoch:15, weight train batch: 316, step:10, loss before: 1.97067424779e-06, loss after: 1.97067424779e-06.\n",
      "Epoch:15, weight train batch: 316, step:11, loss before: 2.19791627387e-06, loss after: 2.19791627387e-06.\n",
      "Epoch:15, weight train batch: 316, step:12, loss before: 1.51246513269e-06, loss after: 1.51246513269e-06.\n",
      "Epoch:15, weight train batch: 316, step:13, loss before: 2.02282444661e-06, loss after: 2.02282444661e-06.\n",
      "Epoch:15, weight train batch: 316, step:14, loss before: 2.68965322903e-06, loss after: 2.68965322903e-06.\n",
      "Epoch:15, weight train batch: 316, step:15, loss before: 2.40653207584e-06, loss after: 2.40653207584e-06.\n",
      "Epoch:15, weight train batch: 316, step:16, loss before: 2.23516917686e-06, loss after: 2.23516917686e-06.\n",
      "Epoch:15, weight train batch: 316, step:17, loss before: 2.54064184446e-06, loss after: 2.54064184446e-06.\n",
      "Epoch:15, weight train batch: 316, step:18, loss before: 3.24099414684e-06, loss after: 3.24099414684e-06.\n",
      "Epoch:15, weight train batch: 316, step:19, loss before: 1.43423460486e-06, loss after: 1.43423460486e-06.\n",
      "Epoch:15, weight train batch: 316, step:20, loss before: 2.78648258245e-06, loss after: 2.78648258245e-06.\n",
      "Epoch:15, weight train batch: 316, step:21, loss before: 2.74925741905e-06, loss after: 2.74925741905e-06.\n",
      "Epoch:15, weight train batch: 316, step:22, loss before: 2.34692743106e-06, loss after: 2.34692743106e-06.\n",
      "Epoch:15, weight train batch: 316, step:23, loss before: 2.74925741905e-06, loss after: 2.74925741905e-06.\n",
      "Epoch:15, weight train batch: 316, step:24, loss before: 1.96694918486e-06, loss after: 1.96694918486e-06.\n",
      "Epoch:15, weight train batch: 316, step:25, loss before: 1.75833372396e-06, loss after: 1.75833372396e-06.\n",
      "Epoch:15, weight train batch: 316, step:26, loss before: 0.0216623581946, loss after: 0.0216623581946.\n",
      "Epoch:15, weight train batch: 316, step:27, loss before: 1.45286094266e-06, loss after: 1.45286094266e-06.\n",
      "Epoch:15, weight train batch: 316, step:28, loss before: 2.40653207584e-06, loss after: 2.40653207584e-06.\n",
      "Epoch:15, weight train batch: 316, step:29, loss before: 1.53109158418e-06, loss after: 1.53109158418e-06.\n",
      "Epoch:15, weight train batch: 316, step:30, loss before: 1.73970727246e-06, loss after: 1.73970727246e-06.\n",
      "Epoch:15, weight train batch: 316, step:31, loss before: 1.18836612728e-06, loss after: 1.18836612728e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 312, loss before: 1.96415544451e-06, loss after: 1.96415544451e-06.\n",
      "Epoch:15, weight train batch: 317, step:0, loss before: 2.10850976146e-06, loss after: 2.10850976146e-06.\n",
      "Epoch:15, weight train batch: 317, step:1, loss before: 2.38790562435e-06, loss after: 2.38790562435e-06.\n",
      "Epoch:15, weight train batch: 317, step:2, loss before: 2.16066337089e-06, loss after: 2.16066337089e-06.\n",
      "Epoch:15, weight train batch: 317, step:3, loss before: 1.77696017545e-06, loss after: 1.75833372396e-06.\n",
      "Epoch:15, weight train batch: 317, step:4, loss before: 1.73970727246e-06, loss after: 1.73970727246e-06.\n",
      "Epoch:15, weight train batch: 317, step:5, loss before: 2.52201562034e-06, loss after: 2.52201562034e-06.\n",
      "Epoch:15, weight train batch: 317, step:6, loss before: 6.61297381157e-05, loss after: 6.60888472339e-05.\n",
      "Epoch:15, weight train batch: 317, step:7, loss before: 2.95042218568e-06, loss after: 2.95042218568e-06.\n",
      "Epoch:15, weight train batch: 317, step:8, loss before: 2.50338916885e-06, loss after: 2.50338916885e-06.\n",
      "Epoch:15, weight train batch: 317, step:9, loss before: 2.37300446315e-06, loss after: 2.37300446315e-06.\n",
      "Epoch:15, weight train batch: 317, step:10, loss before: 2.89454328595e-06, loss after: 2.89454328595e-06.\n",
      "Epoch:15, weight train batch: 317, step:11, loss before: 2.18674040298e-06, loss after: 2.18674040298e-06.\n",
      "Epoch:15, weight train batch: 317, step:12, loss before: 3.07707500724e-06, loss after: 3.07707500724e-06.\n",
      "Epoch:15, weight train batch: 317, step:13, loss before: 1.88871842965e-06, loss after: 1.88871842965e-06.\n",
      "Epoch:15, weight train batch: 317, step:14, loss before: 1.66520158018e-06, loss after: 1.66520158018e-06.\n",
      "Epoch:15, weight train batch: 317, step:15, loss before: 2.37300446315e-06, loss after: 2.37300446315e-06.\n",
      "Epoch:15, weight train batch: 317, step:16, loss before: 2.54064184446e-06, loss after: 2.54064184446e-06.\n",
      "Epoch:15, weight train batch: 317, step:17, loss before: 2.48476271736e-06, loss after: 2.48476271736e-06.\n",
      "Epoch:15, weight train batch: 317, step:18, loss before: 2.05635569728e-06, loss after: 2.05635569728e-06.\n",
      "Epoch:15, weight train batch: 317, step:19, loss before: 2.70827922577e-06, loss after: 2.66730148724e-06.\n",
      "Epoch:15, weight train batch: 317, step:20, loss before: 2.19419143832e-06, loss after: 2.19419143832e-06.\n",
      "Epoch:15, weight train batch: 317, step:21, loss before: 1.84774035006e-06, loss after: 1.84774035006e-06.\n",
      "Epoch:15, weight train batch: 317, step:22, loss before: 2.37672975345e-06, loss after: 2.37672975345e-06.\n",
      "Epoch:15, weight train batch: 317, step:23, loss before: 1.90361959085e-06, loss after: 1.90361959085e-06.\n",
      "Epoch:15, weight train batch: 317, step:24, loss before: 2.42888359026e-06, loss after: 2.42888359026e-06.\n",
      "Epoch:15, weight train batch: 317, step:25, loss before: 1.82538860827e-06, loss after: 1.82538860827e-06.\n",
      "Epoch:15, weight train batch: 317, step:26, loss before: 6.62322418066e-06, loss after: 6.61949979985e-06.\n",
      "Epoch:15, weight train batch: 317, step:27, loss before: 1.57579518145e-06, loss after: 1.57579518145e-06.\n",
      "Epoch:15, weight train batch: 317, step:28, loss before: 2.46613626587e-06, loss after: 2.46613626587e-06.\n",
      "Epoch:15, weight train batch: 317, step:29, loss before: 1.28149827106e-06, loss after: 1.23306972455e-06.\n",
      "Epoch:15, weight train batch: 317, step:30, loss before: 2.29477359426e-06, loss after: 2.29477359426e-06.\n",
      "Epoch:15, weight train batch: 317, step:31, loss before: 1.71363058143e-06, loss after: 1.71363058143e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 313, loss before: 1.79745675268e-05, loss after: 3.33685648002e-06.\n",
      "Epoch:15, weight train batch: 318, step:0, loss before: 2.14576243707e-06, loss after: 2.14576243707e-06.\n",
      "Epoch:15, weight train batch: 318, step:1, loss before: 2.14576243707e-06, loss after: 2.14576243707e-06.\n",
      "Epoch:15, weight train batch: 318, step:2, loss before: 1.98185034606e-06, loss after: 1.98185034606e-06.\n",
      "Epoch:15, weight train batch: 318, step:3, loss before: 1.66892709785e-06, loss after: 1.66892709785e-06.\n",
      "Epoch:15, weight train batch: 318, step:4, loss before: 2.44378475145e-06, loss after: 2.44378475145e-06.\n",
      "Epoch:15, weight train batch: 318, step:5, loss before: 2.45868591264e-06, loss after: 2.45868591264e-06.\n",
      "Epoch:15, weight train batch: 318, step:6, loss before: 2.39908126787e-06, loss after: 2.39908126787e-06.\n",
      "Epoch:15, weight train batch: 318, step:7, loss before: 2.17556475945e-06, loss after: 2.17556475945e-06.\n",
      "Epoch:15, weight train batch: 318, step:8, loss before: 2.16066382563e-06, loss after: 2.16066382563e-06.\n",
      "Epoch:15, weight train batch: 318, step:9, loss before: 0.000974987633526, loss after: 0.000973145884927.\n",
      "Epoch:15, weight train batch: 318, step:10, loss before: 2.45868591264e-06, loss after: 2.45868591264e-06.\n",
      "Epoch:15, weight train batch: 318, step:11, loss before: 1.80303686648e-06, loss after: 1.80303686648e-06.\n",
      "Epoch:15, weight train batch: 318, step:12, loss before: 1.63912466178e-06, loss after: 1.63912466178e-06.\n",
      "Epoch:15, weight train batch: 318, step:13, loss before: 2.02655382964e-06, loss after: 2.02655382964e-06.\n",
      "Epoch:15, weight train batch: 318, step:14, loss before: 1.80303686648e-06, loss after: 1.80303686648e-06.\n",
      "Epoch:15, weight train batch: 318, step:15, loss before: 1.47521245708e-06, loss after: 1.47521245708e-06.\n",
      "Epoch:15, weight train batch: 318, step:16, loss before: 2.13086127587e-06, loss after: 2.13086127587e-06.\n",
      "Epoch:15, weight train batch: 318, step:17, loss before: 2.75670799965e-06, loss after: 2.75670799965e-06.\n",
      "Epoch:15, weight train batch: 318, step:18, loss before: 7.26956277504e-05, loss after: 7.23982811905e-05.\n",
      "Epoch:15, weight train batch: 318, step:19, loss before: 2.16066382563e-06, loss after: 2.13086150325e-06.\n",
      "Epoch:15, weight train batch: 318, step:20, loss before: 2.33575178754e-06, loss after: 2.33575178754e-06.\n",
      "Epoch:15, weight train batch: 318, step:21, loss before: 2.32457614402e-06, loss after: 2.32457614402e-06.\n",
      "Epoch:15, weight train batch: 318, step:22, loss before: 2.98395025311e-06, loss after: 2.98395025311e-06.\n",
      "Epoch:15, weight train batch: 318, step:23, loss before: 4.61918443762e-06, loss after: 4.61173476651e-06.\n",
      "Epoch:15, weight train batch: 318, step:24, loss before: 1.87381738215e-06, loss after: 1.87381738215e-06.\n",
      "Epoch:15, weight train batch: 318, step:25, loss before: 3.06218089463e-06, loss after: 3.06218089463e-06.\n",
      "Epoch:15, weight train batch: 318, step:26, loss before: 2.22771836889e-06, loss after: 2.22771836889e-06.\n",
      "Epoch:15, weight train batch: 318, step:27, loss before: 2.71945509667e-06, loss after: 2.71945509667e-06.\n",
      "Epoch:15, weight train batch: 318, step:28, loss before: 1.82538872195e-06, loss after: 1.82538872195e-06.\n",
      "Epoch:15, weight train batch: 318, step:29, loss before: 2.22771859626e-06, loss after: 2.22771859626e-06.\n",
      "Epoch:15, weight train batch: 318, step:30, loss before: 2.48103765443e-06, loss after: 2.48103765443e-06.\n",
      "Epoch:15, weight train batch: 318, step:31, loss before: 2.26124620895e-06, loss after: 2.26124620895e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 314, loss before: 2.50152675108e-06, loss after: 2.51270262197e-06.\n",
      "Epoch:15, weight train batch: 319, step:0, loss before: 1.75088302967e-06, loss after: 1.75088302967e-06.\n",
      "Epoch:15, weight train batch: 319, step:1, loss before: 2.10105895349e-06, loss after: 2.10105895349e-06.\n",
      "Epoch:15, weight train batch: 319, step:2, loss before: 1.79558639957e-06, loss after: 1.77323465778e-06.\n",
      "Epoch:15, weight train batch: 319, step:3, loss before: 2.35437801166e-06, loss after: 2.35437801166e-06.\n",
      "Epoch:15, weight train batch: 319, step:4, loss before: 1.75833349658e-06, loss after: 1.75833349658e-06.\n",
      "Epoch:15, weight train batch: 319, step:5, loss before: 2.38790562435e-06, loss after: 2.38790562435e-06.\n",
      "Epoch:15, weight train batch: 319, step:6, loss before: 2.72318038697e-06, loss after: 2.72318038697e-06.\n",
      "Epoch:15, weight train batch: 319, step:7, loss before: 1.59442129188e-06, loss after: 1.59442129188e-06.\n",
      "Epoch:15, weight train batch: 319, step:8, loss before: 2.27987243306e-06, loss after: 2.27987243306e-06.\n",
      "Epoch:15, weight train batch: 319, step:9, loss before: 2.20536685447e-06, loss after: 2.20536685447e-06.\n",
      "Epoch:15, weight train batch: 319, step:10, loss before: 1.98930092665e-06, loss after: 1.98930092665e-06.\n",
      "Epoch:15, weight train batch: 319, step:11, loss before: 1.46776187648e-06, loss after: 1.46776187648e-06.\n",
      "Epoch:15, weight train batch: 319, step:12, loss before: 1.98930092665e-06, loss after: 1.98930092665e-06.\n",
      "Epoch:15, weight train batch: 319, step:13, loss before: 1.545992518e-06, loss after: 1.545992518e-06.\n",
      "Epoch:15, weight train batch: 319, step:14, loss before: 1.93342157218e-06, loss after: 1.93342157218e-06.\n",
      "Epoch:15, weight train batch: 319, step:15, loss before: 2.08615801967e-06, loss after: 2.08615801967e-06.\n",
      "Epoch:15, weight train batch: 319, step:16, loss before: 2.09360860026e-06, loss after: 2.09360860026e-06.\n",
      "Epoch:15, weight train batch: 319, step:17, loss before: 6.44822966933e-06, loss after: 6.44450437903e-06.\n",
      "Epoch:15, weight train batch: 319, step:18, loss before: 1.63539948517e-06, loss after: 1.63539948517e-06.\n",
      "Epoch:15, weight train batch: 319, step:19, loss before: 1.78813581897e-06, loss after: 1.78813581897e-06.\n",
      "Epoch:15, weight train batch: 319, step:20, loss before: 2.39535597757e-06, loss after: 2.39535597757e-06.\n",
      "Epoch:15, weight train batch: 319, step:21, loss before: 1.7210805936e-06, loss after: 1.7210805936e-06.\n",
      "Epoch:15, weight train batch: 319, step:22, loss before: 2.13831208384e-06, loss after: 2.13831208384e-06.\n",
      "Epoch:15, weight train batch: 319, step:23, loss before: 1.60932245308e-06, loss after: 1.60932245308e-06.\n",
      "Epoch:15, weight train batch: 319, step:24, loss before: 1.66520180755e-06, loss after: 1.66520180755e-06.\n",
      "Epoch:15, weight train batch: 319, step:25, loss before: 2.20909214477e-06, loss after: 2.20909214477e-06.\n",
      "Epoch:15, weight train batch: 319, step:26, loss before: 2.41398265644e-06, loss after: 2.41398265644e-06.\n",
      "Epoch:15, weight train batch: 319, step:27, loss before: 3.21118841384e-06, loss after: 3.21118841384e-06.\n",
      "Epoch:15, weight train batch: 319, step:28, loss before: 2.30222417485e-06, loss after: 2.30222417485e-06.\n",
      "Epoch:15, weight train batch: 319, step:29, loss before: 1.61304774338e-06, loss after: 1.61304774338e-06.\n",
      "Epoch:15, weight train batch: 319, step:30, loss before: 6.42577506369e-05, loss after: 6.42168524791e-05.\n",
      "Epoch:15, weight train batch: 319, step:31, loss before: 2.08988330996e-06, loss after: 2.06008121495e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:15, struct parameters train batch: 315, loss before: 1.89896331904e-06, loss after: 1.89896331904e-06.\n",
      "Epoch:16, weight train batch: 320, step:0, loss before: 2.29849865718e-06, loss after: 2.29849865718e-06.\n",
      "Epoch:16, weight train batch: 320, step:1, loss before: 2.84984025711e-06, loss after: 2.84984025711e-06.\n",
      "Epoch:16, weight train batch: 320, step:2, loss before: 2.26497149924e-06, loss after: 2.26497149924e-06.\n",
      "Epoch:16, weight train batch: 320, step:3, loss before: 2.66357619694e-06, loss after: 2.66357619694e-06.\n",
      "Epoch:16, weight train batch: 320, step:4, loss before: 2.21654295274e-06, loss after: 2.21654295274e-06.\n",
      "Epoch:16, weight train batch: 320, step:5, loss before: 2.23889469453e-06, loss after: 2.23889469453e-06.\n",
      "Epoch:16, weight train batch: 320, step:6, loss before: 2.50338939622e-06, loss after: 2.50338939622e-06.\n",
      "Epoch:16, weight train batch: 320, step:7, loss before: 2.07498237614e-06, loss after: 2.07498237614e-06.\n",
      "Epoch:16, weight train batch: 320, step:8, loss before: 1.47893797475e-06, loss after: 1.47893797475e-06.\n",
      "Epoch:16, weight train batch: 320, step:9, loss before: 2.44378497882e-06, loss after: 2.44378497882e-06.\n",
      "Epoch:16, weight train batch: 320, step:10, loss before: 1.96694941224e-06, loss after: 1.96694941224e-06.\n",
      "Epoch:16, weight train batch: 320, step:11, loss before: 5.47228773939e-06, loss after: 5.47228773939e-06.\n",
      "Epoch:16, weight train batch: 320, step:12, loss before: 1.56834448717e-06, loss after: 1.54226745508e-06.\n",
      "Epoch:16, weight train batch: 320, step:13, loss before: 1.75460831997e-06, loss after: 1.75460831997e-06.\n",
      "Epoch:16, weight train batch: 320, step:14, loss before: 2.01910324904e-06, loss after: 2.01910324904e-06.\n",
      "Epoch:16, weight train batch: 320, step:15, loss before: 2.32085039897e-06, loss after: 2.28359795074e-06.\n",
      "Epoch:16, weight train batch: 320, step:16, loss before: 2.09733389056e-06, loss after: 2.09733389056e-06.\n",
      "Epoch:16, weight train batch: 320, step:17, loss before: 2.01910324904e-06, loss after: 2.01910324904e-06.\n",
      "Epoch:16, weight train batch: 320, step:18, loss before: 2.30967475545e-06, loss after: 2.30967475545e-06.\n",
      "Epoch:16, weight train batch: 320, step:19, loss before: 1.21444281831e-06, loss after: 1.21444281831e-06.\n",
      "Epoch:16, weight train batch: 320, step:20, loss before: 1.65775099958e-06, loss after: 1.65775099958e-06.\n",
      "Epoch:16, weight train batch: 320, step:21, loss before: 2.11223505175e-06, loss after: 2.11223505175e-06.\n",
      "Epoch:16, weight train batch: 320, step:22, loss before: 1.83283930255e-06, loss after: 1.83283930255e-06.\n",
      "Epoch:16, weight train batch: 320, step:23, loss before: 5.77396303925e-06, loss after: 5.7702382037e-06.\n",
      "Epoch:16, weight train batch: 320, step:24, loss before: 2.29849865718e-06, loss after: 2.29849865718e-06.\n",
      "Epoch:16, weight train batch: 320, step:25, loss before: 0.000940607045777, loss after: 0.000938824785408.\n",
      "Epoch:16, weight train batch: 320, step:26, loss before: 1.68010262769e-06, loss after: 1.68010262769e-06.\n",
      "Epoch:16, weight train batch: 320, step:27, loss before: 1.35972879889e-06, loss after: 1.35972879889e-06.\n",
      "Epoch:16, weight train batch: 320, step:28, loss before: 1.98930092665e-06, loss after: 1.98930092665e-06.\n",
      "Epoch:16, weight train batch: 320, step:29, loss before: 3.26331837641e-06, loss after: 3.25959308611e-06.\n",
      "Epoch:16, weight train batch: 320, step:30, loss before: 2.00420208785e-06, loss after: 2.00420208785e-06.\n",
      "Epoch:16, weight train batch: 320, step:31, loss before: 1.66520158018e-06, loss after: 1.66520158018e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 316, loss before: 2.068462436e-06, loss after: 1.93621599465e-06.\n",
      "Epoch:16, weight train batch: 321, step:0, loss before: 2.01165244107e-06, loss after: 2.01165244107e-06.\n",
      "Epoch:16, weight train batch: 321, step:1, loss before: 0.000432358472608, loss after: 0.000430837273598.\n",
      "Epoch:16, weight train batch: 321, step:2, loss before: 6.4988656959e-05, loss after: 6.50444271741e-05.\n",
      "Epoch:16, weight train batch: 321, step:3, loss before: 2.00792715077e-06, loss after: 2.00792715077e-06.\n",
      "Epoch:16, weight train batch: 321, step:4, loss before: 1.98185034606e-06, loss after: 1.98185034606e-06.\n",
      "Epoch:16, weight train batch: 321, step:5, loss before: 1.99675150725e-06, loss after: 1.99675150725e-06.\n",
      "Epoch:16, weight train batch: 321, step:6, loss before: 1.72108093466e-06, loss after: 1.72108093466e-06.\n",
      "Epoch:16, weight train batch: 321, step:7, loss before: 1.780685011e-06, loss after: 1.780685011e-06.\n",
      "Epoch:16, weight train batch: 321, step:8, loss before: 2.52945983448e-06, loss after: 2.52573477155e-06.\n",
      "Epoch:16, weight train batch: 321, step:9, loss before: 5.79626794206e-06, loss after: 5.79254356126e-06.\n",
      "Epoch:16, weight train batch: 321, step:10, loss before: 1.4938386812e-06, loss after: 1.4938386812e-06.\n",
      "Epoch:16, weight train batch: 321, step:11, loss before: 0.0022722564172, loss after: 0.00224627065472.\n",
      "Epoch:16, weight train batch: 321, step:12, loss before: 1.94832273337e-06, loss after: 1.94832273337e-06.\n",
      "Epoch:16, weight train batch: 321, step:13, loss before: 1.84774023637e-06, loss after: 1.84774023637e-06.\n",
      "Epoch:16, weight train batch: 321, step:14, loss before: 1.75460843366e-06, loss after: 1.75460843366e-06.\n",
      "Epoch:16, weight train batch: 321, step:15, loss before: 2.45123533205e-06, loss after: 2.42888359026e-06.\n",
      "Epoch:16, weight train batch: 321, step:16, loss before: 1.68382803167e-06, loss after: 1.68382803167e-06.\n",
      "Epoch:16, weight train batch: 321, step:17, loss before: 2.30222440223e-06, loss after: 2.30222440223e-06.\n",
      "Epoch:16, weight train batch: 321, step:18, loss before: 6.49651774438e-05, loss after: 6.49763314868e-05.\n",
      "Epoch:16, weight train batch: 321, step:19, loss before: 2.69337806458e-06, loss after: 2.69337806458e-06.\n",
      "Epoch:16, weight train batch: 321, step:20, loss before: 2.22771836889e-06, loss after: 2.22771836889e-06.\n",
      "Epoch:16, weight train batch: 321, step:21, loss before: 1.76950925379e-06, loss after: 1.76950925379e-06.\n",
      "Epoch:16, weight train batch: 321, step:22, loss before: 1.7583333829e-06, loss after: 1.7583333829e-06.\n",
      "Epoch:16, weight train batch: 321, step:23, loss before: 1.70245436948e-06, loss after: 1.70245436948e-06.\n",
      "Epoch:16, weight train batch: 321, step:24, loss before: 2.16066359826e-06, loss after: 2.16066359826e-06.\n",
      "Epoch:16, weight train batch: 321, step:25, loss before: 1.66520158018e-06, loss after: 1.66520158018e-06.\n",
      "Epoch:16, weight train batch: 321, step:26, loss before: 1.6279486772e-06, loss after: 1.6279486772e-06.\n",
      "Epoch:16, weight train batch: 321, step:27, loss before: 1.99675150725e-06, loss after: 1.99675150725e-06.\n",
      "Epoch:16, weight train batch: 321, step:28, loss before: 2.08243272937e-06, loss after: 2.08243272937e-06.\n",
      "Epoch:16, weight train batch: 321, step:29, loss before: 6.20232731308e-06, loss after: 6.20232731308e-06.\n",
      "Epoch:16, weight train batch: 321, step:30, loss before: 1.52736629389e-06, loss after: 1.52736629389e-06.\n",
      "Epoch:16, weight train batch: 321, step:31, loss before: 1.78068512469e-06, loss after: 1.78068512469e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 317, loss before: 2.01817056222e-06, loss after: 1.84867178632e-06.\n",
      "Epoch:16, weight train batch: 322, step:0, loss before: 1.46776164911e-06, loss after: 1.46776164911e-06.\n",
      "Epoch:16, weight train batch: 322, step:1, loss before: 1.05425590391e-06, loss after: 1.05425590391e-06.\n",
      "Epoch:16, weight train batch: 322, step:2, loss before: 2.54064161709e-06, loss after: 2.54064161709e-06.\n",
      "Epoch:16, weight train batch: 322, step:3, loss before: 2.87591683445e-06, loss after: 2.87591683445e-06.\n",
      "Epoch:16, weight train batch: 322, step:4, loss before: 1.34855281431e-06, loss after: 1.34855281431e-06.\n",
      "Epoch:16, weight train batch: 322, step:5, loss before: 2.06753156817e-06, loss after: 2.03400418286e-06.\n",
      "Epoch:16, weight train batch: 322, step:6, loss before: 2.64494974545e-06, loss after: 2.64494974545e-06.\n",
      "Epoch:16, weight train batch: 322, step:7, loss before: 1.92969628188e-06, loss after: 1.92969628188e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16, weight train batch: 322, step:8, loss before: 2.54809265243e-06, loss after: 2.54809265243e-06.\n",
      "Epoch:16, weight train batch: 322, step:9, loss before: 1.62422361427e-06, loss after: 1.62422361427e-06.\n",
      "Epoch:16, weight train batch: 322, step:10, loss before: 2.08243272937e-06, loss after: 2.08243272937e-06.\n",
      "Epoch:16, weight train batch: 322, step:11, loss before: 2.23144388656e-06, loss after: 2.23144388656e-06.\n",
      "Epoch:16, weight train batch: 322, step:12, loss before: 2.07870743907e-06, loss after: 2.07870743907e-06.\n",
      "Epoch:16, weight train batch: 322, step:13, loss before: 1.62422361427e-06, loss after: 1.62422361427e-06.\n",
      "Epoch:16, weight train batch: 322, step:14, loss before: 2.37300446315e-06, loss after: 2.37300446315e-06.\n",
      "Epoch:16, weight train batch: 322, step:15, loss before: 2.73435671261e-06, loss after: 2.73435671261e-06.\n",
      "Epoch:16, weight train batch: 322, step:16, loss before: 2.35810352933e-06, loss after: 2.35810352933e-06.\n",
      "Epoch:16, weight train batch: 322, step:17, loss before: 2.20164156417e-06, loss after: 2.20164156417e-06.\n",
      "Epoch:16, weight train batch: 322, step:18, loss before: 1.85519093066e-06, loss after: 1.85519093066e-06.\n",
      "Epoch:16, weight train batch: 322, step:19, loss before: 1.60559693541e-06, loss after: 1.60559693541e-06.\n",
      "Epoch:16, weight train batch: 322, step:20, loss before: 1.5608936792e-06, loss after: 1.5608936792e-06.\n",
      "Epoch:16, weight train batch: 322, step:21, loss before: 2.23889446715e-06, loss after: 2.20536685447e-06.\n",
      "Epoch:16, weight train batch: 322, step:22, loss before: 1.85146541298e-06, loss after: 1.85146541298e-06.\n",
      "Epoch:16, weight train batch: 322, step:23, loss before: 2.32830097957e-06, loss after: 2.32830097957e-06.\n",
      "Epoch:16, weight train batch: 322, step:24, loss before: 2.38418056142e-06, loss after: 2.38418056142e-06.\n",
      "Epoch:16, weight train batch: 322, step:25, loss before: 2.09733411793e-06, loss after: 2.09733411793e-06.\n",
      "Epoch:16, weight train batch: 322, step:26, loss before: 1.71363012669e-06, loss after: 1.71363012669e-06.\n",
      "Epoch:16, weight train batch: 322, step:27, loss before: 1.84028954209e-06, loss after: 1.84028954209e-06.\n",
      "Epoch:16, weight train batch: 322, step:28, loss before: 1.82538872195e-06, loss after: 1.82538872195e-06.\n",
      "Epoch:16, weight train batch: 322, step:29, loss before: 1.47148716678e-06, loss after: 1.47148716678e-06.\n",
      "Epoch:16, weight train batch: 322, step:30, loss before: 1.76950936748e-06, loss after: 1.76950936748e-06.\n",
      "Epoch:16, weight train batch: 322, step:31, loss before: 2.51083974945e-06, loss after: 2.51083974945e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 318, loss before: 2.08057008422e-06, loss after: 2.08057008422e-06.\n",
      "Epoch:16, weight train batch: 323, step:0, loss before: 1.1101351447e-06, loss after: 1.1101351447e-06.\n",
      "Epoch:16, weight train batch: 323, step:1, loss before: 1.87009186448e-06, loss after: 1.84028965577e-06.\n",
      "Epoch:16, weight train batch: 323, step:2, loss before: 2.59652142631e-06, loss after: 2.59652142631e-06.\n",
      "Epoch:16, weight train batch: 323, step:3, loss before: 2.32085062635e-06, loss after: 2.32085062635e-06.\n",
      "Epoch:16, weight train batch: 323, step:4, loss before: 2.0153765945e-06, loss after: 2.0153765945e-06.\n",
      "Epoch:16, weight train batch: 323, step:5, loss before: 5.20400772075e-06, loss after: 5.20400772075e-06.\n",
      "Epoch:16, weight train batch: 323, step:6, loss before: 1.93342179955e-06, loss after: 1.93342179955e-06.\n",
      "Epoch:16, weight train batch: 323, step:7, loss before: 1.50501466578e-06, loss after: 1.50501466578e-06.\n",
      "Epoch:16, weight train batch: 323, step:8, loss before: 2.25007056542e-06, loss after: 2.25007056542e-06.\n",
      "Epoch:16, weight train batch: 323, step:9, loss before: 2.04518028113e-06, loss after: 2.04518028113e-06.\n",
      "Epoch:16, weight train batch: 323, step:10, loss before: 2.6337743293e-06, loss after: 2.6337743293e-06.\n",
      "Epoch:16, weight train batch: 323, step:11, loss before: 2.18674085772e-06, loss after: 2.18674085772e-06.\n",
      "Epoch:16, weight train batch: 323, step:12, loss before: 2.47731259151e-06, loss after: 2.47731259151e-06.\n",
      "Epoch:16, weight train batch: 323, step:13, loss before: 1.4714870531e-06, loss after: 1.4714870531e-06.\n",
      "Epoch:16, weight train batch: 323, step:14, loss before: 1.89244371995e-06, loss after: 1.89244371995e-06.\n",
      "Epoch:16, weight train batch: 323, step:15, loss before: 2.00792737814e-06, loss after: 2.00792737814e-06.\n",
      "Epoch:16, weight train batch: 323, step:16, loss before: 6.57427808619e-05, loss after: 6.54676696286e-05.\n",
      "Epoch:16, weight train batch: 323, step:17, loss before: 2.17929027713e-06, loss after: 2.17929027713e-06.\n",
      "Epoch:16, weight train batch: 323, step:18, loss before: 2.07498214877e-06, loss after: 2.07498214877e-06.\n",
      "Epoch:16, weight train batch: 323, step:19, loss before: 2.16811440623e-06, loss after: 2.16811440623e-06.\n",
      "Epoch:16, weight train batch: 323, step:20, loss before: 2.03772970053e-06, loss after: 2.05635615202e-06.\n",
      "Epoch:16, weight train batch: 323, step:21, loss before: 2.18674085772e-06, loss after: 2.18674085772e-06.\n",
      "Epoch:16, weight train batch: 323, step:22, loss before: 1.76950948116e-06, loss after: 1.76950948116e-06.\n",
      "Epoch:16, weight train batch: 323, step:23, loss before: 1.59814658218e-06, loss after: 1.59814658218e-06.\n",
      "Epoch:16, weight train batch: 323, step:24, loss before: 2.08243181987e-06, loss after: 2.08243181987e-06.\n",
      "Epoch:16, weight train batch: 323, step:25, loss before: 2.16066382563e-06, loss after: 2.16066382563e-06.\n",
      "Epoch:16, weight train batch: 323, step:26, loss before: 2.57416400018e-06, loss after: 2.57416400018e-06.\n",
      "Epoch:16, weight train batch: 323, step:27, loss before: 1.88499313936e-06, loss after: 1.88499313936e-06.\n",
      "Epoch:16, weight train batch: 323, step:28, loss before: 1.80676238415e-06, loss after: 1.80676238415e-06.\n",
      "Epoch:16, weight train batch: 323, step:29, loss before: 2.07870766644e-06, loss after: 2.04518028113e-06.\n",
      "Epoch:16, weight train batch: 323, step:30, loss before: 2.14576266444e-06, loss after: 2.14576266444e-06.\n",
      "Epoch:16, weight train batch: 323, step:31, loss before: 1.77323499884e-06, loss after: 1.77323499884e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 319, loss before: 1.8309766574e-06, loss after: 1.91945173356e-06.\n",
      "Epoch:16, weight train batch: 324, step:0, loss before: 2.00047702492e-06, loss after: 2.00047702492e-06.\n",
      "Epoch:16, weight train batch: 324, step:1, loss before: 2.02655382964e-06, loss after: 2.02655382964e-06.\n",
      "Epoch:16, weight train batch: 324, step:2, loss before: 2.42143346441e-06, loss after: 2.42143346441e-06.\n",
      "Epoch:16, weight train batch: 324, step:3, loss before: 1.89244394733e-06, loss after: 1.86264162494e-06.\n",
      "Epoch:16, weight train batch: 324, step:4, loss before: 1.86264173863e-06, loss after: 1.86264173863e-06.\n",
      "Epoch:16, weight train batch: 324, step:5, loss before: 1.89989441424e-06, loss after: 1.89989441424e-06.\n",
      "Epoch:16, weight train batch: 324, step:6, loss before: 1.66147651726e-06, loss after: 1.66147651726e-06.\n",
      "Epoch:16, weight train batch: 324, step:7, loss before: 1.67637756476e-06, loss after: 1.67637756476e-06.\n",
      "Epoch:16, weight train batch: 324, step:8, loss before: 1.82538872195e-06, loss after: 1.82538872195e-06.\n",
      "Epoch:16, weight train batch: 324, step:9, loss before: 1.97439976546e-06, loss after: 1.97439976546e-06.\n",
      "Epoch:16, weight train batch: 324, step:10, loss before: 1.86264162494e-06, loss after: 1.86264162494e-06.\n",
      "Epoch:16, weight train batch: 324, step:11, loss before: 2.01165266844e-06, loss after: 2.01165266844e-06.\n",
      "Epoch:16, weight train batch: 324, step:12, loss before: 1.44541036207e-06, loss after: 1.44541036207e-06.\n",
      "Epoch:16, weight train batch: 324, step:13, loss before: 2.06380627787e-06, loss after: 2.06380627787e-06.\n",
      "Epoch:16, weight train batch: 324, step:14, loss before: 2.23516917686e-06, loss after: 2.23516917686e-06.\n",
      "Epoch:16, weight train batch: 324, step:15, loss before: 2.15321347241e-06, loss after: 2.15321347241e-06.\n",
      "Epoch:16, weight train batch: 324, step:16, loss before: 5.25246605321e-06, loss after: 5.25246605321e-06.\n",
      "Epoch:16, weight train batch: 324, step:17, loss before: 1.1846407233e-06, loss after: 1.1846407233e-06.\n",
      "Epoch:16, weight train batch: 324, step:18, loss before: 1.71363058143e-06, loss after: 1.71363058143e-06.\n",
      "Epoch:16, weight train batch: 324, step:19, loss before: 1.95204825104e-06, loss after: 1.95204825104e-06.\n",
      "Epoch:16, weight train batch: 324, step:20, loss before: 1.60932268045e-06, loss after: 1.60932268045e-06.\n",
      "Epoch:16, weight train batch: 324, step:21, loss before: 2.04890557143e-06, loss after: 2.04890557143e-06.\n",
      "Epoch:16, weight train batch: 324, step:22, loss before: 1.38580571729e-06, loss after: 1.38580571729e-06.\n",
      "Epoch:16, weight train batch: 324, step:23, loss before: 1.57206977747e-06, loss after: 1.57206977747e-06.\n",
      "Epoch:16, weight train batch: 324, step:24, loss before: 2.12341115002e-06, loss after: 2.12341115002e-06.\n",
      "Epoch:16, weight train batch: 324, step:25, loss before: 1.67637756476e-06, loss after: 1.67637756476e-06.\n",
      "Epoch:16, weight train batch: 324, step:26, loss before: 1.57206977747e-06, loss after: 1.57206977747e-06.\n",
      "Epoch:16, weight train batch: 324, step:27, loss before: 0.000892620242666, loss after: 0.000890878669452.\n",
      "Epoch:16, weight train batch: 324, step:28, loss before: 2.27987266044e-06, loss after: 2.26497149924e-06.\n",
      "Epoch:16, weight train batch: 324, step:29, loss before: 2.70455484497e-06, loss after: 2.70455484497e-06.\n",
      "Epoch:16, weight train batch: 324, step:30, loss before: 4.14187634306e-05, loss after: 4.11992477893e-05.\n",
      "Epoch:16, weight train batch: 324, step:31, loss before: 2.11596056943e-06, loss after: 2.11596056943e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 320, loss before: 1.52643497131e-06, loss after: 0.000220946210902.\n",
      "Epoch:16, weight train batch: 325, step:0, loss before: 2.35065317611e-06, loss after: 2.35065317611e-06.\n",
      "Epoch:16, weight train batch: 325, step:1, loss before: 1.3597286852e-06, loss after: 1.3597286852e-06.\n",
      "Epoch:16, weight train batch: 325, step:2, loss before: 2.08243272937e-06, loss after: 2.08243272937e-06.\n",
      "Epoch:16, weight train batch: 325, step:3, loss before: 1.43050920087e-06, loss after: 1.43050920087e-06.\n",
      "Epoch:16, weight train batch: 325, step:4, loss before: 2.24634527513e-06, loss after: 2.24634527513e-06.\n",
      "Epoch:16, weight train batch: 325, step:5, loss before: 1.25914630189e-06, loss after: 1.25914630189e-06.\n",
      "Epoch:16, weight train batch: 325, step:6, loss before: 1.88499325304e-06, loss after: 1.88499325304e-06.\n",
      "Epoch:16, weight train batch: 325, step:7, loss before: 2.25752114602e-06, loss after: 2.25752114602e-06.\n",
      "Epoch:16, weight train batch: 325, step:8, loss before: 2.26497195399e-06, loss after: 2.26497195399e-06.\n",
      "Epoch:16, weight train batch: 325, step:9, loss before: 1.86264162494e-06, loss after: 1.86264162494e-06.\n",
      "Epoch:16, weight train batch: 325, step:10, loss before: 2.34320259551e-06, loss after: 2.34320259551e-06.\n",
      "Epoch:16, weight train batch: 325, step:11, loss before: 1.40070687848e-06, loss after: 1.40070687848e-06.\n",
      "Epoch:16, weight train batch: 325, step:12, loss before: 1.92224592865e-06, loss after: 1.92224592865e-06.\n",
      "Epoch:16, weight train batch: 325, step:13, loss before: 2.41398288381e-06, loss after: 2.41398288381e-06.\n",
      "Epoch:16, weight train batch: 325, step:14, loss before: 1.27777275338e-06, loss after: 1.27777275338e-06.\n",
      "Epoch:16, weight train batch: 325, step:15, loss before: 1.65402582297e-06, loss after: 1.65402582297e-06.\n",
      "Epoch:16, weight train batch: 325, step:16, loss before: 2.13831208384e-06, loss after: 2.13831208384e-06.\n",
      "Epoch:16, weight train batch: 325, step:17, loss before: 2.07125708584e-06, loss after: 2.07125708584e-06.\n",
      "Epoch:16, weight train batch: 325, step:18, loss before: 9.61123873822e-07, loss after: 9.61123873822e-07.\n",
      "Epoch:16, weight train batch: 325, step:19, loss before: 1.76205878688e-06, loss after: 1.76205878688e-06.\n",
      "Epoch:16, weight train batch: 325, step:20, loss before: 1.28894862428e-06, loss after: 1.27404746308e-06.\n",
      "Epoch:16, weight train batch: 325, step:21, loss before: 2.22771905101e-06, loss after: 2.22771905101e-06.\n",
      "Epoch:16, weight train batch: 325, step:22, loss before: 1.91107028513e-06, loss after: 1.91107028513e-06.\n",
      "Epoch:16, weight train batch: 325, step:23, loss before: 1.51246524638e-06, loss after: 1.51246524638e-06.\n",
      "Epoch:16, weight train batch: 325, step:24, loss before: 1.53481687448e-06, loss after: 1.53481687448e-06.\n",
      "Epoch:16, weight train batch: 325, step:25, loss before: 2.27242117035e-06, loss after: 2.27242117035e-06.\n",
      "Epoch:16, weight train batch: 325, step:26, loss before: 4.27654140367e-06, loss after: 4.27281656812e-06.\n",
      "Epoch:16, weight train batch: 325, step:27, loss before: 1.79186122296e-06, loss after: 1.79186122296e-06.\n",
      "Epoch:16, weight train batch: 325, step:28, loss before: 2.72318084171e-06, loss after: 2.72318084171e-06.\n",
      "Epoch:16, weight train batch: 325, step:29, loss before: 1.70245425579e-06, loss after: 1.70245425579e-06.\n",
      "Epoch:16, weight train batch: 325, step:30, loss before: 2.20536730922e-06, loss after: 2.20536730922e-06.\n",
      "Epoch:16, weight train batch: 325, step:31, loss before: 1.49011361827e-06, loss after: 1.49011361827e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 321, loss before: 1.73691341843e-06, loss after: 1.73691341843e-06.\n",
      "Epoch:16, weight train batch: 326, step:0, loss before: 1.91852086573e-06, loss after: 1.91852086573e-06.\n",
      "Epoch:16, weight train batch: 326, step:1, loss before: 2.05263063435e-06, loss after: 2.05263063435e-06.\n",
      "Epoch:16, weight train batch: 326, step:2, loss before: 3.16648925036e-06, loss after: 3.16648925036e-06.\n",
      "Epoch:16, weight train batch: 326, step:3, loss before: 1.82166354534e-06, loss after: 1.82166354534e-06.\n",
      "Epoch:16, weight train batch: 326, step:4, loss before: 1.93342179955e-06, loss after: 1.93342179955e-06.\n",
      "Epoch:16, weight train batch: 326, step:5, loss before: 2.20909191739e-06, loss after: 2.20909191739e-06.\n",
      "Epoch:16, weight train batch: 326, step:6, loss before: 2.04145476346e-06, loss after: 2.04145476346e-06.\n",
      "Epoch:16, weight train batch: 326, step:7, loss before: 4.22062385041e-06, loss after: 4.22062385041e-06.\n",
      "Epoch:16, weight train batch: 326, step:8, loss before: 1.54226768245e-06, loss after: 1.54226768245e-06.\n",
      "Epoch:16, weight train batch: 326, step:9, loss before: 3.9300912249e-06, loss after: 3.9300912249e-06.\n",
      "Epoch:16, weight train batch: 326, step:10, loss before: 1.48266292399e-06, loss after: 1.48266292399e-06.\n",
      "Epoch:16, weight train batch: 326, step:11, loss before: 1.78068535206e-06, loss after: 1.78068535206e-06.\n",
      "Epoch:16, weight train batch: 326, step:12, loss before: 1.95949883164e-06, loss after: 1.95949883164e-06.\n",
      "Epoch:16, weight train batch: 326, step:13, loss before: 2.06008144232e-06, loss after: 2.06008144232e-06.\n",
      "Epoch:16, weight train batch: 326, step:14, loss before: 5.46476621821e-06, loss after: 5.46476621821e-06.\n",
      "Epoch:16, weight train batch: 326, step:15, loss before: 2.04890534405e-06, loss after: 2.04890534405e-06.\n",
      "Epoch:16, weight train batch: 326, step:16, loss before: 1.76950948116e-06, loss after: 1.76950948116e-06.\n",
      "Epoch:16, weight train batch: 326, step:17, loss before: 1.63539948517e-06, loss after: 1.63539948517e-06.\n",
      "Epoch:16, weight train batch: 326, step:18, loss before: 0.021662697196, loss after: 0.021662697196.\n",
      "Epoch:16, weight train batch: 326, step:19, loss before: 1.91852086573e-06, loss after: 1.91852086573e-06.\n",
      "Epoch:16, weight train batch: 326, step:20, loss before: 2.22026847041e-06, loss after: 2.22026847041e-06.\n",
      "Epoch:16, weight train batch: 326, step:21, loss before: 1.90361959085e-06, loss after: 1.87009209185e-06.\n",
      "Epoch:16, weight train batch: 326, step:22, loss before: 1.88871854334e-06, loss after: 1.88871854334e-06.\n",
      "Epoch:16, weight train batch: 326, step:23, loss before: 4.69742326459e-06, loss after: 4.69742326459e-06.\n",
      "Epoch:16, weight train batch: 326, step:24, loss before: 2.45868614002e-06, loss after: 2.45868614002e-06.\n",
      "Epoch:16, weight train batch: 326, step:25, loss before: 1.69127883964e-06, loss after: 1.69127883964e-06.\n",
      "Epoch:16, weight train batch: 326, step:26, loss before: 1.70617965978e-06, loss after: 1.70617965978e-06.\n",
      "Epoch:16, weight train batch: 326, step:27, loss before: 1.12876159619e-06, loss after: 1.12876159619e-06.\n",
      "Epoch:16, weight train batch: 326, step:28, loss before: 2.02282853934e-06, loss after: 2.02282853934e-06.\n",
      "Epoch:16, weight train batch: 326, step:29, loss before: 2.03027911994e-06, loss after: 2.03027911994e-06.\n",
      "Epoch:16, weight train batch: 326, step:30, loss before: 4.95445056004e-06, loss after: 4.95072617923e-06.\n",
      "Epoch:16, weight train batch: 326, step:31, loss before: 1.61677303367e-06, loss after: 1.61677303367e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 322, loss before: 6.19567163085e-06, loss after: 1.61491038853e-06.\n",
      "Epoch:16, weight train batch: 327, step:0, loss before: 2.01910324904e-06, loss after: 2.01910324904e-06.\n",
      "Epoch:16, weight train batch: 327, step:1, loss before: 2.13458679355e-06, loss after: 2.13458679355e-06.\n",
      "Epoch:16, weight train batch: 327, step:2, loss before: 2.01910324904e-06, loss after: 2.01910324904e-06.\n",
      "Epoch:16, weight train batch: 327, step:3, loss before: 1.63167419487e-06, loss after: 1.63167419487e-06.\n",
      "Epoch:16, weight train batch: 327, step:4, loss before: 2.04837069759e-05, loss after: 2.04353073059e-05.\n",
      "Epoch:16, weight train batch: 327, step:5, loss before: 1.63539948517e-06, loss after: 1.63539948517e-06.\n",
      "Epoch:16, weight train batch: 327, step:6, loss before: 1.56834448717e-06, loss after: 1.56834448717e-06.\n",
      "Epoch:16, weight train batch: 327, step:7, loss before: 1.72480611127e-06, loss after: 1.72480611127e-06.\n",
      "Epoch:16, weight train batch: 327, step:8, loss before: 2.30222440223e-06, loss after: 2.30222440223e-06.\n",
      "Epoch:16, weight train batch: 327, step:9, loss before: 1.90734488115e-06, loss after: 1.90734488115e-06.\n",
      "Epoch:16, weight train batch: 327, step:10, loss before: 3.93012714994e-06, loss after: 3.93012714994e-06.\n",
      "Epoch:16, weight train batch: 327, step:11, loss before: 2.06008144232e-06, loss after: 2.06008144232e-06.\n",
      "Epoch:16, weight train batch: 327, step:12, loss before: 1.46403658619e-06, loss after: 1.46403658619e-06.\n",
      "Epoch:16, weight train batch: 327, step:13, loss before: 1.21071752801e-06, loss after: 1.21071752801e-06.\n",
      "Epoch:16, weight train batch: 327, step:14, loss before: 1.92224615603e-06, loss after: 1.92224615603e-06.\n",
      "Epoch:16, weight train batch: 327, step:15, loss before: 1.86636668786e-06, loss after: 1.86636668786e-06.\n",
      "Epoch:16, weight train batch: 327, step:16, loss before: 1.50873995608e-06, loss after: 1.50873995608e-06.\n",
      "Epoch:16, weight train batch: 327, step:17, loss before: 3.64432562492e-05, loss after: 3.62944119843e-05.\n",
      "Epoch:16, weight train batch: 327, step:18, loss before: 1.19209107652e-06, loss after: 1.19209107652e-06.\n",
      "Epoch:16, weight train batch: 327, step:19, loss before: 1.2963989775e-06, loss after: 1.2963989775e-06.\n",
      "Epoch:16, weight train batch: 327, step:20, loss before: 2.17183969653e-06, loss after: 2.17183969653e-06.\n",
      "Epoch:16, weight train batch: 327, step:21, loss before: 1.44913542499e-06, loss after: 1.44913542499e-06.\n",
      "Epoch:16, weight train batch: 327, step:22, loss before: 5.51324365006e-06, loss after: 5.51324365006e-06.\n",
      "Epoch:16, weight train batch: 327, step:23, loss before: 1.15856357752e-06, loss after: 1.14366253001e-06.\n",
      "Epoch:16, weight train batch: 327, step:24, loss before: 2.20536730922e-06, loss after: 2.20536730922e-06.\n",
      "Epoch:16, weight train batch: 327, step:25, loss before: 5.40520341019e-06, loss after: 5.40520341019e-06.\n",
      "Epoch:16, weight train batch: 327, step:26, loss before: 1.73598220954e-06, loss after: 1.73598220954e-06.\n",
      "Epoch:16, weight train batch: 327, step:27, loss before: 1.20699246509e-06, loss after: 1.20699246509e-06.\n",
      "Epoch:16, weight train batch: 327, step:28, loss before: 1.43423449117e-06, loss after: 1.43423449117e-06.\n",
      "Epoch:16, weight train batch: 327, step:29, loss before: 2.01165312319e-06, loss after: 2.01165312319e-06.\n",
      "Epoch:16, weight train batch: 327, step:30, loss before: 3.98600650442e-06, loss after: 3.98600650442e-06.\n",
      "Epoch:16, weight train batch: 327, step:31, loss before: 1.01327771063e-06, loss after: 1.01327771063e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 323, loss before: 1.73970772721e-06, loss after: 2.57319607044e-06.\n",
      "Epoch:16, weight train batch: 328, step:0, loss before: 1.3038495581e-06, loss after: 1.3038495581e-06.\n",
      "Epoch:16, weight train batch: 328, step:1, loss before: 1.996751962e-06, loss after: 1.996751962e-06.\n",
      "Epoch:16, weight train batch: 328, step:2, loss before: 4.96190341437e-06, loss after: 4.95817812407e-06.\n",
      "Epoch:16, weight train batch: 328, step:3, loss before: 1.95204847842e-06, loss after: 1.95204847842e-06.\n",
      "Epoch:16, weight train batch: 328, step:4, loss before: 1.48638844166e-06, loss after: 1.48638844166e-06.\n",
      "Epoch:16, weight train batch: 328, step:5, loss before: 2.01537818612e-06, loss after: 1.99302644432e-06.\n",
      "Epoch:16, weight train batch: 328, step:6, loss before: 1.47893786107e-06, loss after: 1.47893786107e-06.\n",
      "Epoch:16, weight train batch: 328, step:7, loss before: 1.54971803568e-06, loss after: 1.54971803568e-06.\n",
      "Epoch:16, weight train batch: 328, step:8, loss before: 1.64284995208e-06, loss after: 1.64284995208e-06.\n",
      "Epoch:16, weight train batch: 328, step:9, loss before: 1.44913553868e-06, loss after: 1.44913553868e-06.\n",
      "Epoch:16, weight train batch: 328, step:10, loss before: 1.15483840091e-06, loss after: 1.15483840091e-06.\n",
      "Epoch:16, weight train batch: 328, step:11, loss before: 3.16271984957e-06, loss after: 3.16271984957e-06.\n",
      "Epoch:16, weight train batch: 328, step:12, loss before: 1.34855281431e-06, loss after: 1.34855281431e-06.\n",
      "Epoch:16, weight train batch: 328, step:13, loss before: 1.86264173863e-06, loss after: 1.86264173863e-06.\n",
      "Epoch:16, weight train batch: 328, step:14, loss before: 1.73225680555e-06, loss after: 1.73225680555e-06.\n",
      "Epoch:16, weight train batch: 328, step:15, loss before: 1.25542078422e-06, loss after: 1.25542078422e-06.\n",
      "Epoch:16, weight train batch: 328, step:16, loss before: 1.43050920087e-06, loss after: 1.43050920087e-06.\n",
      "Epoch:16, weight train batch: 328, step:17, loss before: 2.2537960831e-06, loss after: 2.2537960831e-06.\n",
      "Epoch:16, weight train batch: 328, step:18, loss before: 2.15693899008e-06, loss after: 2.15693899008e-06.\n",
      "Epoch:16, weight train batch: 328, step:19, loss before: 1.18836601359e-06, loss after: 1.18836601359e-06.\n",
      "Epoch:16, weight train batch: 328, step:20, loss before: 1.92224592865e-06, loss after: 1.92224592865e-06.\n",
      "Epoch:16, weight train batch: 328, step:21, loss before: 1.72108116203e-06, loss after: 1.72108116203e-06.\n",
      "Epoch:16, weight train batch: 328, step:22, loss before: 1.65402582297e-06, loss after: 1.65402582297e-06.\n",
      "Epoch:16, weight train batch: 328, step:23, loss before: 6.06732246524e-05, loss after: 6.04129454587e-05.\n",
      "Epoch:16, weight train batch: 328, step:24, loss before: 2.15321369978e-06, loss after: 2.15321369978e-06.\n",
      "Epoch:16, weight train batch: 328, step:25, loss before: 1.52364100359e-06, loss after: 1.52364100359e-06.\n",
      "Epoch:16, weight train batch: 328, step:26, loss before: 1.9185210931e-06, loss after: 1.9185210931e-06.\n",
      "Epoch:16, weight train batch: 328, step:27, loss before: 6.14952150499e-05, loss after: 6.14282471361e-05.\n",
      "Epoch:16, weight train batch: 328, step:28, loss before: 1.71363024037e-06, loss after: 1.71363024037e-06.\n",
      "Epoch:16, weight train batch: 328, step:29, loss before: 1.94832318812e-06, loss after: 1.94832318812e-06.\n",
      "Epoch:16, weight train batch: 328, step:30, loss before: 1.91479557543e-06, loss after: 1.91479557543e-06.\n",
      "Epoch:16, weight train batch: 328, step:31, loss before: 1.57579518145e-06, loss after: 1.57579518145e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 324, loss before: 1.77602873919e-06, loss after: 1.70618000084e-06.\n",
      "Epoch:16, weight train batch: 329, step:0, loss before: 1.58697037023e-06, loss after: 1.58697037023e-06.\n",
      "Epoch:16, weight train batch: 329, step:1, loss before: 1.47521018334e-06, loss after: 1.47148489305e-06.\n",
      "Epoch:16, weight train batch: 329, step:2, loss before: 2.1718399239e-06, loss after: 2.1718399239e-06.\n",
      "Epoch:16, weight train batch: 329, step:3, loss before: 1.86636680155e-06, loss after: 1.86636680155e-06.\n",
      "Epoch:16, weight train batch: 329, step:4, loss before: 0.000861728331074, loss after: 0.000859416031744.\n",
      "Epoch:16, weight train batch: 329, step:5, loss before: 1.38953100759e-06, loss after: 1.38953100759e-06.\n",
      "Epoch:16, weight train batch: 329, step:6, loss before: 1.44541036207e-06, loss after: 1.44541036207e-06.\n",
      "Epoch:16, weight train batch: 329, step:7, loss before: 1.76950959485e-06, loss after: 1.76950959485e-06.\n",
      "Epoch:16, weight train batch: 329, step:8, loss before: 1.55344343966e-06, loss after: 1.55344343966e-06.\n",
      "Epoch:16, weight train batch: 329, step:9, loss before: 1.53109169787e-06, loss after: 1.53109169787e-06.\n",
      "Epoch:16, weight train batch: 329, step:10, loss before: 9.4994805977e-07, loss after: 9.4994805977e-07.\n",
      "Epoch:16, weight train batch: 329, step:11, loss before: 2.21281811719e-06, loss after: 2.21281811719e-06.\n",
      "Epoch:16, weight train batch: 329, step:12, loss before: 1.64657535606e-06, loss after: 1.64657535606e-06.\n",
      "Epoch:16, weight train batch: 329, step:13, loss before: 1.76950959485e-06, loss after: 1.76950959485e-06.\n",
      "Epoch:16, weight train batch: 329, step:14, loss before: 1.28894851059e-06, loss after: 1.28894851059e-06.\n",
      "Epoch:16, weight train batch: 329, step:15, loss before: 1.81421307843e-06, loss after: 1.81421307843e-06.\n",
      "Epoch:16, weight train batch: 329, step:16, loss before: 2.32828097069e-06, loss after: 2.32828097069e-06.\n",
      "Epoch:16, weight train batch: 329, step:17, loss before: 1.10268433673e-06, loss after: 1.10268433673e-06.\n",
      "Epoch:16, weight train batch: 329, step:18, loss before: 2.19791695599e-06, loss after: 2.19791695599e-06.\n",
      "Epoch:16, weight train batch: 329, step:19, loss before: 2.22399398808e-06, loss after: 2.22399398808e-06.\n",
      "Epoch:16, weight train batch: 329, step:20, loss before: 3.95504321204e-05, loss after: 3.94425151171e-05.\n",
      "Epoch:16, weight train batch: 329, step:21, loss before: 9.61123760135e-07, loss after: 9.61123760135e-07.\n",
      "Epoch:16, weight train batch: 329, step:22, loss before: 1.82166365903e-06, loss after: 1.82166365903e-06.\n",
      "Epoch:16, weight train batch: 329, step:23, loss before: 1.51619065036e-06, loss after: 1.51619065036e-06.\n",
      "Epoch:16, weight train batch: 329, step:24, loss before: 2.29849956668e-06, loss after: 2.29849956668e-06.\n",
      "Epoch:16, weight train batch: 329, step:25, loss before: 1.91852086573e-06, loss after: 1.91852086573e-06.\n",
      "Epoch:16, weight train batch: 329, step:26, loss before: 2.28359840548e-06, loss after: 2.28359840548e-06.\n",
      "Epoch:16, weight train batch: 329, step:27, loss before: 1.13248665912e-06, loss after: 1.13248665912e-06.\n",
      "Epoch:16, weight train batch: 329, step:28, loss before: 1.3671792658e-06, loss after: 1.3671792658e-06.\n",
      "Epoch:16, weight train batch: 329, step:29, loss before: 1.71362989931e-06, loss after: 1.71362989931e-06.\n",
      "Epoch:16, weight train batch: 329, step:30, loss before: 1.20326717479e-06, loss after: 1.20326717479e-06.\n",
      "Epoch:16, weight train batch: 329, step:31, loss before: 1.95949905901e-06, loss after: 1.95949905901e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 325, loss before: 2.25096096074e-06, loss after: 1.5249349417e-05.\n",
      "Epoch:16, weight train batch: 330, step:0, loss before: 1.75088348442e-06, loss after: 1.75088348442e-06.\n",
      "Epoch:16, weight train batch: 330, step:1, loss before: 1.45286094266e-06, loss after: 1.45286094266e-06.\n",
      "Epoch:16, weight train batch: 330, step:2, loss before: 1.33365165311e-06, loss after: 1.33365165311e-06.\n",
      "Epoch:16, weight train batch: 330, step:3, loss before: 1.53481698817e-06, loss after: 1.53481698817e-06.\n",
      "Epoch:16, weight train batch: 330, step:4, loss before: 1.2740473494e-06, loss after: 1.2740473494e-06.\n",
      "Epoch:16, weight train batch: 330, step:5, loss before: 1.93342202692e-06, loss after: 1.93342202692e-06.\n",
      "Epoch:16, weight train batch: 330, step:6, loss before: 1.66520180755e-06, loss after: 1.66520180755e-06.\n",
      "Epoch:16, weight train batch: 330, step:7, loss before: 1.53854227847e-06, loss after: 1.51246524638e-06.\n",
      "Epoch:16, weight train batch: 330, step:8, loss before: 4.87619172418e-06, loss after: 4.87246688863e-06.\n",
      "Epoch:16, weight train batch: 330, step:9, loss before: 1.45658600559e-06, loss after: 1.45658600559e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16, weight train batch: 330, step:10, loss before: 1.54971814936e-06, loss after: 1.54971814936e-06.\n",
      "Epoch:16, weight train batch: 330, step:11, loss before: 1.72108093466e-06, loss after: 1.72108093466e-06.\n",
      "Epoch:16, weight train batch: 330, step:12, loss before: 1.49011361827e-06, loss after: 1.49011361827e-06.\n",
      "Epoch:16, weight train batch: 330, step:13, loss before: 2.246344593e-06, loss after: 2.246344593e-06.\n",
      "Epoch:16, weight train batch: 330, step:14, loss before: 1.51991594066e-06, loss after: 1.51991594066e-06.\n",
      "Epoch:16, weight train batch: 330, step:15, loss before: 1.61677303367e-06, loss after: 1.61677303367e-06.\n",
      "Epoch:16, weight train batch: 330, step:16, loss before: 1.53481710186e-06, loss after: 1.53481710186e-06.\n",
      "Epoch:16, weight train batch: 330, step:17, loss before: 1.66892721154e-06, loss after: 1.66892721154e-06.\n",
      "Epoch:16, weight train batch: 330, step:18, loss before: 1.84774057743e-06, loss after: 1.84774057743e-06.\n",
      "Epoch:16, weight train batch: 330, step:19, loss before: 1.65030087373e-06, loss after: 1.65030087373e-06.\n",
      "Epoch:16, weight train batch: 330, step:20, loss before: 1.75833383764e-06, loss after: 1.75833383764e-06.\n",
      "Epoch:16, weight train batch: 330, step:21, loss before: 1.43423449117e-06, loss after: 1.43423449117e-06.\n",
      "Epoch:16, weight train batch: 330, step:22, loss before: 4.421752692e-06, loss after: 4.421752692e-06.\n",
      "Epoch:16, weight train batch: 330, step:23, loss before: 1.73970738615e-06, loss after: 1.73970738615e-06.\n",
      "Epoch:16, weight train batch: 330, step:24, loss before: 2.00792783289e-06, loss after: 2.00792783289e-06.\n",
      "Epoch:16, weight train batch: 330, step:25, loss before: 1.32992681756e-06, loss after: 1.32992681756e-06.\n",
      "Epoch:16, weight train batch: 330, step:26, loss before: 1.59814669587e-06, loss after: 1.59814669587e-06.\n",
      "Epoch:16, weight train batch: 330, step:27, loss before: 1.43423449117e-06, loss after: 1.43423449117e-06.\n",
      "Epoch:16, weight train batch: 330, step:28, loss before: 1.62049855135e-06, loss after: 1.62049855135e-06.\n",
      "Epoch:16, weight train batch: 330, step:29, loss before: 1.85146586773e-06, loss after: 1.85146586773e-06.\n",
      "Epoch:16, weight train batch: 330, step:30, loss before: 0.0216625630856, loss after: 0.0216625630856.\n",
      "Epoch:16, weight train batch: 330, step:31, loss before: 0.000333338452037, loss after: 0.000332066760166.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 326, loss before: 1.44075352182e-06, loss after: 1.35972891258e-06.\n",
      "Epoch:16, weight train batch: 331, step:0, loss before: 1.40070699217e-06, loss after: 1.40070699217e-06.\n",
      "Epoch:16, weight train batch: 331, step:1, loss before: 1.62794901826e-06, loss after: 1.60187198617e-06.\n",
      "Epoch:16, weight train batch: 331, step:2, loss before: 1.69872930655e-06, loss after: 1.69872930655e-06.\n",
      "Epoch:16, weight train batch: 331, step:3, loss before: 1.75833383764e-06, loss after: 1.75833383764e-06.\n",
      "Epoch:16, weight train batch: 331, step:4, loss before: 2.1085102162e-06, loss after: 2.1085102162e-06.\n",
      "Epoch:16, weight train batch: 331, step:5, loss before: 1.46776199017e-06, loss after: 1.46776199017e-06.\n",
      "Epoch:16, weight train batch: 331, step:6, loss before: 1.59442151926e-06, loss after: 1.59442151926e-06.\n",
      "Epoch:16, weight train batch: 331, step:7, loss before: 1.47521245708e-06, loss after: 1.47521245708e-06.\n",
      "Epoch:16, weight train batch: 331, step:8, loss before: 1.996751962e-06, loss after: 1.996751962e-06.\n",
      "Epoch:16, weight train batch: 331, step:9, loss before: 1.86264173863e-06, loss after: 1.86264173863e-06.\n",
      "Epoch:16, weight train batch: 331, step:10, loss before: 1.60187209985e-06, loss after: 1.60187209985e-06.\n",
      "Epoch:16, weight train batch: 331, step:11, loss before: 3.72890417566e-06, loss after: 3.72517888536e-06.\n",
      "Epoch:16, weight train batch: 331, step:12, loss before: 1.47521257077e-06, loss after: 1.47521257077e-06.\n",
      "Epoch:16, weight train batch: 331, step:13, loss before: 1.66147628988e-06, loss after: 1.66147628988e-06.\n",
      "Epoch:16, weight train batch: 331, step:14, loss before: 1.25169572129e-06, loss after: 1.25169572129e-06.\n",
      "Epoch:16, weight train batch: 331, step:15, loss before: 1.42305850659e-06, loss after: 1.42305850659e-06.\n",
      "Epoch:16, weight train batch: 331, step:16, loss before: 2.08615847441e-06, loss after: 2.08615847441e-06.\n",
      "Epoch:16, weight train batch: 331, step:17, loss before: 1.61677326105e-06, loss after: 1.61677326105e-06.\n",
      "Epoch:16, weight train batch: 331, step:18, loss before: 1.34855292799e-06, loss after: 1.34855292799e-06.\n",
      "Epoch:16, weight train batch: 331, step:19, loss before: 1.63167442224e-06, loss after: 1.60187209985e-06.\n",
      "Epoch:16, weight train batch: 331, step:20, loss before: 6.09188391536e-05, loss after: 6.08779373579e-05.\n",
      "Epoch:16, weight train batch: 331, step:21, loss before: 1.94087260752e-06, loss after: 1.94087260752e-06.\n",
      "Epoch:16, weight train batch: 331, step:22, loss before: 1.72480645233e-06, loss after: 1.72480645233e-06.\n",
      "Epoch:16, weight train batch: 331, step:23, loss before: 1.51619076405e-06, loss after: 1.51619076405e-06.\n",
      "Epoch:16, weight train batch: 331, step:24, loss before: 1.06543166112e-06, loss after: 1.06543166112e-06.\n",
      "Epoch:16, weight train batch: 331, step:25, loss before: 1.47893786107e-06, loss after: 1.47893786107e-06.\n",
      "Epoch:16, weight train batch: 331, step:26, loss before: 1.97067492991e-06, loss after: 1.97067492991e-06.\n",
      "Epoch:16, weight train batch: 331, step:27, loss before: 1.69500401626e-06, loss after: 1.69500401626e-06.\n",
      "Epoch:16, weight train batch: 331, step:28, loss before: 4.70483837489e-06, loss after: 4.70111353934e-06.\n",
      "Epoch:16, weight train batch: 331, step:29, loss before: 1.54226745508e-06, loss after: 1.54226745508e-06.\n",
      "Epoch:16, weight train batch: 331, step:30, loss before: 1.53481698817e-06, loss after: 1.53481698817e-06.\n",
      "Epoch:16, weight train batch: 331, step:31, loss before: 1.60187209985e-06, loss after: 1.60187209985e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 327, loss before: 2.34597155213e-06, loss after: 9.83704285318e-06.\n",
      "Epoch:16, weight train batch: 332, step:0, loss before: 5.24131473867e-06, loss after: 5.23758990312e-06.\n",
      "Epoch:16, weight train batch: 332, step:1, loss before: 1.93342202692e-06, loss after: 1.93342202692e-06.\n",
      "Epoch:16, weight train batch: 332, step:2, loss before: 1.94832318812e-06, loss after: 1.94832318812e-06.\n",
      "Epoch:16, weight train batch: 332, step:3, loss before: 1.31875071929e-06, loss after: 1.31875071929e-06.\n",
      "Epoch:16, weight train batch: 332, step:4, loss before: 1.2293439795e-06, loss after: 1.2293439795e-06.\n",
      "Epoch:16, weight train batch: 332, step:5, loss before: 1.48638844166e-06, loss after: 1.48638844166e-06.\n",
      "Epoch:16, weight train batch: 332, step:6, loss before: 1.27032217279e-06, loss after: 1.2442451407e-06.\n",
      "Epoch:16, weight train batch: 332, step:7, loss before: 1.66892698417e-06, loss after: 1.66892698417e-06.\n",
      "Epoch:16, weight train batch: 332, step:8, loss before: 1.02817875813e-06, loss after: 1.01327759694e-06.\n",
      "Epoch:16, weight train batch: 332, step:9, loss before: 1.88499348042e-06, loss after: 1.88499348042e-06.\n",
      "Epoch:16, weight train batch: 332, step:10, loss before: 1.66892732523e-06, loss after: 1.66892732523e-06.\n",
      "Epoch:16, weight train batch: 332, step:11, loss before: 1.24797031731e-06, loss after: 1.24797031731e-06.\n",
      "Epoch:16, weight train batch: 332, step:12, loss before: 1.36345408919e-06, loss after: 1.36345408919e-06.\n",
      "Epoch:16, weight train batch: 332, step:13, loss before: 1.15111311061e-06, loss after: 1.15111311061e-06.\n",
      "Epoch:16, weight train batch: 332, step:14, loss before: 0.000826024683192, loss after: 0.000824337475933.\n",
      "Epoch:16, weight train batch: 332, step:15, loss before: 1.50128948917e-06, loss after: 1.50128948917e-06.\n",
      "Epoch:16, weight train batch: 332, step:16, loss before: 1.59442151926e-06, loss after: 1.59442151926e-06.\n",
      "Epoch:16, weight train batch: 332, step:17, loss before: 1.43423460486e-06, loss after: 1.43423460486e-06.\n",
      "Epoch:16, weight train batch: 332, step:18, loss before: 1.77323511252e-06, loss after: 1.77323511252e-06.\n",
      "Epoch:16, weight train batch: 332, step:19, loss before: 1.77323522621e-06, loss after: 1.81048778813e-06.\n",
      "Epoch:16, weight train batch: 332, step:20, loss before: 1.81793825504e-06, loss after: 1.81793825504e-06.\n",
      "Epoch:16, weight train batch: 332, step:21, loss before: 1.13248665912e-06, loss after: 1.13248665912e-06.\n",
      "Epoch:16, weight train batch: 332, step:22, loss before: 1.24797020362e-06, loss after: 1.24797020362e-06.\n",
      "Epoch:16, weight train batch: 332, step:23, loss before: 1.57579506777e-06, loss after: 1.57579506777e-06.\n",
      "Epoch:16, weight train batch: 332, step:24, loss before: 2.26124643632e-06, loss after: 2.26124643632e-06.\n",
      "Epoch:16, weight train batch: 332, step:25, loss before: 1.79186122296e-06, loss after: 1.79186122296e-06.\n",
      "Epoch:16, weight train batch: 332, step:26, loss before: 1.59069622896e-06, loss after: 1.59069622896e-06.\n",
      "Epoch:16, weight train batch: 332, step:27, loss before: 1.82166354534e-06, loss after: 1.82166354534e-06.\n",
      "Epoch:16, weight train batch: 332, step:28, loss before: 1.53854216478e-06, loss after: 1.53854216478e-06.\n",
      "Epoch:16, weight train batch: 332, step:29, loss before: 1.15111299692e-06, loss after: 1.15111299692e-06.\n",
      "Epoch:16, weight train batch: 332, step:30, loss before: 1.3038495581e-06, loss after: 1.3038495581e-06.\n",
      "Epoch:16, weight train batch: 332, step:31, loss before: 1.63539937148e-06, loss after: 1.60187209985e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 328, loss before: 1.53667974701e-06, loss after: 1.53667974701e-06.\n",
      "Epoch:16, weight train batch: 333, step:0, loss before: 1.65402616403e-06, loss after: 1.65402616403e-06.\n",
      "Epoch:16, weight train batch: 333, step:1, loss before: 1.74715819412e-06, loss after: 1.74715819412e-06.\n",
      "Epoch:16, weight train batch: 333, step:2, loss before: 1.61304728863e-06, loss after: 1.61304728863e-06.\n",
      "Epoch:16, weight train batch: 333, step:3, loss before: 1.36345408919e-06, loss after: 1.36345408919e-06.\n",
      "Epoch:16, weight train batch: 333, step:4, loss before: 1.50874006977e-06, loss after: 1.50874006977e-06.\n",
      "Epoch:16, weight train batch: 333, step:5, loss before: 1.75833395133e-06, loss after: 1.75833395133e-06.\n",
      "Epoch:16, weight train batch: 333, step:6, loss before: 1.05798119421e-06, loss after: 1.05798119421e-06.\n",
      "Epoch:16, weight train batch: 333, step:7, loss before: 2.20909305426e-06, loss after: 2.20909305426e-06.\n",
      "Epoch:16, weight train batch: 333, step:8, loss before: 9.8720056485e-07, loss after: 9.8720056485e-07.\n",
      "Epoch:16, weight train batch: 333, step:9, loss before: 1.54226768245e-06, loss after: 1.54226768245e-06.\n",
      "Epoch:16, weight train batch: 333, step:10, loss before: 1.40070687848e-06, loss after: 1.40070687848e-06.\n",
      "Epoch:16, weight train batch: 333, step:11, loss before: 1.60187209985e-06, loss after: 1.60187209985e-06.\n",
      "Epoch:16, weight train batch: 333, step:12, loss before: 1.01327759694e-06, loss after: 1.01327759694e-06.\n",
      "Epoch:16, weight train batch: 333, step:13, loss before: 1.28894862428e-06, loss after: 1.28894862428e-06.\n",
      "Epoch:16, weight train batch: 333, step:14, loss before: 1.52736652126e-06, loss after: 1.52736652126e-06.\n",
      "Epoch:16, weight train batch: 333, step:15, loss before: 1.64657558344e-06, loss after: 1.64657558344e-06.\n",
      "Epoch:16, weight train batch: 333, step:16, loss before: 1.63539971254e-06, loss after: 1.63539971254e-06.\n",
      "Epoch:16, weight train batch: 333, step:17, loss before: 1.40070699217e-06, loss after: 1.40070699217e-06.\n",
      "Epoch:16, weight train batch: 333, step:18, loss before: 1.56834471454e-06, loss after: 1.56834471454e-06.\n",
      "Epoch:16, weight train batch: 333, step:19, loss before: 1.03562933873e-06, loss after: 1.03562933873e-06.\n",
      "Epoch:16, weight train batch: 333, step:20, loss before: 1.23306915611e-06, loss after: 1.23306915611e-06.\n",
      "Epoch:16, weight train batch: 333, step:21, loss before: 1.65030087373e-06, loss after: 1.65030087373e-06.\n",
      "Epoch:16, weight train batch: 333, step:22, loss before: 1.14738782031e-06, loss after: 1.14738782031e-06.\n",
      "Epoch:16, weight train batch: 333, step:23, loss before: 1.49756431256e-06, loss after: 1.49756431256e-06.\n",
      "Epoch:16, weight train batch: 333, step:24, loss before: 1.12876136882e-06, loss after: 1.12876136882e-06.\n",
      "Epoch:16, weight train batch: 333, step:25, loss before: 1.75460866103e-06, loss after: 1.75460866103e-06.\n",
      "Epoch:16, weight train batch: 333, step:26, loss before: 1.74343279014e-06, loss after: 1.74343279014e-06.\n",
      "Epoch:16, weight train batch: 333, step:27, loss before: 1.84401540082e-06, loss after: 1.84401540082e-06.\n",
      "Epoch:16, weight train batch: 333, step:28, loss before: 1.86264185231e-06, loss after: 1.86264185231e-06.\n",
      "Epoch:16, weight train batch: 333, step:29, loss before: 1.27777275338e-06, loss after: 1.27777275338e-06.\n",
      "Epoch:16, weight train batch: 333, step:30, loss before: 1.1660142718e-06, loss after: 1.1660142718e-06.\n",
      "Epoch:16, weight train batch: 333, step:31, loss before: 1.76950993591e-06, loss after: 1.76950993591e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 329, loss before: 1.49570155372e-06, loss after: 1.49454435814e-05.\n",
      "Epoch:16, weight train batch: 334, step:0, loss before: 7.61417959438e-06, loss after: 7.61417959438e-06.\n",
      "Epoch:16, weight train batch: 334, step:1, loss before: 1.38953112128e-06, loss after: 1.38953112128e-06.\n",
      "Epoch:16, weight train batch: 334, step:2, loss before: 1.2405198504e-06, loss after: 1.2405198504e-06.\n",
      "Epoch:16, weight train batch: 334, step:3, loss before: 1.31875083298e-06, loss after: 1.31875083298e-06.\n",
      "Epoch:16, weight train batch: 334, step:4, loss before: 9.46222655784e-07, loss after: 9.46222655784e-07.\n",
      "Epoch:16, weight train batch: 334, step:5, loss before: 1.62794913194e-06, loss after: 1.62794913194e-06.\n",
      "Epoch:16, weight train batch: 334, step:6, loss before: 1.49383902226e-06, loss after: 1.49383902226e-06.\n",
      "Epoch:16, weight train batch: 334, step:7, loss before: 1.3262011862e-06, loss after: 1.3262011862e-06.\n",
      "Epoch:16, weight train batch: 334, step:8, loss before: 1.74715808043e-06, loss after: 1.74715808043e-06.\n",
      "Epoch:16, weight train batch: 334, step:9, loss before: 4.22804987465e-06, loss after: 4.22432458436e-06.\n",
      "Epoch:16, weight train batch: 334, step:10, loss before: 0.0216625928879, loss after: 0.0216625928879.\n",
      "Epoch:16, weight train batch: 334, step:11, loss before: 2.08988421946e-06, loss after: 2.08988421946e-06.\n",
      "Epoch:16, weight train batch: 334, step:12, loss before: 6.06928988418e-05, loss after: 6.06110188528e-05.\n",
      "Epoch:16, weight train batch: 334, step:13, loss before: 2.06008189707e-06, loss after: 2.06008189707e-06.\n",
      "Epoch:16, weight train batch: 334, step:14, loss before: 0.00079340103548, loss after: 0.000791882805061.\n",
      "Epoch:16, weight train batch: 334, step:15, loss before: 1.09895904643e-06, loss after: 1.09895904643e-06.\n",
      "Epoch:16, weight train batch: 334, step:16, loss before: 1.47521268445e-06, loss after: 1.47521268445e-06.\n",
      "Epoch:16, weight train batch: 334, step:17, loss before: 2.09360928238e-06, loss after: 2.09360928238e-06.\n",
      "Epoch:16, weight train batch: 334, step:18, loss before: 1.35227833198e-06, loss after: 1.35227833198e-06.\n",
      "Epoch:16, weight train batch: 334, step:19, loss before: 1.1622889815e-06, loss after: 1.1622889815e-06.\n",
      "Epoch:16, weight train batch: 334, step:20, loss before: 1.80303732122e-06, loss after: 1.80303732122e-06.\n",
      "Epoch:16, weight train batch: 334, step:21, loss before: 1.40443239616e-06, loss after: 1.40443239616e-06.\n",
      "Epoch:16, weight train batch: 334, step:22, loss before: 1.57952058544e-06, loss after: 1.57952058544e-06.\n",
      "Epoch:16, weight train batch: 334, step:23, loss before: 1.84774080481e-06, loss after: 1.84774080481e-06.\n",
      "Epoch:16, weight train batch: 334, step:24, loss before: 2.19046660277e-06, loss after: 2.19046660277e-06.\n",
      "Epoch:16, weight train batch: 334, step:25, loss before: 1.84401551451e-06, loss after: 1.84401551451e-06.\n",
      "Epoch:16, weight train batch: 334, step:26, loss before: 1.35227833198e-06, loss after: 1.35227833198e-06.\n",
      "Epoch:16, weight train batch: 334, step:27, loss before: 3.29083013639e-05, loss after: 3.27594389091e-05.\n",
      "Epoch:16, weight train batch: 334, step:28, loss before: 1.05053061361e-06, loss after: 1.05053061361e-06.\n",
      "Epoch:16, weight train batch: 334, step:29, loss before: 1.13248665912e-06, loss after: 1.13248665912e-06.\n",
      "Epoch:16, weight train batch: 334, step:30, loss before: 1.43795978147e-06, loss after: 1.43795978147e-06.\n",
      "Epoch:16, weight train batch: 334, step:31, loss before: 1.37835525038e-06, loss after: 1.37835525038e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 330, loss before: 0.000206599739613, loss after: 1.65123242368e-06.\n",
      "Epoch:16, weight train batch: 335, step:0, loss before: 9.05244576188e-07, loss after: 9.05244576188e-07.\n",
      "Epoch:16, weight train batch: 335, step:1, loss before: 1.68382825905e-06, loss after: 1.68382825905e-06.\n",
      "Epoch:16, weight train batch: 335, step:2, loss before: 1.27404746308e-06, loss after: 1.27404746308e-06.\n",
      "Epoch:16, weight train batch: 335, step:3, loss before: 6.03945445619e-05, loss after: 6.03610787948e-05.\n",
      "Epoch:16, weight train batch: 335, step:4, loss before: 1.65030087373e-06, loss after: 1.65030087373e-06.\n",
      "Epoch:16, weight train batch: 335, step:5, loss before: 1.29267391458e-06, loss after: 1.29267391458e-06.\n",
      "Epoch:16, weight train batch: 335, step:6, loss before: 1.59442151926e-06, loss after: 1.59442151926e-06.\n",
      "Epoch:16, weight train batch: 335, step:7, loss before: 0.000764918630011, loss after: 0.000763228163123.\n",
      "Epoch:16, weight train batch: 335, step:8, loss before: 1.22189339891e-06, loss after: 1.22189339891e-06.\n",
      "Epoch:16, weight train batch: 335, step:9, loss before: 1.74343290382e-06, loss after: 1.74343290382e-06.\n",
      "Epoch:16, weight train batch: 335, step:10, loss before: 1.24424525438e-06, loss after: 1.24424525438e-06.\n",
      "Epoch:16, weight train batch: 335, step:11, loss before: 1.21816810861e-06, loss after: 1.21816810861e-06.\n",
      "Epoch:16, weight train batch: 335, step:12, loss before: 3.07648624585e-05, loss after: 3.05787689285e-05.\n",
      "Epoch:16, weight train batch: 335, step:13, loss before: 9.08969866487e-07, loss after: 9.08969866487e-07.\n",
      "Epoch:16, weight train batch: 335, step:14, loss before: 1.41933332998e-06, loss after: 1.41933332998e-06.\n",
      "Epoch:16, weight train batch: 335, step:15, loss before: 1.77696040282e-06, loss after: 1.77696040282e-06.\n",
      "Epoch:16, weight train batch: 335, step:16, loss before: 1.70990529114e-06, loss after: 1.70990529114e-06.\n",
      "Epoch:16, weight train batch: 335, step:17, loss before: 1.0728823554e-06, loss after: 1.0728823554e-06.\n",
      "Epoch:16, weight train batch: 335, step:18, loss before: 1.38580503517e-06, loss after: 1.38580503517e-06.\n",
      "Epoch:16, weight train batch: 335, step:19, loss before: 1.61677326105e-06, loss after: 1.61677326105e-06.\n",
      "Epoch:16, weight train batch: 335, step:20, loss before: 9.94651145447e-07, loss after: 9.94651145447e-07.\n",
      "Epoch:16, weight train batch: 335, step:21, loss before: 9.72299517343e-07, loss after: 9.72299517343e-07.\n",
      "Epoch:16, weight train batch: 335, step:22, loss before: 0.000316975172609, loss after: 0.000315964687616.\n",
      "Epoch:16, weight train batch: 335, step:23, loss before: 1.49011384565e-06, loss after: 1.49011384565e-06.\n",
      "Epoch:16, weight train batch: 335, step:24, loss before: 2.07498305826e-06, loss after: 2.07498305826e-06.\n",
      "Epoch:16, weight train batch: 335, step:25, loss before: 1.4826628103e-06, loss after: 1.4826628103e-06.\n",
      "Epoch:16, weight train batch: 335, step:26, loss before: 1.35227833198e-06, loss after: 1.35227833198e-06.\n",
      "Epoch:16, weight train batch: 335, step:27, loss before: 1.47521268445e-06, loss after: 1.47521268445e-06.\n",
      "Epoch:16, weight train batch: 335, step:28, loss before: 2.17184015128e-06, loss after: 2.17184015128e-06.\n",
      "Epoch:16, weight train batch: 335, step:29, loss before: 1.2367945601e-06, loss after: 1.2367945601e-06.\n",
      "Epoch:16, weight train batch: 335, step:30, loss before: 1.53854250584e-06, loss after: 1.53854250584e-06.\n",
      "Epoch:16, weight train batch: 335, step:31, loss before: 1.04307991933e-06, loss after: 1.04307991933e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 331, loss before: 1.41095165418e-06, loss after: 1.41095165418e-06.\n",
      "Epoch:16, weight train batch: 336, step:0, loss before: 1.09895904643e-06, loss after: 1.09895904643e-06.\n",
      "Epoch:16, weight train batch: 336, step:1, loss before: 1.73970772721e-06, loss after: 1.73970772721e-06.\n",
      "Epoch:16, weight train batch: 336, step:2, loss before: 1.75088359811e-06, loss after: 1.75088359811e-06.\n",
      "Epoch:16, weight train batch: 336, step:3, loss before: 3.11800386044e-06, loss after: 3.11427879751e-06.\n",
      "Epoch:16, weight train batch: 336, step:4, loss before: 1.147387934e-06, loss after: 1.147387934e-06.\n",
      "Epoch:16, weight train batch: 336, step:5, loss before: 1.38208065437e-06, loss after: 1.38208065437e-06.\n",
      "Epoch:16, weight train batch: 336, step:6, loss before: 1.53481710186e-06, loss after: 1.53481710186e-06.\n",
      "Epoch:16, weight train batch: 336, step:7, loss before: 1.67265250184e-06, loss after: 1.67265250184e-06.\n",
      "Epoch:16, weight train batch: 336, step:8, loss before: 1.33365188049e-06, loss after: 1.33365188049e-06.\n",
      "Epoch:16, weight train batch: 336, step:9, loss before: 1.49383913595e-06, loss after: 1.49383913595e-06.\n",
      "Epoch:16, weight train batch: 336, step:10, loss before: 1.45658623296e-06, loss after: 1.45658623296e-06.\n",
      "Epoch:16, weight train batch: 336, step:11, loss before: 1.84029022421e-06, loss after: 1.84029022421e-06.\n",
      "Epoch:16, weight train batch: 336, step:12, loss before: 1.46031152326e-06, loss after: 1.46031152326e-06.\n",
      "Epoch:16, weight train batch: 336, step:13, loss before: 1.84774080481e-06, loss after: 1.84774080481e-06.\n",
      "Epoch:16, weight train batch: 336, step:14, loss before: 9.0151928589e-07, loss after: 9.0151928589e-07.\n",
      "Epoch:16, weight train batch: 336, step:15, loss before: 1.39698181556e-06, loss after: 1.39698181556e-06.\n",
      "Epoch:16, weight train batch: 336, step:16, loss before: 2.01165312319e-06, loss after: 2.01165312319e-06.\n",
      "Epoch:16, weight train batch: 336, step:17, loss before: 1.5147645172e-05, loss after: 1.50917812789e-05.\n",
      "Epoch:16, weight train batch: 336, step:18, loss before: 1.32620129989e-06, loss after: 1.32620129989e-06.\n",
      "Epoch:16, weight train batch: 336, step:19, loss before: 1.69127906702e-06, loss after: 1.69127906702e-06.\n",
      "Epoch:16, weight train batch: 336, step:20, loss before: 5.17429816682e-06, loss after: 5.17429816682e-06.\n",
      "Epoch:16, weight train batch: 336, step:21, loss before: 6.05018394708e-05, loss after: 6.04609376751e-05.\n",
      "Epoch:16, weight train batch: 336, step:22, loss before: 1.3075748484e-06, loss after: 1.3075748484e-06.\n",
      "Epoch:16, weight train batch: 336, step:23, loss before: 1.70990551851e-06, loss after: 1.70990551851e-06.\n",
      "Epoch:16, weight train batch: 336, step:24, loss before: 1.50874029714e-06, loss after: 1.50874029714e-06.\n",
      "Epoch:16, weight train batch: 336, step:25, loss before: 1.7732353399e-06, loss after: 1.7732353399e-06.\n",
      "Epoch:16, weight train batch: 336, step:26, loss before: 1.01700311461e-06, loss after: 1.01700311461e-06.\n",
      "Epoch:16, weight train batch: 336, step:27, loss before: 1.1995417708e-06, loss after: 1.1995417708e-06.\n",
      "Epoch:16, weight train batch: 336, step:28, loss before: 1.47521268445e-06, loss after: 1.47521268445e-06.\n",
      "Epoch:16, weight train batch: 336, step:29, loss before: 8.38189578189e-07, loss after: 8.38189578189e-07.\n",
      "Epoch:16, weight train batch: 336, step:30, loss before: 1.2405198504e-06, loss after: 1.2405198504e-06.\n",
      "Epoch:16, weight train batch: 336, step:31, loss before: 1.31875071929e-06, loss after: 1.31875071929e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 332, loss before: 1.3876687035e-06, loss after: 0.00541656743735.\n",
      "Epoch:16, weight train batch: 337, step:0, loss before: 1.44913565236e-06, loss after: 1.44913565236e-06.\n",
      "Epoch:16, weight train batch: 337, step:1, loss before: 1.08778340291e-06, loss after: 1.08778340291e-06.\n",
      "Epoch:16, weight train batch: 337, step:2, loss before: 1.71363080881e-06, loss after: 1.71363080881e-06.\n",
      "Epoch:16, weight train batch: 337, step:3, loss before: 1.78441098342e-06, loss after: 1.78441098342e-06.\n",
      "Epoch:16, weight train batch: 337, step:4, loss before: 1.27032217279e-06, loss after: 1.27032217279e-06.\n",
      "Epoch:16, weight train batch: 337, step:5, loss before: 2.6997860914e-05, loss after: 2.6915970011e-05.\n",
      "Epoch:16, weight train batch: 337, step:6, loss before: 5.89797346038e-05, loss after: 5.88198199694e-05.\n",
      "Epoch:16, weight train batch: 337, step:7, loss before: 1.49383913595e-06, loss after: 1.49383913595e-06.\n",
      "Epoch:16, weight train batch: 337, step:8, loss before: 1.51991616804e-06, loss after: 1.51991616804e-06.\n",
      "Epoch:16, weight train batch: 337, step:9, loss before: 1.8589166757e-06, loss after: 1.81793870979e-06.\n",
      "Epoch:16, weight train batch: 337, step:10, loss before: 1.24052007777e-06, loss after: 1.24052007777e-06.\n",
      "Epoch:16, weight train batch: 337, step:11, loss before: 9.53673179538e-07, loss after: 9.53673179538e-07.\n",
      "Epoch:16, weight train batch: 337, step:12, loss before: 1.58324610311e-06, loss after: 1.58324610311e-06.\n",
      "Epoch:16, weight train batch: 337, step:13, loss before: 1.5906958879e-06, loss after: 1.5906958879e-06.\n",
      "Epoch:16, weight train batch: 337, step:14, loss before: 1.54971837674e-06, loss after: 1.54971837674e-06.\n",
      "Epoch:16, weight train batch: 337, step:15, loss before: 1.46031152326e-06, loss after: 1.46031152326e-06.\n",
      "Epoch:16, weight train batch: 337, step:16, loss before: 1.40070699217e-06, loss after: 1.40070699217e-06.\n",
      "Epoch:16, weight train batch: 337, step:17, loss before: 1.7359825506e-06, loss after: 1.7359825506e-06.\n",
      "Epoch:16, weight train batch: 337, step:18, loss before: 1.45658623296e-06, loss after: 1.45658623296e-06.\n",
      "Epoch:16, weight train batch: 337, step:19, loss before: 1.42678413795e-06, loss after: 1.42678413795e-06.\n",
      "Epoch:16, weight train batch: 337, step:20, loss before: 1.66147674463e-06, loss after: 1.66147674463e-06.\n",
      "Epoch:16, weight train batch: 337, step:21, loss before: 1.48638855535e-06, loss after: 1.48638855535e-06.\n",
      "Epoch:16, weight train batch: 337, step:22, loss before: 2.04518073588e-06, loss after: 2.04518073588e-06.\n",
      "Epoch:16, weight train batch: 337, step:23, loss before: 1.88126841749e-06, loss after: 1.88126841749e-06.\n",
      "Epoch:16, weight train batch: 337, step:24, loss before: 1.97440044758e-06, loss after: 1.97440044758e-06.\n",
      "Epoch:16, weight train batch: 337, step:25, loss before: 1.32620152726e-06, loss after: 1.32620152726e-06.\n",
      "Epoch:16, weight train batch: 337, step:26, loss before: 4.01199849875e-06, loss after: 3.98219663111e-06.\n",
      "Epoch:16, weight train batch: 337, step:27, loss before: 1.63539993991e-06, loss after: 1.63539993991e-06.\n",
      "Epoch:16, weight train batch: 337, step:28, loss before: 1.79558639957e-06, loss after: 1.79558639957e-06.\n",
      "Epoch:16, weight train batch: 337, step:29, loss before: 1.15483840091e-06, loss after: 1.15483840091e-06.\n",
      "Epoch:16, weight train batch: 337, step:30, loss before: 1.28149804368e-06, loss after: 1.28149804368e-06.\n",
      "Epoch:16, weight train batch: 337, step:31, loss before: 1.87009266028e-06, loss after: 1.87009266028e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 333, loss before: 1.79182893589e-06, loss after: 1.0654317748e-06.\n",
      "Epoch:16, weight train batch: 338, step:0, loss before: 1.32620152726e-06, loss after: 1.32620152726e-06.\n",
      "Epoch:16, weight train batch: 338, step:1, loss before: 1.61304808444e-06, loss after: 1.61304808444e-06.\n",
      "Epoch:16, weight train batch: 338, step:2, loss before: 1.59814692324e-06, loss after: 1.59814692324e-06.\n",
      "Epoch:16, weight train batch: 338, step:3, loss before: 1.27777275338e-06, loss after: 1.27777275338e-06.\n",
      "Epoch:16, weight train batch: 338, step:4, loss before: 1.94087283489e-06, loss after: 1.94087283489e-06.\n",
      "Epoch:16, weight train batch: 338, step:5, loss before: 4.29512238043e-06, loss after: 4.29512238043e-06.\n",
      "Epoch:16, weight train batch: 338, step:6, loss before: 1.7397078409e-06, loss after: 1.7397078409e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16, weight train batch: 338, step:7, loss before: 1.24052007777e-06, loss after: 1.24052007777e-06.\n",
      "Epoch:16, weight train batch: 338, step:8, loss before: 1.27032217279e-06, loss after: 1.27032217279e-06.\n",
      "Epoch:16, weight train batch: 338, step:9, loss before: 1.1846407233e-06, loss after: 1.1846407233e-06.\n",
      "Epoch:16, weight train batch: 338, step:10, loss before: 1.96695009436e-06, loss after: 1.96695009436e-06.\n",
      "Epoch:16, weight train batch: 338, step:11, loss before: 1.06915695142e-06, loss after: 1.06915695142e-06.\n",
      "Epoch:16, weight train batch: 338, step:12, loss before: 7.07804588274e-07, loss after: 7.07804588274e-07.\n",
      "Epoch:16, weight train batch: 338, step:13, loss before: 1.49011384565e-06, loss after: 1.45658623296e-06.\n",
      "Epoch:16, weight train batch: 338, step:14, loss before: 1.49756442624e-06, loss after: 1.49756442624e-06.\n",
      "Epoch:16, weight train batch: 338, step:15, loss before: 1.25169572129e-06, loss after: 1.25169572129e-06.\n",
      "Epoch:16, weight train batch: 338, step:16, loss before: 1.46031152326e-06, loss after: 1.46031152326e-06.\n",
      "Epoch:16, weight train batch: 338, step:17, loss before: 1.49383913595e-06, loss after: 1.49383913595e-06.\n",
      "Epoch:16, weight train batch: 338, step:18, loss before: 1.68010319612e-06, loss after: 1.68010319612e-06.\n",
      "Epoch:16, weight train batch: 338, step:19, loss before: 1.58324587574e-06, loss after: 1.58324587574e-06.\n",
      "Epoch:16, weight train batch: 338, step:20, loss before: 1.69500435732e-06, loss after: 1.69500435732e-06.\n",
      "Epoch:16, weight train batch: 338, step:21, loss before: 1.08033282231e-06, loss after: 1.08033282231e-06.\n",
      "Epoch:16, weight train batch: 338, step:22, loss before: 1.35972891258e-06, loss after: 1.35972891258e-06.\n",
      "Epoch:16, weight train batch: 338, step:23, loss before: 4.48511218565e-06, loss after: 4.48511218565e-06.\n",
      "Epoch:16, weight train batch: 338, step:24, loss before: 1.38208065437e-06, loss after: 1.38208065437e-06.\n",
      "Epoch:16, weight train batch: 338, step:25, loss before: 1.57952058544e-06, loss after: 1.57952058544e-06.\n",
      "Epoch:16, weight train batch: 338, step:26, loss before: 2.02655292014e-06, loss after: 2.02655292014e-06.\n",
      "Epoch:16, weight train batch: 338, step:27, loss before: 5.18703418493e-05, loss after: 5.16285945196e-05.\n",
      "Epoch:16, weight train batch: 338, step:28, loss before: 1.70245493791e-06, loss after: 1.70245493791e-06.\n",
      "Epoch:16, weight train batch: 338, step:29, loss before: 1.14366253001e-06, loss after: 1.14366253001e-06.\n",
      "Epoch:16, weight train batch: 338, step:30, loss before: 1.66892482412e-06, loss after: 1.66892482412e-06.\n",
      "Epoch:16, weight train batch: 338, step:31, loss before: 1.91479603018e-06, loss after: 1.91479603018e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 334, loss before: 1.64282519108e-05, loss after: 1.76018340881e-06.\n",
      "Epoch:16, weight train batch: 339, step:0, loss before: 1.49383913595e-06, loss after: 1.49383913595e-06.\n",
      "Epoch:16, weight train batch: 339, step:1, loss before: 1.31502542899e-06, loss after: 1.31502542899e-06.\n",
      "Epoch:16, weight train batch: 339, step:2, loss before: 1.46031152326e-06, loss after: 1.46031152326e-06.\n",
      "Epoch:16, weight train batch: 339, step:3, loss before: 1.37090478347e-06, loss after: 1.37090478347e-06.\n",
      "Epoch:16, weight train batch: 339, step:4, loss before: 1.05053049992e-06, loss after: 1.05053049992e-06.\n",
      "Epoch:16, weight train batch: 339, step:5, loss before: 1.58324587574e-06, loss after: 1.58324587574e-06.\n",
      "Epoch:16, weight train batch: 339, step:6, loss before: 2.74335743597e-05, loss after: 2.73889090749e-05.\n",
      "Epoch:16, weight train batch: 339, step:7, loss before: 1.35600362228e-06, loss after: 1.35600362228e-06.\n",
      "Epoch:16, weight train batch: 339, step:8, loss before: 1.02072817754e-06, loss after: 1.02072817754e-06.\n",
      "Epoch:16, weight train batch: 339, step:9, loss before: 1.48266326505e-06, loss after: 1.48266326505e-06.\n",
      "Epoch:16, weight train batch: 339, step:10, loss before: 1.71363080881e-06, loss after: 1.71363080881e-06.\n",
      "Epoch:16, weight train batch: 339, step:11, loss before: 1.72480633864e-06, loss after: 1.72480633864e-06.\n",
      "Epoch:16, weight train batch: 339, step:12, loss before: 1.59442174663e-06, loss after: 1.59442174663e-06.\n",
      "Epoch:16, weight train batch: 339, step:13, loss before: 3.9449569158e-06, loss after: 3.94123208025e-06.\n",
      "Epoch:16, weight train batch: 339, step:14, loss before: 8.90343585525e-07, loss after: 8.90343585525e-07.\n",
      "Epoch:16, weight train batch: 339, step:15, loss before: 1.57207000484e-06, loss after: 1.57207000484e-06.\n",
      "Epoch:16, weight train batch: 339, step:16, loss before: 1.35227833198e-06, loss after: 1.32992659019e-06.\n",
      "Epoch:16, weight train batch: 339, step:17, loss before: 1.12876136882e-06, loss after: 1.12876136882e-06.\n",
      "Epoch:16, weight train batch: 339, step:18, loss before: 8.71716906659e-07, loss after: 8.71716906659e-07.\n",
      "Epoch:16, weight train batch: 339, step:19, loss before: 1.00582724372e-06, loss after: 1.00582724372e-06.\n",
      "Epoch:16, weight train batch: 339, step:20, loss before: 1.01700300092e-06, loss after: 1.01700300092e-06.\n",
      "Epoch:16, weight train batch: 339, step:21, loss before: 2.62012417807e-05, loss after: 2.60746601271e-05.\n",
      "Epoch:16, weight train batch: 339, step:22, loss before: 1.1064098544e-06, loss after: 1.1064098544e-06.\n",
      "Epoch:16, weight train batch: 339, step:23, loss before: 9.98376663119e-07, loss after: 9.98376663119e-07.\n",
      "Epoch:16, weight train batch: 339, step:24, loss before: 1.24797065837e-06, loss after: 1.24797065837e-06.\n",
      "Epoch:16, weight train batch: 339, step:25, loss before: 8.67991673204e-07, loss after: 8.67991673204e-07.\n",
      "Epoch:16, weight train batch: 339, step:26, loss before: 1.22561891658e-06, loss after: 1.22561891658e-06.\n",
      "Epoch:16, weight train batch: 339, step:27, loss before: 1.02072840491e-06, loss after: 1.02072840491e-06.\n",
      "Epoch:16, weight train batch: 339, step:28, loss before: 1.64657581081e-06, loss after: 1.64657581081e-06.\n",
      "Epoch:16, weight train batch: 339, step:29, loss before: 1.33365210786e-06, loss after: 1.33365210786e-06.\n",
      "Epoch:16, weight train batch: 339, step:30, loss before: 1.4428979739e-05, loss after: 1.43768475027e-05.\n",
      "Epoch:16, weight train batch: 339, step:31, loss before: 1.19209130389e-06, loss after: 1.19209130389e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:16, struct parameters train batch: 335, loss before: 1.24890186726e-06, loss after: 1.24890186726e-06.\n",
      "Epoch:17, weight train batch: 340, step:0, loss before: 1.40815768646e-06, loss after: 1.40815768646e-06.\n",
      "Epoch:17, weight train batch: 340, step:1, loss before: 9.35046898576e-07, loss after: 9.35046898576e-07.\n",
      "Epoch:17, weight train batch: 340, step:2, loss before: 1.32620152726e-06, loss after: 1.32620152726e-06.\n",
      "Epoch:17, weight train batch: 340, step:3, loss before: 1.00955253401e-06, loss after: 1.00955253401e-06.\n",
      "Epoch:17, weight train batch: 340, step:4, loss before: 1.52736674863e-06, loss after: 1.52736674863e-06.\n",
      "Epoch:17, weight train batch: 340, step:5, loss before: 1.70990551851e-06, loss after: 1.70990551851e-06.\n",
      "Epoch:17, weight train batch: 340, step:6, loss before: 1.1697395621e-06, loss after: 1.1697395621e-06.\n",
      "Epoch:17, weight train batch: 340, step:7, loss before: 1.51619087774e-06, loss after: 1.51619087774e-06.\n",
      "Epoch:17, weight train batch: 340, step:8, loss before: 1.47521291183e-06, loss after: 1.47521291183e-06.\n",
      "Epoch:17, weight train batch: 340, step:9, loss before: 1.1175857253e-06, loss after: 1.1175857253e-06.\n",
      "Epoch:17, weight train batch: 340, step:10, loss before: 1.00955253401e-06, loss after: 1.00955253401e-06.\n",
      "Epoch:17, weight train batch: 340, step:11, loss before: 1.03190427581e-06, loss after: 1.01327782431e-06.\n",
      "Epoch:17, weight train batch: 340, step:12, loss before: 1.31130036607e-06, loss after: 1.31130036607e-06.\n",
      "Epoch:17, weight train batch: 340, step:13, loss before: 1.35600362228e-06, loss after: 1.35600362228e-06.\n",
      "Epoch:17, weight train batch: 340, step:14, loss before: 1.60932290783e-06, loss after: 1.60932290783e-06.\n",
      "Epoch:17, weight train batch: 340, step:15, loss before: 1.47148693941e-06, loss after: 1.47148693941e-06.\n",
      "Epoch:17, weight train batch: 340, step:16, loss before: 4.14984879171e-06, loss after: 4.14984879171e-06.\n",
      "Epoch:17, weight train batch: 340, step:17, loss before: 1.37835536407e-06, loss after: 1.37835536407e-06.\n",
      "Epoch:17, weight train batch: 340, step:18, loss before: 1.01327759694e-06, loss after: 1.01327759694e-06.\n",
      "Epoch:17, weight train batch: 340, step:19, loss before: 3.69168310499e-06, loss after: 3.69168310499e-06.\n",
      "Epoch:17, weight train batch: 340, step:20, loss before: 1.28149804368e-06, loss after: 1.28149804368e-06.\n",
      "Epoch:17, weight train batch: 340, step:21, loss before: 1.37997058118e-05, loss after: 1.37699162224e-05.\n",
      "Epoch:17, weight train batch: 340, step:22, loss before: 1.07660753201e-06, loss after: 1.07660753201e-06.\n",
      "Epoch:17, weight train batch: 340, step:23, loss before: 5.81448803132e-05, loss after: 5.81039785175e-05.\n",
      "Epoch:17, weight train batch: 340, step:24, loss before: 9.83475501926e-07, loss after: 9.83475501926e-07.\n",
      "Epoch:17, weight train batch: 340, step:25, loss before: 1.18836601359e-06, loss after: 1.18836601359e-06.\n",
      "Epoch:17, weight train batch: 340, step:26, loss before: 1.55716884365e-06, loss after: 1.55716884365e-06.\n",
      "Epoch:17, weight train batch: 340, step:27, loss before: 9.38772018344e-07, loss after: 9.38772018344e-07.\n",
      "Epoch:17, weight train batch: 340, step:28, loss before: 1.05053049992e-06, loss after: 1.02817875813e-06.\n",
      "Epoch:17, weight train batch: 340, step:29, loss before: 9.61123760135e-07, loss after: 9.61123760135e-07.\n",
      "Epoch:17, weight train batch: 340, step:30, loss before: 1.70245493791e-06, loss after: 1.70245493791e-06.\n",
      "Epoch:17, weight train batch: 340, step:31, loss before: 1.39698181556e-06, loss after: 1.39698181556e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 336, loss before: 1.2442451407e-06, loss after: 1.35414040869e-06.\n",
      "Epoch:17, weight train batch: 341, step:0, loss before: 1.27032217279e-06, loss after: 1.27032217279e-06.\n",
      "Epoch:17, weight train batch: 341, step:1, loss before: 1.53109192524e-06, loss after: 1.53109192524e-06.\n",
      "Epoch:17, weight train batch: 341, step:2, loss before: 7.11529764885e-07, loss after: 7.11529764885e-07.\n",
      "Epoch:17, weight train batch: 341, step:3, loss before: 1.26659688249e-06, loss after: 1.26659688249e-06.\n",
      "Epoch:17, weight train batch: 341, step:4, loss before: 1.32247612328e-06, loss after: 1.32247612328e-06.\n",
      "Epoch:17, weight train batch: 341, step:5, loss before: 9.16420276553e-07, loss after: 9.16420276553e-07.\n",
      "Epoch:17, weight train batch: 341, step:6, loss before: 1.46031152326e-06, loss after: 1.46031152326e-06.\n",
      "Epoch:17, weight train batch: 341, step:7, loss before: 1.53481710186e-06, loss after: 1.53481710186e-06.\n",
      "Epoch:17, weight train batch: 341, step:8, loss before: 1.11758549792e-06, loss after: 1.11758549792e-06.\n",
      "Epoch:17, weight train batch: 341, step:9, loss before: 1.44168507177e-06, loss after: 1.44168507177e-06.\n",
      "Epoch:17, weight train batch: 341, step:10, loss before: 1.37835536407e-06, loss after: 1.37835536407e-06.\n",
      "Epoch:17, weight train batch: 341, step:11, loss before: 1.08405788524e-06, loss after: 1.08405788524e-06.\n",
      "Epoch:17, weight train batch: 341, step:12, loss before: 1.13621194942e-06, loss after: 1.13621194942e-06.\n",
      "Epoch:17, weight train batch: 341, step:13, loss before: 1.56461942424e-06, loss after: 1.56461942424e-06.\n",
      "Epoch:17, weight train batch: 341, step:14, loss before: 7.15255055184e-07, loss after: 7.15255055184e-07.\n",
      "Epoch:17, weight train batch: 341, step:15, loss before: 9.49947889239e-07, loss after: 9.49947889239e-07.\n",
      "Epoch:17, weight train batch: 341, step:16, loss before: 5.97144253334e-06, loss after: 5.96399240749e-06.\n",
      "Epoch:17, weight train batch: 341, step:17, loss before: 9.61123760135e-07, loss after: 9.61123760135e-07.\n",
      "Epoch:17, weight train batch: 341, step:18, loss before: 1.25914630189e-06, loss after: 1.25914630189e-06.\n",
      "Epoch:17, weight train batch: 341, step:19, loss before: 1.18836578622e-06, loss after: 1.18836578622e-06.\n",
      "Epoch:17, weight train batch: 341, step:20, loss before: 6.96229790265e-06, loss after: 6.95857261235e-06.\n",
      "Epoch:17, weight train batch: 341, step:21, loss before: 1.2330692698e-06, loss after: 1.2330692698e-06.\n",
      "Epoch:17, weight train batch: 341, step:22, loss before: 1.34110257477e-06, loss after: 1.34110257477e-06.\n",
      "Epoch:17, weight train batch: 341, step:23, loss before: 1.13993723971e-06, loss after: 1.13993723971e-06.\n",
      "Epoch:17, weight train batch: 341, step:24, loss before: 2.32080510614e-05, loss after: 2.31484882534e-05.\n",
      "Epoch:17, weight train batch: 341, step:25, loss before: 8.19562956167e-07, loss after: 8.19562956167e-07.\n",
      "Epoch:17, weight train batch: 341, step:26, loss before: 1.67637790582e-06, loss after: 1.67637790582e-06.\n",
      "Epoch:17, weight train batch: 341, step:27, loss before: 1.12876136882e-06, loss after: 1.12876136882e-06.\n",
      "Epoch:17, weight train batch: 341, step:28, loss before: 1.1697395621e-06, loss after: 1.1697395621e-06.\n",
      "Epoch:17, weight train batch: 341, step:29, loss before: 1.13993723971e-06, loss after: 1.13993723971e-06.\n",
      "Epoch:17, weight train batch: 341, step:30, loss before: 9.16420276553e-07, loss after: 9.16420276553e-07.\n",
      "Epoch:17, weight train batch: 341, step:31, loss before: 2.5089681003e-05, loss after: 2.49668282777e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 337, loss before: 1.49011384565e-06, loss after: 1.53842211148e-05.\n",
      "Epoch:17, weight train batch: 342, step:0, loss before: 1.1995417708e-06, loss after: 1.1995417708e-06.\n",
      "Epoch:17, weight train batch: 342, step:1, loss before: 1.2367945601e-06, loss after: 1.27032217279e-06.\n",
      "Epoch:17, weight train batch: 342, step:2, loss before: 2.12340955841e-06, loss after: 2.07498123928e-06.\n",
      "Epoch:17, weight train batch: 342, step:3, loss before: 1.75460695573e-06, loss after: 1.75460695573e-06.\n",
      "Epoch:17, weight train batch: 342, step:4, loss before: 1.5757956362e-06, loss after: 1.5757956362e-06.\n",
      "Epoch:17, weight train batch: 342, step:5, loss before: 3.19994842357e-06, loss after: 3.19622358802e-06.\n",
      "Epoch:17, weight train batch: 342, step:6, loss before: 1.26287181956e-06, loss after: 1.26287181956e-06.\n",
      "Epoch:17, weight train batch: 342, step:7, loss before: 1.35227855935e-06, loss after: 1.35227855935e-06.\n",
      "Epoch:17, weight train batch: 342, step:8, loss before: 1.39698204293e-06, loss after: 1.39698204293e-06.\n",
      "Epoch:17, weight train batch: 342, step:9, loss before: 9.16420447084e-07, loss after: 9.16420447084e-07.\n",
      "Epoch:17, weight train batch: 342, step:10, loss before: 1.01700300092e-06, loss after: 1.01700300092e-06.\n",
      "Epoch:17, weight train batch: 342, step:11, loss before: 3.03603655993e-06, loss after: 3.03603655993e-06.\n",
      "Epoch:17, weight train batch: 342, step:12, loss before: 1.5236408899e-06, loss after: 1.5236408899e-06.\n",
      "Epoch:17, weight train batch: 342, step:13, loss before: 1.35227855935e-06, loss after: 1.35227855935e-06.\n",
      "Epoch:17, weight train batch: 342, step:14, loss before: 1.45658646034e-06, loss after: 1.43050942825e-06.\n",
      "Epoch:17, weight train batch: 342, step:15, loss before: 0.0216625146568, loss after: 0.0216625146568.\n",
      "Epoch:17, weight train batch: 342, step:16, loss before: 1.08405799892e-06, loss after: 1.08405799892e-06.\n",
      "Epoch:17, weight train batch: 342, step:17, loss before: 1.3969814745e-06, loss after: 1.3969814745e-06.\n",
      "Epoch:17, weight train batch: 342, step:18, loss before: 1.30757507577e-06, loss after: 1.30757507577e-06.\n",
      "Epoch:17, weight train batch: 342, step:19, loss before: 1.10640996809e-06, loss after: 1.10640996809e-06.\n",
      "Epoch:17, weight train batch: 342, step:20, loss before: 1.01700300092e-06, loss after: 1.01700300092e-06.\n",
      "Epoch:17, weight train batch: 342, step:21, loss before: 1.51619087774e-06, loss after: 1.51619087774e-06.\n",
      "Epoch:17, weight train batch: 342, step:22, loss before: 1.26974764498e-05, loss after: 1.26714085127e-05.\n",
      "Epoch:17, weight train batch: 342, step:23, loss before: 1.22934420688e-06, loss after: 1.22934420688e-06.\n",
      "Epoch:17, weight train batch: 342, step:24, loss before: 1.1101351447e-06, loss after: 1.1101351447e-06.\n",
      "Epoch:17, weight train batch: 342, step:25, loss before: 2.74549211099e-06, loss after: 2.74549211099e-06.\n",
      "Epoch:17, weight train batch: 342, step:26, loss before: 1.85891485671e-06, loss after: 1.85891485671e-06.\n",
      "Epoch:17, weight train batch: 342, step:27, loss before: 1.51991616804e-06, loss after: 1.51991616804e-06.\n",
      "Epoch:17, weight train batch: 342, step:28, loss before: 1.22561891658e-06, loss after: 1.22561891658e-06.\n",
      "Epoch:17, weight train batch: 342, step:29, loss before: 1.37835559144e-06, loss after: 1.37835559144e-06.\n",
      "Epoch:17, weight train batch: 342, step:30, loss before: 1.31875094667e-06, loss after: 1.31875094667e-06.\n",
      "Epoch:17, weight train batch: 342, step:31, loss before: 9.68574454419e-07, loss after: 9.68574454419e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 338, loss before: 1.19115998132e-06, loss after: 1.19115998132e-06.\n",
      "Epoch:17, weight train batch: 343, step:0, loss before: 1.1064098544e-06, loss after: 1.1064098544e-06.\n",
      "Epoch:17, weight train batch: 343, step:1, loss before: 1.03562945242e-06, loss after: 1.03562945242e-06.\n",
      "Epoch:17, weight train batch: 343, step:2, loss before: 1.34855326905e-06, loss after: 1.34855326905e-06.\n",
      "Epoch:17, weight train batch: 343, step:3, loss before: 1.04680532331e-06, loss after: 1.04680532331e-06.\n",
      "Epoch:17, weight train batch: 343, step:4, loss before: 1.06170648451e-06, loss after: 1.06170648451e-06.\n",
      "Epoch:17, weight train batch: 343, step:5, loss before: 1.13621217679e-06, loss after: 1.13621217679e-06.\n",
      "Epoch:17, weight train batch: 343, step:6, loss before: 1.23306949718e-06, loss after: 1.23306949718e-06.\n",
      "Epoch:17, weight train batch: 343, step:7, loss before: 8.90343358151e-07, loss after: 8.90343358151e-07.\n",
      "Epoch:17, weight train batch: 343, step:8, loss before: 1.27777275338e-06, loss after: 1.27777275338e-06.\n",
      "Epoch:17, weight train batch: 343, step:9, loss before: 8.08387142115e-07, loss after: 8.08387142115e-07.\n",
      "Epoch:17, weight train batch: 343, step:10, loss before: 9.35046841732e-07, loss after: 9.35046841732e-07.\n",
      "Epoch:17, weight train batch: 343, step:11, loss before: 1.1362120631e-06, loss after: 1.1362120631e-06.\n",
      "Epoch:17, weight train batch: 343, step:12, loss before: 1.24797065837e-06, loss after: 1.24797065837e-06.\n",
      "Epoch:17, weight train batch: 343, step:13, loss before: 1.44168529914e-06, loss after: 1.44168529914e-06.\n",
      "Epoch:17, weight train batch: 343, step:14, loss before: 1.30757507577e-06, loss after: 1.30757507577e-06.\n",
      "Epoch:17, weight train batch: 343, step:15, loss before: 1.1026845641e-06, loss after: 1.1026845641e-06.\n",
      "Epoch:17, weight train batch: 343, step:16, loss before: 1.03935474272e-06, loss after: 1.03935474272e-06.\n",
      "Epoch:17, weight train batch: 343, step:17, loss before: 1.72108150309e-06, loss after: 1.72108150309e-06.\n",
      "Epoch:17, weight train batch: 343, step:18, loss before: 1.80676306627e-06, loss after: 1.80676306627e-06.\n",
      "Epoch:17, weight train batch: 343, step:19, loss before: 1.23306949718e-06, loss after: 1.23306949718e-06.\n",
      "Epoch:17, weight train batch: 343, step:20, loss before: 8.27013650451e-07, loss after: 8.12112489257e-07.\n",
      "Epoch:17, weight train batch: 343, step:21, loss before: 1.50874052451e-06, loss after: 1.50874052451e-06.\n",
      "Epoch:17, weight train batch: 343, step:22, loss before: 1.33365222155e-06, loss after: 1.33365222155e-06.\n",
      "Epoch:17, weight train batch: 343, step:23, loss before: 1.64285052051e-06, loss after: 1.64285052051e-06.\n",
      "Epoch:17, weight train batch: 343, step:24, loss before: 1.00955253401e-06, loss after: 1.00955253401e-06.\n",
      "Epoch:17, weight train batch: 343, step:25, loss before: 6.22123025096e-07, loss after: 6.22123025096e-07.\n",
      "Epoch:17, weight train batch: 343, step:26, loss before: 1.21816833598e-06, loss after: 1.21816833598e-06.\n",
      "Epoch:17, weight train batch: 343, step:27, loss before: 7.63683829064e-07, loss after: 7.63683829064e-07.\n",
      "Epoch:17, weight train batch: 343, step:28, loss before: 1.00582724372e-06, loss after: 1.00582724372e-06.\n",
      "Epoch:17, weight train batch: 343, step:29, loss before: 1.5646197653e-06, loss after: 1.5646197653e-06.\n",
      "Epoch:17, weight train batch: 343, step:30, loss before: 1.0840582263e-06, loss after: 1.0840582263e-06.\n",
      "Epoch:17, weight train batch: 343, step:31, loss before: 1.04680520963e-06, loss after: 1.04680520963e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 339, loss before: 1.18184675557e-06, loss after: 1.18184675557e-06.\n",
      "Epoch:17, weight train batch: 344, step:0, loss before: 1.56834494192e-06, loss after: 1.56834494192e-06.\n",
      "Epoch:17, weight train batch: 344, step:1, loss before: 8.41914584271e-07, loss after: 8.41914584271e-07.\n",
      "Epoch:17, weight train batch: 344, step:2, loss before: 1.37090501084e-06, loss after: 1.37090501084e-06.\n",
      "Epoch:17, weight train batch: 344, step:3, loss before: 1.28894873797e-06, loss after: 1.28894873797e-06.\n",
      "Epoch:17, weight train batch: 344, step:4, loss before: 1.1175857253e-06, loss after: 1.1175857253e-06.\n",
      "Epoch:17, weight train batch: 344, step:5, loss before: 4.40315034211e-06, loss after: 4.40315034211e-06.\n",
      "Epoch:17, weight train batch: 344, step:6, loss before: 1.32992693125e-06, loss after: 1.32992693125e-06.\n",
      "Epoch:17, weight train batch: 344, step:7, loss before: 3.91888488593e-06, loss after: 3.91516005038e-06.\n",
      "Epoch:17, weight train batch: 344, step:8, loss before: 1.38580617204e-06, loss after: 1.38580617204e-06.\n",
      "Epoch:17, weight train batch: 344, step:9, loss before: 1.37090489716e-06, loss after: 1.37090489716e-06.\n",
      "Epoch:17, weight train batch: 344, step:10, loss before: 8.12112489257e-07, loss after: 8.12112489257e-07.\n",
      "Epoch:17, weight train batch: 344, step:11, loss before: 9.7229963103e-07, loss after: 9.7229963103e-07.\n",
      "Epoch:17, weight train batch: 344, step:12, loss before: 1.25169583498e-06, loss after: 1.25169583498e-06.\n",
      "Epoch:17, weight train batch: 344, step:13, loss before: 1.09150869321e-06, loss after: 1.09150869321e-06.\n",
      "Epoch:17, weight train batch: 344, step:14, loss before: 2.64863638222e-06, loss after: 2.64863638222e-06.\n",
      "Epoch:17, weight train batch: 344, step:15, loss before: 5.57423081773e-05, loss after: 5.57051207579e-05.\n",
      "Epoch:17, weight train batch: 344, step:16, loss before: 1.44540990732e-06, loss after: 1.44540990732e-06.\n",
      "Epoch:17, weight train batch: 344, step:17, loss before: 0.021662324667, loss after: 0.021662324667.\n",
      "Epoch:17, weight train batch: 344, step:18, loss before: 1.14366253001e-06, loss after: 1.14366253001e-06.\n",
      "Epoch:17, weight train batch: 344, step:19, loss before: 4.96538850712e-05, loss after: 4.94121159136e-05.\n",
      "Epoch:17, weight train batch: 344, step:20, loss before: 9.76024921329e-07, loss after: 9.76024921329e-07.\n",
      "Epoch:17, weight train batch: 344, step:21, loss before: 1.31130036607e-06, loss after: 1.31130036607e-06.\n",
      "Epoch:17, weight train batch: 344, step:22, loss before: 8.23288360152e-07, loss after: 8.23288360152e-07.\n",
      "Epoch:17, weight train batch: 344, step:23, loss before: 1.55344378072e-06, loss after: 1.55344378072e-06.\n",
      "Epoch:17, weight train batch: 344, step:24, loss before: 1.02817875813e-06, loss after: 1.00210195342e-06.\n",
      "Epoch:17, weight train batch: 344, step:25, loss before: 1.00955253401e-06, loss after: 1.00955253401e-06.\n",
      "Epoch:17, weight train batch: 344, step:26, loss before: 1.03190416212e-06, loss after: 1.00955253401e-06.\n",
      "Epoch:17, weight train batch: 344, step:27, loss before: 7.37606796974e-07, loss after: 7.37606796974e-07.\n",
      "Epoch:17, weight train batch: 344, step:28, loss before: 1.2107167322e-06, loss after: 1.2107167322e-06.\n",
      "Epoch:17, weight train batch: 344, step:29, loss before: 1.38580617204e-06, loss after: 1.38580617204e-06.\n",
      "Epoch:17, weight train batch: 344, step:30, loss before: 1.22561891658e-06, loss after: 1.22561891658e-06.\n",
      "Epoch:17, weight train batch: 344, step:31, loss before: 1.20326717479e-06, loss after: 1.20326717479e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 340, loss before: 1.18184686926e-06, loss after: 0.000185561642866.\n",
      "Epoch:17, weight train batch: 345, step:0, loss before: 1.01327782431e-06, loss after: 1.01327782431e-06.\n",
      "Epoch:17, weight train batch: 345, step:1, loss before: 1.19581659419e-06, loss after: 1.19581659419e-06.\n",
      "Epoch:17, weight train batch: 345, step:2, loss before: 1.0989592738e-06, loss after: 1.0989592738e-06.\n",
      "Epoch:17, weight train batch: 345, step:3, loss before: 8.38189407659e-07, loss after: 8.38189407659e-07.\n",
      "Epoch:17, weight train batch: 345, step:4, loss before: 1.34482809244e-06, loss after: 1.34482809244e-06.\n",
      "Epoch:17, weight train batch: 345, step:5, loss before: 1.06915717879e-06, loss after: 1.06915717879e-06.\n",
      "Epoch:17, weight train batch: 345, step:6, loss before: 8.45639988256e-07, loss after: 8.45639988256e-07.\n",
      "Epoch:17, weight train batch: 345, step:7, loss before: 9.61123873822e-07, loss after: 9.61123873822e-07.\n",
      "Epoch:17, weight train batch: 345, step:8, loss before: 1.35227867304e-06, loss after: 1.35227867304e-06.\n",
      "Epoch:17, weight train batch: 345, step:9, loss before: 3.46441447618e-06, loss after: 3.46068964063e-06.\n",
      "Epoch:17, weight train batch: 345, step:10, loss before: 9.83475501926e-07, loss after: 9.83475501926e-07.\n",
      "Epoch:17, weight train batch: 345, step:11, loss before: 1.23306949718e-06, loss after: 1.23306949718e-06.\n",
      "Epoch:17, weight train batch: 345, step:12, loss before: 1.33365222155e-06, loss after: 1.33365222155e-06.\n",
      "Epoch:17, weight train batch: 345, step:13, loss before: 1.40443250984e-06, loss after: 1.40443250984e-06.\n",
      "Epoch:17, weight train batch: 345, step:14, loss before: 1.03562945242e-06, loss after: 1.03562945242e-06.\n",
      "Epoch:17, weight train batch: 345, step:15, loss before: 6.89178136781e-07, loss after: 6.89178136781e-07.\n",
      "Epoch:17, weight train batch: 345, step:16, loss before: 9.20145680539e-07, loss after: 9.20145680539e-07.\n",
      "Epoch:17, weight train batch: 345, step:17, loss before: 1.0505307273e-06, loss after: 1.0505307273e-06.\n",
      "Epoch:17, weight train batch: 345, step:18, loss before: 8.56815915995e-07, loss after: 8.56815915995e-07.\n",
      "Epoch:17, weight train batch: 345, step:19, loss before: 1.0542560176e-06, loss after: 1.0542560176e-06.\n",
      "Epoch:17, weight train batch: 345, step:20, loss before: 1.35227787723e-06, loss after: 1.35227787723e-06.\n",
      "Epoch:17, weight train batch: 345, step:21, loss before: 1.23679478747e-06, loss after: 1.23679478747e-06.\n",
      "Epoch:17, weight train batch: 345, step:22, loss before: 1.31875106035e-06, loss after: 1.31875106035e-06.\n",
      "Epoch:17, weight train batch: 345, step:23, loss before: 1.03190427581e-06, loss after: 1.03190427581e-06.\n",
      "Epoch:17, weight train batch: 345, step:24, loss before: 1.113860435e-06, loss after: 1.113860435e-06.\n",
      "Epoch:17, weight train batch: 345, step:25, loss before: 1.24052007777e-06, loss after: 1.24052007777e-06.\n",
      "Epoch:17, weight train batch: 345, step:26, loss before: 6.74276975587e-07, loss after: 6.74276975587e-07.\n",
      "Epoch:17, weight train batch: 345, step:27, loss before: 1.28894873797e-06, loss after: 1.28894873797e-06.\n",
      "Epoch:17, weight train batch: 345, step:28, loss before: 1.34855326905e-06, loss after: 1.34855326905e-06.\n",
      "Epoch:17, weight train batch: 345, step:29, loss before: 2.17189208342e-05, loss after: 2.16630796785e-05.\n",
      "Epoch:17, weight train batch: 345, step:30, loss before: 1.21816833598e-06, loss after: 1.21816833598e-06.\n",
      "Epoch:17, weight train batch: 345, step:31, loss before: 1.38953146234e-06, loss after: 1.38953146234e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 341, loss before: 1.11199778985e-06, loss after: 0.000186281613423.\n",
      "Epoch:17, weight train batch: 346, step:0, loss before: 9.01519229046e-07, loss after: 9.01519229046e-07.\n",
      "Epoch:17, weight train batch: 346, step:1, loss before: 1.31130047976e-06, loss after: 1.31130047976e-06.\n",
      "Epoch:17, weight train batch: 346, step:2, loss before: 1.1734648524e-06, loss after: 1.1734648524e-06.\n",
      "Epoch:17, weight train batch: 346, step:3, loss before: 9.49948002926e-07, loss after: 9.49948002926e-07.\n",
      "Epoch:17, weight train batch: 346, step:4, loss before: 9.94651372821e-07, loss after: 9.94651372821e-07.\n",
      "Epoch:17, weight train batch: 346, step:5, loss before: 1.34110280214e-06, loss after: 1.34110280214e-06.\n",
      "Epoch:17, weight train batch: 346, step:6, loss before: 1.44913587974e-06, loss after: 1.44913587974e-06.\n",
      "Epoch:17, weight train batch: 346, step:7, loss before: 1.03190427581e-06, loss after: 1.00582724372e-06.\n",
      "Epoch:17, weight train batch: 346, step:8, loss before: 1.78813661478e-06, loss after: 1.78813661478e-06.\n",
      "Epoch:17, weight train batch: 346, step:9, loss before: 1.0356295661e-06, loss after: 1.0356295661e-06.\n",
      "Epoch:17, weight train batch: 346, step:10, loss before: 1.31130047976e-06, loss after: 1.31130047976e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:17, weight train batch: 346, step:11, loss before: 7.59958481922e-07, loss after: 7.59958481922e-07.\n",
      "Epoch:17, weight train batch: 346, step:12, loss before: 1.34855326905e-06, loss after: 1.34855326905e-06.\n",
      "Epoch:17, weight train batch: 346, step:13, loss before: 8.30738827062e-07, loss after: 8.30738827062e-07.\n",
      "Epoch:17, weight train batch: 346, step:14, loss before: 1.00955242033e-06, loss after: 1.00955242033e-06.\n",
      "Epoch:17, weight train batch: 346, step:15, loss before: 0.000739251903724, loss after: 0.000735908048227.\n",
      "Epoch:17, weight train batch: 346, step:16, loss before: 1.19954188449e-06, loss after: 1.19954188449e-06.\n",
      "Epoch:17, weight train batch: 346, step:17, loss before: 1.00582713003e-06, loss after: 1.00582713003e-06.\n",
      "Epoch:17, weight train batch: 346, step:18, loss before: 9.1642039024e-07, loss after: 9.1642039024e-07.\n",
      "Epoch:17, weight train batch: 346, step:19, loss before: 1.12131101559e-06, loss after: 1.15111333798e-06.\n",
      "Epoch:17, weight train batch: 346, step:20, loss before: 7.71134409661e-07, loss after: 7.71134409661e-07.\n",
      "Epoch:17, weight train batch: 346, step:21, loss before: 6.55650524095e-07, loss after: 6.55650524095e-07.\n",
      "Epoch:17, weight train batch: 346, step:22, loss before: 1.76950982222e-06, loss after: 1.76950982222e-06.\n",
      "Epoch:17, weight train batch: 346, step:23, loss before: 1.25169594867e-06, loss after: 1.25169594867e-06.\n",
      "Epoch:17, weight train batch: 346, step:24, loss before: 1.12503630589e-06, loss after: 1.12503630589e-06.\n",
      "Epoch:17, weight train batch: 346, step:25, loss before: 1.34855338274e-06, loss after: 1.34855338274e-06.\n",
      "Epoch:17, weight train batch: 346, step:26, loss before: 3.40108181263e-06, loss after: 3.40480664818e-06.\n",
      "Epoch:17, weight train batch: 346, step:27, loss before: 1.18836555885e-06, loss after: 1.18836555885e-06.\n",
      "Epoch:17, weight train batch: 346, step:28, loss before: 1.13621217679e-06, loss after: 1.13621217679e-06.\n",
      "Epoch:17, weight train batch: 346, step:29, loss before: 1.50501523422e-06, loss after: 1.50501523422e-06.\n",
      "Epoch:17, weight train batch: 346, step:30, loss before: 1.33365222155e-06, loss after: 1.33365222155e-06.\n",
      "Epoch:17, weight train batch: 346, step:31, loss before: 1.06170648451e-06, loss after: 1.06170648451e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 342, loss before: 1.20140452964e-06, loss after: 1.25635233417e-06.\n",
      "Epoch:17, weight train batch: 347, step:0, loss before: 1.59069668371e-06, loss after: 1.59069668371e-06.\n",
      "Epoch:17, weight train batch: 347, step:1, loss before: 1.35600384965e-06, loss after: 1.35600384965e-06.\n",
      "Epoch:17, weight train batch: 347, step:2, loss before: 1.05425590391e-06, loss after: 1.05425590391e-06.\n",
      "Epoch:17, weight train batch: 347, step:3, loss before: 1.05798119421e-06, loss after: 1.05798119421e-06.\n",
      "Epoch:17, weight train batch: 347, step:4, loss before: 1.06543188849e-06, loss after: 1.06543188849e-06.\n",
      "Epoch:17, weight train batch: 347, step:5, loss before: 1.22189362628e-06, loss after: 1.22189362628e-06.\n",
      "Epoch:17, weight train batch: 347, step:6, loss before: 1.22561891658e-06, loss after: 1.22561891658e-06.\n",
      "Epoch:17, weight train batch: 347, step:7, loss before: 9.05244633032e-07, loss after: 9.05244633032e-07.\n",
      "Epoch:17, weight train batch: 347, step:8, loss before: 1.13621217679e-06, loss after: 1.13621217679e-06.\n",
      "Epoch:17, weight train batch: 347, step:9, loss before: 1.22561891658e-06, loss after: 1.19209130389e-06.\n",
      "Epoch:17, weight train batch: 347, step:10, loss before: 9.76025035015e-07, loss after: 9.76025035015e-07.\n",
      "Epoch:17, weight train batch: 347, step:11, loss before: 1.1026845641e-06, loss after: 1.1026845641e-06.\n",
      "Epoch:17, weight train batch: 347, step:12, loss before: 1.06915717879e-06, loss after: 1.06915717879e-06.\n",
      "Epoch:17, weight train batch: 347, step:13, loss before: 9.53673293225e-07, loss after: 9.53673293225e-07.\n",
      "Epoch:17, weight train batch: 347, step:14, loss before: 1.05798130789e-06, loss after: 1.05798130789e-06.\n",
      "Epoch:17, weight train batch: 347, step:15, loss before: 1.31875117404e-06, loss after: 1.31875117404e-06.\n",
      "Epoch:17, weight train batch: 347, step:16, loss before: 1.35600384965e-06, loss after: 1.35600384965e-06.\n",
      "Epoch:17, weight train batch: 347, step:17, loss before: 1.48266349242e-06, loss after: 1.48266349242e-06.\n",
      "Epoch:17, weight train batch: 347, step:18, loss before: 7.56233248467e-07, loss after: 7.56233248467e-07.\n",
      "Epoch:17, weight train batch: 347, step:19, loss before: 9.94651259134e-07, loss after: 9.94651259134e-07.\n",
      "Epoch:17, weight train batch: 347, step:20, loss before: 9.98376663119e-07, loss after: 9.98376663119e-07.\n",
      "Epoch:17, weight train batch: 347, step:21, loss before: 0.000296349928249, loss after: 0.000295312900562.\n",
      "Epoch:17, weight train batch: 347, step:22, loss before: 5.99771340148e-07, loss after: 5.99771340148e-07.\n",
      "Epoch:17, weight train batch: 347, step:23, loss before: 1.08778340291e-06, loss after: 1.08778340291e-06.\n",
      "Epoch:17, weight train batch: 347, step:24, loss before: 1.19581659419e-06, loss after: 1.19581659419e-06.\n",
      "Epoch:17, weight train batch: 347, step:25, loss before: 1.1026845641e-06, loss after: 1.1026845641e-06.\n",
      "Epoch:17, weight train batch: 347, step:26, loss before: 1.37090501084e-06, loss after: 1.37090501084e-06.\n",
      "Epoch:17, weight train batch: 347, step:27, loss before: 2.03772128771e-06, loss after: 2.03772128771e-06.\n",
      "Epoch:17, weight train batch: 347, step:28, loss before: 1.13993746709e-06, loss after: 1.13993746709e-06.\n",
      "Epoch:17, weight train batch: 347, step:29, loss before: 1.1064098544e-06, loss after: 1.1064098544e-06.\n",
      "Epoch:17, weight train batch: 347, step:30, loss before: 1.13993746709e-06, loss after: 1.13993746709e-06.\n",
      "Epoch:17, weight train batch: 347, step:31, loss before: 9.83475615612e-07, loss after: 9.83475615612e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 343, loss before: 1.19116020869e-06, loss after: 1.19116020869e-06.\n",
      "Epoch:17, weight train batch: 348, step:0, loss before: 1.29267402826e-06, loss after: 1.29267402826e-06.\n",
      "Epoch:17, weight train batch: 348, step:1, loss before: 1.27404757677e-06, loss after: 1.27404757677e-06.\n",
      "Epoch:17, weight train batch: 348, step:2, loss before: 5.51173579879e-05, loss after: 5.50876065972e-05.\n",
      "Epoch:17, weight train batch: 348, step:3, loss before: 0.0216619670391, loss after: 0.0216619670391.\n",
      "Epoch:17, weight train batch: 348, step:4, loss before: 1.24797054468e-06, loss after: 1.24797054468e-06.\n",
      "Epoch:17, weight train batch: 348, step:5, loss before: 1.20326717479e-06, loss after: 1.20326717479e-06.\n",
      "Epoch:17, weight train batch: 348, step:6, loss before: 1.15111333798e-06, loss after: 1.15111333798e-06.\n",
      "Epoch:17, weight train batch: 348, step:7, loss before: 1.28723149828e-05, loss after: 1.28388001031e-05.\n",
      "Epoch:17, weight train batch: 348, step:8, loss before: 1.34482797876e-06, loss after: 1.34482797876e-06.\n",
      "Epoch:17, weight train batch: 348, step:9, loss before: 8.75442196957e-07, loss after: 8.75442196957e-07.\n",
      "Epoch:17, weight train batch: 348, step:10, loss before: 1.37463018746e-06, loss after: 1.37463018746e-06.\n",
      "Epoch:17, weight train batch: 348, step:11, loss before: 9.27596261135e-07, loss after: 9.27596261135e-07.\n",
      "Epoch:17, weight train batch: 348, step:12, loss before: 1.02072840491e-06, loss after: 1.02072840491e-06.\n",
      "Epoch:17, weight train batch: 348, step:13, loss before: 9.87200678537e-07, loss after: 9.87200678537e-07.\n",
      "Epoch:17, weight train batch: 348, step:14, loss before: 8.04661851816e-07, loss after: 8.04661851816e-07.\n",
      "Epoch:17, weight train batch: 348, step:15, loss before: 1.22189362628e-06, loss after: 1.22189362628e-06.\n",
      "Epoch:17, weight train batch: 348, step:16, loss before: 1.0989592738e-06, loss after: 1.0989592738e-06.\n",
      "Epoch:17, weight train batch: 348, step:17, loss before: 1.21444304568e-06, loss after: 1.21444304568e-06.\n",
      "Epoch:17, weight train batch: 348, step:18, loss before: 1.22189362628e-06, loss after: 1.22189362628e-06.\n",
      "Epoch:17, weight train batch: 348, step:19, loss before: 1.02072840491e-06, loss after: 1.02072840491e-06.\n",
      "Epoch:17, weight train batch: 348, step:20, loss before: 3.18133311339e-06, loss after: 3.17760805046e-06.\n",
      "Epoch:17, weight train batch: 348, step:21, loss before: 1.02072829122e-06, loss after: 1.02072829122e-06.\n",
      "Epoch:17, weight train batch: 348, step:22, loss before: 1.18836601359e-06, loss after: 1.18836601359e-06.\n",
      "Epoch:17, weight train batch: 348, step:23, loss before: 1.01700311461e-06, loss after: 1.01700311461e-06.\n",
      "Epoch:17, weight train batch: 348, step:24, loss before: 1.28894873797e-06, loss after: 1.28894873797e-06.\n",
      "Epoch:17, weight train batch: 348, step:25, loss before: 1.09150869321e-06, loss after: 1.09150869321e-06.\n",
      "Epoch:17, weight train batch: 348, step:26, loss before: 9.12695099942e-07, loss after: 9.12695099942e-07.\n",
      "Epoch:17, weight train batch: 348, step:27, loss before: 1.50128983023e-06, loss after: 1.45286128372e-06.\n",
      "Epoch:17, weight train batch: 348, step:28, loss before: 1.44541081681e-06, loss after: 1.44541081681e-06.\n",
      "Epoch:17, weight train batch: 348, step:29, loss before: 9.16420447084e-07, loss after: 9.16420447084e-07.\n",
      "Epoch:17, weight train batch: 348, step:30, loss before: 1.00582724372e-06, loss after: 1.00582724372e-06.\n",
      "Epoch:17, weight train batch: 348, step:31, loss before: 9.79750211627e-07, loss after: 9.79750211627e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 344, loss before: 1.16787714433e-06, loss after: 1.16787714433e-06.\n",
      "Epoch:17, weight train batch: 349, step:0, loss before: 1.15856391858e-06, loss after: 1.15856391858e-06.\n",
      "Epoch:17, weight train batch: 349, step:1, loss before: 3.72518320546e-06, loss after: 3.72518320546e-06.\n",
      "Epoch:17, weight train batch: 349, step:2, loss before: 0.000703311176039, loss after: 0.000701693701558.\n",
      "Epoch:17, weight train batch: 349, step:3, loss before: 8.23288360152e-07, loss after: 8.23288360152e-07.\n",
      "Epoch:17, weight train batch: 349, step:4, loss before: 9.79750211627e-07, loss after: 9.79750211627e-07.\n",
      "Epoch:17, weight train batch: 349, step:5, loss before: 1.91851358977e-06, loss after: 1.91478829947e-06.\n",
      "Epoch:17, weight train batch: 349, step:6, loss before: 9.49947661866e-07, loss after: 9.49947661866e-07.\n",
      "Epoch:17, weight train batch: 349, step:7, loss before: 8.38189521346e-07, loss after: 8.56815915995e-07.\n",
      "Epoch:17, weight train batch: 349, step:8, loss before: 1.07660753201e-06, loss after: 1.07660753201e-06.\n",
      "Epoch:17, weight train batch: 349, step:9, loss before: 1.1064098544e-06, loss after: 1.1064098544e-06.\n",
      "Epoch:17, weight train batch: 349, step:10, loss before: 1.07660753201e-06, loss after: 1.07660753201e-06.\n",
      "Epoch:17, weight train batch: 349, step:11, loss before: 1.16973967579e-06, loss after: 1.16973967579e-06.\n",
      "Epoch:17, weight train batch: 349, step:12, loss before: 7.30156216378e-07, loss after: 7.30156216378e-07.\n",
      "Epoch:17, weight train batch: 349, step:13, loss before: 1.34110268846e-06, loss after: 1.34110268846e-06.\n",
      "Epoch:17, weight train batch: 349, step:14, loss before: 7.33881506676e-07, loss after: 7.33881506676e-07.\n",
      "Epoch:17, weight train batch: 349, step:15, loss before: 1.1771901427e-06, loss after: 1.1771901427e-06.\n",
      "Epoch:17, weight train batch: 349, step:16, loss before: 1.19581670788e-06, loss after: 1.19581670788e-06.\n",
      "Epoch:17, weight train batch: 349, step:17, loss before: 1.180915433e-06, loss after: 1.180915433e-06.\n",
      "Epoch:17, weight train batch: 349, step:18, loss before: 1.19413271022e-05, loss after: 1.19040878417e-05.\n",
      "Epoch:17, weight train batch: 349, step:19, loss before: 1.25914641558e-06, loss after: 1.25914641558e-06.\n",
      "Epoch:17, weight train batch: 349, step:20, loss before: 1.27032228647e-06, loss after: 1.27032228647e-06.\n",
      "Epoch:17, weight train batch: 349, step:21, loss before: 1.13993746709e-06, loss after: 1.13993746709e-06.\n",
      "Epoch:17, weight train batch: 349, step:22, loss before: 9.79750211627e-07, loss after: 9.79750211627e-07.\n",
      "Epoch:17, weight train batch: 349, step:23, loss before: 1.22934420688e-06, loss after: 1.22934420688e-06.\n",
      "Epoch:17, weight train batch: 349, step:24, loss before: 1.12503630589e-06, loss after: 1.12503630589e-06.\n",
      "Epoch:17, weight train batch: 349, step:25, loss before: 1.25169583498e-06, loss after: 1.21444304568e-06.\n",
      "Epoch:17, weight train batch: 349, step:26, loss before: 1.02072840491e-06, loss after: 1.02072840491e-06.\n",
      "Epoch:17, weight train batch: 349, step:27, loss before: 8.19563069854e-07, loss after: 8.19563069854e-07.\n",
      "Epoch:17, weight train batch: 349, step:28, loss before: 1.16601449918e-06, loss after: 1.16601449918e-06.\n",
      "Epoch:17, weight train batch: 349, step:29, loss before: 8.15837779555e-07, loss after: 8.15837779555e-07.\n",
      "Epoch:17, weight train batch: 349, step:30, loss before: 1.0877835166e-06, loss after: 1.0877835166e-06.\n",
      "Epoch:17, weight train batch: 349, step:31, loss before: 1.05425590391e-06, loss after: 1.05425590391e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 345, loss before: 1.43049976487e-06, loss after: 4.14764872403e-06.\n",
      "Epoch:17, weight train batch: 350, step:0, loss before: 4.99188558933e-07, loss after: 4.99188558933e-07.\n",
      "Epoch:17, weight train batch: 350, step:1, loss before: 9.35046614359e-07, loss after: 9.35046614359e-07.\n",
      "Epoch:17, weight train batch: 350, step:2, loss before: 1.09150880689e-06, loss after: 1.09150880689e-06.\n",
      "Epoch:17, weight train batch: 350, step:3, loss before: 8.27013650451e-07, loss after: 8.27013650451e-07.\n",
      "Epoch:17, weight train batch: 350, step:4, loss before: 8.79167714629e-07, loss after: 8.79167714629e-07.\n",
      "Epoch:17, weight train batch: 350, step:5, loss before: 1.20699246509e-06, loss after: 1.20699246509e-06.\n",
      "Epoch:17, weight train batch: 350, step:6, loss before: 1.22561891658e-06, loss after: 1.22561891658e-06.\n",
      "Epoch:17, weight train batch: 350, step:7, loss before: 1.02817887182e-06, loss after: 1.02817887182e-06.\n",
      "Epoch:17, weight train batch: 350, step:8, loss before: 1.5012900576e-06, loss after: 1.5012900576e-06.\n",
      "Epoch:17, weight train batch: 350, step:9, loss before: 1.24424536807e-06, loss after: 1.24424536807e-06.\n",
      "Epoch:17, weight train batch: 350, step:10, loss before: 1.13380983748e-05, loss after: 1.1297133824e-05.\n",
      "Epoch:17, weight train batch: 350, step:11, loss before: 9.16420503927e-07, loss after: 9.16420503927e-07.\n",
      "Epoch:17, weight train batch: 350, step:12, loss before: 1.23306949718e-06, loss after: 1.23306949718e-06.\n",
      "Epoch:17, weight train batch: 350, step:13, loss before: 1.15483862828e-06, loss after: 1.15483862828e-06.\n",
      "Epoch:17, weight train batch: 350, step:14, loss before: 1.22934420688e-06, loss after: 1.22934420688e-06.\n",
      "Epoch:17, weight train batch: 350, step:15, loss before: 7.56233248467e-07, loss after: 7.56233248467e-07.\n",
      "Epoch:17, weight train batch: 350, step:16, loss before: 9.76024921329e-07, loss after: 9.76024921329e-07.\n",
      "Epoch:17, weight train batch: 350, step:17, loss before: 4.60193841718e-05, loss after: 4.58333888673e-05.\n",
      "Epoch:17, weight train batch: 350, step:18, loss before: 1.25914664295e-06, loss after: 1.25914664295e-06.\n",
      "Epoch:17, weight train batch: 350, step:19, loss before: 7.45057377571e-07, loss after: 7.45057377571e-07.\n",
      "Epoch:17, weight train batch: 350, step:20, loss before: 1.04680532331e-06, loss after: 1.04680532331e-06.\n",
      "Epoch:17, weight train batch: 350, step:21, loss before: 9.83475501926e-07, loss after: 9.83475501926e-07.\n",
      "Epoch:17, weight train batch: 350, step:22, loss before: 9.46222655784e-07, loss after: 9.46222655784e-07.\n",
      "Epoch:17, weight train batch: 350, step:23, loss before: 2.26495103561e-06, loss after: 2.26495103561e-06.\n",
      "Epoch:17, weight train batch: 350, step:24, loss before: 1.22561891658e-06, loss after: 1.22561891658e-06.\n",
      "Epoch:17, weight train batch: 350, step:25, loss before: 1.03562945242e-06, loss after: 1.03562945242e-06.\n",
      "Epoch:17, weight train batch: 350, step:26, loss before: 8.94068762136e-07, loss after: 8.94068762136e-07.\n",
      "Epoch:17, weight train batch: 350, step:27, loss before: 9.7229963103e-07, loss after: 9.7229963103e-07.\n",
      "Epoch:17, weight train batch: 350, step:28, loss before: 8.90343471838e-07, loss after: 8.90343471838e-07.\n",
      "Epoch:17, weight train batch: 350, step:29, loss before: 8.0466190866e-07, loss after: 8.0466190866e-07.\n",
      "Epoch:17, weight train batch: 350, step:30, loss before: 1.02445369521e-06, loss after: 1.02445369521e-06.\n",
      "Epoch:17, weight train batch: 350, step:31, loss before: 1.0877835166e-06, loss after: 1.0877835166e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 346, loss before: 1.09523409719e-06, loss after: 1.09523409719e-06.\n",
      "Epoch:17, weight train batch: 351, step:0, loss before: 1.82538292393e-06, loss after: 1.82538292393e-06.\n",
      "Epoch:17, weight train batch: 351, step:1, loss before: 1.34110291583e-06, loss after: 1.34110291583e-06.\n",
      "Epoch:17, weight train batch: 351, step:2, loss before: 9.0896992333e-07, loss after: 9.0896992333e-07.\n",
      "Epoch:17, weight train batch: 351, step:3, loss before: 5.3271617162e-07, loss after: 5.3271617162e-07.\n",
      "Epoch:17, weight train batch: 351, step:4, loss before: 1.43050965562e-06, loss after: 1.43050965562e-06.\n",
      "Epoch:17, weight train batch: 351, step:5, loss before: 1.00210195342e-06, loss after: 1.00210195342e-06.\n",
      "Epoch:17, weight train batch: 351, step:6, loss before: 9.27596374822e-07, loss after: 9.27596374822e-07.\n",
      "Epoch:17, weight train batch: 351, step:7, loss before: 1.30012472255e-06, loss after: 1.30012472255e-06.\n",
      "Epoch:17, weight train batch: 351, step:8, loss before: 8.94068762136e-07, loss after: 8.94068762136e-07.\n",
      "Epoch:17, weight train batch: 351, step:9, loss before: 1.25542135265e-06, loss after: 1.25542135265e-06.\n",
      "Epoch:17, weight train batch: 351, step:10, loss before: 1.15483862828e-06, loss after: 1.15483862828e-06.\n",
      "Epoch:17, weight train batch: 351, step:11, loss before: 0.000273579527857, loss after: 0.000272630422842.\n",
      "Epoch:17, weight train batch: 351, step:12, loss before: 1.11385998025e-06, loss after: 1.11013480364e-06.\n",
      "Epoch:17, weight train batch: 351, step:13, loss before: 1.0766076457e-06, loss after: 1.0766076457e-06.\n",
      "Epoch:17, weight train batch: 351, step:14, loss before: 8.19563069854e-07, loss after: 8.19563069854e-07.\n",
      "Epoch:17, weight train batch: 351, step:15, loss before: 1.05425590391e-06, loss after: 1.05425590391e-06.\n",
      "Epoch:17, weight train batch: 351, step:16, loss before: 1.29267402826e-06, loss after: 1.29267402826e-06.\n",
      "Epoch:17, weight train batch: 351, step:17, loss before: 7.63683715377e-07, loss after: 7.63683715377e-07.\n",
      "Epoch:17, weight train batch: 351, step:18, loss before: 9.79750211627e-07, loss after: 9.79750211627e-07.\n",
      "Epoch:17, weight train batch: 351, step:19, loss before: 9.38772188874e-07, loss after: 9.38772188874e-07.\n",
      "Epoch:17, weight train batch: 351, step:20, loss before: 9.27596317979e-07, loss after: 9.27596317979e-07.\n",
      "Epoch:17, weight train batch: 351, step:21, loss before: 1.11758413368e-06, loss after: 1.11758413368e-06.\n",
      "Epoch:17, weight train batch: 351, step:22, loss before: 1.09523409719e-06, loss after: 1.09523409719e-06.\n",
      "Epoch:17, weight train batch: 351, step:23, loss before: 8.45640101943e-07, loss after: 8.45640101943e-07.\n",
      "Epoch:17, weight train batch: 351, step:24, loss before: 1.34482809244e-06, loss after: 1.34482809244e-06.\n",
      "Epoch:17, weight train batch: 351, step:25, loss before: 1.06543188849e-06, loss after: 1.06543188849e-06.\n",
      "Epoch:17, weight train batch: 351, step:26, loss before: 7.74859586272e-07, loss after: 7.74859586272e-07.\n",
      "Epoch:17, weight train batch: 351, step:27, loss before: 1.24424536807e-06, loss after: 1.24424536807e-06.\n",
      "Epoch:17, weight train batch: 351, step:28, loss before: 8.94068762136e-07, loss after: 8.94068762136e-07.\n",
      "Epoch:17, weight train batch: 351, step:29, loss before: 1.18464095067e-06, loss after: 1.18464095067e-06.\n",
      "Epoch:17, weight train batch: 351, step:30, loss before: 7.41332144116e-07, loss after: 7.41332144116e-07.\n",
      "Epoch:17, weight train batch: 351, step:31, loss before: 1.17719037007e-06, loss after: 1.17719037007e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 347, loss before: 1.15297598313e-06, loss after: 1.15297598313e-06.\n",
      "Epoch:17, weight train batch: 352, step:0, loss before: 1.12131101559e-06, loss after: 1.12131101559e-06.\n",
      "Epoch:17, weight train batch: 352, step:1, loss before: 8.00936618361e-07, loss after: 8.00936618361e-07.\n",
      "Epoch:17, weight train batch: 352, step:2, loss before: 3.72145518668e-06, loss after: 3.71773035113e-06.\n",
      "Epoch:17, weight train batch: 352, step:3, loss before: 1.16228920888e-06, loss after: 1.16228920888e-06.\n",
      "Epoch:17, weight train batch: 352, step:4, loss before: 1.12131101559e-06, loss after: 1.12131101559e-06.\n",
      "Epoch:17, weight train batch: 352, step:5, loss before: 1.33737751185e-06, loss after: 1.29639943225e-06.\n",
      "Epoch:17, weight train batch: 352, step:6, loss before: 8.34464174204e-07, loss after: 8.34464174204e-07.\n",
      "Epoch:17, weight train batch: 352, step:7, loss before: 1.07660775939e-06, loss after: 1.07660775939e-06.\n",
      "Epoch:17, weight train batch: 352, step:8, loss before: 1.15111345167e-06, loss after: 1.15111345167e-06.\n",
      "Epoch:17, weight train batch: 352, step:9, loss before: 5.99771283305e-07, loss after: 5.99771283305e-07.\n",
      "Epoch:17, weight train batch: 352, step:10, loss before: 1.5497187178e-06, loss after: 1.5497187178e-06.\n",
      "Epoch:17, weight train batch: 352, step:11, loss before: 8.15837779555e-07, loss after: 8.15837779555e-07.\n",
      "Epoch:17, weight train batch: 352, step:12, loss before: 1.0393548564e-06, loss after: 1.0393548564e-06.\n",
      "Epoch:17, weight train batch: 352, step:13, loss before: 1.37463041483e-06, loss after: 1.37463041483e-06.\n",
      "Epoch:17, weight train batch: 352, step:14, loss before: 8.56815915995e-07, loss after: 8.56815915995e-07.\n",
      "Epoch:17, weight train batch: 352, step:15, loss before: 2.36926189245e-06, loss after: 2.36926189245e-06.\n",
      "Epoch:17, weight train batch: 352, step:16, loss before: 1.27777298076e-06, loss after: 1.27777298076e-06.\n",
      "Epoch:17, weight train batch: 352, step:17, loss before: 1.0728823554e-06, loss after: 1.0728823554e-06.\n",
      "Epoch:17, weight train batch: 352, step:18, loss before: 1.30757530314e-06, loss after: 1.30757530314e-06.\n",
      "Epoch:17, weight train batch: 352, step:19, loss before: 7.74859699959e-07, loss after: 7.74859699959e-07.\n",
      "Epoch:17, weight train batch: 352, step:20, loss before: 1.20326740216e-06, loss after: 1.20326740216e-06.\n",
      "Epoch:17, weight train batch: 352, step:21, loss before: 1.37463041483e-06, loss after: 1.37463041483e-06.\n",
      "Epoch:17, weight train batch: 352, step:22, loss before: 6.14672444499e-07, loss after: 6.14672444499e-07.\n",
      "Epoch:17, weight train batch: 352, step:23, loss before: 2.02148894459e-05, loss after: 2.0144152586e-05.\n",
      "Epoch:17, weight train batch: 352, step:24, loss before: 7.86035514011e-07, loss after: 7.86035514011e-07.\n",
      "Epoch:17, weight train batch: 352, step:25, loss before: 1.12131101559e-06, loss after: 1.12131101559e-06.\n",
      "Epoch:17, weight train batch: 352, step:26, loss before: 9.87200905911e-07, loss after: 9.87200905911e-07.\n",
      "Epoch:17, weight train batch: 352, step:27, loss before: 1.12876170988e-06, loss after: 1.12876170988e-06.\n",
      "Epoch:17, weight train batch: 352, step:28, loss before: 1.15111333798e-06, loss after: 1.15111333798e-06.\n",
      "Epoch:17, weight train batch: 352, step:29, loss before: 1.21444315937e-06, loss after: 1.21444315937e-06.\n",
      "Epoch:17, weight train batch: 352, step:30, loss before: 1.5310922663e-06, loss after: 1.51619110511e-06.\n",
      "Epoch:17, weight train batch: 352, step:31, loss before: 1.20326694741e-06, loss after: 1.20326694741e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 348, loss before: 1.0430801467e-06, loss after: 1.594401283e-06.\n",
      "Epoch:17, weight train batch: 353, step:0, loss before: 1.44168552652e-06, loss after: 1.44168552652e-06.\n",
      "Epoch:17, weight train batch: 353, step:1, loss before: 1.25914652926e-06, loss after: 1.25914652926e-06.\n",
      "Epoch:17, weight train batch: 353, step:2, loss before: 1.0356295661e-06, loss after: 1.0356295661e-06.\n",
      "Epoch:17, weight train batch: 353, step:3, loss before: 1.28149827106e-06, loss after: 1.28149827106e-06.\n",
      "Epoch:17, weight train batch: 353, step:4, loss before: 1.25914652926e-06, loss after: 1.25914652926e-06.\n",
      "Epoch:17, weight train batch: 353, step:5, loss before: 3.78106255994e-06, loss after: 3.78106255994e-06.\n",
      "Epoch:17, weight train batch: 353, step:6, loss before: 1.16228920888e-06, loss after: 1.16228920888e-06.\n",
      "Epoch:17, weight train batch: 353, step:7, loss before: 1.16228909519e-06, loss after: 1.16228909519e-06.\n",
      "Epoch:17, weight train batch: 353, step:8, loss before: 1.25914652926e-06, loss after: 1.25914652926e-06.\n",
      "Epoch:17, weight train batch: 353, step:9, loss before: 1.14366275739e-06, loss after: 1.14366275739e-06.\n",
      "Epoch:17, weight train batch: 353, step:10, loss before: 9.05244519345e-07, loss after: 9.05244519345e-07.\n",
      "Epoch:17, weight train batch: 353, step:11, loss before: 3.44951286024e-06, loss after: 3.44578756994e-06.\n",
      "Epoch:17, weight train batch: 353, step:12, loss before: 1.18464083698e-06, loss after: 1.18464083698e-06.\n",
      "Epoch:17, weight train batch: 353, step:13, loss before: 1.01327771063e-06, loss after: 1.01327771063e-06.\n",
      "Epoch:17, weight train batch: 353, step:14, loss before: 7.78584933414e-07, loss after: 7.78584933414e-07.\n",
      "Epoch:17, weight train batch: 353, step:15, loss before: 1.15111333798e-06, loss after: 1.15111333798e-06.\n",
      "Epoch:17, weight train batch: 353, step:16, loss before: 1.18464095067e-06, loss after: 1.18464095067e-06.\n",
      "Epoch:17, weight train batch: 353, step:17, loss before: 8.64266439748e-07, loss after: 8.64266439748e-07.\n",
      "Epoch:17, weight train batch: 353, step:18, loss before: 7.56233191623e-07, loss after: 7.56233191623e-07.\n",
      "Epoch:17, weight train batch: 353, step:19, loss before: 1.13248688649e-06, loss after: 1.13248688649e-06.\n",
      "Epoch:17, weight train batch: 353, step:20, loss before: 7.22705578937e-07, loss after: 7.22705578937e-07.\n",
      "Epoch:17, weight train batch: 353, step:21, loss before: 7.56233191623e-07, loss after: 7.56233191623e-07.\n",
      "Epoch:17, weight train batch: 353, step:22, loss before: 1.32247623696e-06, loss after: 1.32247623696e-06.\n",
      "Epoch:17, weight train batch: 353, step:23, loss before: 1.25169606235e-06, loss after: 1.25169606235e-06.\n",
      "Epoch:17, weight train batch: 353, step:24, loss before: 9.27596261135e-07, loss after: 9.27596261135e-07.\n",
      "Epoch:17, weight train batch: 353, step:25, loss before: 8.49365335398e-07, loss after: 8.49365335398e-07.\n",
      "Epoch:17, weight train batch: 353, step:26, loss before: 1.12503607852e-06, loss after: 1.12503607852e-06.\n",
      "Epoch:17, weight train batch: 353, step:27, loss before: 8.1956301301e-07, loss after: 8.1956301301e-07.\n",
      "Epoch:17, weight train batch: 353, step:28, loss before: 1.13993746709e-06, loss after: 1.13993746709e-06.\n",
      "Epoch:17, weight train batch: 353, step:29, loss before: 1.0356295661e-06, loss after: 1.0356295661e-06.\n",
      "Epoch:17, weight train batch: 353, step:30, loss before: 9.72299744717e-07, loss after: 9.72299744717e-07.\n",
      "Epoch:17, weight train batch: 353, step:31, loss before: 4.20465912612e-05, loss after: 4.18158815592e-05.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 349, loss before: 1.45314807014e-05, loss after: 5.95356505073e-06.\n",
      "Epoch:17, weight train batch: 354, step:0, loss before: 1.13621217679e-06, loss after: 1.13621217679e-06.\n",
      "Epoch:17, weight train batch: 354, step:1, loss before: 8.41914811645e-07, loss after: 8.41914811645e-07.\n",
      "Epoch:17, weight train batch: 354, step:2, loss before: 1.20326728847e-06, loss after: 1.20326728847e-06.\n",
      "Epoch:17, weight train batch: 354, step:3, loss before: 1.0877835166e-06, loss after: 1.0877835166e-06.\n",
      "Epoch:17, weight train batch: 354, step:4, loss before: 1.33737751185e-06, loss after: 1.33737751185e-06.\n",
      "Epoch:17, weight train batch: 354, step:5, loss before: 1.30012472255e-06, loss after: 1.30012472255e-06.\n",
      "Epoch:17, weight train batch: 354, step:6, loss before: 9.46222712628e-07, loss after: 9.46222712628e-07.\n",
      "Epoch:17, weight train batch: 354, step:7, loss before: 8.45639988256e-07, loss after: 8.45639988256e-07.\n",
      "Epoch:17, weight train batch: 354, step:8, loss before: 1.35972925364e-06, loss after: 1.35972925364e-06.\n",
      "Epoch:17, weight train batch: 354, step:9, loss before: 0.000254931335803, loss after: 0.000254051876254.\n",
      "Epoch:17, weight train batch: 354, step:10, loss before: 7.26430926079e-07, loss after: 7.26430926079e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:17, weight train batch: 354, step:11, loss before: 1.13621217679e-06, loss after: 1.13621217679e-06.\n",
      "Epoch:17, weight train batch: 354, step:12, loss before: 1.00582724372e-06, loss after: 1.00582724372e-06.\n",
      "Epoch:17, weight train batch: 354, step:13, loss before: 1.113860435e-06, loss after: 1.09523398351e-06.\n",
      "Epoch:17, weight train batch: 354, step:14, loss before: 7.0035389399e-07, loss after: 7.0035389399e-07.\n",
      "Epoch:17, weight train batch: 354, step:15, loss before: 8.49365278555e-07, loss after: 8.49365278555e-07.\n",
      "Epoch:17, weight train batch: 354, step:16, loss before: 9.61123873822e-07, loss after: 9.61123873822e-07.\n",
      "Epoch:17, weight train batch: 354, step:17, loss before: 7.89760747466e-07, loss after: 7.89760747466e-07.\n",
      "Epoch:17, weight train batch: 354, step:18, loss before: 7.89760747466e-07, loss after: 7.89760747466e-07.\n",
      "Epoch:17, weight train batch: 354, step:19, loss before: 1.1026845641e-06, loss after: 1.1026845641e-06.\n",
      "Epoch:17, weight train batch: 354, step:20, loss before: 0.0216621160507, loss after: 0.0216621160507.\n",
      "Epoch:17, weight train batch: 354, step:21, loss before: 1.16228909519e-06, loss after: 1.16228909519e-06.\n",
      "Epoch:17, weight train batch: 354, step:22, loss before: 9.53673236381e-07, loss after: 9.53673236381e-07.\n",
      "Epoch:17, weight train batch: 354, step:23, loss before: 8.94068762136e-07, loss after: 8.94068762136e-07.\n",
      "Epoch:17, weight train batch: 354, step:24, loss before: 1.1175857253e-06, loss after: 1.1175857253e-06.\n",
      "Epoch:17, weight train batch: 354, step:25, loss before: 0.000684889557306, loss after: 0.000683141173795.\n",
      "Epoch:17, weight train batch: 354, step:26, loss before: 1.15483862828e-06, loss after: 1.15483862828e-06.\n",
      "Epoch:17, weight train batch: 354, step:27, loss before: 1.0430801467e-06, loss after: 1.0430801467e-06.\n",
      "Epoch:17, weight train batch: 354, step:28, loss before: 6.1839762111e-07, loss after: 6.1839762111e-07.\n",
      "Epoch:17, weight train batch: 354, step:29, loss before: 8.64266439748e-07, loss after: 8.64266439748e-07.\n",
      "Epoch:17, weight train batch: 354, step:30, loss before: 8.86618181539e-07, loss after: 8.86618181539e-07.\n",
      "Epoch:17, weight train batch: 354, step:31, loss before: 9.46222712628e-07, loss after: 9.46222712628e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 350, loss before: 1.05798130789e-06, loss after: 1.49605639308e-05.\n",
      "Epoch:17, weight train batch: 355, step:0, loss before: 1.13248688649e-06, loss after: 1.13248688649e-06.\n",
      "Epoch:17, weight train batch: 355, step:1, loss before: 1.0430801467e-06, loss after: 1.0430801467e-06.\n",
      "Epoch:17, weight train batch: 355, step:2, loss before: 5.51342509425e-07, loss after: 5.51342509425e-07.\n",
      "Epoch:17, weight train batch: 355, step:3, loss before: 8.12112489257e-07, loss after: 8.12112489257e-07.\n",
      "Epoch:17, weight train batch: 355, step:4, loss before: 8.86618181539e-07, loss after: 8.86618181539e-07.\n",
      "Epoch:17, weight train batch: 355, step:5, loss before: 7.82310166869e-07, loss after: 7.82310166869e-07.\n",
      "Epoch:17, weight train batch: 355, step:6, loss before: 1.12503641958e-06, loss after: 1.12503641958e-06.\n",
      "Epoch:17, weight train batch: 355, step:7, loss before: 9.23870970837e-07, loss after: 9.23870970837e-07.\n",
      "Epoch:17, weight train batch: 355, step:8, loss before: 1.1026845641e-06, loss after: 1.1026845641e-06.\n",
      "Epoch:17, weight train batch: 355, step:9, loss before: 8.56815859152e-07, loss after: 8.56815859152e-07.\n",
      "Epoch:17, weight train batch: 355, step:10, loss before: 6.85452846483e-07, loss after: 6.85452846483e-07.\n",
      "Epoch:17, weight train batch: 355, step:11, loss before: 1.45286139741e-06, loss after: 1.45286139741e-06.\n",
      "Epoch:17, weight train batch: 355, step:12, loss before: 1.78768059413e-05, loss after: 1.78023401531e-05.\n",
      "Epoch:17, weight train batch: 355, step:13, loss before: 3.23719541484e-06, loss after: 3.23719541484e-06.\n",
      "Epoch:17, weight train batch: 355, step:14, loss before: 9.90926082522e-07, loss after: 9.90926082522e-07.\n",
      "Epoch:17, weight train batch: 355, step:15, loss before: 9.46222712628e-07, loss after: 9.46222712628e-07.\n",
      "Epoch:17, weight train batch: 355, step:16, loss before: 7.07804474587e-07, loss after: 7.07804474587e-07.\n",
      "Epoch:17, weight train batch: 355, step:17, loss before: 8.71717020345e-07, loss after: 8.71717020345e-07.\n",
      "Epoch:17, weight train batch: 355, step:18, loss before: 6.85452732796e-07, loss after: 6.85452732796e-07.\n",
      "Epoch:17, weight train batch: 355, step:19, loss before: 8.79167544099e-07, loss after: 8.79167544099e-07.\n",
      "Epoch:17, weight train batch: 355, step:20, loss before: 9.38772075187e-07, loss after: 9.38772075187e-07.\n",
      "Epoch:17, weight train batch: 355, step:21, loss before: 6.85452732796e-07, loss after: 6.85452732796e-07.\n",
      "Epoch:17, weight train batch: 355, step:22, loss before: 9.46222655784e-07, loss after: 9.46222655784e-07.\n",
      "Epoch:17, weight train batch: 355, step:23, loss before: 7.22705635781e-07, loss after: 7.22705635781e-07.\n",
      "Epoch:17, weight train batch: 355, step:24, loss before: 1.12131033347e-06, loss after: 1.12131033347e-06.\n",
      "Epoch:17, weight train batch: 355, step:25, loss before: 1.1175857253e-06, loss after: 1.1175857253e-06.\n",
      "Epoch:17, weight train batch: 355, step:26, loss before: 9.089697528e-07, loss after: 9.089697528e-07.\n",
      "Epoch:17, weight train batch: 355, step:27, loss before: 9.61123873822e-07, loss after: 9.61123873822e-07.\n",
      "Epoch:17, weight train batch: 355, step:28, loss before: 1.04680509594e-06, loss after: 1.04680509594e-06.\n",
      "Epoch:17, weight train batch: 355, step:29, loss before: 1.1026845641e-06, loss after: 1.1026845641e-06.\n",
      "Epoch:17, weight train batch: 355, step:30, loss before: 3.97478061132e-06, loss after: 3.97478061132e-06.\n",
      "Epoch:17, weight train batch: 355, step:31, loss before: 1.17719025639e-06, loss after: 1.17719025639e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 351, loss before: 1.44650202856e-05, loss after: 1.11758583898e-06.\n",
      "Epoch:17, weight train batch: 356, step:0, loss before: 1.45285684994e-06, loss after: 1.45285684994e-06.\n",
      "Epoch:17, weight train batch: 356, step:1, loss before: 7.82310166869e-07, loss after: 7.82310166869e-07.\n",
      "Epoch:17, weight train batch: 356, step:2, loss before: 8.64266439748e-07, loss after: 8.64266439748e-07.\n",
      "Epoch:17, weight train batch: 356, step:3, loss before: 9.38772188874e-07, loss after: 9.38772188874e-07.\n",
      "Epoch:17, weight train batch: 356, step:4, loss before: 1.02072840491e-06, loss after: 1.02072840491e-06.\n",
      "Epoch:17, weight train batch: 356, step:5, loss before: 8.56815859152e-07, loss after: 8.56815859152e-07.\n",
      "Epoch:17, weight train batch: 356, step:6, loss before: 8.34464231048e-07, loss after: 8.34464231048e-07.\n",
      "Epoch:17, weight train batch: 356, step:7, loss before: 9.76024921329e-07, loss after: 9.76024921329e-07.\n",
      "Epoch:17, weight train batch: 356, step:8, loss before: 2.16810008169e-06, loss after: 2.16810008169e-06.\n",
      "Epoch:17, weight train batch: 356, step:9, loss before: 1.27404769046e-06, loss after: 1.27404769046e-06.\n",
      "Epoch:17, weight train batch: 356, step:10, loss before: 8.86618181539e-07, loss after: 8.86618181539e-07.\n",
      "Epoch:17, weight train batch: 356, step:11, loss before: 8.86618124696e-07, loss after: 8.86618124696e-07.\n",
      "Epoch:17, weight train batch: 356, step:12, loss before: 8.64266439748e-07, loss after: 8.64266439748e-07.\n",
      "Epoch:17, weight train batch: 356, step:13, loss before: 6.25848201707e-07, loss after: 6.25848201707e-07.\n",
      "Epoch:17, weight train batch: 356, step:14, loss before: 1.09523398351e-06, loss after: 1.09523398351e-06.\n",
      "Epoch:17, weight train batch: 356, step:15, loss before: 1.17719037007e-06, loss after: 1.17719037007e-06.\n",
      "Epoch:17, weight train batch: 356, step:16, loss before: 9.46222655784e-07, loss after: 9.46222655784e-07.\n",
      "Epoch:17, weight train batch: 356, step:17, loss before: 8.64266439748e-07, loss after: 8.64266439748e-07.\n",
      "Epoch:17, weight train batch: 356, step:18, loss before: 1.43796023622e-06, loss after: 1.43796023622e-06.\n",
      "Epoch:17, weight train batch: 356, step:19, loss before: 8.56815859152e-07, loss after: 8.56815859152e-07.\n",
      "Epoch:17, weight train batch: 356, step:20, loss before: 1.6167693957e-06, loss after: 1.6167693957e-06.\n",
      "Epoch:17, weight train batch: 356, step:21, loss before: 9.46222655784e-07, loss after: 9.46222655784e-07.\n",
      "Epoch:17, weight train batch: 356, step:22, loss before: 3.48306593878e-06, loss after: 3.48306593878e-06.\n",
      "Epoch:17, weight train batch: 356, step:23, loss before: 9.38772075187e-07, loss after: 9.38772075187e-07.\n",
      "Epoch:17, weight train batch: 356, step:24, loss before: 9.39403707889e-06, loss after: 9.37541608437e-06.\n",
      "Epoch:17, weight train batch: 356, step:25, loss before: 1.13248688649e-06, loss after: 1.13248688649e-06.\n",
      "Epoch:17, weight train batch: 356, step:26, loss before: 1.19209141758e-06, loss after: 1.19209141758e-06.\n",
      "Epoch:17, weight train batch: 356, step:27, loss before: 1.670769052e-05, loss after: 1.66406680364e-05.\n",
      "Epoch:17, weight train batch: 356, step:28, loss before: 1.28894885165e-06, loss after: 1.28894885165e-06.\n",
      "Epoch:17, weight train batch: 356, step:29, loss before: 1.0430801467e-06, loss after: 1.0430801467e-06.\n",
      "Epoch:17, weight train batch: 356, step:30, loss before: 7.07804474587e-07, loss after: 7.07804474587e-07.\n",
      "Epoch:17, weight train batch: 356, step:31, loss before: 9.68574340732e-07, loss after: 9.68574340732e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 352, loss before: 9.38772188874e-07, loss after: 9.38772188874e-07.\n",
      "Epoch:17, weight train batch: 357, step:0, loss before: 1.09523398351e-06, loss after: 1.09523398351e-06.\n",
      "Epoch:17, weight train batch: 357, step:1, loss before: 9.68574340732e-07, loss after: 9.68574340732e-07.\n",
      "Epoch:17, weight train batch: 357, step:2, loss before: 9.08121091925e-06, loss after: 9.0402436399e-06.\n",
      "Epoch:17, weight train batch: 357, step:3, loss before: 1.23679478747e-06, loss after: 1.23679478747e-06.\n",
      "Epoch:17, weight train batch: 357, step:4, loss before: 1.0356295661e-06, loss after: 1.0356295661e-06.\n",
      "Epoch:17, weight train batch: 357, step:5, loss before: 1.0840582263e-06, loss after: 1.0840582263e-06.\n",
      "Epoch:17, weight train batch: 357, step:6, loss before: 8.79167544099e-07, loss after: 8.79167544099e-07.\n",
      "Epoch:17, weight train batch: 357, step:7, loss before: 2.53689177043e-06, loss after: 2.53316648013e-06.\n",
      "Epoch:17, weight train batch: 357, step:8, loss before: 1.1175857253e-06, loss after: 1.1175857253e-06.\n",
      "Epoch:17, weight train batch: 357, step:9, loss before: 8.75346177054e-06, loss after: 8.70876920089e-06.\n",
      "Epoch:17, weight train batch: 357, step:10, loss before: 7.82310166869e-07, loss after: 7.82310166869e-07.\n",
      "Epoch:17, weight train batch: 357, step:11, loss before: 1.18464095067e-06, loss after: 1.14366275739e-06.\n",
      "Epoch:17, weight train batch: 357, step:12, loss before: 9.46222712628e-07, loss after: 9.46222712628e-07.\n",
      "Epoch:17, weight train batch: 357, step:13, loss before: 6.10947040514e-07, loss after: 6.10947040514e-07.\n",
      "Epoch:17, weight train batch: 357, step:14, loss before: 1.20699257877e-06, loss after: 1.20699257877e-06.\n",
      "Epoch:17, weight train batch: 357, step:15, loss before: 9.1642039024e-07, loss after: 9.1642039024e-07.\n",
      "Epoch:17, weight train batch: 357, step:16, loss before: 8.30738827062e-07, loss after: 8.30738827062e-07.\n",
      "Epoch:17, weight train batch: 357, step:17, loss before: 5.34467544639e-05, loss after: 5.34021237399e-05.\n",
      "Epoch:17, weight train batch: 357, step:18, loss before: 7.67409005675e-07, loss after: 7.67409005675e-07.\n",
      "Epoch:17, weight train batch: 357, step:19, loss before: 9.08969809643e-07, loss after: 9.08969809643e-07.\n",
      "Epoch:17, weight train batch: 357, step:20, loss before: 1.07660730464e-06, loss after: 1.07660730464e-06.\n",
      "Epoch:17, weight train batch: 357, step:21, loss before: 5.38792955922e-05, loss after: 5.37900377822e-05.\n",
      "Epoch:17, weight train batch: 357, step:22, loss before: 1.15856391858e-06, loss after: 1.15856391858e-06.\n",
      "Epoch:17, weight train batch: 357, step:23, loss before: 1.03562945242e-06, loss after: 1.03562945242e-06.\n",
      "Epoch:17, weight train batch: 357, step:24, loss before: 6.89178079938e-07, loss after: 6.89178079938e-07.\n",
      "Epoch:17, weight train batch: 357, step:25, loss before: 8.45639988256e-07, loss after: 8.45639988256e-07.\n",
      "Epoch:17, weight train batch: 357, step:26, loss before: 7.67409005675e-07, loss after: 7.67409005675e-07.\n",
      "Epoch:17, weight train batch: 357, step:27, loss before: 1.40070744692e-06, loss after: 1.40070744692e-06.\n",
      "Epoch:17, weight train batch: 357, step:28, loss before: 8.30738827062e-07, loss after: 8.30738827062e-07.\n",
      "Epoch:17, weight train batch: 357, step:29, loss before: 9.31321551434e-07, loss after: 9.31321551434e-07.\n",
      "Epoch:17, weight train batch: 357, step:30, loss before: 8.53090568853e-07, loss after: 8.53090568853e-07.\n",
      "Epoch:17, weight train batch: 357, step:31, loss before: 1.00955253401e-06, loss after: 1.00955253401e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 353, loss before: 9.22008382531e-07, loss after: 9.22008382531e-07.\n",
      "Epoch:17, weight train batch: 358, step:0, loss before: 7.82310166869e-07, loss after: 7.82310166869e-07.\n",
      "Epoch:17, weight train batch: 358, step:1, loss before: 1.0728823554e-06, loss after: 1.0356295661e-06.\n",
      "Epoch:17, weight train batch: 358, step:2, loss before: 1.12503641958e-06, loss after: 1.12503641958e-06.\n",
      "Epoch:17, weight train batch: 358, step:3, loss before: 6.81727556184e-07, loss after: 6.81727556184e-07.\n",
      "Epoch:17, weight train batch: 358, step:4, loss before: 1.0430801467e-06, loss after: 1.0430801467e-06.\n",
      "Epoch:17, weight train batch: 358, step:5, loss before: 9.46222712628e-07, loss after: 9.46222712628e-07.\n",
      "Epoch:17, weight train batch: 358, step:6, loss before: 7.37606796974e-07, loss after: 7.37606796974e-07.\n",
      "Epoch:17, weight train batch: 358, step:7, loss before: 8.86618238383e-07, loss after: 8.86618238383e-07.\n",
      "Epoch:17, weight train batch: 358, step:8, loss before: 9.68574454419e-07, loss after: 9.68574454419e-07.\n",
      "Epoch:17, weight train batch: 358, step:9, loss before: 1.17719037007e-06, loss after: 1.17719037007e-06.\n",
      "Epoch:17, weight train batch: 358, step:10, loss before: 1.0505307273e-06, loss after: 1.0505307273e-06.\n",
      "Epoch:17, weight train batch: 358, step:11, loss before: 9.46222712628e-07, loss after: 9.46222712628e-07.\n",
      "Epoch:17, weight train batch: 358, step:12, loss before: 6.70551685289e-07, loss after: 6.70551685289e-07.\n",
      "Epoch:17, weight train batch: 358, step:13, loss before: 1.07288246909e-06, loss after: 1.07288246909e-06.\n",
      "Epoch:17, weight train batch: 358, step:14, loss before: 1.30385001285e-06, loss after: 1.30385001285e-06.\n",
      "Epoch:17, weight train batch: 358, step:15, loss before: 7.59958538765e-07, loss after: 7.59958538765e-07.\n",
      "Epoch:17, weight train batch: 358, step:16, loss before: 1.11013525839e-06, loss after: 1.11013525839e-06.\n",
      "Epoch:17, weight train batch: 358, step:17, loss before: 1.07288246909e-06, loss after: 1.07288246909e-06.\n",
      "Epoch:17, weight train batch: 358, step:18, loss before: 8.79167600942e-07, loss after: 8.79167600942e-07.\n",
      "Epoch:17, weight train batch: 358, step:19, loss before: 4.18154049839e-05, loss after: 4.16033362853e-05.\n",
      "Epoch:17, weight train batch: 358, step:20, loss before: 7.07804588274e-07, loss after: 7.07804588274e-07.\n",
      "Epoch:17, weight train batch: 358, step:21, loss before: 8.94068762136e-07, loss after: 8.94068762136e-07.\n",
      "Epoch:17, weight train batch: 358, step:22, loss before: 1.0430801467e-06, loss after: 1.0430801467e-06.\n",
      "Epoch:17, weight train batch: 358, step:23, loss before: 1.16973876629e-06, loss after: 1.16973876629e-06.\n",
      "Epoch:17, weight train batch: 358, step:24, loss before: 0.0216617211699, loss after: 0.0216617211699.\n",
      "Epoch:17, weight train batch: 358, step:25, loss before: 8.12112489257e-07, loss after: 8.12112489257e-07.\n",
      "Epoch:17, weight train batch: 358, step:26, loss before: 1.11758583898e-06, loss after: 1.11758583898e-06.\n",
      "Epoch:17, weight train batch: 358, step:27, loss before: 1.16228920888e-06, loss after: 1.16228920888e-06.\n",
      "Epoch:17, weight train batch: 358, step:28, loss before: 8.49365392241e-07, loss after: 8.49365392241e-07.\n",
      "Epoch:17, weight train batch: 358, step:29, loss before: 7.97211328063e-07, loss after: 7.97211328063e-07.\n",
      "Epoch:17, weight train batch: 358, step:30, loss before: 1.15483771879e-06, loss after: 1.15483771879e-06.\n",
      "Epoch:17, weight train batch: 358, step:31, loss before: 8.94068762136e-07, loss after: 8.94068762136e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 354, loss before: 4.44342913397e-06, loss after: 1.37274889767e-06.\n",
      "Epoch:17, weight train batch: 359, step:0, loss before: 8.0466190866e-07, loss after: 8.0466190866e-07.\n",
      "Epoch:17, weight train batch: 359, step:1, loss before: 8.86618181539e-07, loss after: 8.86618181539e-07.\n",
      "Epoch:17, weight train batch: 359, step:2, loss before: 1.14738816137e-06, loss after: 1.14738816137e-06.\n",
      "Epoch:17, weight train batch: 359, step:3, loss before: 1.0505307273e-06, loss after: 1.0505307273e-06.\n",
      "Epoch:17, weight train batch: 359, step:4, loss before: 1.00582667528e-06, loss after: 1.00582667528e-06.\n",
      "Epoch:17, weight train batch: 359, step:5, loss before: 1.05798130789e-06, loss after: 1.05798130789e-06.\n",
      "Epoch:17, weight train batch: 359, step:6, loss before: 7.37606796974e-07, loss after: 7.37606796974e-07.\n",
      "Epoch:17, weight train batch: 359, step:7, loss before: 6.63101104692e-07, loss after: 6.63101104692e-07.\n",
      "Epoch:17, weight train batch: 359, step:8, loss before: 1.02817898551e-06, loss after: 1.02817898551e-06.\n",
      "Epoch:17, weight train batch: 359, step:9, loss before: 1.0505307273e-06, loss after: 1.0505307273e-06.\n",
      "Epoch:17, weight train batch: 359, step:10, loss before: 8.79167600942e-07, loss after: 8.79167600942e-07.\n",
      "Epoch:17, weight train batch: 359, step:11, loss before: 7.30156216378e-07, loss after: 7.30156216378e-07.\n",
      "Epoch:17, weight train batch: 359, step:12, loss before: 8.86618181539e-07, loss after: 8.86618181539e-07.\n",
      "Epoch:17, weight train batch: 359, step:13, loss before: 1.31875117404e-06, loss after: 1.31875117404e-06.\n",
      "Epoch:17, weight train batch: 359, step:14, loss before: 1.0058273574e-06, loss after: 1.0058273574e-06.\n",
      "Epoch:17, weight train batch: 359, step:15, loss before: 1.17719037007e-06, loss after: 1.17719037007e-06.\n",
      "Epoch:17, weight train batch: 359, step:16, loss before: 1.02072840491e-06, loss after: 1.02072840491e-06.\n",
      "Epoch:17, weight train batch: 359, step:17, loss before: 1.0430801467e-06, loss after: 1.0430801467e-06.\n",
      "Epoch:17, weight train batch: 359, step:18, loss before: 1.05798130789e-06, loss after: 1.0207285186e-06.\n",
      "Epoch:17, weight train batch: 359, step:19, loss before: 8.30739054436e-07, loss after: 8.30739054436e-07.\n",
      "Epoch:17, weight train batch: 359, step:20, loss before: 9.83475729299e-07, loss after: 9.83475729299e-07.\n",
      "Epoch:17, weight train batch: 359, step:21, loss before: 9.27596374822e-07, loss after: 9.27596374822e-07.\n",
      "Epoch:17, weight train batch: 359, step:22, loss before: 1.18463731269e-06, loss after: 1.18463731269e-06.\n",
      "Epoch:17, weight train batch: 359, step:23, loss before: 1.32992704494e-06, loss after: 1.32992704494e-06.\n",
      "Epoch:17, weight train batch: 359, step:24, loss before: 1.04680555069e-06, loss after: 1.04680555069e-06.\n",
      "Epoch:17, weight train batch: 359, step:25, loss before: 8.08387312645e-07, loss after: 8.08387312645e-07.\n",
      "Epoch:17, weight train batch: 359, step:26, loss before: 9.27596374822e-07, loss after: 9.27596374822e-07.\n",
      "Epoch:17, weight train batch: 359, step:27, loss before: 6.89178193625e-07, loss after: 6.89178193625e-07.\n",
      "Epoch:17, weight train batch: 359, step:28, loss before: 8.00936732048e-07, loss after: 8.00936732048e-07.\n",
      "Epoch:17, weight train batch: 359, step:29, loss before: 6.66826451834e-07, loss after: 6.66826451834e-07.\n",
      "Epoch:17, weight train batch: 359, step:30, loss before: 7.07804588274e-07, loss after: 7.07804588274e-07.\n",
      "Epoch:17, weight train batch: 359, step:31, loss before: 1.29267323246e-06, loss after: 1.29267323246e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:17, struct parameters train batch: 355, loss before: 9.31321608277e-07, loss after: 9.31321608277e-07.\n",
      "Epoch:18, weight train batch: 360, step:0, loss before: 8.67991900577e-07, loss after: 8.67991900577e-07.\n",
      "Epoch:18, weight train batch: 360, step:1, loss before: 1.47893854319e-06, loss after: 1.47893854319e-06.\n",
      "Epoch:18, weight train batch: 360, step:2, loss before: 6.44474710043e-07, loss after: 6.44474710043e-07.\n",
      "Epoch:18, weight train batch: 360, step:3, loss before: 6.44474766887e-07, loss after: 6.44474766887e-07.\n",
      "Epoch:18, weight train batch: 360, step:4, loss before: 8.86618295226e-07, loss after: 8.86618295226e-07.\n",
      "Epoch:18, weight train batch: 360, step:5, loss before: 8.49365392241e-07, loss after: 8.49365392241e-07.\n",
      "Epoch:18, weight train batch: 360, step:6, loss before: 1.09150892058e-06, loss after: 1.09150892058e-06.\n",
      "Epoch:18, weight train batch: 360, step:7, loss before: 4.26535552833e-06, loss after: 4.26163069278e-06.\n",
      "Epoch:18, weight train batch: 360, step:8, loss before: 1.94084782379e-06, loss after: 1.94084782379e-06.\n",
      "Epoch:18, weight train batch: 360, step:9, loss before: 5.14131133968e-05, loss after: 5.13722006872e-05.\n",
      "Epoch:18, weight train batch: 360, step:10, loss before: 1.046805437e-06, loss after: 1.046805437e-06.\n",
      "Epoch:18, weight train batch: 360, step:11, loss before: 1.01327805169e-06, loss after: 1.01327805169e-06.\n",
      "Epoch:18, weight train batch: 360, step:12, loss before: 9.68574568105e-07, loss after: 9.68574568105e-07.\n",
      "Epoch:18, weight train batch: 360, step:13, loss before: 7.37606853818e-07, loss after: 7.37606853818e-07.\n",
      "Epoch:18, weight train batch: 360, step:14, loss before: 9.27596374822e-07, loss after: 9.27596374822e-07.\n",
      "Epoch:18, weight train batch: 360, step:15, loss before: 9.83475615612e-07, loss after: 9.83475615612e-07.\n",
      "Epoch:18, weight train batch: 360, step:16, loss before: 7.63683829064e-07, loss after: 7.63683829064e-07.\n",
      "Epoch:18, weight train batch: 360, step:17, loss before: 8.49365392241e-07, loss after: 8.49365392241e-07.\n",
      "Epoch:18, weight train batch: 360, step:18, loss before: 7.71134409661e-07, loss after: 7.71134409661e-07.\n",
      "Epoch:18, weight train batch: 360, step:19, loss before: 4.39583999423e-07, loss after: 4.39583999423e-07.\n",
      "Epoch:18, weight train batch: 360, step:20, loss before: 8.79167714629e-07, loss after: 8.79167714629e-07.\n",
      "Epoch:18, weight train batch: 360, step:21, loss before: 7.00354007677e-07, loss after: 7.00354007677e-07.\n",
      "Epoch:18, weight train batch: 360, step:22, loss before: 9.35046955419e-07, loss after: 9.35046955419e-07.\n",
      "Epoch:18, weight train batch: 360, step:23, loss before: 1.18836635465e-06, loss after: 1.18836635465e-06.\n",
      "Epoch:18, weight train batch: 360, step:24, loss before: 1.16228943625e-06, loss after: 1.16228943625e-06.\n",
      "Epoch:18, weight train batch: 360, step:25, loss before: 1.27404791783e-06, loss after: 1.27404791783e-06.\n",
      "Epoch:18, weight train batch: 360, step:26, loss before: 6.51925347483e-07, loss after: 6.51925347483e-07.\n",
      "Epoch:18, weight train batch: 360, step:27, loss before: 8.15837893242e-07, loss after: 8.15837893242e-07.\n",
      "Epoch:18, weight train batch: 360, step:28, loss before: 9.27596374822e-07, loss after: 9.27596374822e-07.\n",
      "Epoch:18, weight train batch: 360, step:29, loss before: 9.35046955419e-07, loss after: 9.35046955419e-07.\n",
      "Epoch:18, weight train batch: 360, step:30, loss before: 7.86035570854e-07, loss after: 7.86035570854e-07.\n",
      "Epoch:18, weight train batch: 360, step:31, loss before: 8.71717134032e-07, loss after: 8.41914868488e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 356, loss before: 1.37647714382e-06, loss after: 8.27013650451e-07.\n",
      "Epoch:18, weight train batch: 361, step:0, loss before: 6.55650637782e-07, loss after: 6.55650637782e-07.\n",
      "Epoch:18, weight train batch: 361, step:1, loss before: 2.30592195294e-06, loss after: 2.30592195294e-06.\n",
      "Epoch:18, weight train batch: 361, step:2, loss before: 6.33298895991e-07, loss after: 6.33298895991e-07.\n",
      "Epoch:18, weight train batch: 361, step:3, loss before: 8.94068875823e-07, loss after: 8.94068875823e-07.\n",
      "Epoch:18, weight train batch: 361, step:4, loss before: 7.30156330064e-07, loss after: 7.30156330064e-07.\n",
      "Epoch:18, weight train batch: 361, step:5, loss before: 8.15837836399e-07, loss after: 8.15837836399e-07.\n",
      "Epoch:18, weight train batch: 361, step:6, loss before: 9.16420617614e-07, loss after: 9.16420617614e-07.\n",
      "Epoch:18, weight train batch: 361, step:7, loss before: 9.68574681792e-07, loss after: 9.68574681792e-07.\n",
      "Epoch:18, weight train batch: 361, step:8, loss before: 7.07804588274e-07, loss after: 7.07804588274e-07.\n",
      "Epoch:18, weight train batch: 361, step:9, loss before: 8.71717247719e-07, loss after: 8.71717247719e-07.\n",
      "Epoch:18, weight train batch: 361, step:10, loss before: 7.89760917996e-07, loss after: 7.89760917996e-07.\n",
      "Epoch:18, weight train batch: 361, step:11, loss before: 9.38772302561e-07, loss after: 9.38772302561e-07.\n",
      "Epoch:18, weight train batch: 361, step:12, loss before: 8.27013764138e-07, loss after: 8.27013764138e-07.\n",
      "Epoch:18, weight train batch: 361, step:13, loss before: 7.82310394243e-07, loss after: 7.82310394243e-07.\n",
      "Epoch:18, weight train batch: 361, step:14, loss before: 8.12112602944e-07, loss after: 8.12112602944e-07.\n",
      "Epoch:18, weight train batch: 361, step:15, loss before: 9.53673463755e-07, loss after: 9.53673463755e-07.\n",
      "Epoch:18, weight train batch: 361, step:16, loss before: 7.07804645117e-07, loss after: 7.07804645117e-07.\n",
      "Epoch:18, weight train batch: 361, step:17, loss before: 7.67409176206e-07, loss after: 7.67409176206e-07.\n",
      "Epoch:18, weight train batch: 361, step:18, loss before: 9.23871198211e-07, loss after: 9.23871198211e-07.\n",
      "Epoch:18, weight train batch: 361, step:19, loss before: 9.83475729299e-07, loss after: 9.83475729299e-07.\n",
      "Epoch:18, weight train batch: 361, step:20, loss before: 9.08970037017e-07, loss after: 9.08970037017e-07.\n",
      "Epoch:18, weight train batch: 361, step:21, loss before: 8.41914868488e-07, loss after: 8.41914868488e-07.\n",
      "Epoch:18, weight train batch: 361, step:22, loss before: 6.03496630447e-07, loss after: 6.03496630447e-07.\n",
      "Epoch:18, weight train batch: 361, step:23, loss before: 8.97793881904e-07, loss after: 8.97793881904e-07.\n",
      "Epoch:18, weight train batch: 361, step:24, loss before: 5.88595526096e-07, loss after: 5.88595526096e-07.\n",
      "Epoch:18, weight train batch: 361, step:25, loss before: 0.000237995467614, loss after: 0.000237037907937.\n",
      "Epoch:18, weight train batch: 361, step:26, loss before: 6.85452903326e-07, loss after: 6.85452903326e-07.\n",
      "Epoch:18, weight train batch: 361, step:27, loss before: 7.82310394243e-07, loss after: 7.82310394243e-07.\n",
      "Epoch:18, weight train batch: 361, step:28, loss before: 6.9290342708e-07, loss after: 6.9290342708e-07.\n",
      "Epoch:18, weight train batch: 361, step:29, loss before: 1.52814700414e-05, loss after: 1.52181582962e-05.\n",
      "Epoch:18, weight train batch: 361, step:30, loss before: 9.01519399577e-07, loss after: 9.01519399577e-07.\n",
      "Epoch:18, weight train batch: 361, step:31, loss before: 8.08387312645e-07, loss after: 8.08387312645e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 357, loss before: 2.64566347141e-06, loss after: 7.80447578563e-07.\n",
      "Epoch:18, weight train batch: 362, step:0, loss before: 2.55178247244e-06, loss after: 2.55178247244e-06.\n",
      "Epoch:18, weight train batch: 362, step:1, loss before: 6.96628774222e-07, loss after: 6.96628774222e-07.\n",
      "Epoch:18, weight train batch: 362, step:2, loss before: 8.30739054436e-07, loss after: 8.30739054436e-07.\n",
      "Epoch:18, weight train batch: 362, step:3, loss before: 7.86035627698e-07, loss after: 7.86035627698e-07.\n",
      "Epoch:18, weight train batch: 362, step:4, loss before: 9.16420617614e-07, loss after: 9.16420617614e-07.\n",
      "Epoch:18, weight train batch: 362, step:5, loss before: 7.4133220096e-07, loss after: 7.4133220096e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:18, weight train batch: 362, step:6, loss before: 8.34464344734e-07, loss after: 8.34464344734e-07.\n",
      "Epoch:18, weight train batch: 362, step:7, loss before: 7.18980516012e-07, loss after: 7.18980516012e-07.\n",
      "Epoch:18, weight train batch: 362, step:8, loss before: 7.37606910661e-07, loss after: 7.37606910661e-07.\n",
      "Epoch:18, weight train batch: 362, step:9, loss before: 5.5506791341e-07, loss after: 5.5506791341e-07.\n",
      "Epoch:18, weight train batch: 362, step:10, loss before: 7.48782724713e-07, loss after: 7.48782724713e-07.\n",
      "Epoch:18, weight train batch: 362, step:11, loss before: 3.73581788153e-05, loss after: 3.71870155504e-05.\n",
      "Epoch:18, weight train batch: 362, step:12, loss before: 7.59958652452e-07, loss after: 7.59958652452e-07.\n",
      "Epoch:18, weight train batch: 362, step:13, loss before: 9.35047012263e-07, loss after: 9.35047012263e-07.\n",
      "Epoch:18, weight train batch: 362, step:14, loss before: 8.04662022347e-07, loss after: 8.04662022347e-07.\n",
      "Epoch:18, weight train batch: 362, step:15, loss before: 9.35047012263e-07, loss after: 9.35047012263e-07.\n",
      "Epoch:18, weight train batch: 362, step:16, loss before: 7.93486151451e-07, loss after: 7.93486151451e-07.\n",
      "Epoch:18, weight train batch: 362, step:17, loss before: 8.67991843734e-07, loss after: 8.67991843734e-07.\n",
      "Epoch:18, weight train batch: 362, step:18, loss before: 6.37024129446e-07, loss after: 6.37024129446e-07.\n",
      "Epoch:18, weight train batch: 362, step:19, loss before: 7.78584990258e-07, loss after: 7.78584990258e-07.\n",
      "Epoch:18, weight train batch: 362, step:20, loss before: 3.9934088818e-06, loss after: 3.98595875595e-06.\n",
      "Epoch:18, weight train batch: 362, step:21, loss before: 8.33627746033e-06, loss after: 8.33255307953e-06.\n",
      "Epoch:18, weight train batch: 362, step:22, loss before: 7.41332144116e-07, loss after: 7.41332144116e-07.\n",
      "Epoch:18, weight train batch: 362, step:23, loss before: 8.38189521346e-07, loss after: 8.38189521346e-07.\n",
      "Epoch:18, weight train batch: 362, step:24, loss before: 6.55650580939e-07, loss after: 6.55650580939e-07.\n",
      "Epoch:18, weight train batch: 362, step:25, loss before: 2.72312399829e-06, loss after: 2.71939893537e-06.\n",
      "Epoch:18, weight train batch: 362, step:26, loss before: 8.75442424331e-07, loss after: 8.75442424331e-07.\n",
      "Epoch:18, weight train batch: 362, step:27, loss before: 5.17815010426e-07, loss after: 5.17815010426e-07.\n",
      "Epoch:18, weight train batch: 362, step:28, loss before: 8.64266553435e-07, loss after: 8.64266553435e-07.\n",
      "Epoch:18, weight train batch: 362, step:29, loss before: 7.37606910661e-07, loss after: 7.37606910661e-07.\n",
      "Epoch:18, weight train batch: 362, step:30, loss before: 7.07804588274e-07, loss after: 7.07804588274e-07.\n",
      "Epoch:18, weight train batch: 362, step:31, loss before: 1.00210218079e-06, loss after: 1.00210218079e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 358, loss before: 6.31436193999e-07, loss after: 0.00541756395251.\n",
      "Epoch:18, weight train batch: 363, step:0, loss before: 8.86618295226e-07, loss after: 8.86618295226e-07.\n",
      "Epoch:18, weight train batch: 363, step:1, loss before: 8.82892436493e-07, loss after: 8.82892436493e-07.\n",
      "Epoch:18, weight train batch: 363, step:2, loss before: 9.94651600195e-07, loss after: 9.94651600195e-07.\n",
      "Epoch:18, weight train batch: 363, step:3, loss before: 7.00354007677e-07, loss after: 7.00354007677e-07.\n",
      "Epoch:18, weight train batch: 363, step:4, loss before: 8.67991843734e-07, loss after: 8.67991843734e-07.\n",
      "Epoch:18, weight train batch: 363, step:5, loss before: 1.31875140141e-06, loss after: 1.31875140141e-06.\n",
      "Epoch:18, weight train batch: 363, step:6, loss before: 9.27596431666e-07, loss after: 9.27596431666e-07.\n",
      "Epoch:18, weight train batch: 363, step:7, loss before: 5.62518437164e-07, loss after: 5.62518437164e-07.\n",
      "Epoch:18, weight train batch: 363, step:8, loss before: 5.92320702708e-07, loss after: 5.92320702708e-07.\n",
      "Epoch:18, weight train batch: 363, step:9, loss before: 6.37024129446e-07, loss after: 6.37024129446e-07.\n",
      "Epoch:18, weight train batch: 363, step:10, loss before: 7.26431039766e-07, loss after: 7.26431039766e-07.\n",
      "Epoch:18, weight train batch: 363, step:11, loss before: 5.6251838032e-07, loss after: 5.6251838032e-07.\n",
      "Epoch:18, weight train batch: 363, step:12, loss before: 8.34464287891e-07, loss after: 8.34464287891e-07.\n",
      "Epoch:18, weight train batch: 363, step:13, loss before: 7.9824230852e-06, loss after: 7.94517472968e-06.\n",
      "Epoch:18, weight train batch: 363, step:14, loss before: 7.1525516887e-07, loss after: 7.1525516887e-07.\n",
      "Epoch:18, weight train batch: 363, step:15, loss before: 1.03190438949e-06, loss after: 1.03190438949e-06.\n",
      "Epoch:18, weight train batch: 363, step:16, loss before: 2.66723941422e-06, loss after: 2.6635143513e-06.\n",
      "Epoch:18, weight train batch: 363, step:17, loss before: 7.67409176206e-07, loss after: 7.67409176206e-07.\n",
      "Epoch:18, weight train batch: 363, step:18, loss before: 1.05053095467e-06, loss after: 1.05053095467e-06.\n",
      "Epoch:18, weight train batch: 363, step:19, loss before: 9.0151945642e-07, loss after: 9.0151945642e-07.\n",
      "Epoch:18, weight train batch: 363, step:20, loss before: 1.06915729248e-06, loss after: 1.06915729248e-06.\n",
      "Epoch:18, weight train batch: 363, step:21, loss before: 7.11529878572e-07, loss after: 7.11529878572e-07.\n",
      "Epoch:18, weight train batch: 363, step:22, loss before: 8.79167714629e-07, loss after: 8.79167714629e-07.\n",
      "Epoch:18, weight train batch: 363, step:23, loss before: 6.25848258551e-07, loss after: 6.25848258551e-07.\n",
      "Epoch:18, weight train batch: 363, step:24, loss before: 6.3702418629e-07, loss after: 6.3702418629e-07.\n",
      "Epoch:18, weight train batch: 363, step:25, loss before: 7.04079297975e-07, loss after: 7.04079297975e-07.\n",
      "Epoch:18, weight train batch: 363, step:26, loss before: 7.93486151451e-07, loss after: 7.93486151451e-07.\n",
      "Epoch:18, weight train batch: 363, step:27, loss before: 7.04079297975e-07, loss after: 7.04079297975e-07.\n",
      "Epoch:18, weight train batch: 363, step:28, loss before: 6.6682639499e-07, loss after: 6.6682639499e-07.\n",
      "Epoch:18, weight train batch: 363, step:29, loss before: 7.82310280556e-07, loss after: 7.82310280556e-07.\n",
      "Epoch:18, weight train batch: 363, step:30, loss before: 9.16420617614e-07, loss after: 9.16420617614e-07.\n",
      "Epoch:18, weight train batch: 363, step:31, loss before: 5.3271617162e-07, loss after: 5.3271617162e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 359, loss before: 5.55522674404e-05, loss after: 7.05942056811e-07.\n",
      "Epoch:18, weight train batch: 364, step:0, loss before: 9.53673406912e-07, loss after: 9.53673406912e-07.\n",
      "Epoch:18, weight train batch: 364, step:1, loss before: 9.35047012263e-07, loss after: 9.35047012263e-07.\n",
      "Epoch:18, weight train batch: 364, step:2, loss before: 7.5623330531e-07, loss after: 7.5623330531e-07.\n",
      "Epoch:18, weight train batch: 364, step:3, loss before: 1.11013548576e-06, loss after: 1.11013548576e-06.\n",
      "Epoch:18, weight train batch: 364, step:4, loss before: 1.13621240416e-06, loss after: 1.13621240416e-06.\n",
      "Epoch:18, weight train batch: 364, step:5, loss before: 5.96045993007e-07, loss after: 5.96045993007e-07.\n",
      "Epoch:18, weight train batch: 364, step:6, loss before: 2.20908032134e-06, loss after: 2.20908032134e-06.\n",
      "Epoch:18, weight train batch: 364, step:7, loss before: 9.05244746718e-07, loss after: 9.05244746718e-07.\n",
      "Epoch:18, weight train batch: 364, step:8, loss before: 8.38189521346e-07, loss after: 8.38189521346e-07.\n",
      "Epoch:18, weight train batch: 364, step:9, loss before: 6.55650580939e-07, loss after: 6.55650580939e-07.\n",
      "Epoch:18, weight train batch: 364, step:10, loss before: 8.67991843734e-07, loss after: 8.67991843734e-07.\n",
      "Epoch:18, weight train batch: 364, step:11, loss before: 9.61123987508e-07, loss after: 9.61123987508e-07.\n",
      "Epoch:18, weight train batch: 364, step:12, loss before: 3.4072487324e-05, loss after: 3.39199104928e-05.\n",
      "Epoch:18, weight train batch: 364, step:13, loss before: 4.91886275995e-05, loss after: 4.91402752232e-05.\n",
      "Epoch:18, weight train batch: 364, step:14, loss before: 7.5623330531e-07, loss after: 7.5623330531e-07.\n",
      "Epoch:18, weight train batch: 364, step:15, loss before: 9.64849277807e-07, loss after: 9.64849277807e-07.\n",
      "Epoch:18, weight train batch: 364, step:16, loss before: 9.53673406912e-07, loss after: 9.53673406912e-07.\n",
      "Epoch:18, weight train batch: 364, step:17, loss before: 1.07660787307e-06, loss after: 1.07660787307e-06.\n",
      "Epoch:18, weight train batch: 364, step:18, loss before: 8.04662022347e-07, loss after: 7.67409176206e-07.\n",
      "Epoch:18, weight train batch: 364, step:19, loss before: 6.74276975587e-07, loss after: 6.74276975587e-07.\n",
      "Epoch:18, weight train batch: 364, step:20, loss before: 9.79750439001e-07, loss after: 9.79750439001e-07.\n",
      "Epoch:18, weight train batch: 364, step:21, loss before: 8.19563183541e-07, loss after: 8.19563183541e-07.\n",
      "Epoch:18, weight train batch: 364, step:22, loss before: 7.89760804309e-07, loss after: 7.89760804309e-07.\n",
      "Epoch:18, weight train batch: 364, step:23, loss before: 9.94651600195e-07, loss after: 9.94651600195e-07.\n",
      "Epoch:18, weight train batch: 364, step:24, loss before: 8.71717134032e-07, loss after: 8.71717134032e-07.\n",
      "Epoch:18, weight train batch: 364, step:25, loss before: 7.9721144175e-07, loss after: 7.9721144175e-07.\n",
      "Epoch:18, weight train batch: 364, step:26, loss before: 8.121125461e-07, loss after: 8.121125461e-07.\n",
      "Epoch:18, weight train batch: 364, step:27, loss before: 6.22123025096e-07, loss after: 6.22123025096e-07.\n",
      "Epoch:18, weight train batch: 364, step:28, loss before: 8.71717134032e-07, loss after: 8.34464344734e-07.\n",
      "Epoch:18, weight train batch: 364, step:29, loss before: 5.77419541514e-07, loss after: 5.77419541514e-07.\n",
      "Epoch:18, weight train batch: 364, step:30, loss before: 7.82310280556e-07, loss after: 7.82310280556e-07.\n",
      "Epoch:18, weight train batch: 364, step:31, loss before: 6.07221863902e-07, loss after: 6.07221863902e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 360, loss before: 6.65895186103e-07, loss after: 6.65895186103e-07.\n",
      "Epoch:18, weight train batch: 365, step:0, loss before: 6.5937592808e-07, loss after: 6.5937592808e-07.\n",
      "Epoch:18, weight train batch: 365, step:1, loss before: 7.26431039766e-07, loss after: 7.26431039766e-07.\n",
      "Epoch:18, weight train batch: 365, step:2, loss before: 7.1525516887e-07, loss after: 7.1525516887e-07.\n",
      "Epoch:18, weight train batch: 365, step:3, loss before: 7.4133220096e-07, loss after: 7.4133220096e-07.\n",
      "Epoch:18, weight train batch: 365, step:4, loss before: 9.53673463755e-07, loss after: 9.53673463755e-07.\n",
      "Epoch:18, weight train batch: 365, step:5, loss before: 7.86035570854e-07, loss after: 7.86035570854e-07.\n",
      "Epoch:18, weight train batch: 365, step:6, loss before: 8.27013820981e-07, loss after: 8.27013820981e-07.\n",
      "Epoch:18, weight train batch: 365, step:7, loss before: 1.04680566437e-06, loss after: 1.04680566437e-06.\n",
      "Epoch:18, weight train batch: 365, step:8, loss before: 8.27013707294e-07, loss after: 8.27013707294e-07.\n",
      "Epoch:18, weight train batch: 365, step:9, loss before: 7.71134409661e-07, loss after: 7.71134409661e-07.\n",
      "Epoch:18, weight train batch: 365, step:10, loss before: 7.96008498583e-06, loss after: 7.94518746261e-06.\n",
      "Epoch:18, weight train batch: 365, step:11, loss before: 5.28990881321e-07, loss after: 5.28990881321e-07.\n",
      "Epoch:18, weight train batch: 365, step:12, loss before: 8.6799161636e-07, loss after: 8.6799161636e-07.\n",
      "Epoch:18, weight train batch: 365, step:13, loss before: 6.48200000342e-07, loss after: 6.48200000342e-07.\n",
      "Epoch:18, weight train batch: 365, step:14, loss before: 7.1525516887e-07, loss after: 7.1525516887e-07.\n",
      "Epoch:18, weight train batch: 365, step:15, loss before: 4.50759813475e-07, loss after: 4.50759813475e-07.\n",
      "Epoch:18, weight train batch: 365, step:16, loss before: 6.66826451834e-07, loss after: 6.66826451834e-07.\n",
      "Epoch:18, weight train batch: 365, step:17, loss before: 9.64849050433e-07, loss after: 9.64849050433e-07.\n",
      "Epoch:18, weight train batch: 365, step:18, loss before: 5.40166752216e-07, loss after: 5.40166752216e-07.\n",
      "Epoch:18, weight train batch: 365, step:19, loss before: 0.000640361045953, loss after: 0.000638338911813.\n",
      "Epoch:18, weight train batch: 365, step:20, loss before: 4.20957576353e-07, loss after: 4.20957576353e-07.\n",
      "Epoch:18, weight train batch: 365, step:21, loss before: 5.92320702708e-07, loss after: 5.92320702708e-07.\n",
      "Epoch:18, weight train batch: 365, step:22, loss before: 1.70615749084e-06, loss after: 1.70988255377e-06.\n",
      "Epoch:18, weight train batch: 365, step:23, loss before: 6.03496573603e-07, loss after: 6.03496573603e-07.\n",
      "Epoch:18, weight train batch: 365, step:24, loss before: 5.21540300724e-07, loss after: 5.21540300724e-07.\n",
      "Epoch:18, weight train batch: 365, step:25, loss before: 6.03496573603e-07, loss after: 6.03496573603e-07.\n",
      "Epoch:18, weight train batch: 365, step:26, loss before: 6.37024129446e-07, loss after: 6.37024129446e-07.\n",
      "Epoch:18, weight train batch: 365, step:27, loss before: 8.41914925331e-07, loss after: 8.41914925331e-07.\n",
      "Epoch:18, weight train batch: 365, step:28, loss before: 6.74276975587e-07, loss after: 6.74276975587e-07.\n",
      "Epoch:18, weight train batch: 365, step:29, loss before: 7.07804588274e-07, loss after: 7.07804588274e-07.\n",
      "Epoch:18, weight train batch: 365, step:30, loss before: 3.76254149614e-07, loss after: 3.76254149614e-07.\n",
      "Epoch:18, weight train batch: 365, step:31, loss before: 0.000219040055526, loss after: 0.000218163288082.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 361, loss before: 6.91040895617e-07, loss after: 6.91040895617e-07.\n",
      "Epoch:18, weight train batch: 366, step:0, loss before: 7.18980459169e-07, loss after: 7.18980459169e-07.\n",
      "Epoch:18, weight train batch: 366, step:1, loss before: 6.48200000342e-07, loss after: 6.48200000342e-07.\n",
      "Epoch:18, weight train batch: 366, step:2, loss before: 7.71134409661e-07, loss after: 7.71134409661e-07.\n",
      "Epoch:18, weight train batch: 366, step:3, loss before: 8.53090796227e-07, loss after: 8.53090796227e-07.\n",
      "Epoch:18, weight train batch: 366, step:4, loss before: 6.5192529064e-07, loss after: 6.5192529064e-07.\n",
      "Epoch:18, weight train batch: 366, step:5, loss before: 7.59958595609e-07, loss after: 7.59958595609e-07.\n",
      "Epoch:18, weight train batch: 366, step:6, loss before: 6.37024129446e-07, loss after: 6.37024129446e-07.\n",
      "Epoch:18, weight train batch: 366, step:7, loss before: 6.48200057185e-07, loss after: 6.48200057185e-07.\n",
      "Epoch:18, weight train batch: 366, step:8, loss before: 1.34109052397e-06, loss after: 1.34109052397e-06.\n",
      "Epoch:18, weight train batch: 366, step:9, loss before: 1.00210195342e-06, loss after: 1.00210195342e-06.\n",
      "Epoch:18, weight train batch: 366, step:10, loss before: 6.55650580939e-07, loss after: 6.55650580939e-07.\n",
      "Epoch:18, weight train batch: 366, step:11, loss before: 8.38189578189e-07, loss after: 8.38189578189e-07.\n",
      "Epoch:18, weight train batch: 366, step:12, loss before: 8.34464344734e-07, loss after: 8.34464344734e-07.\n",
      "Epoch:18, weight train batch: 366, step:13, loss before: 7.1525516887e-07, loss after: 7.1525516887e-07.\n",
      "Epoch:18, weight train batch: 366, step:14, loss before: 5.21540300724e-07, loss after: 5.21540300724e-07.\n",
      "Epoch:18, weight train batch: 366, step:15, loss before: 9.61123987508e-07, loss after: 9.61123987508e-07.\n",
      "Epoch:18, weight train batch: 366, step:16, loss before: 7.67409176206e-07, loss after: 7.67409176206e-07.\n",
      "Epoch:18, weight train batch: 366, step:17, loss before: 1.01327805169e-06, loss after: 1.01327805169e-06.\n",
      "Epoch:18, weight train batch: 366, step:18, loss before: 1.38206894462e-06, loss after: 1.38206894462e-06.\n",
      "Epoch:18, weight train batch: 366, step:19, loss before: 2.14200827031e-06, loss after: 2.14200827031e-06.\n",
      "Epoch:18, weight train batch: 366, step:20, loss before: 6.55650637782e-07, loss after: 6.55650637782e-07.\n",
      "Epoch:18, weight train batch: 366, step:21, loss before: 3.16649590104e-07, loss after: 3.16649590104e-07.\n",
      "Epoch:18, weight train batch: 366, step:22, loss before: 3.10503528453e-05, loss after: 3.09126517095e-05.\n",
      "Epoch:18, weight train batch: 366, step:23, loss before: 6.40749419745e-07, loss after: 6.40749419745e-07.\n",
      "Epoch:18, weight train batch: 366, step:24, loss before: 5.99771283305e-07, loss after: 5.99771283305e-07.\n",
      "Epoch:18, weight train batch: 366, step:25, loss before: 7.26431039766e-07, loss after: 7.26431039766e-07.\n",
      "Epoch:18, weight train batch: 366, step:26, loss before: 5.6251838032e-07, loss after: 5.6251838032e-07.\n",
      "Epoch:18, weight train batch: 366, step:27, loss before: 1.11758606636e-06, loss after: 1.11758606636e-06.\n",
      "Epoch:18, weight train batch: 366, step:28, loss before: 4.73111526844e-07, loss after: 4.73111526844e-07.\n",
      "Epoch:18, weight train batch: 366, step:29, loss before: 1.79928906618e-06, loss after: 1.79928906618e-06.\n",
      "Epoch:18, weight train batch: 366, step:30, loss before: 6.51925347483e-07, loss after: 6.51925347483e-07.\n",
      "Epoch:18, weight train batch: 366, step:31, loss before: 6.66826451834e-07, loss after: 6.66826451834e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 362, loss before: 7.08735967692e-07, loss after: 7.08735967692e-07.\n",
      "Epoch:18, weight train batch: 367, step:0, loss before: 5.36441461918e-07, loss after: 5.36441461918e-07.\n",
      "Epoch:18, weight train batch: 367, step:1, loss before: 7.30156330064e-07, loss after: 7.30156330064e-07.\n",
      "Epoch:18, weight train batch: 367, step:2, loss before: 8.30739054436e-07, loss after: 8.30739054436e-07.\n",
      "Epoch:18, weight train batch: 367, step:3, loss before: 8.41914868488e-07, loss after: 8.41914868488e-07.\n",
      "Epoch:18, weight train batch: 367, step:4, loss before: 1.99300370696e-06, loss after: 1.99300370696e-06.\n",
      "Epoch:18, weight train batch: 367, step:5, loss before: 4.89615849801e-05, loss after: 4.89206686325e-05.\n",
      "Epoch:18, weight train batch: 367, step:6, loss before: 8.45640158786e-07, loss after: 8.45640158786e-07.\n",
      "Epoch:18, weight train batch: 367, step:7, loss before: 6.85452846483e-07, loss after: 6.85452846483e-07.\n",
      "Epoch:18, weight train batch: 367, step:8, loss before: 8.00936732048e-07, loss after: 8.00936732048e-07.\n",
      "Epoch:18, weight train batch: 367, step:9, loss before: 8.94068875823e-07, loss after: 8.94068875823e-07.\n",
      "Epoch:18, weight train batch: 367, step:10, loss before: 8.53090739383e-07, loss after: 8.53090739383e-07.\n",
      "Epoch:18, weight train batch: 367, step:11, loss before: 8.34464287891e-07, loss after: 8.34464287891e-07.\n",
      "Epoch:18, weight train batch: 367, step:12, loss before: 1.05425624497e-06, loss after: 1.05425624497e-06.\n",
      "Epoch:18, weight train batch: 367, step:13, loss before: 8.86618295226e-07, loss after: 8.86618295226e-07.\n",
      "Epoch:18, weight train batch: 367, step:14, loss before: 8.39584663481e-06, loss after: 8.37722473079e-06.\n",
      "Epoch:18, weight train batch: 367, step:15, loss before: 1.89241677617e-06, loss after: 1.89241677617e-06.\n",
      "Epoch:18, weight train batch: 367, step:16, loss before: 4.73111583688e-07, loss after: 4.73111583688e-07.\n",
      "Epoch:18, weight train batch: 367, step:17, loss before: 0.0216646250337, loss after: 0.0216617435217.\n",
      "Epoch:18, weight train batch: 367, step:18, loss before: 7.18980459169e-07, loss after: 7.18980459169e-07.\n",
      "Epoch:18, weight train batch: 367, step:19, loss before: 8.30738997593e-07, loss after: 8.30738997593e-07.\n",
      "Epoch:18, weight train batch: 367, step:20, loss before: 6.5192529064e-07, loss after: 6.89178193625e-07.\n",
      "Epoch:18, weight train batch: 367, step:21, loss before: 8.67991900577e-07, loss after: 8.67991900577e-07.\n",
      "Epoch:18, weight train batch: 367, step:22, loss before: 7.26431039766e-07, loss after: 7.26431039766e-07.\n",
      "Epoch:18, weight train batch: 367, step:23, loss before: 7.97211555437e-07, loss after: 7.97211555437e-07.\n",
      "Epoch:18, weight train batch: 367, step:24, loss before: 5.73694364903e-07, loss after: 5.73694364903e-07.\n",
      "Epoch:18, weight train batch: 367, step:25, loss before: 5.55067856567e-07, loss after: 5.55067856567e-07.\n",
      "Epoch:18, weight train batch: 367, step:26, loss before: 7.04079297975e-07, loss after: 7.04079297975e-07.\n",
      "Epoch:18, weight train batch: 367, step:27, loss before: 7.0035406452e-07, loss after: 7.0035406452e-07.\n",
      "Epoch:18, weight train batch: 367, step:28, loss before: 9.38772359405e-07, loss after: 9.38772359405e-07.\n",
      "Epoch:18, weight train batch: 367, step:29, loss before: 7.52508071855e-07, loss after: 7.52508071855e-07.\n",
      "Epoch:18, weight train batch: 367, step:30, loss before: 7.07804588274e-07, loss after: 7.07804588274e-07.\n",
      "Epoch:18, weight train batch: 367, step:31, loss before: 8.08387312645e-07, loss after: 8.08387312645e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 363, loss before: 8.1397536178e-07, loss after: 1.49660468196e-06.\n",
      "Epoch:18, weight train batch: 368, step:0, loss before: 7.86035684541e-07, loss after: 7.86035684541e-07.\n",
      "Epoch:18, weight train batch: 368, step:1, loss before: 7.30156330064e-07, loss after: 7.30156330064e-07.\n",
      "Epoch:18, weight train batch: 368, step:2, loss before: 6.07221863902e-07, loss after: 5.84870122111e-07.\n",
      "Epoch:18, weight train batch: 368, step:3, loss before: 8.86618352069e-07, loss after: 8.86618352069e-07.\n",
      "Epoch:18, weight train batch: 368, step:4, loss before: 6.48200000342e-07, loss after: 6.48200000342e-07.\n",
      "Epoch:18, weight train batch: 368, step:5, loss before: 8.60541376824e-07, loss after: 8.60541376824e-07.\n",
      "Epoch:18, weight train batch: 368, step:6, loss before: 7.63683829064e-07, loss after: 7.63683829064e-07.\n",
      "Epoch:18, weight train batch: 368, step:7, loss before: 7.15255112027e-07, loss after: 7.15255112027e-07.\n",
      "Epoch:18, weight train batch: 368, step:8, loss before: 6.40749476588e-07, loss after: 6.40749476588e-07.\n",
      "Epoch:18, weight train batch: 368, step:9, loss before: 6.51925347483e-07, loss after: 6.51925347483e-07.\n",
      "Epoch:18, weight train batch: 368, step:10, loss before: 8.56816029682e-07, loss after: 8.56816029682e-07.\n",
      "Epoch:18, weight train batch: 368, step:11, loss before: 5.06994365423e-06, loss after: 5.07739423483e-06.\n",
      "Epoch:18, weight train batch: 368, step:12, loss before: 7.67409233049e-07, loss after: 7.67409233049e-07.\n",
      "Epoch:18, weight train batch: 368, step:13, loss before: 6.74276975587e-07, loss after: 6.74276975587e-07.\n",
      "Epoch:18, weight train batch: 368, step:14, loss before: 7.63683885907e-07, loss after: 7.63683885907e-07.\n",
      "Epoch:18, weight train batch: 368, step:15, loss before: 8.27013764138e-07, loss after: 8.27013764138e-07.\n",
      "Epoch:18, weight train batch: 368, step:16, loss before: 7.26431039766e-07, loss after: 7.26431039766e-07.\n",
      "Epoch:18, weight train batch: 368, step:17, loss before: 8.15837893242e-07, loss after: 8.15837893242e-07.\n",
      "Epoch:18, weight train batch: 368, step:18, loss before: 7.59958652452e-07, loss after: 7.59958652452e-07.\n",
      "Epoch:18, weight train batch: 368, step:19, loss before: 7.26431039766e-07, loss after: 7.26431039766e-07.\n",
      "Epoch:18, weight train batch: 368, step:20, loss before: 8.82893061771e-07, loss after: 8.82893061771e-07.\n",
      "Epoch:18, weight train batch: 368, step:21, loss before: 8.19563240384e-07, loss after: 8.19563240384e-07.\n",
      "Epoch:18, weight train batch: 368, step:22, loss before: 8.79167828316e-07, loss after: 8.79167828316e-07.\n",
      "Epoch:18, weight train batch: 368, step:23, loss before: 7.07804588274e-07, loss after: 7.07804588274e-07.\n",
      "Epoch:18, weight train batch: 368, step:24, loss before: 7.59958595609e-07, loss after: 7.59958595609e-07.\n",
      "Epoch:18, weight train batch: 368, step:25, loss before: 6.63101161535e-07, loss after: 6.63101161535e-07.\n",
      "Epoch:18, weight train batch: 368, step:26, loss before: 6.03496573603e-07, loss after: 6.03496573603e-07.\n",
      "Epoch:18, weight train batch: 368, step:27, loss before: 7.71134466504e-07, loss after: 7.71134466504e-07.\n",
      "Epoch:18, weight train batch: 368, step:28, loss before: 6.81727556184e-07, loss after: 6.81727556184e-07.\n",
      "Epoch:18, weight train batch: 368, step:29, loss before: 1.91104845726e-06, loss after: 1.90732339433e-06.\n",
      "Epoch:18, weight train batch: 368, step:30, loss before: 6.96628717378e-07, loss after: 6.96628717378e-07.\n",
      "Epoch:18, weight train batch: 368, step:31, loss before: 6.63101218379e-07, loss after: 6.63101218379e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 364, loss before: 8.96859830846e-07, loss after: 6.69620476401e-07.\n",
      "Epoch:18, weight train batch: 369, step:0, loss before: 6.70551798976e-07, loss after: 6.70551798976e-07.\n",
      "Epoch:18, weight train batch: 369, step:1, loss before: 6.5937592808e-07, loss after: 6.5937592808e-07.\n",
      "Epoch:18, weight train batch: 369, step:2, loss before: 7.33881620363e-07, loss after: 7.33881620363e-07.\n",
      "Epoch:18, weight train batch: 369, step:3, loss before: 7.52508071855e-07, loss after: 7.52508071855e-07.\n",
      "Epoch:18, weight train batch: 369, step:4, loss before: 7.18980459169e-07, loss after: 7.18980459169e-07.\n",
      "Epoch:18, weight train batch: 369, step:5, loss before: 1.02072863228e-06, loss after: 1.02072863228e-06.\n",
      "Epoch:18, weight train batch: 369, step:6, loss before: 6.70551798976e-07, loss after: 6.70551798976e-07.\n",
      "Epoch:18, weight train batch: 369, step:7, loss before: 8.60540922076e-07, loss after: 8.60540922076e-07.\n",
      "Epoch:18, weight train batch: 369, step:8, loss before: 9.05244803562e-07, loss after: 9.05244803562e-07.\n",
      "Epoch:18, weight train batch: 369, step:9, loss before: 0.0216614231467, loss after: 0.0216614231467.\n",
      "Epoch:18, weight train batch: 369, step:10, loss before: 1.3969702195e-06, loss after: 1.3969702195e-06.\n",
      "Epoch:18, weight train batch: 369, step:11, loss before: 4.69386293389e-07, loss after: 4.69386293389e-07.\n",
      "Epoch:18, weight train batch: 369, step:12, loss before: 8.49365505928e-07, loss after: 8.49365505928e-07.\n",
      "Epoch:18, weight train batch: 369, step:13, loss before: 7.67409233049e-07, loss after: 7.67409233049e-07.\n",
      "Epoch:18, weight train batch: 369, step:14, loss before: 7.18980459169e-07, loss after: 7.18980459169e-07.\n",
      "Epoch:18, weight train batch: 369, step:15, loss before: 9.57398810897e-07, loss after: 9.57398810897e-07.\n",
      "Epoch:18, weight train batch: 369, step:16, loss before: 7.48782724713e-07, loss after: 7.48782724713e-07.\n",
      "Epoch:18, weight train batch: 369, step:17, loss before: 8.90343642368e-07, loss after: 8.90343642368e-07.\n",
      "Epoch:18, weight train batch: 369, step:18, loss before: 8.67991900577e-07, loss after: 8.67991900577e-07.\n",
      "Epoch:18, weight train batch: 369, step:19, loss before: 8.97794222965e-07, loss after: 8.97794222965e-07.\n",
      "Epoch:18, weight train batch: 369, step:20, loss before: 5.3271617162e-07, loss after: 5.3271617162e-07.\n",
      "Epoch:18, weight train batch: 369, step:21, loss before: 6.03496573603e-07, loss after: 6.03496573603e-07.\n",
      "Epoch:18, weight train batch: 369, step:22, loss before: 7.1525516887e-07, loss after: 7.1525516887e-07.\n",
      "Epoch:18, weight train batch: 369, step:23, loss before: 6.14672444499e-07, loss after: 6.14672444499e-07.\n",
      "Epoch:18, weight train batch: 369, step:24, loss before: 7.22705692624e-07, loss after: 7.22705692624e-07.\n",
      "Epoch:18, weight train batch: 369, step:25, loss before: 8.0466207919e-07, loss after: 8.0466207919e-07.\n",
      "Epoch:18, weight train batch: 369, step:26, loss before: 5.36441461918e-07, loss after: 5.36441461918e-07.\n",
      "Epoch:18, weight train batch: 369, step:27, loss before: 6.03496573603e-07, loss after: 6.03496573603e-07.\n",
      "Epoch:18, weight train batch: 369, step:28, loss before: 8.08387312645e-07, loss after: 8.08387312645e-07.\n",
      "Epoch:18, weight train batch: 369, step:29, loss before: 5.92320702708e-07, loss after: 5.92320702708e-07.\n",
      "Epoch:18, weight train batch: 369, step:30, loss before: 5.28990824478e-07, loss after: 5.28990824478e-07.\n",
      "Epoch:18, weight train batch: 369, step:31, loss before: 6.9290342708e-07, loss after: 6.9290342708e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 365, loss before: 7.17117927707e-07, loss after: 7.17117927707e-07.\n",
      "Epoch:18, weight train batch: 370, step:0, loss before: 6.14672444499e-07, loss after: 6.14672444499e-07.\n",
      "Epoch:18, weight train batch: 370, step:1, loss before: 4.71759849461e-05, loss after: 4.71350685984e-05.\n",
      "Epoch:18, weight train batch: 370, step:2, loss before: 7.33881620363e-07, loss after: 7.33881620363e-07.\n",
      "Epoch:18, weight train batch: 370, step:3, loss before: 7.48782781557e-07, loss after: 7.48782781557e-07.\n",
      "Epoch:18, weight train batch: 370, step:4, loss before: 9.68574681792e-07, loss after: 9.68574681792e-07.\n",
      "Epoch:18, weight train batch: 370, step:5, loss before: 4.91737978336e-07, loss after: 4.91737978336e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:18, weight train batch: 370, step:6, loss before: 6.03496573603e-07, loss after: 6.03496573603e-07.\n",
      "Epoch:18, weight train batch: 370, step:7, loss before: 6.96628717378e-07, loss after: 6.96628717378e-07.\n",
      "Epoch:18, weight train batch: 370, step:8, loss before: 9.01519513263e-07, loss after: 9.01519513263e-07.\n",
      "Epoch:18, weight train batch: 370, step:9, loss before: 8.27013764138e-07, loss after: 8.27013764138e-07.\n",
      "Epoch:18, weight train batch: 370, step:10, loss before: 6.44474710043e-07, loss after: 6.18397791641e-07.\n",
      "Epoch:18, weight train batch: 370, step:11, loss before: 6.14672558186e-07, loss after: 6.14672558186e-07.\n",
      "Epoch:18, weight train batch: 370, step:12, loss before: 1.69871839262e-06, loss after: 1.69871839262e-06.\n",
      "Epoch:18, weight train batch: 370, step:13, loss before: 7.45057548102e-07, loss after: 7.45057548102e-07.\n",
      "Epoch:18, weight train batch: 370, step:14, loss before: 8.38189578189e-07, loss after: 8.38189578189e-07.\n",
      "Epoch:18, weight train batch: 370, step:15, loss before: 6.81727669871e-07, loss after: 6.81727669871e-07.\n",
      "Epoch:18, weight train batch: 370, step:16, loss before: 3.94880572685e-07, loss after: 3.94880572685e-07.\n",
      "Epoch:18, weight train batch: 370, step:17, loss before: 1.02817909919e-06, loss after: 1.02817909919e-06.\n",
      "Epoch:18, weight train batch: 370, step:18, loss before: 7.15255112027e-07, loss after: 7.15255112027e-07.\n",
      "Epoch:18, weight train batch: 370, step:19, loss before: 8.38189691876e-07, loss after: 8.38189691876e-07.\n",
      "Epoch:18, weight train batch: 370, step:20, loss before: 8.38189691876e-07, loss after: 8.38189691876e-07.\n",
      "Epoch:18, weight train batch: 370, step:21, loss before: 6.07221920745e-07, loss after: 6.07221920745e-07.\n",
      "Epoch:18, weight train batch: 370, step:22, loss before: 6.25848201707e-07, loss after: 6.25848201707e-07.\n",
      "Epoch:18, weight train batch: 370, step:23, loss before: 8.02341219241e-06, loss after: 8.0047902884e-06.\n",
      "Epoch:18, weight train batch: 370, step:24, loss before: 5.3271617162e-07, loss after: 5.3271617162e-07.\n",
      "Epoch:18, weight train batch: 370, step:25, loss before: 7.37606910661e-07, loss after: 7.37606910661e-07.\n",
      "Epoch:18, weight train batch: 370, step:26, loss before: 7.37606967505e-07, loss after: 7.37606967505e-07.\n",
      "Epoch:18, weight train batch: 370, step:27, loss before: 8.00936845735e-07, loss after: 8.00936845735e-07.\n",
      "Epoch:18, weight train batch: 370, step:28, loss before: 7.93486265138e-07, loss after: 7.93486265138e-07.\n",
      "Epoch:18, weight train batch: 370, step:29, loss before: 7.78585103944e-07, loss after: 7.78585103944e-07.\n",
      "Epoch:18, weight train batch: 370, step:30, loss before: 6.78002379573e-07, loss after: 6.78002379573e-07.\n",
      "Epoch:18, weight train batch: 370, step:31, loss before: 6.81727669871e-07, loss after: 6.81727669871e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 366, loss before: 6.48200114028e-07, loss after: 6.72414444125e-07.\n",
      "Epoch:18, weight train batch: 371, step:0, loss before: 8.30739111279e-07, loss after: 8.30739111279e-07.\n",
      "Epoch:18, weight train batch: 371, step:1, loss before: 8.19563297227e-07, loss after: 8.19563297227e-07.\n",
      "Epoch:18, weight train batch: 371, step:2, loss before: 0.000210757600144, loss after: 0.00020994352235.\n",
      "Epoch:18, weight train batch: 371, step:3, loss before: 5.47617332813e-07, loss after: 5.47617332813e-07.\n",
      "Epoch:18, weight train batch: 371, step:4, loss before: 8.04662136034e-07, loss after: 8.04662136034e-07.\n",
      "Epoch:18, weight train batch: 371, step:5, loss before: 7.8976097484e-07, loss after: 7.8976097484e-07.\n",
      "Epoch:18, weight train batch: 371, step:6, loss before: 7.8976097484e-07, loss after: 7.8976097484e-07.\n",
      "Epoch:18, weight train batch: 371, step:7, loss before: 6.89178250468e-07, loss after: 6.89178250468e-07.\n",
      "Epoch:18, weight train batch: 371, step:8, loss before: 1.63538925335e-06, loss after: 1.63166419043e-06.\n",
      "Epoch:18, weight train batch: 371, step:9, loss before: 7.8976097484e-07, loss after: 7.8976097484e-07.\n",
      "Epoch:18, weight train batch: 371, step:10, loss before: 7.59958652452e-07, loss after: 7.59958652452e-07.\n",
      "Epoch:18, weight train batch: 371, step:11, loss before: 4.73111612109e-07, loss after: 4.73111612109e-07.\n",
      "Epoch:18, weight train batch: 371, step:12, loss before: 9.16420731301e-07, loss after: 9.16420731301e-07.\n",
      "Epoch:18, weight train batch: 371, step:13, loss before: 6.74277146118e-07, loss after: 6.74277146118e-07.\n",
      "Epoch:18, weight train batch: 371, step:14, loss before: 7.04079354819e-07, loss after: 7.04079354819e-07.\n",
      "Epoch:18, weight train batch: 371, step:15, loss before: 6.4447482373e-07, loss after: 6.4447482373e-07.\n",
      "Epoch:18, weight train batch: 371, step:16, loss before: 6.59375984924e-07, loss after: 6.59375984924e-07.\n",
      "Epoch:18, weight train batch: 371, step:17, loss before: 5.66243784306e-07, loss after: 5.66243784306e-07.\n",
      "Epoch:18, weight train batch: 371, step:18, loss before: 7.86035514011e-07, loss after: 7.86035514011e-07.\n",
      "Epoch:18, weight train batch: 371, step:19, loss before: 8.41914982175e-07, loss after: 8.41914982175e-07.\n",
      "Epoch:18, weight train batch: 371, step:20, loss before: 6.70551798976e-07, loss after: 6.70551798976e-07.\n",
      "Epoch:18, weight train batch: 371, step:21, loss before: 7.97211555437e-07, loss after: 7.97211555437e-07.\n",
      "Epoch:18, weight train batch: 371, step:22, loss before: 7.78585103944e-07, loss after: 7.78585103944e-07.\n",
      "Epoch:18, weight train batch: 371, step:23, loss before: 4.5075989874e-07, loss after: 4.5075989874e-07.\n",
      "Epoch:18, weight train batch: 371, step:24, loss before: 7.37606967505e-07, loss after: 7.37606967505e-07.\n",
      "Epoch:18, weight train batch: 371, step:25, loss before: 7.0780470196e-07, loss after: 7.0780470196e-07.\n",
      "Epoch:18, weight train batch: 371, step:26, loss before: 6.0349668729e-07, loss after: 6.0349668729e-07.\n",
      "Epoch:18, weight train batch: 371, step:27, loss before: 8.12112716631e-07, loss after: 8.12112716631e-07.\n",
      "Epoch:18, weight train batch: 371, step:28, loss before: 7.74859699959e-07, loss after: 7.74859699959e-07.\n",
      "Epoch:18, weight train batch: 371, step:29, loss before: 4.64172189822e-05, loss after: 4.63800206489e-05.\n",
      "Epoch:18, weight train batch: 371, step:30, loss before: 8.34464401578e-07, loss after: 8.34464401578e-07.\n",
      "Epoch:18, weight train batch: 371, step:31, loss before: 8.6054131998e-07, loss after: 8.6054131998e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 367, loss before: 8.5867600319e-07, loss after: 7.68339702972e-07.\n",
      "Epoch:18, weight train batch: 372, step:0, loss before: 3.0323046758e-06, loss after: 3.0323046758e-06.\n",
      "Epoch:18, weight train batch: 372, step:1, loss before: 0.000195936081582, loss after: 0.000195180837181.\n",
      "Epoch:18, weight train batch: 372, step:2, loss before: 7.86035684541e-07, loss after: 7.86035684541e-07.\n",
      "Epoch:18, weight train batch: 372, step:3, loss before: 6.25848372238e-07, loss after: 6.25848372238e-07.\n",
      "Epoch:18, weight train batch: 372, step:4, loss before: 6.70551798976e-07, loss after: 6.70551798976e-07.\n",
      "Epoch:18, weight train batch: 372, step:5, loss before: 4.60115625174e-05, loss after: 4.59743605461e-05.\n",
      "Epoch:18, weight train batch: 372, step:6, loss before: 3.00994543068e-06, loss after: 3.00994543068e-06.\n",
      "Epoch:18, weight train batch: 372, step:7, loss before: 4.09781762301e-07, loss after: 4.09781762301e-07.\n",
      "Epoch:18, weight train batch: 372, step:8, loss before: 6.25848429081e-07, loss after: 6.25848429081e-07.\n",
      "Epoch:18, weight train batch: 372, step:9, loss before: 2.31596204685e-05, loss after: 2.31186713791e-05.\n",
      "Epoch:18, weight train batch: 372, step:10, loss before: 4.88012744881e-07, loss after: 4.88012744881e-07.\n",
      "Epoch:18, weight train batch: 372, step:11, loss before: 8.00936845735e-07, loss after: 8.00936845735e-07.\n",
      "Epoch:18, weight train batch: 372, step:12, loss before: 6.74277089274e-07, loss after: 6.74277089274e-07.\n",
      "Epoch:18, weight train batch: 372, step:13, loss before: 5.51342623112e-07, loss after: 5.28990881321e-07.\n",
      "Epoch:18, weight train batch: 372, step:14, loss before: 5.5506791341e-07, loss after: 5.5506791341e-07.\n",
      "Epoch:18, weight train batch: 372, step:15, loss before: 6.70551798976e-07, loss after: 6.70551798976e-07.\n",
      "Epoch:18, weight train batch: 372, step:16, loss before: 6.18397791641e-07, loss after: 6.18397791641e-07.\n",
      "Epoch:18, weight train batch: 372, step:17, loss before: 7.74859813646e-07, loss after: 7.74859813646e-07.\n",
      "Epoch:18, weight train batch: 372, step:18, loss before: 5.58793203709e-07, loss after: 5.58793203709e-07.\n",
      "Epoch:18, weight train batch: 372, step:19, loss before: 7.63683885907e-07, loss after: 7.63683885907e-07.\n",
      "Epoch:18, weight train batch: 372, step:20, loss before: 7.18980516012e-07, loss after: 7.18980516012e-07.\n",
      "Epoch:18, weight train batch: 372, step:21, loss before: 4.36828995589e-05, loss after: 4.34113280789e-05.\n",
      "Epoch:18, weight train batch: 372, step:22, loss before: 6.07221920745e-07, loss after: 6.07221920745e-07.\n",
      "Epoch:18, weight train batch: 372, step:23, loss before: 7.48782895243e-07, loss after: 7.48782895243e-07.\n",
      "Epoch:18, weight train batch: 372, step:24, loss before: 8.12112716631e-07, loss after: 8.12112716631e-07.\n",
      "Epoch:18, weight train batch: 372, step:25, loss before: 7.04079411662e-07, loss after: 7.04079411662e-07.\n",
      "Epoch:18, weight train batch: 372, step:26, loss before: 7.04079354819e-07, loss after: 7.04079354819e-07.\n",
      "Epoch:18, weight train batch: 372, step:27, loss before: 5.88595526096e-07, loss after: 5.88595526096e-07.\n",
      "Epoch:18, weight train batch: 372, step:28, loss before: 7.58764554121e-06, loss after: 7.59509475756e-06.\n",
      "Epoch:18, weight train batch: 372, step:29, loss before: 6.4447482373e-07, loss after: 6.4447482373e-07.\n",
      "Epoch:18, weight train batch: 372, step:30, loss before: 5.58793203709e-07, loss after: 5.58793203709e-07.\n",
      "Epoch:18, weight train batch: 372, step:31, loss before: 5.36441461918e-07, loss after: 5.36441461918e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 368, loss before: 6.99422741945e-07, loss after: 6.88246927893e-07.\n",
      "Epoch:18, weight train batch: 373, step:0, loss before: 6.25848315394e-07, loss after: 6.25848315394e-07.\n",
      "Epoch:18, weight train batch: 373, step:1, loss before: 5.3271617162e-07, loss after: 5.3271617162e-07.\n",
      "Epoch:18, weight train batch: 373, step:2, loss before: 4.58526483271e-05, loss after: 4.58080103272e-05.\n",
      "Epoch:18, weight train batch: 373, step:3, loss before: 1.44540194924e-06, loss after: 1.44540194924e-06.\n",
      "Epoch:18, weight train batch: 373, step:4, loss before: 7.67409233049e-07, loss after: 7.67409233049e-07.\n",
      "Epoch:18, weight train batch: 373, step:5, loss before: 4.73111640531e-07, loss after: 4.73111640531e-07.\n",
      "Epoch:18, weight train batch: 373, step:6, loss before: 6.85452903326e-07, loss after: 6.85452903326e-07.\n",
      "Epoch:18, weight train batch: 373, step:7, loss before: 6.78002322729e-07, loss after: 6.78002322729e-07.\n",
      "Epoch:18, weight train batch: 373, step:8, loss before: 6.18397734797e-07, loss after: 6.18397734797e-07.\n",
      "Epoch:18, weight train batch: 373, step:9, loss before: 8.19563183541e-07, loss after: 8.19563183541e-07.\n",
      "Epoch:18, weight train batch: 373, step:10, loss before: 5.14089720127e-07, loss after: 5.14089720127e-07.\n",
      "Epoch:18, weight train batch: 373, step:11, loss before: 3.15893203151e-06, loss after: 3.15893203151e-06.\n",
      "Epoch:18, weight train batch: 373, step:12, loss before: 5.36441518761e-07, loss after: 5.36441518761e-07.\n",
      "Epoch:18, weight train batch: 373, step:13, loss before: 7.0035406452e-07, loss after: 7.0035406452e-07.\n",
      "Epoch:18, weight train batch: 373, step:14, loss before: 6.55650694625e-07, loss after: 6.55650694625e-07.\n",
      "Epoch:18, weight train batch: 373, step:15, loss before: 0.000607218942605, loss after: 0.000605424924288.\n",
      "Epoch:18, weight train batch: 373, step:16, loss before: 1.12130805974e-06, loss after: 1.11758288313e-06.\n",
      "Epoch:18, weight train batch: 373, step:17, loss before: 4.61935769636e-07, loss after: 4.61935769636e-07.\n",
      "Epoch:18, weight train batch: 373, step:18, loss before: 2.29101306104e-06, loss after: 2.28728799812e-06.\n",
      "Epoch:18, weight train batch: 373, step:19, loss before: 7.00354121363e-07, loss after: 7.00354121363e-07.\n",
      "Epoch:18, weight train batch: 373, step:20, loss before: 5.66243784306e-07, loss after: 5.66243784306e-07.\n",
      "Epoch:18, weight train batch: 373, step:21, loss before: 6.3702418629e-07, loss after: 6.3702418629e-07.\n",
      "Epoch:18, weight train batch: 373, step:22, loss before: 6.03496630447e-07, loss after: 6.03496630447e-07.\n",
      "Epoch:18, weight train batch: 373, step:23, loss before: 0.000180966992048, loss after: 0.000180115093826.\n",
      "Epoch:18, weight train batch: 373, step:24, loss before: 2.76781474895e-06, loss after: 2.76408968602e-06.\n",
      "Epoch:18, weight train batch: 373, step:25, loss before: 4.65661003091e-07, loss after: 4.65661003091e-07.\n",
      "Epoch:18, weight train batch: 373, step:26, loss before: 1.38105424412e-05, loss after: 1.37807528517e-05.\n",
      "Epoch:18, weight train batch: 373, step:27, loss before: 6.33299009678e-07, loss after: 6.33299009678e-07.\n",
      "Epoch:18, weight train batch: 373, step:28, loss before: 5.4016680906e-07, loss after: 5.4016680906e-07.\n",
      "Epoch:18, weight train batch: 373, step:29, loss before: 6.70551855819e-07, loss after: 6.70551855819e-07.\n",
      "Epoch:18, weight train batch: 373, step:30, loss before: 8.64266667122e-07, loss after: 8.64266667122e-07.\n",
      "Epoch:18, weight train batch: 373, step:31, loss before: 8.71717247719e-07, loss after: 8.71717247719e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 369, loss before: 1.15668399303e-06, loss after: 1.15668387934e-06.\n",
      "Epoch:18, weight train batch: 374, step:0, loss before: 7.63683999594e-07, loss after: 7.63683999594e-07.\n",
      "Epoch:18, weight train batch: 374, step:1, loss before: 6.74277089274e-07, loss after: 6.74277089274e-07.\n",
      "Epoch:18, weight train batch: 374, step:2, loss before: 6.18397791641e-07, loss after: 6.18397791641e-07.\n",
      "Epoch:18, weight train batch: 374, step:3, loss before: 5.47617332813e-07, loss after: 5.47617332813e-07.\n",
      "Epoch:18, weight train batch: 374, step:4, loss before: 6.51925347483e-07, loss after: 6.51925347483e-07.\n",
      "Epoch:18, weight train batch: 374, step:5, loss before: 7.487828384e-07, loss after: 7.487828384e-07.\n",
      "Epoch:18, weight train batch: 374, step:6, loss before: 7.22705863154e-07, loss after: 7.22705863154e-07.\n",
      "Epoch:18, weight train batch: 374, step:7, loss before: 6.10947211044e-07, loss after: 5.77419655201e-07.\n",
      "Epoch:18, weight train batch: 374, step:8, loss before: 7.86035684541e-07, loss after: 7.86035684541e-07.\n",
      "Epoch:18, weight train batch: 374, step:9, loss before: 4.9173803518e-07, loss after: 4.9173803518e-07.\n",
      "Epoch:18, weight train batch: 374, step:10, loss before: 6.22123025096e-07, loss after: 6.22123025096e-07.\n",
      "Epoch:18, weight train batch: 374, step:11, loss before: 6.4447482373e-07, loss after: 6.4447482373e-07.\n",
      "Epoch:18, weight train batch: 374, step:12, loss before: 8.19563297227e-07, loss after: 8.19563297227e-07.\n",
      "Epoch:18, weight train batch: 374, step:13, loss before: 5.81144888656e-07, loss after: 5.81144888656e-07.\n",
      "Epoch:18, weight train batch: 374, step:14, loss before: 7.15255282557e-07, loss after: 7.15255282557e-07.\n",
      "Epoch:18, weight train batch: 374, step:15, loss before: 5.81144888656e-07, loss after: 5.81144888656e-07.\n",
      "Epoch:18, weight train batch: 374, step:16, loss before: 1.53001146828e-05, loss after: 1.52479842654e-05.\n",
      "Epoch:18, weight train batch: 374, step:17, loss before: 5.84870235798e-07, loss after: 5.84870235798e-07.\n",
      "Epoch:18, weight train batch: 374, step:18, loss before: 5.92320759552e-07, loss after: 5.92320759552e-07.\n",
      "Epoch:18, weight train batch: 374, step:19, loss before: 5.88595526096e-07, loss after: 5.88595526096e-07.\n",
      "Epoch:18, weight train batch: 374, step:20, loss before: 3.42718703905e-06, loss after: 3.42718703905e-06.\n",
      "Epoch:18, weight train batch: 374, step:21, loss before: 7.41332257803e-07, loss after: 7.41332257803e-07.\n",
      "Epoch:18, weight train batch: 374, step:22, loss before: 5.47617332813e-07, loss after: 5.47617332813e-07.\n",
      "Epoch:18, weight train batch: 374, step:23, loss before: 6.07221920745e-07, loss after: 6.07221920745e-07.\n",
      "Epoch:18, weight train batch: 374, step:24, loss before: 8.19563297227e-07, loss after: 8.19563297227e-07.\n",
      "Epoch:18, weight train batch: 374, step:25, loss before: 6.22123081939e-07, loss after: 6.22123081939e-07.\n",
      "Epoch:18, weight train batch: 374, step:26, loss before: 4.70588929602e-05, loss after: 4.70179729746e-05.\n",
      "Epoch:18, weight train batch: 374, step:27, loss before: 6.33298895991e-07, loss after: 6.33298895991e-07.\n",
      "Epoch:18, weight train batch: 374, step:28, loss before: 6.18397734797e-07, loss after: 6.18397734797e-07.\n",
      "Epoch:18, weight train batch: 374, step:29, loss before: 7.22705806311e-07, loss after: 7.22705806311e-07.\n",
      "Epoch:18, weight train batch: 374, step:30, loss before: 5.3271617162e-07, loss after: 5.3271617162e-07.\n",
      "Epoch:18, weight train batch: 374, step:31, loss before: 5.92320759552e-07, loss after: 5.92320759552e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 370, loss before: 5.57861881134e-07, loss after: 8.40978771066e-07.\n",
      "Epoch:18, weight train batch: 375, step:0, loss before: 6.22123025096e-07, loss after: 6.22123025096e-07.\n",
      "Epoch:18, weight train batch: 375, step:1, loss before: 2.3431698537e-06, loss after: 2.33571972785e-06.\n",
      "Epoch:18, weight train batch: 375, step:2, loss before: 5.47617332813e-07, loss after: 5.47617332813e-07.\n",
      "Epoch:18, weight train batch: 375, step:3, loss before: 8.04662136034e-07, loss after: 8.04662136034e-07.\n",
      "Epoch:18, weight train batch: 375, step:4, loss before: 2.63371771325e-06, loss after: 2.63371771325e-06.\n",
      "Epoch:18, weight train batch: 375, step:5, loss before: 6.44474766887e-07, loss after: 6.44474766887e-07.\n",
      "Epoch:18, weight train batch: 375, step:6, loss before: 6.74277089274e-07, loss after: 6.74277089274e-07.\n",
      "Epoch:18, weight train batch: 375, step:7, loss before: 4.58210507759e-07, loss after: 4.43309346565e-07.\n",
      "Epoch:18, weight train batch: 375, step:8, loss before: 6.8545296017e-07, loss after: 6.8545296017e-07.\n",
      "Epoch:18, weight train batch: 375, step:9, loss before: 5.21540357568e-07, loss after: 5.21540357568e-07.\n",
      "Epoch:18, weight train batch: 375, step:10, loss before: 5.69969074604e-07, loss after: 5.69969074604e-07.\n",
      "Epoch:18, weight train batch: 375, step:11, loss before: 8.56816143369e-07, loss after: 8.56816143369e-07.\n",
      "Epoch:18, weight train batch: 375, step:12, loss before: 3.90675049857e-05, loss after: 3.88368061977e-05.\n",
      "Epoch:18, weight train batch: 375, step:13, loss before: 7.11529992259e-07, loss after: 7.11529992259e-07.\n",
      "Epoch:18, weight train batch: 375, step:14, loss before: 4.88012801725e-07, loss after: 4.88012801725e-07.\n",
      "Epoch:18, weight train batch: 375, step:15, loss before: 4.43309318143e-07, loss after: 4.43309318143e-07.\n",
      "Epoch:18, weight train batch: 375, step:16, loss before: 5.99771396992e-07, loss after: 5.99771396992e-07.\n",
      "Epoch:18, weight train batch: 375, step:17, loss before: 5.43892042515e-07, loss after: 5.43892042515e-07.\n",
      "Epoch:18, weight train batch: 375, step:18, loss before: 6.0349668729e-07, loss after: 6.0349668729e-07.\n",
      "Epoch:18, weight train batch: 375, step:19, loss before: 6.48200170872e-07, loss after: 6.48200170872e-07.\n",
      "Epoch:18, weight train batch: 375, step:20, loss before: 6.74277089274e-07, loss after: 6.74277089274e-07.\n",
      "Epoch:18, weight train batch: 375, step:21, loss before: 6.10947267887e-07, loss after: 6.10947267887e-07.\n",
      "Epoch:18, weight train batch: 375, step:22, loss before: 5.96046106693e-07, loss after: 5.96046106693e-07.\n",
      "Epoch:18, weight train batch: 375, step:23, loss before: 7.37607024348e-07, loss after: 7.37607024348e-07.\n",
      "Epoch:18, weight train batch: 375, step:24, loss before: 5.96046106693e-07, loss after: 5.96046106693e-07.\n",
      "Epoch:18, weight train batch: 375, step:25, loss before: 6.51925233797e-07, loss after: 6.51925233797e-07.\n",
      "Epoch:18, weight train batch: 375, step:26, loss before: 5.73694421746e-07, loss after: 5.73694421746e-07.\n",
      "Epoch:18, weight train batch: 375, step:27, loss before: 1.08405856736e-06, loss after: 1.08405856736e-06.\n",
      "Epoch:18, weight train batch: 375, step:28, loss before: 6.59375984924e-07, loss after: 6.59375984924e-07.\n",
      "Epoch:18, weight train batch: 375, step:29, loss before: 4.17232342897e-07, loss after: 4.17232342897e-07.\n",
      "Epoch:18, weight train batch: 375, step:30, loss before: 7.45057604945e-07, loss after: 7.45057604945e-07.\n",
      "Epoch:18, weight train batch: 375, step:31, loss before: 5.28990995008e-07, loss after: 5.28990995008e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 371, loss before: 5.96977372425e-07, loss after: 8.91484251042e-06.\n",
      "Epoch:18, weight train batch: 376, step:0, loss before: 6.55650694625e-07, loss after: 6.55650694625e-07.\n",
      "Epoch:18, weight train batch: 376, step:1, loss before: 5.51342679955e-07, loss after: 5.51342679955e-07.\n",
      "Epoch:18, weight train batch: 376, step:2, loss before: 5.02913962919e-07, loss after: 5.02913962919e-07.\n",
      "Epoch:18, weight train batch: 376, step:3, loss before: 7.56233418997e-07, loss after: 7.56233418997e-07.\n",
      "Epoch:18, weight train batch: 376, step:4, loss before: 6.8545296017e-07, loss after: 6.8545296017e-07.\n",
      "Epoch:18, weight train batch: 376, step:5, loss before: 3.24100142279e-07, loss after: 3.24100142279e-07.\n",
      "Epoch:18, weight train batch: 376, step:6, loss before: 6.66826508677e-07, loss after: 6.66826508677e-07.\n",
      "Epoch:18, weight train batch: 376, step:7, loss before: 5.47617389657e-07, loss after: 5.47617389657e-07.\n",
      "Epoch:18, weight train batch: 376, step:8, loss before: 6.89178250468e-07, loss after: 6.89178250468e-07.\n",
      "Epoch:18, weight train batch: 376, step:9, loss before: 4.28408185371e-07, loss after: 4.28408185371e-07.\n",
      "Epoch:18, weight train batch: 376, step:10, loss before: 4.17232342897e-07, loss after: 4.17232342897e-07.\n",
      "Epoch:18, weight train batch: 376, step:11, loss before: 7.56233418997e-07, loss after: 7.56233418997e-07.\n",
      "Epoch:18, weight train batch: 376, step:12, loss before: 0.0216613188386, loss after: 0.0216613188386.\n",
      "Epoch:18, weight train batch: 376, step:13, loss before: 1.76948105945e-06, loss after: 1.76948105945e-06.\n",
      "Epoch:18, weight train batch: 376, step:14, loss before: 5.99771396992e-07, loss after: 5.99771396992e-07.\n",
      "Epoch:18, weight train batch: 376, step:15, loss before: 4.58210507759e-07, loss after: 4.58210507759e-07.\n",
      "Epoch:18, weight train batch: 376, step:16, loss before: 5.32716228463e-07, loss after: 5.32716228463e-07.\n",
      "Epoch:18, weight train batch: 376, step:17, loss before: 6.81727669871e-07, loss after: 6.81727669871e-07.\n",
      "Epoch:18, weight train batch: 376, step:18, loss before: 6.8545296017e-07, loss after: 6.8545296017e-07.\n",
      "Epoch:18, weight train batch: 376, step:19, loss before: 4.54485189039e-07, loss after: 4.54485189039e-07.\n",
      "Epoch:18, weight train batch: 376, step:20, loss before: 5.66243784306e-07, loss after: 5.66243784306e-07.\n",
      "Epoch:18, weight train batch: 376, step:21, loss before: 6.22123138783e-07, loss after: 6.22123138783e-07.\n",
      "Epoch:18, weight train batch: 376, step:22, loss before: 3.3115655242e-05, loss after: 3.29370304826e-05.\n",
      "Epoch:18, weight train batch: 376, step:23, loss before: 4.88012801725e-07, loss after: 4.88012801725e-07.\n",
      "Epoch:18, weight train batch: 376, step:24, loss before: 5.99771396992e-07, loss after: 5.99771396992e-07.\n",
      "Epoch:18, weight train batch: 376, step:25, loss before: 3.31550722876e-07, loss after: 3.31550722876e-07.\n",
      "Epoch:18, weight train batch: 376, step:26, loss before: 5.06639253217e-07, loss after: 5.06639253217e-07.\n",
      "Epoch:18, weight train batch: 376, step:27, loss before: 5.51342679955e-07, loss after: 5.51342679955e-07.\n",
      "Epoch:18, weight train batch: 376, step:28, loss before: 5.10364486672e-07, loss after: 5.10364486672e-07.\n",
      "Epoch:18, weight train batch: 376, step:29, loss before: 4.88012801725e-07, loss after: 4.88012801725e-07.\n",
      "Epoch:18, weight train batch: 376, step:30, loss before: 6.5192546117e-07, loss after: 6.5192546117e-07.\n",
      "Epoch:18, weight train batch: 376, step:31, loss before: 6.96628831065e-07, loss after: 6.96628831065e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 372, loss before: 5.811449455e-07, loss after: 5.811449455e-07.\n",
      "Epoch:18, weight train batch: 377, step:0, loss before: 5.36441518761e-07, loss after: 5.36441518761e-07.\n",
      "Epoch:18, weight train batch: 377, step:1, loss before: 6.18397848484e-07, loss after: 6.18397848484e-07.\n",
      "Epoch:18, weight train batch: 377, step:2, loss before: 1.01699981769e-06, loss after: 1.01699981769e-06.\n",
      "Epoch:18, weight train batch: 377, step:3, loss before: 6.37024243133e-07, loss after: 6.37024243133e-07.\n",
      "Epoch:18, weight train batch: 377, step:4, loss before: 8.34464458421e-07, loss after: 8.34464458421e-07.\n",
      "Epoch:18, weight train batch: 377, step:5, loss before: 6.81727669871e-07, loss after: 6.81727669871e-07.\n",
      "Epoch:18, weight train batch: 377, step:6, loss before: 7.71134523347e-07, loss after: 7.71134523347e-07.\n",
      "Epoch:18, weight train batch: 377, step:7, loss before: 0.000571801501792, loss after: 0.000570078613237.\n",
      "Epoch:18, weight train batch: 377, step:8, loss before: 4.35858737546e-07, loss after: 4.35858737546e-07.\n",
      "Epoch:18, weight train batch: 377, step:9, loss before: 5.99771396992e-07, loss after: 5.99771396992e-07.\n",
      "Epoch:18, weight train batch: 377, step:10, loss before: 4.39584084688e-07, loss after: 4.39584084688e-07.\n",
      "Epoch:18, weight train batch: 377, step:11, loss before: 7.26431153453e-07, loss after: 7.26431153453e-07.\n",
      "Epoch:18, weight train batch: 377, step:12, loss before: 4.61935769636e-07, loss after: 4.61935769636e-07.\n",
      "Epoch:18, weight train batch: 377, step:13, loss before: 6.70551798976e-07, loss after: 6.70551798976e-07.\n",
      "Epoch:18, weight train batch: 377, step:14, loss before: 7.0780470196e-07, loss after: 7.0780470196e-07.\n",
      "Epoch:18, weight train batch: 377, step:15, loss before: 5.811449455e-07, loss after: 5.811449455e-07.\n",
      "Epoch:18, weight train batch: 377, step:16, loss before: 6.8545296017e-07, loss after: 6.8545296017e-07.\n",
      "Epoch:18, weight train batch: 377, step:17, loss before: 4.5448521746e-07, loss after: 4.5448521746e-07.\n",
      "Epoch:18, weight train batch: 377, step:18, loss before: 4.61935769636e-07, loss after: 4.61935769636e-07.\n",
      "Epoch:18, weight train batch: 377, step:19, loss before: 0.0216612648219, loss after: 0.0216611996293.\n",
      "Epoch:18, weight train batch: 377, step:20, loss before: 5.10364543516e-07, loss after: 5.10364543516e-07.\n",
      "Epoch:18, weight train batch: 377, step:21, loss before: 2.70078317044e-06, loss after: 2.70823329629e-06.\n",
      "Epoch:18, weight train batch: 377, step:22, loss before: 5.40166752216e-07, loss after: 5.40166752216e-07.\n",
      "Epoch:18, weight train batch: 377, step:23, loss before: 7.5623347584e-07, loss after: 7.5623347584e-07.\n",
      "Epoch:18, weight train batch: 377, step:24, loss before: 4.43309346565e-07, loss after: 4.43309346565e-07.\n",
      "Epoch:18, weight train batch: 377, step:25, loss before: 5.51342679955e-07, loss after: 5.51342679955e-07.\n",
      "Epoch:18, weight train batch: 377, step:26, loss before: 6.33298952835e-07, loss after: 6.33298952835e-07.\n",
      "Epoch:18, weight train batch: 377, step:27, loss before: 5.84870235798e-07, loss after: 5.84870235798e-07.\n",
      "Epoch:18, weight train batch: 377, step:28, loss before: 6.63101218379e-07, loss after: 6.63101218379e-07.\n",
      "Epoch:18, weight train batch: 377, step:29, loss before: 5.06639253217e-07, loss after: 5.06639253217e-07.\n",
      "Epoch:18, weight train batch: 377, step:30, loss before: 4.84287511426e-07, loss after: 4.84287511426e-07.\n",
      "Epoch:18, weight train batch: 377, step:31, loss before: 5.5506791341e-07, loss after: 5.5506791341e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 373, loss before: 6.77069351696e-07, loss after: 8.68915094543e-07.\n",
      "Epoch:18, weight train batch: 378, step:0, loss before: 6.96628831065e-07, loss after: 6.96628831065e-07.\n",
      "Epoch:18, weight train batch: 378, step:1, loss before: 5.69969074604e-07, loss after: 5.69969074604e-07.\n",
      "Epoch:18, weight train batch: 378, step:2, loss before: 6.66826508677e-07, loss after: 6.66826508677e-07.\n",
      "Epoch:18, weight train batch: 378, step:3, loss before: 4.65661059934e-07, loss after: 4.65661059934e-07.\n",
      "Epoch:18, weight train batch: 378, step:4, loss before: 4.95463382322e-07, loss after: 4.95463382322e-07.\n",
      "Epoch:18, weight train batch: 378, step:5, loss before: 1.71361159573e-06, loss after: 1.70988641912e-06.\n",
      "Epoch:18, weight train batch: 378, step:6, loss before: 5.5506791341e-07, loss after: 5.5506791341e-07.\n",
      "Epoch:18, weight train batch: 378, step:7, loss before: 5.14089776971e-07, loss after: 5.14089776971e-07.\n",
      "Epoch:18, weight train batch: 378, step:8, loss before: 5.96046106693e-07, loss after: 5.96046106693e-07.\n",
      "Epoch:18, weight train batch: 378, step:9, loss before: 5.99771396992e-07, loss after: 5.99771396992e-07.\n",
      "Epoch:18, weight train batch: 378, step:10, loss before: 7.3388173405e-07, loss after: 7.3388173405e-07.\n",
      "Epoch:18, weight train batch: 378, step:11, loss before: 7.86035741385e-07, loss after: 7.86035741385e-07.\n",
      "Epoch:18, weight train batch: 378, step:12, loss before: 7.5623347584e-07, loss after: 7.5623347584e-07.\n",
      "Epoch:18, weight train batch: 378, step:13, loss before: 5.69969074604e-07, loss after: 5.69969074604e-07.\n",
      "Epoch:18, weight train batch: 378, step:14, loss before: 5.73694364903e-07, loss after: 5.73694364903e-07.\n",
      "Epoch:18, weight train batch: 378, step:15, loss before: 6.63101275222e-07, loss after: 6.63101275222e-07.\n",
      "Epoch:18, weight train batch: 378, step:16, loss before: 5.73694364903e-07, loss after: 5.73694364903e-07.\n",
      "Epoch:18, weight train batch: 378, step:17, loss before: 8.41915039018e-07, loss after: 8.41915039018e-07.\n",
      "Epoch:18, weight train batch: 378, step:18, loss before: 2.89819377031e-06, loss after: 2.89446870738e-06.\n",
      "Epoch:18, weight train batch: 378, step:19, loss before: 1.03935178686e-06, loss after: 1.03935178686e-06.\n",
      "Epoch:18, weight train batch: 378, step:20, loss before: 4.17232342897e-07, loss after: 4.17232342897e-07.\n",
      "Epoch:18, weight train batch: 378, step:21, loss before: 5.47617332813e-07, loss after: 5.47617332813e-07.\n",
      "Epoch:18, weight train batch: 378, step:22, loss before: 5.47617389657e-07, loss after: 5.47617389657e-07.\n",
      "Epoch:18, weight train batch: 378, step:23, loss before: 6.74277089274e-07, loss after: 6.74277089274e-07.\n",
      "Epoch:18, weight train batch: 378, step:24, loss before: 0.000538533902727, loss after: 0.000536944658961.\n",
      "Epoch:18, weight train batch: 378, step:25, loss before: 4.54485189039e-07, loss after: 4.54485189039e-07.\n",
      "Epoch:18, weight train batch: 378, step:26, loss before: 6.59375814394e-07, loss after: 6.59375814394e-07.\n",
      "Epoch:18, weight train batch: 378, step:27, loss before: 0.000531416910235, loss after: 0.000527508789673.\n",
      "Epoch:18, weight train batch: 378, step:28, loss before: 4.20957604774e-07, loss after: 4.20957604774e-07.\n",
      "Epoch:18, weight train batch: 378, step:29, loss before: 6.81727669871e-07, loss after: 6.81727669871e-07.\n",
      "Epoch:18, weight train batch: 378, step:30, loss before: 5.47617332813e-07, loss after: 5.47617332813e-07.\n",
      "Epoch:18, weight train batch: 378, step:31, loss before: 6.78002379573e-07, loss after: 6.78002379573e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 374, loss before: 5.60655848858e-07, loss after: 5.60655848858e-07.\n",
      "Epoch:18, weight train batch: 379, step:0, loss before: 5.36441461918e-07, loss after: 4.95463325478e-07.\n",
      "Epoch:18, weight train batch: 379, step:1, loss before: 7.18980572856e-07, loss after: 7.18980572856e-07.\n",
      "Epoch:18, weight train batch: 379, step:2, loss before: 4.28408185371e-07, loss after: 4.28408185371e-07.\n",
      "Epoch:18, weight train batch: 379, step:3, loss before: 4.35858737546e-07, loss after: 4.35858737546e-07.\n",
      "Epoch:18, weight train batch: 379, step:4, loss before: 5.99771340148e-07, loss after: 5.99771340148e-07.\n",
      "Epoch:18, weight train batch: 379, step:5, loss before: 5.51342623112e-07, loss after: 5.51342623112e-07.\n",
      "Epoch:18, weight train batch: 379, step:6, loss before: 3.65078278719e-07, loss after: 3.65078278719e-07.\n",
      "Epoch:18, weight train batch: 379, step:7, loss before: 4.95463325478e-07, loss after: 4.95463325478e-07.\n",
      "Epoch:18, weight train batch: 379, step:8, loss before: 2.75290881291e-06, loss after: 2.75290881291e-06.\n",
      "Epoch:18, weight train batch: 379, step:9, loss before: 7.26431153453e-07, loss after: 7.26431153453e-07.\n",
      "Epoch:18, weight train batch: 379, step:10, loss before: 4.84287511426e-07, loss after: 4.84287511426e-07.\n",
      "Epoch:18, weight train batch: 379, step:11, loss before: 4.65661059934e-07, loss after: 4.65661059934e-07.\n",
      "Epoch:18, weight train batch: 379, step:12, loss before: 7.26431153453e-07, loss after: 7.26431153453e-07.\n",
      "Epoch:18, weight train batch: 379, step:13, loss before: 5.40166752216e-07, loss after: 5.40166752216e-07.\n",
      "Epoch:18, weight train batch: 379, step:14, loss before: 5.17815067269e-07, loss after: 5.17815067269e-07.\n",
      "Epoch:18, weight train batch: 379, step:15, loss before: 3.61352988421e-07, loss after: 3.61352988421e-07.\n",
      "Epoch:18, weight train batch: 379, step:16, loss before: 6.78002379573e-07, loss after: 6.78002379573e-07.\n",
      "Epoch:18, weight train batch: 379, step:17, loss before: 7.52508071855e-07, loss after: 7.52508071855e-07.\n",
      "Epoch:18, weight train batch: 379, step:18, loss before: 4.61935712792e-07, loss after: 4.61935712792e-07.\n",
      "Epoch:18, weight train batch: 379, step:19, loss before: 6.48200057185e-07, loss after: 6.48200057185e-07.\n",
      "Epoch:18, weight train batch: 379, step:20, loss before: 4.58210479337e-07, loss after: 4.58210479337e-07.\n",
      "Epoch:18, weight train batch: 379, step:21, loss before: 7.04079411662e-07, loss after: 7.04079411662e-07.\n",
      "Epoch:18, weight train batch: 379, step:22, loss before: 3.79979439913e-07, loss after: 3.79979439913e-07.\n",
      "Epoch:18, weight train batch: 379, step:23, loss before: 5.06639253217e-07, loss after: 5.06639253217e-07.\n",
      "Epoch:18, weight train batch: 379, step:24, loss before: 3.50177117525e-07, loss after: 3.50177117525e-07.\n",
      "Epoch:18, weight train batch: 379, step:25, loss before: 6.40749476588e-07, loss after: 6.40749476588e-07.\n",
      "Epoch:18, weight train batch: 379, step:26, loss before: 4.84287511426e-07, loss after: 4.84287511426e-07.\n",
      "Epoch:18, weight train batch: 379, step:27, loss before: 1.80674453532e-06, loss after: 1.80674453532e-06.\n",
      "Epoch:18, weight train batch: 379, step:28, loss before: 4.5075989874e-07, loss after: 4.5075989874e-07.\n",
      "Epoch:18, weight train batch: 379, step:29, loss before: 7.48782724713e-07, loss after: 7.48782724713e-07.\n",
      "Epoch:18, weight train batch: 379, step:30, loss before: 7.59958709295e-07, loss after: 7.59958709295e-07.\n",
      "Epoch:18, weight train batch: 379, step:31, loss before: 5.3271617162e-07, loss after: 5.3271617162e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:18, struct parameters train batch: 375, loss before: 5.38304107067e-07, loss after: 5.38304107067e-07.\n",
      "Epoch:19, weight train batch: 380, step:0, loss before: 2.73055957223e-06, loss after: 2.73055957223e-06.\n",
      "Epoch:19, weight train batch: 380, step:1, loss before: 5.58793203709e-07, loss after: 5.58793203709e-07.\n",
      "Epoch:19, weight train batch: 380, step:2, loss before: 4.69386321811e-07, loss after: 4.69386321811e-07.\n",
      "Epoch:19, weight train batch: 380, step:3, loss before: 4.76836902408e-07, loss after: 4.76836902408e-07.\n",
      "Epoch:19, weight train batch: 380, step:4, loss before: 3.24100113858e-07, loss after: 3.24100113858e-07.\n",
      "Epoch:19, weight train batch: 380, step:5, loss before: 4.61935741214e-07, loss after: 4.61935741214e-07.\n",
      "Epoch:19, weight train batch: 380, step:6, loss before: 7.26431153453e-07, loss after: 7.26431153453e-07.\n",
      "Epoch:19, weight train batch: 380, step:7, loss before: 3.79979439913e-07, loss after: 3.79979439913e-07.\n",
      "Epoch:19, weight train batch: 380, step:8, loss before: 4.84287511426e-07, loss after: 4.84287511426e-07.\n",
      "Epoch:19, weight train batch: 380, step:9, loss before: 7.26431153453e-07, loss after: 7.26431153453e-07.\n",
      "Epoch:19, weight train batch: 380, step:10, loss before: 6.0349668729e-07, loss after: 6.0349668729e-07.\n",
      "Epoch:19, weight train batch: 380, step:11, loss before: 7.93486265138e-07, loss after: 7.93486265138e-07.\n",
      "Epoch:19, weight train batch: 380, step:12, loss before: 4.69386293389e-07, loss after: 4.69386293389e-07.\n",
      "Epoch:19, weight train batch: 380, step:13, loss before: 5.811449455e-07, loss after: 5.811449455e-07.\n",
      "Epoch:19, weight train batch: 380, step:14, loss before: 5.811449455e-07, loss after: 5.811449455e-07.\n",
      "Epoch:19, weight train batch: 380, step:15, loss before: 7.37606910661e-07, loss after: 7.37606910661e-07.\n",
      "Epoch:19, weight train batch: 380, step:16, loss before: 8.00936845735e-07, loss after: 8.00936845735e-07.\n",
      "Epoch:19, weight train batch: 380, step:17, loss before: 4.20957576353e-07, loss after: 4.20957576353e-07.\n",
      "Epoch:19, weight train batch: 380, step:18, loss before: 6.55650637782e-07, loss after: 6.55650637782e-07.\n",
      "Epoch:19, weight train batch: 380, step:19, loss before: 3.8743002051e-07, loss after: 3.8743002051e-07.\n",
      "Epoch:19, weight train batch: 380, step:20, loss before: 4.84287511426e-07, loss after: 4.84287511426e-07.\n",
      "Epoch:19, weight train batch: 380, step:21, loss before: 6.66826508677e-07, loss after: 6.66826508677e-07.\n",
      "Epoch:19, weight train batch: 380, step:22, loss before: 6.22123138783e-07, loss after: 6.22123138783e-07.\n",
      "Epoch:19, weight train batch: 380, step:23, loss before: 6.70551855819e-07, loss after: 6.70551855819e-07.\n",
      "Epoch:19, weight train batch: 380, step:24, loss before: 7.67409233049e-07, loss after: 7.67409233049e-07.\n",
      "Epoch:19, weight train batch: 380, step:25, loss before: 6.63101218379e-07, loss after: 6.63101218379e-07.\n",
      "Epoch:19, weight train batch: 380, step:26, loss before: 6.07221920745e-07, loss after: 6.07221920745e-07.\n",
      "Epoch:19, weight train batch: 380, step:27, loss before: 4.17232314476e-07, loss after: 4.17232314476e-07.\n",
      "Epoch:19, weight train batch: 380, step:28, loss before: 5.10364429829e-07, loss after: 5.10364429829e-07.\n",
      "Epoch:19, weight train batch: 380, step:29, loss before: 1.91850313058e-06, loss after: 1.91477784028e-06.\n",
      "Epoch:19, weight train batch: 380, step:30, loss before: 8.49365562772e-07, loss after: 8.49365562772e-07.\n",
      "Epoch:19, weight train batch: 380, step:31, loss before: 5.17815010426e-07, loss after: 5.17815010426e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 376, loss before: 1.21591674542e-05, loss after: 6.09084509051e-07.\n",
      "Epoch:19, weight train batch: 381, step:0, loss before: 5.17815010426e-07, loss after: 5.17815010426e-07.\n",
      "Epoch:19, weight train batch: 381, step:1, loss before: 4.69386321811e-07, loss after: 4.69386321811e-07.\n",
      "Epoch:19, weight train batch: 381, step:2, loss before: 7.38278777135e-06, loss after: 7.36044148653e-06.\n",
      "Epoch:19, weight train batch: 381, step:3, loss before: 4.28408156949e-07, loss after: 4.28408156949e-07.\n",
      "Epoch:19, weight train batch: 381, step:4, loss before: 2.65605604e-06, loss after: 2.65605604e-06.\n",
      "Epoch:19, weight train batch: 381, step:5, loss before: 5.10364486672e-07, loss after: 5.10364486672e-07.\n",
      "Epoch:19, weight train batch: 381, step:6, loss before: 5.88595526096e-07, loss after: 5.88595526096e-07.\n",
      "Epoch:19, weight train batch: 381, step:7, loss before: 5.51342623112e-07, loss after: 5.51342623112e-07.\n",
      "Epoch:19, weight train batch: 381, step:8, loss before: 2.42511282522e-06, loss after: 2.42511282522e-06.\n",
      "Epoch:19, weight train batch: 381, step:9, loss before: 5.73694364903e-07, loss after: 5.73694364903e-07.\n",
      "Epoch:19, weight train batch: 381, step:10, loss before: 4.69386350233e-07, loss after: 4.69386350233e-07.\n",
      "Epoch:19, weight train batch: 381, step:11, loss before: 5.51342623112e-07, loss after: 5.51342623112e-07.\n",
      "Epoch:19, weight train batch: 381, step:12, loss before: 6.48200057185e-07, loss after: 6.48200057185e-07.\n",
      "Epoch:19, weight train batch: 381, step:13, loss before: 4.76836873986e-07, loss after: 4.76836873986e-07.\n",
      "Epoch:19, weight train batch: 381, step:14, loss before: 7.78585103944e-07, loss after: 7.78585103944e-07.\n",
      "Epoch:19, weight train batch: 381, step:15, loss before: 6.37024243133e-07, loss after: 6.37024243133e-07.\n",
      "Epoch:19, weight train batch: 381, step:16, loss before: 5.58793203709e-07, loss after: 5.58793203709e-07.\n",
      "Epoch:19, weight train batch: 381, step:17, loss before: 4.95463325478e-07, loss after: 4.95463325478e-07.\n",
      "Epoch:19, weight train batch: 381, step:18, loss before: 7.18980572856e-07, loss after: 7.18980572856e-07.\n",
      "Epoch:19, weight train batch: 381, step:19, loss before: 5.25265591023e-07, loss after: 5.25265591023e-07.\n",
      "Epoch:19, weight train batch: 381, step:20, loss before: 7.37606967505e-07, loss after: 7.37606967505e-07.\n",
      "Epoch:19, weight train batch: 381, step:21, loss before: 5.99771340148e-07, loss after: 5.99771340148e-07.\n",
      "Epoch:19, weight train batch: 381, step:22, loss before: 5.02913849232e-07, loss after: 5.02913849232e-07.\n",
      "Epoch:19, weight train batch: 381, step:23, loss before: 4.95463268635e-07, loss after: 4.95463268635e-07.\n",
      "Epoch:19, weight train batch: 381, step:24, loss before: 4.20957576353e-07, loss after: 4.20957576353e-07.\n",
      "Epoch:19, weight train batch: 381, step:25, loss before: 5.14089776971e-07, loss after: 5.14089776971e-07.\n",
      "Epoch:19, weight train batch: 381, step:26, loss before: 5.02913849232e-07, loss after: 5.02913849232e-07.\n",
      "Epoch:19, weight train batch: 381, step:27, loss before: 4.84287511426e-07, loss after: 4.84287511426e-07.\n",
      "Epoch:19, weight train batch: 381, step:28, loss before: 0.000479926675325, loss after: 0.00047862061183.\n",
      "Epoch:19, weight train batch: 381, step:29, loss before: 5.51342623112e-07, loss after: 5.51342623112e-07.\n",
      "Epoch:19, weight train batch: 381, step:30, loss before: 6.33298782304e-07, loss after: 6.33298782304e-07.\n",
      "Epoch:19, weight train batch: 381, step:31, loss before: 6.2957371938e-07, loss after: 6.2957371938e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 377, loss before: 5.52273888843e-07, loss after: 5.52273888843e-07.\n",
      "Epoch:19, weight train batch: 382, step:0, loss before: 4.69118385809e-05, loss after: 4.69527585665e-05.\n",
      "Epoch:19, weight train batch: 382, step:1, loss before: 1.39074109029e-05, loss after: 1.38366604006e-05.\n",
      "Epoch:19, weight train batch: 382, step:2, loss before: 5.10364486672e-07, loss after: 5.10364486672e-07.\n",
      "Epoch:19, weight train batch: 382, step:3, loss before: 2.55922418546e-06, loss after: 2.55922418546e-06.\n",
      "Epoch:19, weight train batch: 382, step:4, loss before: 6.14672501342e-07, loss after: 6.14672501342e-07.\n",
      "Epoch:19, weight train batch: 382, step:5, loss before: 5.4016680906e-07, loss after: 5.4016680906e-07.\n",
      "Epoch:19, weight train batch: 382, step:6, loss before: 5.811449455e-07, loss after: 5.811449455e-07.\n",
      "Epoch:19, weight train batch: 382, step:7, loss before: 7.04079411662e-07, loss after: 7.04079411662e-07.\n",
      "Epoch:19, weight train batch: 382, step:8, loss before: 6.96628831065e-07, loss after: 6.96628831065e-07.\n",
      "Epoch:19, weight train batch: 382, step:9, loss before: 5.14089833814e-07, loss after: 5.14089833814e-07.\n",
      "Epoch:19, weight train batch: 382, step:10, loss before: 4.76836902408e-07, loss after: 4.76836902408e-07.\n",
      "Epoch:19, weight train batch: 382, step:11, loss before: 3.8743002051e-07, loss after: 3.8743002051e-07.\n",
      "Epoch:19, weight train batch: 382, step:12, loss before: 3.94880601107e-07, loss after: 3.94880601107e-07.\n",
      "Epoch:19, weight train batch: 382, step:13, loss before: 4.43309318143e-07, loss after: 4.43309318143e-07.\n",
      "Epoch:19, weight train batch: 382, step:14, loss before: 3.8743002051e-07, loss after: 3.8743002051e-07.\n",
      "Epoch:19, weight train batch: 382, step:15, loss before: 6.55650637782e-07, loss after: 6.55650637782e-07.\n",
      "Epoch:19, weight train batch: 382, step:16, loss before: 5.51342623112e-07, loss after: 5.51342623112e-07.\n",
      "Epoch:19, weight train batch: 382, step:17, loss before: 6.37024243133e-07, loss after: 6.37024243133e-07.\n",
      "Epoch:19, weight train batch: 382, step:18, loss before: 6.63101218379e-07, loss after: 6.63101218379e-07.\n",
      "Epoch:19, weight train batch: 382, step:19, loss before: 5.25265591023e-07, loss after: 5.25265591023e-07.\n",
      "Epoch:19, weight train batch: 382, step:20, loss before: 5.4016680906e-07, loss after: 5.4016680906e-07.\n",
      "Epoch:19, weight train batch: 382, step:21, loss before: 7.26431153453e-07, loss after: 7.26431153453e-07.\n",
      "Epoch:19, weight train batch: 382, step:22, loss before: 4.43309318143e-07, loss after: 4.43309318143e-07.\n",
      "Epoch:19, weight train batch: 382, step:23, loss before: 4.20957576353e-07, loss after: 4.20957576353e-07.\n",
      "Epoch:19, weight train batch: 382, step:24, loss before: 5.3271617162e-07, loss after: 5.3271617162e-07.\n",
      "Epoch:19, weight train batch: 382, step:25, loss before: 3.24100142279e-07, loss after: 3.24100142279e-07.\n",
      "Epoch:19, weight train batch: 382, step:26, loss before: 0.0216613560915, loss after: 0.0216613560915.\n",
      "Epoch:19, weight train batch: 382, step:27, loss before: 4.91738092023e-07, loss after: 4.91738092023e-07.\n",
      "Epoch:19, weight train batch: 382, step:28, loss before: 6.8545296017e-07, loss after: 6.8545296017e-07.\n",
      "Epoch:19, weight train batch: 382, step:29, loss before: 5.66243784306e-07, loss after: 5.66243784306e-07.\n",
      "Epoch:19, weight train batch: 382, step:30, loss before: 5.66243784306e-07, loss after: 5.66243784306e-07.\n",
      "Epoch:19, weight train batch: 382, step:31, loss before: 4.88012744881e-07, loss after: 4.88012744881e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 378, loss before: 5.21540300724e-07, loss after: 5.40166752216e-07.\n",
      "Epoch:19, weight train batch: 383, step:0, loss before: 3.31550694455e-07, loss after: 3.31550694455e-07.\n",
      "Epoch:19, weight train batch: 383, step:1, loss before: 5.3271617162e-07, loss after: 5.3271617162e-07.\n",
      "Epoch:19, weight train batch: 383, step:2, loss before: 2.62253138317e-06, loss after: 2.59645457845e-06.\n",
      "Epoch:19, weight train batch: 383, step:3, loss before: 5.51342623112e-07, loss after: 5.51342623112e-07.\n",
      "Epoch:19, weight train batch: 383, step:4, loss before: 3.20374823559e-07, loss after: 3.20374823559e-07.\n",
      "Epoch:19, weight train batch: 383, step:5, loss before: 2.10848156712e-06, loss after: 2.10848156712e-06.\n",
      "Epoch:19, weight train batch: 383, step:6, loss before: 5.88595526096e-07, loss after: 5.88595526096e-07.\n",
      "Epoch:19, weight train batch: 383, step:7, loss before: 6.40749476588e-07, loss after: 6.40749476588e-07.\n",
      "Epoch:19, weight train batch: 383, step:8, loss before: 5.14089720127e-07, loss after: 5.14089720127e-07.\n",
      "Epoch:19, weight train batch: 383, step:9, loss before: 4.39584027845e-07, loss after: 4.39584027845e-07.\n",
      "Epoch:19, weight train batch: 383, step:10, loss before: 5.66243784306e-07, loss after: 5.66243784306e-07.\n",
      "Epoch:19, weight train batch: 383, step:11, loss before: 5.14089720127e-07, loss after: 5.14089720127e-07.\n",
      "Epoch:19, weight train batch: 383, step:12, loss before: 3.27825404156e-07, loss after: 3.27825404156e-07.\n",
      "Epoch:19, weight train batch: 383, step:13, loss before: 4.17232286054e-07, loss after: 4.17232286054e-07.\n",
      "Epoch:19, weight train batch: 383, step:14, loss before: 4.24682866651e-07, loss after: 4.24682866651e-07.\n",
      "Epoch:19, weight train batch: 383, step:15, loss before: 4.64318109152e-05, loss after: 4.63871729153e-05.\n",
      "Epoch:19, weight train batch: 383, step:16, loss before: 5.58793203709e-07, loss after: 5.58793203709e-07.\n",
      "Epoch:19, weight train batch: 383, step:17, loss before: 4.32133418826e-07, loss after: 4.32133418826e-07.\n",
      "Epoch:19, weight train batch: 383, step:18, loss before: 0.000162133947015, loss after: 0.000161618794664.\n",
      "Epoch:19, weight train batch: 383, step:19, loss before: 5.9604604985e-07, loss after: 5.9604604985e-07.\n",
      "Epoch:19, weight train batch: 383, step:20, loss before: 5.43892042515e-07, loss after: 5.43892042515e-07.\n",
      "Epoch:19, weight train batch: 383, step:21, loss before: 5.28990881321e-07, loss after: 5.28990881321e-07.\n",
      "Epoch:19, weight train batch: 383, step:22, loss before: 6.33298952835e-07, loss after: 6.33298952835e-07.\n",
      "Epoch:19, weight train batch: 383, step:23, loss before: 5.28990881321e-07, loss after: 5.28990881321e-07.\n",
      "Epoch:19, weight train batch: 383, step:24, loss before: 6.78002379573e-07, loss after: 6.78002379573e-07.\n",
      "Epoch:19, weight train batch: 383, step:25, loss before: 4.76836845564e-07, loss after: 4.76836845564e-07.\n",
      "Epoch:19, weight train batch: 383, step:26, loss before: 5.73694308059e-07, loss after: 5.73694308059e-07.\n",
      "Epoch:19, weight train batch: 383, step:27, loss before: 6.22123081939e-07, loss after: 6.22123081939e-07.\n",
      "Epoch:19, weight train batch: 383, step:28, loss before: 6.44474596356e-07, loss after: 6.44474596356e-07.\n",
      "Epoch:19, weight train batch: 383, step:29, loss before: 6.40749533432e-07, loss after: 6.40749533432e-07.\n",
      "Epoch:19, weight train batch: 383, step:30, loss before: 6.78002379573e-07, loss after: 6.78002379573e-07.\n",
      "Epoch:19, weight train batch: 383, step:31, loss before: 6.109471542e-07, loss after: 6.109471542e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 379, loss before: 9.72287466539e-07, loss after: 1.04865114281e-06.\n",
      "Epoch:19, weight train batch: 384, step:0, loss before: 7.52508071855e-07, loss after: 7.52508071855e-07.\n",
      "Epoch:19, weight train batch: 384, step:1, loss before: 4.4703458002e-07, loss after: 4.4703458002e-07.\n",
      "Epoch:19, weight train batch: 384, step:2, loss before: 5.28990881321e-07, loss after: 5.28990881321e-07.\n",
      "Epoch:19, weight train batch: 384, step:3, loss before: 7.93485980921e-07, loss after: 7.93485980921e-07.\n",
      "Epoch:19, weight train batch: 384, step:4, loss before: 2.12710847336e-06, loss after: 2.12710847336e-06.\n",
      "Epoch:19, weight train batch: 384, step:5, loss before: 5.36441461918e-07, loss after: 5.36441461918e-07.\n",
      "Epoch:19, weight train batch: 384, step:6, loss before: 5.21540357568e-07, loss after: 5.21540357568e-07.\n",
      "Epoch:19, weight train batch: 384, step:7, loss before: 7.27116821508e-06, loss after: 7.25627023712e-06.\n",
      "Epoch:19, weight train batch: 384, step:8, loss before: 4.09781677035e-07, loss after: 4.09781677035e-07.\n",
      "Epoch:19, weight train batch: 384, step:9, loss before: 4.99188615777e-07, loss after: 4.99188615777e-07.\n",
      "Epoch:19, weight train batch: 384, step:10, loss before: 6.33298895991e-07, loss after: 6.33298895991e-07.\n",
      "Epoch:19, weight train batch: 384, step:11, loss before: 3.8743002051e-07, loss after: 3.8743002051e-07.\n",
      "Epoch:19, weight train batch: 384, step:12, loss before: 6.10947211044e-07, loss after: 6.10947211044e-07.\n",
      "Epoch:19, weight train batch: 384, step:13, loss before: 5.51342623112e-07, loss after: 5.51342623112e-07.\n",
      "Epoch:19, weight train batch: 384, step:14, loss before: 6.92903483923e-07, loss after: 6.92903483923e-07.\n",
      "Epoch:19, weight train batch: 384, step:15, loss before: 4.09781705457e-07, loss after: 4.09781705457e-07.\n",
      "Epoch:19, weight train batch: 384, step:16, loss before: 4.09781705457e-07, loss after: 4.09781705457e-07.\n",
      "Epoch:19, weight train batch: 384, step:17, loss before: 6.92903540767e-07, loss after: 6.92903540767e-07.\n",
      "Epoch:19, weight train batch: 384, step:18, loss before: 6.31753664493e-06, loss after: 6.29146461506e-06.\n",
      "Epoch:19, weight train batch: 384, step:19, loss before: 6.0349668729e-07, loss after: 6.0349668729e-07.\n",
      "Epoch:19, weight train batch: 384, step:20, loss before: 6.14672501342e-07, loss after: 6.14672501342e-07.\n",
      "Epoch:19, weight train batch: 384, step:21, loss before: 4.17232286054e-07, loss after: 4.17232286054e-07.\n",
      "Epoch:19, weight train batch: 384, step:22, loss before: 6.70551798976e-07, loss after: 6.70551798976e-07.\n",
      "Epoch:19, weight train batch: 384, step:23, loss before: 2.90572501171e-07, loss after: 2.90572501171e-07.\n",
      "Epoch:19, weight train batch: 384, step:24, loss before: 5.28990881321e-07, loss after: 5.28990881321e-07.\n",
      "Epoch:19, weight train batch: 384, step:25, loss before: 6.03496630447e-07, loss after: 6.03496630447e-07.\n",
      "Epoch:19, weight train batch: 384, step:26, loss before: 7.00354121363e-07, loss after: 7.00354121363e-07.\n",
      "Epoch:19, weight train batch: 384, step:27, loss before: 4.99188615777e-07, loss after: 4.99188615777e-07.\n",
      "Epoch:19, weight train batch: 384, step:28, loss before: 3.87429963666e-07, loss after: 3.87429963666e-07.\n",
      "Epoch:19, weight train batch: 384, step:29, loss before: 5.58793203709e-07, loss after: 5.58793203709e-07.\n",
      "Epoch:19, weight train batch: 384, step:30, loss before: 6.70551798976e-07, loss after: 6.70551798976e-07.\n",
      "Epoch:19, weight train batch: 384, step:31, loss before: 5.5506791341e-07, loss after: 5.5506791341e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 380, loss before: 0.000114171474706, loss after: 9.45279111875e-07.\n",
      "Epoch:19, weight train batch: 385, step:0, loss before: 4.0233112486e-07, loss after: 4.0233112486e-07.\n",
      "Epoch:19, weight train batch: 385, step:1, loss before: 5.21540300724e-07, loss after: 5.21540300724e-07.\n",
      "Epoch:19, weight train batch: 385, step:2, loss before: 5.3271617162e-07, loss after: 5.3271617162e-07.\n",
      "Epoch:19, weight train batch: 385, step:3, loss before: 2.04887805921e-06, loss after: 2.04887805921e-06.\n",
      "Epoch:19, weight train batch: 385, step:4, loss before: 2.26119914259e-06, loss after: 2.26119914259e-06.\n",
      "Epoch:19, weight train batch: 385, step:5, loss before: 6.10947267887e-07, loss after: 6.10947267887e-07.\n",
      "Epoch:19, weight train batch: 385, step:6, loss before: 4.76836902408e-07, loss after: 4.76836902408e-07.\n",
      "Epoch:19, weight train batch: 385, step:7, loss before: 5.14089776971e-07, loss after: 5.14089776971e-07.\n",
      "Epoch:19, weight train batch: 385, step:8, loss before: 7.0780470196e-07, loss after: 7.0780470196e-07.\n",
      "Epoch:19, weight train batch: 385, step:9, loss before: 1.62793401159e-06, loss after: 1.62420883498e-06.\n",
      "Epoch:19, weight train batch: 385, step:10, loss before: 4.4703458002e-07, loss after: 4.4703458002e-07.\n",
      "Epoch:19, weight train batch: 385, step:11, loss before: 5.66243727462e-07, loss after: 5.66243727462e-07.\n",
      "Epoch:19, weight train batch: 385, step:12, loss before: 5.811449455e-07, loss after: 5.811449455e-07.\n",
      "Epoch:19, weight train batch: 385, step:13, loss before: 5.06639196374e-07, loss after: 5.06639196374e-07.\n",
      "Epoch:19, weight train batch: 385, step:14, loss before: 4.76836845564e-07, loss after: 4.76836845564e-07.\n",
      "Epoch:19, weight train batch: 385, step:15, loss before: 4.69386264967e-07, loss after: 4.69386264967e-07.\n",
      "Epoch:19, weight train batch: 385, step:16, loss before: 0.000456766574644, loss after: 0.000455514586065.\n",
      "Epoch:19, weight train batch: 385, step:17, loss before: 4.69386293389e-07, loss after: 4.69386293389e-07.\n",
      "Epoch:19, weight train batch: 385, step:18, loss before: 6.78002379573e-07, loss after: 6.78002379573e-07.\n",
      "Epoch:19, weight train batch: 385, step:19, loss before: 5.0663913953e-07, loss after: 5.0663913953e-07.\n",
      "Epoch:19, weight train batch: 385, step:20, loss before: 4.84287454583e-07, loss after: 4.84287454583e-07.\n",
      "Epoch:19, weight train batch: 385, step:21, loss before: 4.4703458002e-07, loss after: 4.4703458002e-07.\n",
      "Epoch:19, weight train batch: 385, step:22, loss before: 5.28990881321e-07, loss after: 5.28990881321e-07.\n",
      "Epoch:19, weight train batch: 385, step:23, loss before: 8.04660317044e-07, loss after: 8.00935026746e-07.\n",
      "Epoch:19, weight train batch: 385, step:24, loss before: 5.43892042515e-07, loss after: 5.43892042515e-07.\n",
      "Epoch:19, weight train batch: 385, step:25, loss before: 4.60784467577e-05, loss after: 4.60784467577e-05.\n",
      "Epoch:19, weight train batch: 385, step:26, loss before: 8.41915039018e-07, loss after: 8.41915039018e-07.\n",
      "Epoch:19, weight train batch: 385, step:27, loss before: 5.66243727462e-07, loss after: 5.66243727462e-07.\n",
      "Epoch:19, weight train batch: 385, step:28, loss before: 4.433092613e-07, loss after: 4.433092613e-07.\n",
      "Epoch:19, weight train batch: 385, step:29, loss before: 5.0663913953e-07, loss after: 5.0663913953e-07.\n",
      "Epoch:19, weight train batch: 385, step:30, loss before: 6.70551798976e-07, loss after: 6.70551798976e-07.\n",
      "Epoch:19, weight train batch: 385, step:31, loss before: 5.21540300724e-07, loss after: 5.21540300724e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 381, loss before: 7.93788240117e-06, loss after: 5.59724526283e-07.\n",
      "Epoch:19, weight train batch: 386, step:0, loss before: 4.9173803518e-07, loss after: 4.9173803518e-07.\n",
      "Epoch:19, weight train batch: 386, step:1, loss before: 2.55175450548e-06, loss after: 2.54802921518e-06.\n",
      "Epoch:19, weight train batch: 386, step:2, loss before: 6.25848372238e-07, loss after: 6.25848372238e-07.\n",
      "Epoch:19, weight train batch: 386, step:3, loss before: 6.29573662536e-07, loss after: 6.29573662536e-07.\n",
      "Epoch:19, weight train batch: 386, step:4, loss before: 4.09781705457e-07, loss after: 4.09781705457e-07.\n",
      "Epoch:19, weight train batch: 386, step:5, loss before: 7.07804645117e-07, loss after: 7.07804645117e-07.\n",
      "Epoch:19, weight train batch: 386, step:6, loss before: 4.84287454583e-07, loss after: 4.84287454583e-07.\n",
      "Epoch:19, weight train batch: 386, step:7, loss before: 4.58330650872e-05, loss after: 4.57437345176e-05.\n",
      "Epoch:19, weight train batch: 386, step:8, loss before: 4.06056472002e-07, loss after: 4.06056472002e-07.\n",
      "Epoch:19, weight train batch: 386, step:9, loss before: 5.40166752216e-07, loss after: 5.40166752216e-07.\n",
      "Epoch:19, weight train batch: 386, step:10, loss before: 4.99188615777e-07, loss after: 4.99188615777e-07.\n",
      "Epoch:19, weight train batch: 386, step:11, loss before: 5.17815010426e-07, loss after: 5.17815010426e-07.\n",
      "Epoch:19, weight train batch: 386, step:12, loss before: 6.51925006423e-07, loss after: 6.51925006423e-07.\n",
      "Epoch:19, weight train batch: 386, step:13, loss before: 4.99188615777e-07, loss after: 4.99188615777e-07.\n",
      "Epoch:19, weight train batch: 386, step:14, loss before: 4.5293574658e-05, loss after: 4.52042986581e-05.\n",
      "Epoch:19, weight train batch: 386, step:15, loss before: 4.9173803518e-07, loss after: 4.9173803518e-07.\n",
      "Epoch:19, weight train batch: 386, step:16, loss before: 5.811449455e-07, loss after: 5.811449455e-07.\n",
      "Epoch:19, weight train batch: 386, step:17, loss before: 4.88012801725e-07, loss after: 4.88012801725e-07.\n",
      "Epoch:19, weight train batch: 386, step:18, loss before: 4.28408185371e-07, loss after: 4.28408185371e-07.\n",
      "Epoch:19, weight train batch: 386, step:19, loss before: 5.47617332813e-07, loss after: 5.47617332813e-07.\n",
      "Epoch:19, weight train batch: 386, step:20, loss before: 4.65661059934e-07, loss after: 4.65661059934e-07.\n",
      "Epoch:19, weight train batch: 386, step:21, loss before: 5.06639196374e-07, loss after: 5.06639196374e-07.\n",
      "Epoch:19, weight train batch: 386, step:22, loss before: 7.37607024348e-07, loss after: 7.37607024348e-07.\n",
      "Epoch:19, weight train batch: 386, step:23, loss before: 4.9173803518e-07, loss after: 4.9173803518e-07.\n",
      "Epoch:19, weight train batch: 386, step:24, loss before: 4.24682866651e-07, loss after: 4.24682866651e-07.\n",
      "Epoch:19, weight train batch: 386, step:25, loss before: 5.06639196374e-07, loss after: 5.06639196374e-07.\n",
      "Epoch:19, weight train batch: 386, step:26, loss before: 4.09781705457e-07, loss after: 4.09781705457e-07.\n",
      "Epoch:19, weight train batch: 386, step:27, loss before: 4.73111640531e-07, loss after: 4.73111640531e-07.\n",
      "Epoch:19, weight train batch: 386, step:28, loss before: 5.96046106693e-07, loss after: 5.96046106693e-07.\n",
      "Epoch:19, weight train batch: 386, step:29, loss before: 4.88012801725e-07, loss after: 4.88012801725e-07.\n",
      "Epoch:19, weight train batch: 386, step:30, loss before: 6.14672558186e-07, loss after: 6.14672558186e-07.\n",
      "Epoch:19, weight train batch: 386, step:31, loss before: 6.22123138783e-07, loss after: 6.22123138783e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 382, loss before: 5.00119938351e-07, loss after: 4.97325970628e-07.\n",
      "Epoch:19, weight train batch: 387, step:0, loss before: 5.99771396992e-07, loss after: 5.99771396992e-07.\n",
      "Epoch:19, weight train batch: 387, step:1, loss before: 5.92320816395e-07, loss after: 5.92320816395e-07.\n",
      "Epoch:19, weight train batch: 387, step:2, loss before: 6.10947267887e-07, loss after: 6.10947267887e-07.\n",
      "Epoch:19, weight train batch: 387, step:3, loss before: 4.84287454583e-07, loss after: 4.84287454583e-07.\n",
      "Epoch:19, weight train batch: 387, step:4, loss before: 6.0349668729e-07, loss after: 6.0349668729e-07.\n",
      "Epoch:19, weight train batch: 387, step:5, loss before: 2.17179467654e-06, loss after: 2.17179467654e-06.\n",
      "Epoch:19, weight train batch: 387, step:6, loss before: 5.69969074604e-07, loss after: 5.69969074604e-07.\n",
      "Epoch:19, weight train batch: 387, step:7, loss before: 7.04079411662e-07, loss after: 7.04079411662e-07.\n",
      "Epoch:19, weight train batch: 387, step:8, loss before: 5.73694364903e-07, loss after: 5.73694364903e-07.\n",
      "Epoch:19, weight train batch: 387, step:9, loss before: 0.000152103515575, loss after: 0.000151599335368.\n",
      "Epoch:19, weight train batch: 387, step:10, loss before: 3.57627698122e-07, loss after: 3.57627698122e-07.\n",
      "Epoch:19, weight train batch: 387, step:11, loss before: 4.39584027845e-07, loss after: 4.39584027845e-07.\n",
      "Epoch:19, weight train batch: 387, step:12, loss before: 4.0605644358e-07, loss after: 4.0605644358e-07.\n",
      "Epoch:19, weight train batch: 387, step:13, loss before: 4.88012801725e-07, loss after: 4.88012801725e-07.\n",
      "Epoch:19, weight train batch: 387, step:14, loss before: 4.32133447248e-07, loss after: 4.32133447248e-07.\n",
      "Epoch:19, weight train batch: 387, step:15, loss before: 6.40749362901e-07, loss after: 6.40749362901e-07.\n",
      "Epoch:19, weight train batch: 387, step:16, loss before: 5.811449455e-07, loss after: 5.811449455e-07.\n",
      "Epoch:19, weight train batch: 387, step:17, loss before: 7.78585160788e-07, loss after: 7.78585160788e-07.\n",
      "Epoch:19, weight train batch: 387, step:18, loss before: 3.83704730211e-07, loss after: 3.83704730211e-07.\n",
      "Epoch:19, weight train batch: 387, step:19, loss before: 4.9173803518e-07, loss after: 4.9173803518e-07.\n",
      "Epoch:19, weight train batch: 387, step:20, loss before: 5.21540357568e-07, loss after: 5.21540357568e-07.\n",
      "Epoch:19, weight train batch: 387, step:21, loss before: 4.80562221128e-07, loss after: 4.80562221128e-07.\n",
      "Epoch:19, weight train batch: 387, step:22, loss before: 6.55650694625e-07, loss after: 6.55650694625e-07.\n",
      "Epoch:19, weight train batch: 387, step:23, loss before: 4.9173803518e-07, loss after: 4.9173803518e-07.\n",
      "Epoch:19, weight train batch: 387, step:24, loss before: 7.11529992259e-07, loss after: 7.11529992259e-07.\n",
      "Epoch:19, weight train batch: 387, step:25, loss before: 5.96046106693e-07, loss after: 5.96046106693e-07.\n",
      "Epoch:19, weight train batch: 387, step:26, loss before: 3.01748400489e-07, loss after: 3.01748400489e-07.\n",
      "Epoch:19, weight train batch: 387, step:27, loss before: 6.44474880573e-07, loss after: 6.44474880573e-07.\n",
      "Epoch:19, weight train batch: 387, step:28, loss before: 6.37024299976e-07, loss after: 6.37024299976e-07.\n",
      "Epoch:19, weight train batch: 387, step:29, loss before: 4.17232286054e-07, loss after: 4.17232286054e-07.\n",
      "Epoch:19, weight train batch: 387, step:30, loss before: 3.72528859316e-07, loss after: 3.72528859316e-07.\n",
      "Epoch:19, weight train batch: 387, step:31, loss before: 3.35275984753e-07, loss after: 3.35275984753e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 383, loss before: 8.27006999771e-07, loss after: 0.00541569665074.\n",
      "Epoch:19, weight train batch: 388, step:0, loss before: 4.39584027845e-07, loss after: 4.39584027845e-07.\n",
      "Epoch:19, weight train batch: 388, step:1, loss before: 5.47617332813e-07, loss after: 5.47617332813e-07.\n",
      "Epoch:19, weight train batch: 388, step:2, loss before: 4.61935769636e-07, loss after: 4.61935769636e-07.\n",
      "Epoch:19, weight train batch: 388, step:3, loss before: 6.78002436416e-07, loss after: 6.33299009678e-07.\n",
      "Epoch:19, weight train batch: 388, step:4, loss before: 3.8743002051e-07, loss after: 3.8743002051e-07.\n",
      "Epoch:19, weight train batch: 388, step:5, loss before: 5.10364486672e-07, loss after: 5.10364486672e-07.\n",
      "Epoch:19, weight train batch: 388, step:6, loss before: 4.39584056267e-07, loss after: 4.39584056267e-07.\n",
      "Epoch:19, weight train batch: 388, step:7, loss before: 4.24682895073e-07, loss after: 4.24682895073e-07.\n",
      "Epoch:19, weight train batch: 388, step:8, loss before: 5.21540414411e-07, loss after: 5.21540414411e-07.\n",
      "Epoch:19, weight train batch: 388, step:9, loss before: 5.14089833814e-07, loss after: 5.14089833814e-07.\n",
      "Epoch:19, weight train batch: 388, step:10, loss before: 5.14089776971e-07, loss after: 5.14089776971e-07.\n",
      "Epoch:19, weight train batch: 388, step:11, loss before: 4.61935769636e-07, loss after: 4.61935769636e-07.\n",
      "Epoch:19, weight train batch: 388, step:12, loss before: 4.09781762301e-07, loss after: 4.09781762301e-07.\n",
      "Epoch:19, weight train batch: 388, step:13, loss before: 6.40749590275e-07, loss after: 6.40749590275e-07.\n",
      "Epoch:19, weight train batch: 388, step:14, loss before: 4.3213347567e-07, loss after: 4.3213347567e-07.\n",
      "Epoch:19, weight train batch: 388, step:15, loss before: 4.9918867262e-07, loss after: 4.9918867262e-07.\n",
      "Epoch:19, weight train batch: 388, step:16, loss before: 4.24682923494e-07, loss after: 4.24682923494e-07.\n",
      "Epoch:19, weight train batch: 388, step:17, loss before: 3.72528887738e-07, loss after: 3.72528887738e-07.\n",
      "Epoch:19, weight train batch: 388, step:18, loss before: 4.09781762301e-07, loss after: 4.09781762301e-07.\n",
      "Epoch:19, weight train batch: 388, step:19, loss before: 4.84287511426e-07, loss after: 4.84287511426e-07.\n",
      "Epoch:19, weight train batch: 388, step:20, loss before: 7.82308575253e-07, loss after: 7.82308575253e-07.\n",
      "Epoch:19, weight train batch: 388, step:21, loss before: 5.51342679955e-07, loss after: 5.51342679955e-07.\n",
      "Epoch:19, weight train batch: 388, step:22, loss before: 4.69386350233e-07, loss after: 4.69386350233e-07.\n",
      "Epoch:19, weight train batch: 388, step:23, loss before: 5.28990938164e-07, loss after: 5.28990938164e-07.\n",
      "Epoch:19, weight train batch: 388, step:24, loss before: 4.17232314476e-07, loss after: 4.17232314476e-07.\n",
      "Epoch:19, weight train batch: 388, step:25, loss before: 4.24682866651e-07, loss after: 4.24682866651e-07.\n",
      "Epoch:19, weight train batch: 388, step:26, loss before: 4.91738092023e-07, loss after: 4.91738092023e-07.\n",
      "Epoch:19, weight train batch: 388, step:27, loss before: 3.35275984753e-07, loss after: 3.35275984753e-07.\n",
      "Epoch:19, weight train batch: 388, step:28, loss before: 4.02331181704e-07, loss after: 4.02331181704e-07.\n",
      "Epoch:19, weight train batch: 388, step:29, loss before: 5.06639253217e-07, loss after: 5.06639253217e-07.\n",
      "Epoch:19, weight train batch: 388, step:30, loss before: 4.39584056267e-07, loss after: 4.39584056267e-07.\n",
      "Epoch:19, weight train batch: 388, step:31, loss before: 9.12691859867e-07, loss after: 9.12691859867e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 384, loss before: 3.61813072232e-05, loss after: 5.02913962919e-07.\n",
      "Epoch:19, weight train batch: 389, step:0, loss before: 4.84287511426e-07, loss after: 4.84287511426e-07.\n",
      "Epoch:19, weight train batch: 389, step:1, loss before: 3.57627726544e-07, loss after: 3.57627726544e-07.\n",
      "Epoch:19, weight train batch: 389, step:2, loss before: 4.35858737546e-07, loss after: 4.35858737546e-07.\n",
      "Epoch:19, weight train batch: 389, step:3, loss before: 5.36441518761e-07, loss after: 5.36441518761e-07.\n",
      "Epoch:19, weight train batch: 389, step:4, loss before: 4.76836930829e-07, loss after: 4.76836930829e-07.\n",
      "Epoch:19, weight train batch: 389, step:5, loss before: 3.05473719209e-07, loss after: 3.05473719209e-07.\n",
      "Epoch:19, weight train batch: 389, step:6, loss before: 2.90962707368e-05, loss after: 2.89250638161e-05.\n",
      "Epoch:19, weight train batch: 389, step:7, loss before: 3.65078307141e-07, loss after: 3.65078307141e-07.\n",
      "Epoch:19, weight train batch: 389, step:8, loss before: 4.17232342897e-07, loss after: 4.17232342897e-07.\n",
      "Epoch:19, weight train batch: 389, step:9, loss before: 2.9802311019e-07, loss after: 2.9802311019e-07.\n",
      "Epoch:19, weight train batch: 389, step:10, loss before: 4.76836930829e-07, loss after: 4.76836930829e-07.\n",
      "Epoch:19, weight train batch: 389, step:11, loss before: 5.06639253217e-07, loss after: 5.06639253217e-07.\n",
      "Epoch:19, weight train batch: 389, step:12, loss before: 4.02331153282e-07, loss after: 4.02331153282e-07.\n",
      "Epoch:19, weight train batch: 389, step:13, loss before: 3.94880601107e-07, loss after: 3.94880601107e-07.\n",
      "Epoch:19, weight train batch: 389, step:14, loss before: 5.73694421746e-07, loss after: 5.73694421746e-07.\n",
      "Epoch:19, weight train batch: 389, step:15, loss before: 5.66243841149e-07, loss after: 5.66243841149e-07.\n",
      "Epoch:19, weight train batch: 389, step:16, loss before: 3.35276013175e-07, loss after: 3.35276013175e-07.\n",
      "Epoch:19, weight train batch: 389, step:17, loss before: 4.3213347567e-07, loss after: 4.3213347567e-07.\n",
      "Epoch:19, weight train batch: 389, step:18, loss before: 4.39584027845e-07, loss after: 4.39584027845e-07.\n",
      "Epoch:19, weight train batch: 389, step:19, loss before: 5.96046106693e-07, loss after: 5.96046106693e-07.\n",
      "Epoch:19, weight train batch: 389, step:20, loss before: 5.6251838032e-07, loss after: 5.6251838032e-07.\n",
      "Epoch:19, weight train batch: 389, step:21, loss before: 5.21540414411e-07, loss after: 5.21540414411e-07.\n",
      "Epoch:19, weight train batch: 389, step:22, loss before: 3.94880629528e-07, loss after: 3.94880629528e-07.\n",
      "Epoch:19, weight train batch: 389, step:23, loss before: 3.94880601107e-07, loss after: 3.68803569017e-07.\n",
      "Epoch:19, weight train batch: 389, step:24, loss before: 4.43309318143e-07, loss after: 4.43309318143e-07.\n",
      "Epoch:19, weight train batch: 389, step:25, loss before: 3.98605862983e-07, loss after: 3.98605862983e-07.\n",
      "Epoch:19, weight train batch: 389, step:26, loss before: 3.76254149614e-07, loss after: 3.76254149614e-07.\n",
      "Epoch:19, weight train batch: 389, step:27, loss before: 5.32716228463e-07, loss after: 5.32716228463e-07.\n",
      "Epoch:19, weight train batch: 389, step:28, loss before: 3.68803569017e-07, loss after: 3.68803569017e-07.\n",
      "Epoch:19, weight train batch: 389, step:29, loss before: 4.02331153282e-07, loss after: 4.02331153282e-07.\n",
      "Epoch:19, weight train batch: 389, step:30, loss before: 2.33569926422e-06, loss after: 2.3319742013e-06.\n",
      "Epoch:19, weight train batch: 389, step:31, loss before: 1.51617553001e-06, loss after: 1.51617553001e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 385, loss before: 3.60863377864e-05, loss after: 5.09432652507e-07.\n",
      "Epoch:19, weight train batch: 390, step:0, loss before: 5.10364486672e-07, loss after: 5.10364486672e-07.\n",
      "Epoch:19, weight train batch: 390, step:1, loss before: 4.47034608442e-07, loss after: 4.47034608442e-07.\n",
      "Epoch:19, weight train batch: 390, step:2, loss before: 4.17232314476e-07, loss after: 4.17232314476e-07.\n",
      "Epoch:19, weight train batch: 390, step:3, loss before: 5.51342623112e-07, loss after: 5.51342623112e-07.\n",
      "Epoch:19, weight train batch: 390, step:4, loss before: 5.10364486672e-07, loss after: 5.10364486672e-07.\n",
      "Epoch:19, weight train batch: 390, step:5, loss before: 4.84287511426e-07, loss after: 4.84287511426e-07.\n",
      "Epoch:19, weight train batch: 390, step:6, loss before: 4.84287511426e-07, loss after: 4.84287511426e-07.\n",
      "Epoch:19, weight train batch: 390, step:7, loss before: 4.5075989874e-07, loss after: 4.5075989874e-07.\n",
      "Epoch:19, weight train batch: 390, step:8, loss before: 4.47034608442e-07, loss after: 4.47034608442e-07.\n",
      "Epoch:19, weight train batch: 390, step:9, loss before: 3.35275984753e-07, loss after: 3.35275984753e-07.\n",
      "Epoch:19, weight train batch: 390, step:10, loss before: 3.53902436245e-07, loss after: 3.53902436245e-07.\n",
      "Epoch:19, weight train batch: 390, step:11, loss before: 3.31550694455e-07, loss after: 3.31550694455e-07.\n",
      "Epoch:19, weight train batch: 390, step:12, loss before: 4.0605644358e-07, loss after: 4.0605644358e-07.\n",
      "Epoch:19, weight train batch: 390, step:13, loss before: 4.39584027845e-07, loss after: 4.39584027845e-07.\n",
      "Epoch:19, weight train batch: 390, step:14, loss before: 0.000433792476542, loss after: 0.000432561675552.\n",
      "Epoch:19, weight train batch: 390, step:15, loss before: 4.17232314476e-07, loss after: 4.17232314476e-07.\n",
      "Epoch:19, weight train batch: 390, step:16, loss before: 6.37342373011e-06, loss after: 6.33245053905e-06.\n",
      "Epoch:19, weight train batch: 390, step:17, loss before: 2.75671339978e-07, loss after: 2.75671339978e-07.\n",
      "Epoch:19, weight train batch: 390, step:18, loss before: 3.91155282387e-07, loss after: 3.91155282387e-07.\n",
      "Epoch:19, weight train batch: 390, step:19, loss before: 6.06051844443e-06, loss after: 6.0158231463e-06.\n",
      "Epoch:19, weight train batch: 390, step:20, loss before: 1.27641596919e-05, loss after: 1.26375498439e-05.\n",
      "Epoch:19, weight train batch: 390, step:21, loss before: 3.3900124663e-07, loss after: 3.3900124663e-07.\n",
      "Epoch:19, weight train batch: 390, step:22, loss before: 4.24682866651e-07, loss after: 4.24682866651e-07.\n",
      "Epoch:19, weight train batch: 390, step:23, loss before: 5.3271617162e-07, loss after: 5.3271617162e-07.\n",
      "Epoch:19, weight train batch: 390, step:24, loss before: 3.76254121193e-07, loss after: 3.76254121193e-07.\n",
      "Epoch:19, weight train batch: 390, step:25, loss before: 6.4447482373e-07, loss after: 6.4447482373e-07.\n",
      "Epoch:19, weight train batch: 390, step:26, loss before: 0.000416880619014, loss after: 0.00041500950465.\n",
      "Epoch:19, weight train batch: 390, step:27, loss before: 4.61935741214e-07, loss after: 4.61935741214e-07.\n",
      "Epoch:19, weight train batch: 390, step:28, loss before: 5.92320816395e-07, loss after: 5.92320816395e-07.\n",
      "Epoch:19, weight train batch: 390, step:29, loss before: 1.17363842946e-05, loss after: 1.16097698992e-05.\n",
      "Epoch:19, weight train batch: 390, step:30, loss before: 3.79979411491e-07, loss after: 3.79979411491e-07.\n",
      "Epoch:19, weight train batch: 390, step:31, loss before: 4.35858737546e-07, loss after: 4.35858737546e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 386, loss before: 5.17815010426e-07, loss after: 5.41098074791e-07.\n",
      "Epoch:19, weight train batch: 391, step:0, loss before: 3.87429992088e-07, loss after: 3.87429992088e-07.\n",
      "Epoch:19, weight train batch: 391, step:1, loss before: 7.05526053935e-06, loss after: 7.01056433172e-06.\n",
      "Epoch:19, weight train batch: 391, step:2, loss before: 3.94880544263e-07, loss after: 3.94880544263e-07.\n",
      "Epoch:19, weight train batch: 391, step:3, loss before: 5.58793203709e-07, loss after: 5.58793203709e-07.\n",
      "Epoch:19, weight train batch: 391, step:4, loss before: 4.28408156949e-07, loss after: 4.28408156949e-07.\n",
      "Epoch:19, weight train batch: 391, step:5, loss before: 3.68803540596e-07, loss after: 3.68803540596e-07.\n",
      "Epoch:19, weight train batch: 391, step:6, loss before: 3.24100085436e-07, loss after: 3.24100085436e-07.\n",
      "Epoch:19, weight train batch: 391, step:7, loss before: 3.65078278719e-07, loss after: 3.65078278719e-07.\n",
      "Epoch:19, weight train batch: 391, step:8, loss before: 3.46451798805e-07, loss after: 3.46451798805e-07.\n",
      "Epoch:19, weight train batch: 391, step:9, loss before: 5.36441461918e-07, loss after: 5.36441461918e-07.\n",
      "Epoch:19, weight train batch: 391, step:10, loss before: 5.55066662855e-07, loss after: 5.55066662855e-07.\n",
      "Epoch:19, weight train batch: 391, step:11, loss before: 1.0410590221e-05, loss after: 1.03510046756e-05.\n",
      "Epoch:19, weight train batch: 391, step:12, loss before: 4.32133447248e-07, loss after: 4.32133447248e-07.\n",
      "Epoch:19, weight train batch: 391, step:13, loss before: 4.32133447248e-07, loss after: 4.32133447248e-07.\n",
      "Epoch:19, weight train batch: 391, step:14, loss before: 2.57044916907e-07, loss after: 2.57044916907e-07.\n",
      "Epoch:19, weight train batch: 391, step:15, loss before: 3.31550666033e-07, loss after: 3.31550666033e-07.\n",
      "Epoch:19, weight train batch: 391, step:16, loss before: 4.35858709125e-07, loss after: 4.35858709125e-07.\n",
      "Epoch:19, weight train batch: 391, step:17, loss before: 4.17232286054e-07, loss after: 4.17232286054e-07.\n",
      "Epoch:19, weight train batch: 391, step:18, loss before: 0.0216612480581, loss after: 0.0216612480581.\n",
      "Epoch:19, weight train batch: 391, step:19, loss before: 5.3271617162e-07, loss after: 5.3271617162e-07.\n",
      "Epoch:19, weight train batch: 391, step:20, loss before: 4.95463325478e-07, loss after: 4.95463325478e-07.\n",
      "Epoch:19, weight train batch: 391, step:21, loss before: 3.57627698122e-07, loss after: 3.57627698122e-07.\n",
      "Epoch:19, weight train batch: 391, step:22, loss before: 3.72528830894e-07, loss after: 3.72528830894e-07.\n",
      "Epoch:19, weight train batch: 391, step:23, loss before: 0.000391063513234, loss after: 0.000388948014006.\n",
      "Epoch:19, weight train batch: 391, step:24, loss before: 3.57627698122e-07, loss after: 3.91155310808e-07.\n",
      "Epoch:19, weight train batch: 391, step:25, loss before: 5.47617332813e-07, loss after: 5.47617332813e-07.\n",
      "Epoch:19, weight train batch: 391, step:26, loss before: 8.6798911525e-07, loss after: 8.6798911525e-07.\n",
      "Epoch:19, weight train batch: 391, step:27, loss before: 4.17232286054e-07, loss after: 4.17232286054e-07.\n",
      "Epoch:19, weight train batch: 391, step:28, loss before: 4.20957604774e-07, loss after: 4.20957604774e-07.\n",
      "Epoch:19, weight train batch: 391, step:29, loss before: 3.65078278719e-07, loss after: 3.65078278719e-07.\n",
      "Epoch:19, weight train batch: 391, step:30, loss before: 3.98605862983e-07, loss after: 3.98605862983e-07.\n",
      "Epoch:19, weight train batch: 391, step:31, loss before: 5.02913962919e-07, loss after: 5.02913962919e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 387, loss before: 2.99754697153e-06, loss after: 1.67816301655e-06.\n",
      "Epoch:19, weight train batch: 392, step:0, loss before: 4.28408185371e-07, loss after: 4.28408185371e-07.\n",
      "Epoch:19, weight train batch: 392, step:1, loss before: 6.37024299976e-07, loss after: 6.37024299976e-07.\n",
      "Epoch:19, weight train batch: 392, step:2, loss before: 4.65661031512e-07, loss after: 4.65661031512e-07.\n",
      "Epoch:19, weight train batch: 392, step:3, loss before: 4.09781733879e-07, loss after: 4.09781733879e-07.\n",
      "Epoch:19, weight train batch: 392, step:4, loss before: 4.24682866651e-07, loss after: 4.54485132195e-07.\n",
      "Epoch:19, weight train batch: 392, step:5, loss before: 5.43892042515e-07, loss after: 5.43892042515e-07.\n",
      "Epoch:19, weight train batch: 392, step:6, loss before: 6.59375984924e-07, loss after: 6.59375984924e-07.\n",
      "Epoch:19, weight train batch: 392, step:7, loss before: 7.18979322301e-07, loss after: 7.18979322301e-07.\n",
      "Epoch:19, weight train batch: 392, step:8, loss before: 4.0233112486e-07, loss after: 3.83704673368e-07.\n",
      "Epoch:19, weight train batch: 392, step:9, loss before: 5.02913906075e-07, loss after: 5.02913906075e-07.\n",
      "Epoch:19, weight train batch: 392, step:10, loss before: 5.14089776971e-07, loss after: 5.14089776971e-07.\n",
      "Epoch:19, weight train batch: 392, step:11, loss before: 4.58210450915e-07, loss after: 4.58210450915e-07.\n",
      "Epoch:19, weight train batch: 392, step:12, loss before: 0.000139303898322, loss after: 0.000138866249472.\n",
      "Epoch:19, weight train batch: 392, step:13, loss before: 3.53902436245e-07, loss after: 3.53902436245e-07.\n",
      "Epoch:19, weight train batch: 392, step:14, loss before: 3.76254178036e-07, loss after: 3.94880572685e-07.\n",
      "Epoch:19, weight train batch: 392, step:15, loss before: 1.30011153487e-06, loss after: 1.30011153487e-06.\n",
      "Epoch:19, weight train batch: 392, step:16, loss before: 6.78002379573e-07, loss after: 6.78002379573e-07.\n",
      "Epoch:19, weight train batch: 392, step:17, loss before: 6.22123138783e-07, loss after: 6.22123138783e-07.\n",
      "Epoch:19, weight train batch: 392, step:18, loss before: 3.01748343645e-07, loss after: 3.01748343645e-07.\n",
      "Epoch:19, weight train batch: 392, step:19, loss before: 5.811449455e-07, loss after: 5.811449455e-07.\n",
      "Epoch:19, weight train batch: 392, step:20, loss before: 3.50177117525e-07, loss after: 3.50177117525e-07.\n",
      "Epoch:19, weight train batch: 392, step:21, loss before: 0.000134255751618, loss after: 0.000133517576614.\n",
      "Epoch:19, weight train batch: 392, step:22, loss before: 5.69969074604e-07, loss after: 5.69969074604e-07.\n",
      "Epoch:19, weight train batch: 392, step:23, loss before: 4.35858737546e-07, loss after: 4.35858737546e-07.\n",
      "Epoch:19, weight train batch: 392, step:24, loss before: 4.80562164284e-07, loss after: 4.80562164284e-07.\n",
      "Epoch:19, weight train batch: 392, step:25, loss before: 2.3096791324e-07, loss after: 2.3096791324e-07.\n",
      "Epoch:19, weight train batch: 392, step:26, loss before: 4.0233112486e-07, loss after: 4.0233112486e-07.\n",
      "Epoch:19, weight train batch: 392, step:27, loss before: 3.57627698122e-07, loss after: 3.57627698122e-07.\n",
      "Epoch:19, weight train batch: 392, step:28, loss before: 4.91737978336e-07, loss after: 4.91737978336e-07.\n",
      "Epoch:19, weight train batch: 392, step:29, loss before: 4.76836873986e-07, loss after: 4.76836873986e-07.\n",
      "Epoch:19, weight train batch: 392, step:30, loss before: 4.4703458002e-07, loss after: 4.4703458002e-07.\n",
      "Epoch:19, weight train batch: 392, step:31, loss before: 4.17232286054e-07, loss after: 4.17232286054e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 388, loss before: 3.8370470179e-07, loss after: 3.8370470179e-07.\n",
      "Epoch:19, weight train batch: 393, step:0, loss before: 4.13506967334e-07, loss after: 4.13506967334e-07.\n",
      "Epoch:19, weight train batch: 393, step:1, loss before: 3.16649504839e-07, loss after: 3.16649504839e-07.\n",
      "Epoch:19, weight train batch: 393, step:2, loss before: 4.32133418826e-07, loss after: 4.32133418826e-07.\n",
      "Epoch:19, weight train batch: 393, step:3, loss before: 5.28990881321e-07, loss after: 5.28990881321e-07.\n",
      "Epoch:19, weight train batch: 393, step:4, loss before: 6.25848372238e-07, loss after: 6.25848372238e-07.\n",
      "Epoch:19, weight train batch: 393, step:5, loss before: 5.88595526096e-07, loss after: 5.88595526096e-07.\n",
      "Epoch:19, weight train batch: 393, step:6, loss before: 4.9173803518e-07, loss after: 4.9173803518e-07.\n",
      "Epoch:19, weight train batch: 393, step:7, loss before: 1.23305665056e-06, loss after: 1.23305665056e-06.\n",
      "Epoch:19, weight train batch: 393, step:8, loss before: 4.69386350233e-07, loss after: 4.69386350233e-07.\n",
      "Epoch:19, weight train batch: 393, step:9, loss before: 0.000124512953334, loss after: 0.000124030586448.\n",
      "Epoch:19, weight train batch: 393, step:10, loss before: 4.69386293389e-07, loss after: 4.69386293389e-07.\n",
      "Epoch:19, weight train batch: 393, step:11, loss before: 5.36441177701e-07, loss after: 5.36441177701e-07.\n",
      "Epoch:19, weight train batch: 393, step:12, loss before: 4.61935712792e-07, loss after: 4.61935712792e-07.\n",
      "Epoch:19, weight train batch: 393, step:13, loss before: 6.25848372238e-07, loss after: 6.25848372238e-07.\n",
      "Epoch:19, weight train batch: 393, step:14, loss before: 3.27825375734e-07, loss after: 3.27825375734e-07.\n",
      "Epoch:19, weight train batch: 393, step:15, loss before: 4.06056415159e-07, loss after: 4.06056415159e-07.\n",
      "Epoch:19, weight train batch: 393, step:16, loss before: 5.13683880854e-06, loss after: 5.12566475663e-06.\n",
      "Epoch:19, weight train batch: 393, step:17, loss before: 3.83704673368e-07, loss after: 3.83704673368e-07.\n",
      "Epoch:19, weight train batch: 393, step:18, loss before: 5.17815067269e-07, loss after: 5.17815067269e-07.\n",
      "Epoch:19, weight train batch: 393, step:19, loss before: 5.02913906075e-07, loss after: 5.02913906075e-07.\n",
      "Epoch:19, weight train batch: 393, step:20, loss before: 5.14089776971e-07, loss after: 5.14089776971e-07.\n",
      "Epoch:19, weight train batch: 393, step:21, loss before: 0.000119070435176, loss after: 0.000118506322906.\n",
      "Epoch:19, weight train batch: 393, step:22, loss before: 2.28726730711e-06, loss after: 2.28726730711e-06.\n",
      "Epoch:19, weight train batch: 393, step:23, loss before: 5.25265591023e-07, loss after: 5.25265591023e-07.\n",
      "Epoch:19, weight train batch: 393, step:24, loss before: 4.54485189039e-07, loss after: 4.54485189039e-07.\n",
      "Epoch:19, weight train batch: 393, step:25, loss before: 3.83704673368e-07, loss after: 3.83704673368e-07.\n",
      "Epoch:19, weight train batch: 393, step:26, loss before: 2.50705966209e-06, loss after: 2.50705966209e-06.\n",
      "Epoch:19, weight train batch: 393, step:27, loss before: 5.47617332813e-07, loss after: 5.47617332813e-07.\n",
      "Epoch:19, weight train batch: 393, step:28, loss before: 2.4362793738e-06, loss after: 2.43255431087e-06.\n",
      "Epoch:19, weight train batch: 393, step:29, loss before: 4.32133447248e-07, loss after: 4.06056415159e-07.\n",
      "Epoch:19, weight train batch: 393, step:30, loss before: 3.3527592791e-07, loss after: 3.3527592791e-07.\n",
      "Epoch:19, weight train batch: 393, step:31, loss before: 3.9860580614e-07, loss after: 3.9860580614e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 389, loss before: 4.05125064162e-07, loss after: 0.00541560631245.\n",
      "Epoch:19, weight train batch: 394, step:0, loss before: 2.42143755713e-07, loss after: 2.42143755713e-07.\n",
      "Epoch:19, weight train batch: 394, step:1, loss before: 4.28408100106e-07, loss after: 4.28408100106e-07.\n",
      "Epoch:19, weight train batch: 394, step:2, loss before: 6.92903540767e-07, loss after: 6.92903540767e-07.\n",
      "Epoch:19, weight train batch: 394, step:3, loss before: 4.61935712792e-07, loss after: 4.61935712792e-07.\n",
      "Epoch:19, weight train batch: 394, step:4, loss before: 0.0001121030582, loss after: 0.000111598114017.\n",
      "Epoch:19, weight train batch: 394, step:5, loss before: 4.69386321811e-07, loss after: 5.02913849232e-07.\n",
      "Epoch:19, weight train batch: 394, step:6, loss before: 5.47617332813e-07, loss after: 5.47617332813e-07.\n",
      "Epoch:19, weight train batch: 394, step:7, loss before: 4.39583971001e-07, loss after: 4.39583971001e-07.\n",
      "Epoch:19, weight train batch: 394, step:8, loss before: 5.69969074604e-07, loss after: 5.69969074604e-07.\n",
      "Epoch:19, weight train batch: 394, step:9, loss before: 3.50177089103e-07, loss after: 3.50177089103e-07.\n",
      "Epoch:19, weight train batch: 394, step:10, loss before: 3.72528802473e-07, loss after: 3.72528802473e-07.\n",
      "Epoch:19, weight train batch: 394, step:11, loss before: 1.7769381202e-06, loss after: 1.77321294359e-06.\n",
      "Epoch:19, weight train batch: 394, step:12, loss before: 4.28408100106e-07, loss after: 3.98605834562e-07.\n",
      "Epoch:19, weight train batch: 394, step:13, loss before: 3.68803540596e-07, loss after: 3.68803540596e-07.\n",
      "Epoch:19, weight train batch: 394, step:14, loss before: 3.87429992088e-07, loss after: 3.87429992088e-07.\n",
      "Epoch:19, weight train batch: 394, step:15, loss before: 3.94880544263e-07, loss after: 3.94880544263e-07.\n",
      "Epoch:19, weight train batch: 394, step:16, loss before: 3.72528830894e-07, loss after: 3.72528830894e-07.\n",
      "Epoch:19, weight train batch: 394, step:17, loss before: 4.84287454583e-07, loss after: 4.84287454583e-07.\n",
      "Epoch:19, weight train batch: 394, step:18, loss before: 3.87429992088e-07, loss after: 3.87429992088e-07.\n",
      "Epoch:19, weight train batch: 394, step:19, loss before: 4.65661031512e-07, loss after: 4.65661031512e-07.\n",
      "Epoch:19, weight train batch: 394, step:20, loss before: 4.84287511426e-07, loss after: 4.84287511426e-07.\n",
      "Epoch:19, weight train batch: 394, step:21, loss before: 3.94880544263e-07, loss after: 3.94880544263e-07.\n",
      "Epoch:19, weight train batch: 394, step:22, loss before: 2.75671368399e-07, loss after: 2.75671368399e-07.\n",
      "Epoch:19, weight train batch: 394, step:23, loss before: 4.5075989874e-07, loss after: 4.5075989874e-07.\n",
      "Epoch:19, weight train batch: 394, step:24, loss before: 4.54485160617e-07, loss after: 4.54485160617e-07.\n",
      "Epoch:19, weight train batch: 394, step:25, loss before: 4.28408156949e-07, loss after: 4.28408156949e-07.\n",
      "Epoch:19, weight train batch: 394, step:26, loss before: 2.83297085844e-05, loss after: 2.81510529021e-05.\n",
      "Epoch:19, weight train batch: 394, step:27, loss before: 3.01748372067e-07, loss after: 3.01748372067e-07.\n",
      "Epoch:19, weight train batch: 394, step:28, loss before: 4.20957576353e-07, loss after: 4.20957576353e-07.\n",
      "Epoch:19, weight train batch: 394, step:29, loss before: 4.80562164284e-07, loss after: 4.80562164284e-07.\n",
      "Epoch:19, weight train batch: 394, step:30, loss before: 3.98605862983e-07, loss after: 3.98605862983e-07.\n",
      "Epoch:19, weight train batch: 394, step:31, loss before: 4.88012744881e-07, loss after: 4.88012744881e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 390, loss before: 9.12679824978e-05, loss after: 3.2689405316e-07.\n",
      "Epoch:19, weight train batch: 395, step:0, loss before: 4.35858709125e-07, loss after: 4.35858709125e-07.\n",
      "Epoch:19, weight train batch: 395, step:1, loss before: 3.27825375734e-07, loss after: 3.27825375734e-07.\n",
      "Epoch:19, weight train batch: 395, step:2, loss before: 5.28990653947e-07, loss after: 5.28990653947e-07.\n",
      "Epoch:19, weight train batch: 395, step:3, loss before: 7.26431153453e-07, loss after: 7.26431153453e-07.\n",
      "Epoch:19, weight train batch: 395, step:4, loss before: 3.68803569017e-07, loss after: 3.68803569017e-07.\n",
      "Epoch:19, weight train batch: 395, step:5, loss before: 4.0605644358e-07, loss after: 4.0605644358e-07.\n",
      "Epoch:19, weight train batch: 395, step:6, loss before: 3.53902407824e-07, loss after: 3.53902407824e-07.\n",
      "Epoch:19, weight train batch: 395, step:7, loss before: 4.35858709125e-07, loss after: 4.35858709125e-07.\n",
      "Epoch:19, weight train batch: 395, step:8, loss before: 6.0349668729e-07, loss after: 6.0349668729e-07.\n",
      "Epoch:19, weight train batch: 395, step:9, loss before: 5.77419655201e-07, loss after: 5.77419655201e-07.\n",
      "Epoch:19, weight train batch: 395, step:10, loss before: 4.76836873986e-07, loss after: 4.76836873986e-07.\n",
      "Epoch:19, weight train batch: 395, step:11, loss before: 4.54485160617e-07, loss after: 4.54485160617e-07.\n",
      "Epoch:19, weight train batch: 395, step:12, loss before: 3.91155282387e-07, loss after: 3.91155282387e-07.\n",
      "Epoch:19, weight train batch: 395, step:13, loss before: 3.05473662365e-07, loss after: 3.05473662365e-07.\n",
      "Epoch:19, weight train batch: 395, step:14, loss before: 3.94880572685e-07, loss after: 3.94880572685e-07.\n",
      "Epoch:19, weight train batch: 395, step:15, loss before: 1.9408373646e-06, loss after: 1.9408373646e-06.\n",
      "Epoch:19, weight train batch: 395, step:16, loss before: 5.06639196374e-07, loss after: 5.06639196374e-07.\n",
      "Epoch:19, weight train batch: 395, step:17, loss before: 4.20957576353e-07, loss after: 4.20957576353e-07.\n",
      "Epoch:19, weight train batch: 395, step:18, loss before: 4.95463325478e-07, loss after: 4.95463325478e-07.\n",
      "Epoch:19, weight train batch: 395, step:19, loss before: 4.76836902408e-07, loss after: 4.76836902408e-07.\n",
      "Epoch:19, weight train batch: 395, step:20, loss before: 4.99188615777e-07, loss after: 4.99188615777e-07.\n",
      "Epoch:19, weight train batch: 395, step:21, loss before: 4.28408156949e-07, loss after: 4.28408156949e-07.\n",
      "Epoch:19, weight train batch: 395, step:22, loss before: 4.43309289722e-07, loss after: 4.43309289722e-07.\n",
      "Epoch:19, weight train batch: 395, step:23, loss before: 2.64495497504e-07, loss after: 2.64495497504e-07.\n",
      "Epoch:19, weight train batch: 395, step:24, loss before: 0.000104618244222, loss after: 0.000104350918264.\n",
      "Epoch:19, weight train batch: 395, step:25, loss before: 5.25265591023e-07, loss after: 5.25265591023e-07.\n",
      "Epoch:19, weight train batch: 395, step:26, loss before: 4.58210450915e-07, loss after: 4.58210450915e-07.\n",
      "Epoch:19, weight train batch: 395, step:27, loss before: 5.84870235798e-07, loss after: 5.84870235798e-07.\n",
      "Epoch:19, weight train batch: 395, step:28, loss before: 4.65661031512e-07, loss after: 4.65661031512e-07.\n",
      "Epoch:19, weight train batch: 395, step:29, loss before: 2.62426219706e-05, loss after: 2.60862798314e-05.\n",
      "Epoch:19, weight train batch: 395, step:30, loss before: 2.71946078101e-07, loss after: 2.71946078101e-07.\n",
      "Epoch:19, weight train batch: 395, step:31, loss before: 2.83121948996e-07, loss after: 2.83121948996e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 391, loss before: 0.00541583076119, loss after: 3.43657859503e-07.\n",
      "Epoch:19, weight train batch: 396, step:0, loss before: 3.46451685118e-07, loss after: 3.46451685118e-07.\n",
      "Epoch:19, weight train batch: 396, step:1, loss before: 4.54485160617e-07, loss after: 4.54485160617e-07.\n",
      "Epoch:19, weight train batch: 396, step:2, loss before: 3.42726536928e-07, loss after: 3.42726536928e-07.\n",
      "Epoch:19, weight train batch: 396, step:3, loss before: 3.76254121193e-07, loss after: 3.76254121193e-07.\n",
      "Epoch:19, weight train batch: 396, step:4, loss before: 4.06056415159e-07, loss after: 4.06056415159e-07.\n",
      "Epoch:19, weight train batch: 396, step:5, loss before: 3.98605834562e-07, loss after: 3.98605834562e-07.\n",
      "Epoch:19, weight train batch: 396, step:6, loss before: 4.28408128528e-07, loss after: 4.28408128528e-07.\n",
      "Epoch:19, weight train batch: 396, step:7, loss before: 4.61935741214e-07, loss after: 4.61935741214e-07.\n",
      "Epoch:19, weight train batch: 396, step:8, loss before: 2.27242622941e-07, loss after: 2.27242622941e-07.\n",
      "Epoch:19, weight train batch: 396, step:9, loss before: 2.27721793635e-05, loss after: 2.25786006922e-05.\n",
      "Epoch:19, weight train batch: 396, step:10, loss before: 1.70988812442e-06, loss after: 1.70616294781e-06.\n",
      "Epoch:19, weight train batch: 396, step:11, loss before: 4.13506995756e-07, loss after: 4.13506995756e-07.\n",
      "Epoch:19, weight train batch: 396, step:12, loss before: 4.69386321811e-07, loss after: 4.69386321811e-07.\n",
      "Epoch:19, weight train batch: 396, step:13, loss before: 4.17232286054e-07, loss after: 4.17232286054e-07.\n",
      "Epoch:19, weight train batch: 396, step:14, loss before: 5.43892042515e-07, loss after: 5.43892042515e-07.\n",
      "Epoch:19, weight train batch: 396, step:15, loss before: 3.24100113858e-07, loss after: 3.24100113858e-07.\n",
      "Epoch:19, weight train batch: 396, step:16, loss before: 5.25265591023e-07, loss after: 5.25265591023e-07.\n",
      "Epoch:19, weight train batch: 396, step:17, loss before: 1.47519619986e-06, loss after: 1.47147113694e-06.\n",
      "Epoch:19, weight train batch: 396, step:18, loss before: 3.53902407824e-07, loss after: 3.53902407824e-07.\n",
      "Epoch:19, weight train batch: 396, step:19, loss before: 4.32133447248e-07, loss after: 4.32133447248e-07.\n",
      "Epoch:19, weight train batch: 396, step:20, loss before: 5.58793203709e-07, loss after: 5.58793203709e-07.\n",
      "Epoch:19, weight train batch: 396, step:21, loss before: 4.61935741214e-07, loss after: 4.61935741214e-07.\n",
      "Epoch:19, weight train batch: 396, step:22, loss before: 5.47617332813e-07, loss after: 5.47617332813e-07.\n",
      "Epoch:19, weight train batch: 396, step:23, loss before: 5.14089776971e-07, loss after: 5.14089776971e-07.\n",
      "Epoch:19, weight train batch: 396, step:24, loss before: 3.16649533261e-07, loss after: 3.16649533261e-07.\n",
      "Epoch:19, weight train batch: 396, step:25, loss before: 5.02913906075e-07, loss after: 5.02913906075e-07.\n",
      "Epoch:19, weight train batch: 396, step:26, loss before: 3.50177117525e-07, loss after: 3.50177117525e-07.\n",
      "Epoch:19, weight train batch: 396, step:27, loss before: 2.38418493836e-07, loss after: 2.38418493836e-07.\n",
      "Epoch:19, weight train batch: 396, step:28, loss before: 5.28990881321e-07, loss after: 5.28990881321e-07.\n",
      "Epoch:19, weight train batch: 396, step:29, loss before: 4.35858709125e-07, loss after: 4.35858709125e-07.\n",
      "Epoch:19, weight train batch: 396, step:30, loss before: 3.98605834562e-07, loss after: 3.98605834562e-07.\n",
      "Epoch:19, weight train batch: 396, step:31, loss before: 5.21540300724e-07, loss after: 5.21540300724e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 392, loss before: 3.31311798618e-06, loss after: 4.43309289722e-07.\n",
      "Epoch:19, weight train batch: 397, step:0, loss before: 0.0216665379703, loss after: 0.0216665267944.\n",
      "Epoch:19, weight train batch: 397, step:1, loss before: 3.39001218208e-07, loss after: 3.39001218208e-07.\n",
      "Epoch:19, weight train batch: 397, step:2, loss before: 5.47617332813e-07, loss after: 5.47617332813e-07.\n",
      "Epoch:19, weight train batch: 397, step:3, loss before: 4.65661003091e-07, loss after: 4.65661003091e-07.\n",
      "Epoch:19, weight train batch: 397, step:4, loss before: 4.69386321811e-07, loss after: 4.69386321811e-07.\n",
      "Epoch:19, weight train batch: 397, step:5, loss before: 2.53319626609e-07, loss after: 2.53319626609e-07.\n",
      "Epoch:19, weight train batch: 397, step:6, loss before: 4.20957576353e-07, loss after: 4.20957576353e-07.\n",
      "Epoch:19, weight train batch: 397, step:7, loss before: 4.54485160617e-07, loss after: 4.54485160617e-07.\n",
      "Epoch:19, weight train batch: 397, step:8, loss before: 4.9173803518e-07, loss after: 4.9173803518e-07.\n",
      "Epoch:19, weight train batch: 397, step:9, loss before: 4.13507024177e-07, loss after: 4.13507024177e-07.\n",
      "Epoch:19, weight train batch: 397, step:10, loss before: 4.80562164284e-07, loss after: 4.80562164284e-07.\n",
      "Epoch:19, weight train batch: 397, step:11, loss before: 4.54485160617e-07, loss after: 4.54485160617e-07.\n",
      "Epoch:19, weight train batch: 397, step:12, loss before: 4.65661003091e-07, loss after: 4.65661003091e-07.\n",
      "Epoch:19, weight train batch: 397, step:13, loss before: 5.10364429829e-07, loss after: 5.10364429829e-07.\n",
      "Epoch:19, weight train batch: 397, step:14, loss before: 4.09781705457e-07, loss after: 4.09781705457e-07.\n",
      "Epoch:19, weight train batch: 397, step:15, loss before: 3.87429992088e-07, loss after: 3.87429992088e-07.\n",
      "Epoch:19, weight train batch: 397, step:16, loss before: 4.80562164284e-07, loss after: 4.80562164284e-07.\n",
      "Epoch:19, weight train batch: 397, step:17, loss before: 4.62566276838e-05, loss after: 4.62008320028e-05.\n",
      "Epoch:19, weight train batch: 397, step:18, loss before: 3.72528830894e-07, loss after: 3.72528830894e-07.\n",
      "Epoch:19, weight train batch: 397, step:19, loss before: 8.86617044671e-07, loss after: 8.86617044671e-07.\n",
      "Epoch:19, weight train batch: 397, step:20, loss before: 4.24682866651e-07, loss after: 4.24682866651e-07.\n",
      "Epoch:19, weight train batch: 397, step:21, loss before: 3.20374823559e-07, loss after: 3.20374823559e-07.\n",
      "Epoch:19, weight train batch: 397, step:22, loss before: 4.39583999423e-07, loss after: 4.39583999423e-07.\n",
      "Epoch:19, weight train batch: 397, step:23, loss before: 5.38265658179e-06, loss after: 5.36775769433e-06.\n",
      "Epoch:19, weight train batch: 397, step:24, loss before: 3.87429992088e-07, loss after: 3.87429992088e-07.\n",
      "Epoch:19, weight train batch: 397, step:25, loss before: 5.40874043509e-06, loss after: 5.37149344382e-06.\n",
      "Epoch:19, weight train batch: 397, step:26, loss before: 4.0233112486e-07, loss after: 3.72528859316e-07.\n",
      "Epoch:19, weight train batch: 397, step:27, loss before: 3.65078278719e-07, loss after: 3.65078278719e-07.\n",
      "Epoch:19, weight train batch: 397, step:28, loss before: 5.32716228463e-07, loss after: 5.32716228463e-07.\n",
      "Epoch:19, weight train batch: 397, step:29, loss before: 2.79396658698e-07, loss after: 2.79396658698e-07.\n",
      "Epoch:19, weight train batch: 397, step:30, loss before: 4.02331181704e-07, loss after: 4.02331181704e-07.\n",
      "Epoch:19, weight train batch: 397, step:31, loss before: 3.61352988421e-07, loss after: 3.61352988421e-07.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 393, loss before: 2.83121920575e-07, loss after: 2.83121920575e-07.\n",
      "Epoch:19, weight train batch: 398, step:0, loss before: 3.53902407824e-07, loss after: 3.53902407824e-07.\n",
      "Epoch:19, weight train batch: 398, step:1, loss before: 6.78001242704e-07, loss after: 6.78001242704e-07.\n",
      "Epoch:19, weight train batch: 398, step:2, loss before: 4.39584056267e-07, loss after: 4.39584056267e-07.\n",
      "Epoch:19, weight train batch: 398, step:3, loss before: 3.53902436245e-07, loss after: 3.53902436245e-07.\n",
      "Epoch:19, weight train batch: 398, step:4, loss before: 5.10364486672e-07, loss after: 5.10364486672e-07.\n",
      "Epoch:19, weight train batch: 398, step:5, loss before: 4.84287511426e-07, loss after: 4.84287511426e-07.\n",
      "Epoch:19, weight train batch: 398, step:6, loss before: 4.84287511426e-07, loss after: 4.84287511426e-07.\n",
      "Epoch:19, weight train batch: 398, step:7, loss before: 3.27825404156e-07, loss after: 3.27825404156e-07.\n",
      "Epoch:19, weight train batch: 398, step:8, loss before: 5.06639253217e-07, loss after: 5.06639253217e-07.\n",
      "Epoch:19, weight train batch: 398, step:9, loss before: 3.27825404156e-07, loss after: 3.27825404156e-07.\n",
      "Epoch:19, weight train batch: 398, step:10, loss before: 4.54485189039e-07, loss after: 4.54485189039e-07.\n",
      "Epoch:19, weight train batch: 398, step:11, loss before: 9.98210016405e-05, loss after: 9.95722002699e-05.\n",
      "Epoch:19, weight train batch: 398, step:12, loss before: 5.14089833814e-07, loss after: 5.14089833814e-07.\n",
      "Epoch:19, weight train batch: 398, step:13, loss before: 0.0216611921787, loss after: 0.0216611921787.\n",
      "Epoch:19, weight train batch: 398, step:14, loss before: 5.06639253217e-07, loss after: 5.06639253217e-07.\n",
      "Epoch:19, weight train batch: 398, step:15, loss before: 4.61935798057e-07, loss after: 4.61935798057e-07.\n",
      "Epoch:19, weight train batch: 398, step:16, loss before: 5.84870235798e-07, loss after: 5.84870235798e-07.\n",
      "Epoch:19, weight train batch: 398, step:17, loss before: 3.83704730211e-07, loss after: 3.83704730211e-07.\n",
      "Epoch:19, weight train batch: 398, step:18, loss before: 3.94880572685e-07, loss after: 3.94880572685e-07.\n",
      "Epoch:19, weight train batch: 398, step:19, loss before: 4.17232314476e-07, loss after: 4.17232314476e-07.\n",
      "Epoch:19, weight train batch: 398, step:20, loss before: 5.06639253217e-07, loss after: 5.06639253217e-07.\n",
      "Epoch:19, weight train batch: 398, step:21, loss before: 3.61352988421e-07, loss after: 3.61352988421e-07.\n",
      "Epoch:19, weight train batch: 398, step:22, loss before: 3.57627698122e-07, loss after: 3.57627698122e-07.\n",
      "Epoch:19, weight train batch: 398, step:23, loss before: 3.16649561682e-07, loss after: 3.16649561682e-07.\n",
      "Epoch:19, weight train batch: 398, step:24, loss before: 5.10364486672e-07, loss after: 5.10364486672e-07.\n",
      "Epoch:19, weight train batch: 398, step:25, loss before: 4.20957604774e-07, loss after: 4.20957604774e-07.\n",
      "Epoch:19, weight train batch: 398, step:26, loss before: 4.06056472002e-07, loss after: 4.06056472002e-07.\n",
      "Epoch:19, weight train batch: 398, step:27, loss before: 4.88012801725e-07, loss after: 4.88012801725e-07.\n",
      "Epoch:19, weight train batch: 398, step:28, loss before: 3.72528887738e-07, loss after: 3.72528887738e-07.\n",
      "Epoch:19, weight train batch: 398, step:29, loss before: 3.20374851981e-07, loss after: 3.20374851981e-07.\n",
      "Epoch:19, weight train batch: 398, step:30, loss before: 3.46451827227e-07, loss after: 3.46451827227e-07.\n",
      "Epoch:19, weight train batch: 398, step:31, loss before: 1.64282607784e-06, loss after: 1.63910101492e-06.\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 394, loss before: 4.43309289722e-07, loss after: 5.15952137903e-07.\n",
      "Epoch:19, weight train batch: 399, step:0, loss before: 1.44539558278e-06, loss after: 1.44167040617e-06.\n",
      "Epoch:19, weight train batch: 399, step:1, loss before: 3.12924271384e-07, loss after: 3.12924271384e-07.\n",
      "Epoch:19, weight train batch: 399, step:2, loss before: 2.30967941661e-07, loss after: 2.30967941661e-07.\n",
      "Epoch:19, weight train batch: 399, step:3, loss before: 2.34693203538e-07, loss after: 2.34693203538e-07.\n",
      "Epoch:19, weight train batch: 399, step:4, loss before: 3.76254149614e-07, loss after: 3.76254149614e-07.\n",
      "Epoch:19, weight train batch: 399, step:5, loss before: 3.53902407824e-07, loss after: 3.53902407824e-07.\n",
      "Epoch:19, weight train batch: 399, step:6, loss before: 3.57627698122e-07, loss after: 3.57627698122e-07.\n",
      "Epoch:19, weight train batch: 399, step:7, loss before: 4.47034665285e-07, loss after: 4.47034665285e-07.\n",
      "Epoch:19, weight train batch: 399, step:8, loss before: 3.91155310808e-07, loss after: 3.91155310808e-07.\n",
      "Epoch:19, weight train batch: 399, step:9, loss before: 4.43309318143e-07, loss after: 4.43309318143e-07.\n",
      "Epoch:19, weight train batch: 399, step:10, loss before: 3.68803569017e-07, loss after: 3.68803569017e-07.\n",
      "Epoch:19, weight train batch: 399, step:11, loss before: 4.69386378654e-07, loss after: 4.69386378654e-07.\n",
      "Epoch:19, weight train batch: 399, step:12, loss before: 5.36441518761e-07, loss after: 5.36441518761e-07.\n",
      "Epoch:19, weight train batch: 399, step:13, loss before: 3.76254149614e-07, loss after: 3.76254149614e-07.\n",
      "Epoch:19, weight train batch: 399, step:14, loss before: 3.91155310808e-07, loss after: 3.91155310808e-07.\n",
      "Epoch:19, weight train batch: 399, step:15, loss before: 3.46451827227e-07, loss after: 3.46451827227e-07.\n",
      "Epoch:19, weight train batch: 399, step:16, loss before: 0.000101325073047, loss after: 9.79012329481e-05.\n",
      "Epoch:19, weight train batch: 399, step:17, loss before: 4.13507024177e-07, loss after: 4.13507024177e-07.\n",
      "Epoch:19, weight train batch: 399, step:18, loss before: 3.79979439913e-07, loss after: 3.79979439913e-07.\n",
      "Epoch:19, weight train batch: 399, step:19, loss before: 5.21540357568e-07, loss after: 5.21540357568e-07.\n",
      "Epoch:19, weight train batch: 399, step:20, loss before: 2.3096791324e-07, loss after: 2.3096791324e-07.\n",
      "Epoch:19, weight train batch: 399, step:21, loss before: 5.43891928828e-07, loss after: 5.4016663853e-07.\n",
      "Epoch:19, weight train batch: 399, step:22, loss before: 3.76254149614e-07, loss after: 3.76254149614e-07.\n",
      "Epoch:19, weight train batch: 399, step:23, loss before: 2.27242622941e-07, loss after: 2.27242622941e-07.\n",
      "Epoch:19, weight train batch: 399, step:24, loss before: 3.76254149614e-07, loss after: 3.76254149614e-07.\n",
      "Epoch:19, weight train batch: 399, step:25, loss before: 4.61935769636e-07, loss after: 4.61935769636e-07.\n",
      "Epoch:19, weight train batch: 399, step:26, loss before: 3.65078307141e-07, loss after: 3.65078307141e-07.\n",
      "Epoch:19, weight train batch: 399, step:27, loss before: 3.09198981086e-07, loss after: 3.09198981086e-07.\n",
      "Epoch:19, weight train batch: 399, step:28, loss before: 5.06639253217e-07, loss after: 5.06639253217e-07.\n",
      "Epoch:19, weight train batch: 399, step:29, loss before: 4.73111640531e-07, loss after: 4.73111640531e-07.\n",
      "Epoch:19, weight train batch: 399, step:30, loss before: 3.79979439913e-07, loss after: 3.79979439913e-07.\n",
      "Epoch:19, weight train batch: 399, step:31, loss before: 3.57627726544e-07, loss after: 3.57627726544e-07.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "[[[ 0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001]]]\n",
      "Epoch:19, struct parameters train batch: 395, loss before: 7.18045214398e-07, loss after: 4.77768253404e-07.\n"
     ]
    }
   ],
   "source": [
    "inputs_train, targets_train = xor_data(20480, [1, 1, 2])\n",
    "inputs_valid, targets_valid = xor_data(1024, [1, 1, 2])\n",
    "#inputs_train, targets_train, inputs_valid, targets_valid = np.load('test_data.npy')\n",
    "#inputs_train[0:32, ...] = np.array([[[[1.26491106407, 0, 0]]]] * 10 \n",
    "#                                   + [[[[0, 1.26491106407, 0]]]] * 10 \n",
    "#                                   + [[[[0, 0, 1.15470053838]]]] * 12, dtype = np.float32)\n",
    "model.train(inputs_train, targets_train, inputs_valid, targets_valid, num_epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('./log/results.csv', 'a+') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(model.train_losses)\n",
    "    writer.writerow(model.valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected a type in (<class 'tensorflow.python.framework.ops.Operation'>), got: <class 'tensorflow.python.ops.variables.Variable'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0af6a2b36eb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m_graph_replace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_editor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_replace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss_edited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_graph_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/yang.zhang/Documents/virtual_environments/rl_struct/lib/python2.7/site-packages/tensorflow/contrib/graph_editor/transform.pyc\u001b[0m in \u001b[0;36mgraph_replace\u001b[0;34m(target_ts, replacement_ts, dst_scope, src_scope, reuse_dst_scope)\u001b[0m\n\u001b[1;32m    655\u001b[0m   ops = select.get_walks_intersection_ops(list(iterkeys(replacement_ts)),\n\u001b[1;32m    656\u001b[0m                                           \u001b[0mflatten_target_ts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                                           control_ios=control_ios)\n\u001b[0m\u001b[1;32m    658\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Targets and replacements are not connected!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yang.zhang/Documents/virtual_environments/rl_struct/lib/python2.7/site-packages/tensorflow/contrib/graph_editor/select.pyc\u001b[0m in \u001b[0;36mget_walks_intersection_ops\u001b[0;34m(forward_seed_ops, backward_seed_ops, forward_inclusive, backward_inclusive, within_ops, control_inputs, control_outputs, control_ios)\u001b[0m\n\u001b[1;32m    556\u001b[0m       \u001b[0minclusive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforward_inclusive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m       \u001b[0mwithin_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwithin_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m       control_outputs=control_outputs)\n\u001b[0m\u001b[1;32m    559\u001b[0m   backward_ops = get_backward_walk_ops(\n\u001b[1;32m    560\u001b[0m       \u001b[0mbackward_seed_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yang.zhang/Documents/virtual_environments/rl_struct/lib/python2.7/site-packages/tensorflow/contrib/graph_editor/select.pyc\u001b[0m in \u001b[0;36mget_forward_walk_ops\u001b[0;34m(seed_ops, inclusive, within_ops, stop_at_ts, control_outputs)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mseed_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_consuming_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m     \u001b[0mseed_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_list_of_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m   \u001b[0mseed_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yang.zhang/Documents/virtual_environments/rl_struct/lib/python2.7/site-packages/tensorflow/contrib/graph_editor/util.pyc\u001b[0m in \u001b[0;36mmake_list_of_op\u001b[0;34m(ops, check_graph, allow_graph, ignore_ts)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0mcheck_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mignore_ts\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m       \u001b[0mget_unique_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yang.zhang/Documents/virtual_environments/rl_struct/lib/python2.7/site-packages/tensorflow/contrib/graph_editor/util.pyc\u001b[0m in \u001b[0;36mget_unique_graph\u001b[0;34m(tops, check_types, none_if_empty)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       raise TypeError(\"Expected a type in ({}), got: {}\".format(\", \".join([str(\n\u001b[0;32m--> 207\u001b[0;31m           t) for t in check_types]), type(op)))\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected a type in (<class 'tensorflow.python.framework.ops.Operation'>), got: <class 'tensorflow.python.ops.variables.Variable'>"
     ]
    }
   ],
   "source": [
    "_graph_replace = tf.contrib.graph_editor.graph_replace\n",
    "loss_edited = _graph_replace(model.loss, {model.weights[0] : model.weights[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'input/weights:0' shape=(1, 1, 2, 10) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "print(model.weights[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
